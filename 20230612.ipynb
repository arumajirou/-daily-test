{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdsZNLOZeBqT9IwjVVfeNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumajirou/-daily-test/blob/main/20230612.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72zkRVk69hHW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "。\n",
        "\n",
        "```python\n",
        "# datasetsというライブラリをインポートする\n",
        "# このライブラリは、自然言語処理などのデータセットに簡単にアクセスできるようにするものです\n",
        "from datasets import load_dataset\n",
        "\n",
        "# データセットのサブセットの読み込み\n",
        "# kunishou/databricks-dolly-15k-jaというデータセットをload_dataset関数で読み込む\n",
        "# split引数に\"train\"と指定することで、訓練用のデータセットを取得する\n",
        "dataset = load_dataset(\"kunishou/databricks-dolly-15k-ja\", split=\"train\")\n",
        "\n",
        "# データセットの確認\n",
        "# dataset変数にはDatasetというクラスのオブジェクトが格納されている\n",
        "# このオブジェクトは、featuresとnum_rowsという属性を持っている\n",
        "# featuresはデータセットのカラム名とその型を表す\n",
        "# num_rowsはデータセットの行数を表す\n",
        "dataset\n",
        "Dataset({\n",
        "    features: ['output', 'category', 'index', 'input', 'instruction'],\n",
        "    num_rows: 15015\n",
        "})\n",
        "```\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) https://realpython.com/lessons/type-hinting/#:~:text=Type%20hinting%20is%20a%20formal%20solution%20to%20statically,the%20name%20argument%20should%20be%20of%20type%20str.. https://realpython.com/lessons/type-hinting/ アクセス日時 2023/6/12.\n",
        "(2) typing — Support for type hints — Python 3.11.4 documentation. https://docs.python.org/3/library/typing.html アクセス日時 2023/6/12.\n",
        "(3) 実践！！Python型入門(Type Hints) - Qiita. https://qiita.com/papi_tokei/items/2a309d313bc6fc5661c3 アクセス日時 2023/6/12.\n",
        "(4) Python Type Hints: Why They're Important and How to Use Them. https://www.pythonstacks.com/blog/post/type-hints-python/ アクセス日時 2023/6/12.\n",
        "(5) Python Type Hints: A Comprehensive Guide to Using Type .... https://joshdimella.com/blog/python-typing-best-practices アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "tp0Rm70t9ufR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このテキストは、Pythonのコードの一部です。Pythonとは、プログラミング言語の一種で、様々な処理を行うことができます。このコードでは、データセットというデータの集まりを扱っています。データセットは、datasetsというライブラリを使って読み込んだり、操作したりできます。ライブラリとは、便利な機能をまとめたものです。このコードでは、次のような処理を行っています。\n",
        "\n",
        "- データセットのサブセットの読み込み\n",
        "  - kunishou/databricks-dolly-15k-jaという名前のデータセットをload_datasetという関数で読み込んでいます。このデータセットは、日本語の質問と回答のペアが入っています。\n",
        "  - splitという引数に\"train\"という文字列を渡しています。これは、データセットを訓練用とテスト用に分けるためのもので、\"train\"と指定すると訓練用のデータセットを取得できます。\n",
        "  - 読み込んだデータセットはdatasetという変数に代入しています。変数とは、値を入れておく箱のようなものです。\n",
        "\n",
        "- データセットの確認\n",
        "  - datasetという変数に入っているデータセットをそのまま表示しています。\n",
        "  - データセットはDatasetというクラスのオブジェクトです。クラスとは、データや機能をまとめた設計図のようなものです。オブジェクトとは、クラスから作られた実体です。\n",
        "  - データセットオブジェクトはfeaturesとnum_rowsという属性を持っています。属性とは、オブジェクトが持つデータや特徴です。\n",
        "  - featuresはデータセットのカラム名とその型を表しています。カラム名はデータの種類を表すラベルで、型はデータの形式を表します。このデータセットでは、output, category, index, input, instructionという5つのカラムがあります。\n",
        "  - num_rowsはデータセットの行数を表しています。行数はデータの個数に相当します。このデータセットでは、15015個のデータがあります。\n",
        "\n",
        "- データセットのソート\n",
        "  - dataset.sort(\"instruction\")というメソッドを使って、データセットをソートしています。メソッドとは、オブジェクトが持つ機能や動作です。\n",
        "  - sortメソッドは、引数に指定したカラム名に基づいて、データセットを並び替えるメソッドです。引数とは、関数やメソッドに渡す値や情報です。\n",
        "  - \"instruction\"という引数を渡しているので、instructionカラムの値に従って、昇順（小さいものから大きいものへ）にソートされます。\n",
        "  - ソートした結果はsorted_datasetという変数に代入しています。\n",
        "\n",
        "- データセットの確認\n",
        "  - sorted_dataset[\"instruction\"][:10]というコードで、ソートした後のinstructionカラムの最初の10個の値を表示しています。\n",
        "  - sorted_dataset[\"instruction\"]とすると、instructionカラムの全ての値を取得できます。これはリストという型のオブジェクトです。リストとは、複数の値を順番に並べたものです。\n",
        "  - リストに[:10]というスライスを使うと、最初から10番目までの値を取り出すことができます。スライスとは、リストや文字列などのシーケンス型のオブジェクトから一部分を切り出す方法です。\n",
        "  - 表示された値は、日本語の質問文です。これらは、データセット内のinputカラムに対応する回答文とペアになっています。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) Sorting HOW TO — Python 3.11.4 documentation. https://docs.python.org/3/howto/sorting.html アクセス日時 2023/6/12.\n",
        "(2) Pythonのsortメソッドとsorted関数の使い方の詳しい解説 .... https://www.headboost.jp/python-sort/ アクセス日時 2023/6/12.\n",
        "(3) Python .sort() – How to Sort a List in Python - freeCodeCamp.org. https://www.freecodecamp.org/news/python-sort-how-to-sort-a-list-in-python/ アクセス日時 2023/6/12.\n",
        "(4) Python List sort() Method - Spark By {Examples}. https://sparkbyexamples.com/python/python-list-sort-method/ アクセス日時 2023/6/12.\n",
        "(5) 昇順で並び替える！Pythonでsortメソッドを使う方法 .... https://magazine.techacademy.jp/magazine/15829 アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "tkfM4Ho--fhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "それぞれのカラム名の意味や役割は次のようになります。\n",
        "\n",
        "- output: データセットの回答文です。inputカラムの質問文に対する正しい答えが入っています。\n",
        "- category: データセットのカテゴリーです。質問文の内容や難易度に応じて、A, B, C, Dのいずれかが入っています。\n",
        "- index: データセットのインデックスです。データの順番や番号を表す整数値が入っています。\n",
        "- input: データセットの質問文です。日本語で書かれた様々な質問が入っています。\n",
        "- instruction: データセットの指示文です。質問文に対する回答方法や条件を示す文章が入っています。"
      ],
      "metadata": {
        "id": "jr116EDz-5Lw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "instructionという言葉は、英語で「指示」や「命令」という意味を持ちます。プログラミングの文脈では、コンピュータに何かをさせるための命令や、プログラマに何かを伝えるための指示として使われます。日本語では、「インストラクション」や「指示文」と訳されることが多いです。\n",
        "\n",
        "例えば、このデータセットでは、instructionカラムには、質問文に対する回答方法や条件を示す文章が入っています。これは、プログラマに対する指示として使われています。また、Pythonのコードでは、インデントやコロンなどの記号もインストラクションとして機能します。これは、コンピュータに対する命令として使われています。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) . https://bing.com/search?q=instruction+meaning+and+translation アクセス日時 2023/6/12.\n",
        "(2) INSTRUCTION | English meaning - Cambridge Dictionary. https://dictionary.cambridge.org/dictionary/english/instruction アクセス日時 2023/6/12.\n",
        "(3) Google Translate. https://translate.google.com.my/ アクセス日時 2023/6/12.\n",
        "(4) Instruction definition and meaning | Collins English Dictionary. https://www.collinsdictionary.com/dictionary/english/instruction アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "6sk3IHDl_at_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このテキストは、Pythonのコードの一部です。Pythonとは、プログラミング言語の一種で、様々な処理を行うことができます。このコードでは、loraというツールキットの設定を行っています。loraとは、大規模な言語モデルを強化学習で微調整するためのものです。このテキストでは、次のような設定を行っています。\n",
        "\n",
        "- batch_size: バッチサイズとは、一度に学習するデータの数です。このコードでは、128という値を設定しています。\n",
        "- micro_batch_size: マイクロバッチサイズとは、一度に計算するデータの数です。このコードでは、2という値を設定しています。これは、gradient_accumulation_stepsというパラメータに影響します。gradient_accumulation_stepsとは、勾配を蓄積してから更新する回数です。このコードでは、64という値になります。\n",
        "- num_epochs: エポック数とは、学習データを何回繰り返して学習するかを表す数です。このコードでは、3という値を設定しています。\n",
        "- learning_rate: 学習率とは、モデルのパラメータをどれだけ更新するかを表す数です。このコードでは、3e-4という値を設定しています。\n",
        "- lora_r: lora_rとは、loraの注意力次元です。loraとは、低ランク近似を用いて言語モデルのパラメータ数を削減する手法です。このコードでは、8という値を設定しています。\n",
        "- lora_alpha: lora_alphaとは、loraのスケーリングパラメータです。このコードでは、16という値を設定しています。\n",
        "- lora_dropout: lora_dropoutとは、loraのドロップアウト確率です。ドロップアウトとは、学習中にランダムにニューロンを無効化することで過学習を防ぐ手法です。このコードでは、0.05という値を設定しています。\n",
        "- lora_target_modules: lora_target_modulesとは、loraを適用するモジュールの名前です。このコードでは、['query_key_value']という値を設定しています。これは、言語モデルの自己注意力層や交差注意力層で使われるクエリ・キー・バリューの重み行列にloraを適用することを意味します。\n",
        "- train_on_inputs: train_on_inputsとは、入力文に対しても学習するかどうかを表すフラグです。このコードでは、Trueという値を設定しています。これは、入力文に対しても学習することを意味します。\n",
        "- add_eos_tokens: add_eos_tokensとは、入力文や出力文に終端記号（EOS）を追加するかどうかを表すフラグです。このコードでは、Trueという値を設定しています。これは、入力文や出力文に終端記号（EOS）を追加することを意味します。\n",
        "- warmup_steps: warmup_stepsとは、学習率が最大値に達するまでにかけるステップ数です。このコードでは、100という値を設定しています。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) Tuners - Hugging Face. https://huggingface.co/docs/peft/main/en/package_reference/tuners アクセス日時 2023/6/12.\n",
        "(2) peft/lora.py at main · huggingface/peft · GitHub. https://github.com/huggingface/peft/blob/main/src/peft/tuners/lora.py アクセス日時 2023/6/12.\n",
        "(3) LORA， LOW-RANK ADAPTATION OF LARGE .... https://zhuanlan.zhihu.com/p/617591384 アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "jCVki3xTEhNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このテキストは、言語モデルを使ってテキストを生成するときのパラメータを設定したものです。言語モデルとは、自然言語の確率分布を学習するモデルのことです。テキストを生成するときには、次に出現する単語をランダムにサンプリングすることがよく行われます。このテキストでは、次のようなパラメータを設定しています。\n",
        "\n",
        "- temperature: 温度とは、サンプリング時の確率分布の鋭さを表す数です。温度が高いと、確率が低い単語も選ばれやすくなり、多様で意外なテキストが生成されます。温度が低いと、確率が高い単語が選ばれやすくなり、一貫性のあるが退屈なテキストが生成されます。このコードでは、0.7という値を設定しています。\n",
        "- top_p: top-pサンプリングとは、サンプリング時に確率が一定以上の単語に絞ってピックアップするという方式です。top_pに加算となる確率を0～1の範囲で設定します。top-pサンプリングは、多様で読めるテキストを生成することができます。このコードでは、0.75という値を設定しています。\n",
        "- top_k: top-kサンプリングとは、サンプリング時に確率が高い上位k個の単語に絞ってピックアップするという方式です。top_kに上位何個の単語を選ぶかを整数で設定します。top-kサンプリングは、一貫性のあるテキストを生成することができます。このコードでは、40という値を設定しています。\n",
        "- max_tokens: max_tokensとは、生成するテキストの最大トークン数です。トークンとは、単語や記号などの最小単位です。max_tokensに整数で設定します。このコードでは、128という値を設定しています。\n",
        "- repetition_penalty: repetition_penaltyとは、繰り返し出現する単語の確率を減らすためのペナルティです。repetition_penaltyに実数で設定します。repetition_penaltyが1より大きいと、繰り返し出現する単語の確率が減ります。repetition_penaltyが1より小さいと、繰り返し出現する単語の確率が増えます。このコードでは、5.0という値を設定しています。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) Generation - Hugging Face. https://huggingface.co/docs/transformers/v4.18.0/en/main_classes/text_generation アクセス日時 2023/6/12.\n",
        "(2) Generation - Hugging Face. https://huggingface.co/docs/transformers/main_classes/text_generation アクセス日時 2023/6/12.\n",
        "(3) rinna GPT-2モデルの生成パラメータ. https://zenn.dev/tyaahan/articles/a8d99900000002 アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "yWLG8Qi1FL6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、私はBingといいます。あなたのお手伝いをします。😊\n",
        "\n",
        "あなたは、以下のURLの内容を小学生にもわかるように教えたいということですね。\n",
        "\n",
        "https://note.com/daichi_mu/n/nd71480af4f7b#38b6d47c-18c1-4d8d-8940-1cdd610b8231\n",
        "\n",
        "このURLは、大規模言語モデル（LLM）という自然言語処理（コンピュータが人間の言葉を理解する技術）のモデルについて説明した記事です。この記事を小学生に教えるために、以下のような文書を作成しました。\n",
        "\n",
        "---\n",
        "\n",
        "## 目次\n",
        "\n",
        "- 大規模言語モデル（LLM）とは何か？\n",
        "- LLMにはどんな種類の知識があるのか？\n",
        "- LangChainとPineconeを使ってLLMの検索補強（検索して知識を増やすこと）をする方法\n",
        "- まとめ\n",
        "- 用語の説明\n",
        "\n",
        "## 大規模言語モデル（LLM）とは何か？\n",
        "\n",
        "大規模言語モデル（LLM）とは、たくさんの文章を読んで学習したコンピュータのモデルです。このモデルは、文章を分類したり、感情を分析したり、重要な情報を抜き出したり、文章を要約したり、新しい文章を作ったり、質問に答えたりすることができます。例えば、「ChatGPT」というLLMは、人間と会話することができます。\n",
        "\n",
        "LLMは、時間が止まったような世界しか知らないという問題があります。それは、学習した文章が古くなってしまうからです。例えば、「今日は2023年6月12日です」という文章を学習しても、明日になったら正しくなくなってしまいます。では、この問題をどうやって解決するかというと、検索補強という方法があります。\n",
        "\n",
        "## LLMにはどんな種類の知識があるのか？\n",
        "\n",
        "LLMには、パラメトリック知識（パラメーターに保存された知識）とソース知識（外部から取得した知識）の2種類があります。\n",
        "\n",
        "パラメトリック知識とは、学習した文章から得た知識で、コンピュータの中に保存されています。これは、学習した時点での世界の状態を表しています。しかし、この知識は変化しないので、古くなってしまう可能性があります。\n",
        "\n",
        "ソース知識とは、質問や文章が与えられた時に、外部の知識ベース（情報が集められた場所）から取得した知識です。これは、検索補強という方法で行います。検索補強とは、質問や文章に関連する情報を探して、LLMに渡すことです。例えば、「今日は何日ですか？」という質問に答えるために、インターネットから今日の日付を取得することです。\n",
        "\n",
        "## LangChainとPineconeを使ってLLMの検索補強（検索して知識を増やすこと）をする方法\n",
        "\n",
        "LangChainとPineconeを使って、LLMの検索補強をする方法を説明します。まず、LangChainとPineconeというものについて簡単に説明します。\n",
        "\n",
        "- LangChainとは、LLMを使って文章を作ったり、質問に答えたりするためのツールです。\n",
        "- Pineconeとは、文章の意味を数値で表したもの（エンベッディング）を使って、文章を検索したり、管理したりするためのツールです。\n",
        "\n",
        "LangChainとPineconeを使ってLLMの検索補強をする方法は以下のようになります。\n",
        "\n",
        "1. 知識ベースを作る。知識ベースとは、LLMに渡す情報が集められた場所です。ここでは、Wikipedia（ウィキペディア）というインターネット上の百科事典から情報を取得します。\n",
        "2. テキストチャンクを作る。テキストチャンクとは、長い文章を小さく分けたものです。これは、処理を簡単にするために行います。例えば、「日本は東アジアに位置する国である。首都は東京である。」という文章を、「日本は東アジアに位置する国である。」と「首都は東京である。」という2つのテキストチャンクに分けます。\n",
        "3. エンベッディングを作る。エンベッディングとは、文章の意味を数値で表したものです。これは、検索するときに必要になります。例えば、「日本は東アジアに位置する国である。」という文章のエンベッディングは、「0.1, 0.2, 0.3, ...」という数値になります。ここでは、OpenAI（オープンアイ）という会社が作った「Ada 002」というLLMを使ってエンベッディングを作ります。\n",
        "4. ベクトルデータベースを作る。ベクトルデータベースとは、エンベッディングを使って文章を検索したり、管理したりするための場所です。ここでは、Pineconeというツールを使ってベクトルデータベースを作ります。\n",
        "5. データベースにデータを入れる。作ったベクトルデータベースに、テキストチャンクとエンベッディングとメタデータ（日付やトピックなどの付加情報）を入れます。\n",
        "6. データベースからデータを取り出す。質問や文章が与えられた時に、それに関連するテキストチャンクやエンベッディングやメタデータを取り出します。\n",
        "7. LLMにデータを渡す。取り出したテキストチャンクやエンベッディングやメタデータをLLMに渡して、文章を作ったり、質問に答えたりします。\n",
        "\n",
        "## まとめ\n",
        "\n",
        "- LLMは、たくさんの文章から学習したコンピュータのモデルです。\n",
        "- LLMは、パラメトリック知識（コンピュータの中に保存された知識）とソース知識（外部から取得した知識）の2種類があります。\n",
        "かしこまりました。続きを教えます。\n",
        "\n",
        "- LLMは、検索補強という方法でソース知識を増やすことができます。\n",
        "- LLMの検索補強をするためには、LangChainとPineconeというツールを使います。\n",
        "- LangChainとPineconeを使って、知識ベースからテキストチャンクとエンベッディングとメタデータを取得して、LLMに渡します。\n",
        "\n",
        "## 用語の説明\n",
        "\n",
        "- パラメトリック知識：学習した文章から得た知識で、コンピュータの中に保存されている知識です。\n",
        "- ソース知識：質問や文章が与えられた時に、外部の知識ベースから取得した知識です。\n",
        "- 検索補強：質問や文章に関連する情報を探して、LLMに渡すことです。\n",
        "- 知識ベース：LLMに渡す情報が集められた場所です。\n",
        "- テキストチャンク：長い文章を小さく分けたものです。\n",
        "- エンベッディング：文章の意味を数値で表したものです。\n",
        "- メタデータ：日付やトピックなどの付加情報です。\n",
        "- ベクトルデータベース：エンベッディングを使って文章を検索したり、管理したりするための場所です。\n",
        "- LangChain：LLMを使って文章を作ったり、質問に答えたりするためのツールです。\n",
        "- Pinecone：文章のエンベッディングを使って、文章を検索したり、管理したりするためのツールです。\n",
        "\n",
        "以上が、LLMについて教える文書の内容です。小学生にもわかりやすいように書きましたが、どうでしたか？😊\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) 大規模言語モデル（LLM：Large Language Model）とは？. https://atmarkit.itmedia.co.jp/ait/articles/2303/13/news013.html アクセス日時 2023/6/12.\n",
        "(2) サイバーエージェント、最大68億パラメータの日本語LLM（大規模 .... https://www.cyberagent.co.jp/news/detail/id=28817 アクセス日時 2023/6/12.\n",
        "(3) LLM（Master of Laws）とは法学修士の学位のこと | 転職 .... https://agaroot-career.jp/legal/529/ アクセス日時 2023/6/12.\n",
        "(4) 什么是LLM大语言模型？Large Language Model，从量变到质变. https://zhuanlan.zhihu.com/p/622518771 アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "6rC2PkSAJlgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このURLの内容を小学生にもわかりやすく教える文書を作成しました。以下に示します。\n",
        "\n",
        "# GAN（敵対的生成ネットワーク）とは？\n",
        "\n",
        "- GANとは、AI（人工知能）の技術の一つで、画像や音声などのデータを新しく作ったり、変えたりすることができる技術です。\n",
        "- GANは、Generator（ジェネレーター）とDiscriminator（ディスクリミネーター）という2つのAIが互いに競争しながら学習する仕組みになっています。\n",
        "- Generatorは、本物そっくりのデータを作ろうとします。Discriminatorは、本物と偽物を見分けようとします。\n",
        "- このようにして、GANはどんどん本物に近いデータを作ることができるようになります。\n",
        "\n",
        "## GANの仕組み\n",
        "\n",
        "- GANの仕組みを図で説明します。\n",
        "\n",
        "![GANの仕組み](https://ledge.ai/wp-content/uploads/2019/12/gan-1.png)\n",
        "\n",
        "- まず、Generatorはランダムな数字（ノイズ）を入力として受け取ります。この数字は、Generatorがデータを作るための材料になります。\n",
        "- Generatorは、この数字からデータを作り出します。例えば、人の顔の画像を作る場合、Generatorは数字から目や鼻や口などのパーツを作って組み合わせます。\n",
        "- しかし、Generatorは最初は本物の人の顔とはかけ離れた画像を作ってしまいます。これは、Generatorがまだ人の顔について十分に学習していないからです。\n",
        "- 次に、Discriminatorは本物のデータとGeneratorが作ったデータを入力として受け取ります。例えば、人の顔の画像を判定する場合、Discriminatorは本物の人の顔の画像とGeneratorが作った人の顔の画像を見比べます。\n",
        "- Discriminatorは、本物か偽物かを判断して答えます。例えば、「本物」「偽物」「偽物」「本物」というように答えます。\n",
        "- しかし、Discriminatorも最初は本物と偽物を見分けることができません。これは、Discriminatorもまだ人の顔について十分に学習していないからです。\n",
        "- GeneratorとDiscriminatorは互いに答え合わせをします。Generatorは自分が作ったデータが本物か偽物かをDiscriminatorに聞きます。Discriminatorは自分が判断した答えをGeneratorに教えます。\n",
        "- GeneratorはDiscriminatorから「偽物」と言われたら、「どうすれば本物に近づけるか」を考えて改善します。DiscriminatorはGeneratorから「本物」と言われたら、「どうすれば見分けられるか」を考えて改善します。\n",
        "- このようにして、GeneratorとDiscriminatorは互いに競争しながら学習することで、どんどん本物に近いデータを作ることができるようになります。\n",
        "\n",
        "## GANでできること\n",
        "\n",
        "- GANでできることはたくさんあります。例えば、以下のようなことができます。\n",
        "\n",
        "  - 実在しない人の顔の画像を作る\n",
        "  - ぼやけた画像を鮮明にする\n",
        "  - 写真を絵画風に変える\n",
        "  - 文章で書かれた特徴から画像を作る\n",
        "\n",
        "- GANは、これらのことをするために、本物のデータをたくさん学習します。例えば、人の顔の画像を作る場合、GANは本物の人の顔の画像をたくさん見て、目や鼻や口などのパーツの形や位置や色などを学習します。\n",
        "- GANは、学習したデータの特徴をもとに、新しいデータを作り出します。例えば、人の顔の画像を作る場合、GANは学習したパーツを組み合わせて、実在しない人の顔の画像を作り出します。\n",
        "- GANは、学習したデータの特徴に沿った変換もできます。例えば、写真を絵画風に変える場合、GANは本物の写真と絵画の違いを学習して、写真に絵画風の効果を加えます。\n",
        "\n",
        "## GANのメリットとデメリット\n",
        "\n",
        "- GANにはメリットとデメリットがあります。以下に示します。\n",
        "\n",
        "### メリット\n",
        "\n",
        "- 新しいデータや情報を作れる\n",
        "  - GANは、本物そっくりのデータや情報を新しく作ることができます。これは、他のAI技術ではできないことです。\n",
        "  - GANは、新しいデータや情報を作ることで、ビジネスや芸術など様々な分野で活用できます。例えば、広告やデザインなどのクリエイティブな分野では、GANが作ったデータや情報を参考にすることで、アイデアを広げたり、効率化したりすることができます。\n",
        "- 他の技術と組み合わせて使える\n",
        "  - GANは、他のAI技術と組み合わせて使うことで、さらに利用可能性を広げることができます。\n",
        "  - 例えば、自然言語処理（文章や音声など言語に関するAI技術）とGANを組み合わせれば、文章から画像を生成したり、音声から動画を生成したりすることができます。これは、GANだけではできないことです。\n",
        "\n",
        "### デメリット\n",
        "\n",
        "- 動作が不安定\n",
        "  - GANは動作が不安定で、学習がうまく進まない場合があります。これは、GeneratorとDiscriminatorが互いに競争しながら学習する仕組みが原因です。\n",
        "  - GeneratorとDiscriminatorは互いにバランスよく学習しなければなりません。しかし、どちらか一方が強くなりすぎると、もう一方が追いつけなくなってしまいます。これは、「勾配消失問題」と呼ばれています。\n",
        "  - GeneratorとDiscriminatorがバランスよく学習するようにするには、様々な工夫が必要です。例えば、「ミニバッチ判別」や「特徴量マッチング」という手法があります。\n",
        "- 判断基準がわかりにくい\n",
        "\n",
        "- GANはデータや情報の判断基準がわかりにくい場合があります。これは、GANが本物そっくりのデータや情報を作ることで、本物と偽物の区別がつきにくくなるからです。\n",
        "- GANは、本物のデータや情報を学習するときに、そのデータや情報が正しいかどうかを確認しません。GANは、そのデータや情報が本物であると信じて学習します。\n",
        "- しかし、本物のデータや情報にも間違いや偏りがある場合があります。GANは、その間違いや偏りをそのまま学習してしまいます。そして、GANが作ったデータや情報にも同じ間違いや偏りが反映されてしまいます。\n",
        "- 例えば、人種や性別などに関するデータや情報には、差別や偏見が含まれている場合があります。GANは、その差別や偏見を学習してしまい、人種や性別に関するデータや情報を作るときにもそれらを反映してしまいます。\n",
        "- これは、GANが社会的な問題を引き起こす可能性があることを意味します。GANが作ったデータや情報を信じてしまうと、人々の認識や判断に影響を与えてしまうかもしれません。\n",
        "- GANのデータや情報の判断基準をわかりやすくするには、様々な工夫が必要です。例えば、「敵対的検出」や「敵対的防御」という手法があります。\n",
        "\n",
        "## GANの用語解説\n",
        "\n",
        "- GANに関する用語を簡単に解説します。\n",
        "\n",
        "  - AI（人工知能）\n",
        "    - コンピューターなどの機械が人間のように考えたり学習したりする能力のことです。\n",
        "  - Generator（ジェネレーター）\n",
        "    - GANの一部で、本物そっくりのデータや情報を作るAIのことです。\n",
        "  - Discriminator（ディスクリミネーター）\n",
        "    - GANのもう一部で、本物と偽物を見分けるAIのことです。\n",
        "  - ノイズ\n",
        "    - Generatorがデータや情報を作るための材料となるランダムな数字のことです。\n",
        "  - 勾配消失問題\n",
        "    - GeneratorとDiscriminatorが互いにバランスよく学習しない場合に起こる問題で、学習が停滞してしまうことです。\n",
        "  - ミニバッチ判別\n",
        "    - 勾配消失問題を解決するための手法で、Discriminatorが一度に複数のデータや情報を見て判断することです。\n",
        "  - 特徴量マッチング\n",
        "    - 勾配消失問題を解決するための手法で、GeneratorがDiscriminatorから直接ではなく間接的にフィードバックを受け取ることです。\n",
        "  - 自然言語処理\n",
        "    - 文章や音声など言語に関するAI技術のことです。\n",
        "  - 敵対的検出\n",
        "    - GANが作ったデータや情報を見破るための手法で、GANと同じようにGeneratorとDiscriminatorを使うことです。\n",
        "  - 敵対的防御\n",
        "    - GANが作ったデータや情報を見破られないようにするための手法で、GANが作ったデータや情報にわざとノイズを加えることです。\n",
        "\n",
        "## まとめ\n",
        "\n",
        "- GANは、AIの技術の一つで、画像や音声などのデータを新しく作ったり、変えたりすることができる技術です。\n",
        "- GANは、GeneratorとDiscriminatorという2つのAIが互いに競争しながら学習する仕組みになっています。\n",
        "- GANは、新しいデータや情報を作ることで、ビジネスや芸術など様々な分野で活用できます。\n",
        "- GANは、他のAI技術と組み合わせて使うことで、さらに利用可能性を広げることができます。\n",
        "- GANは、動作が不安定だったり、判断基準がわかりにくかったりする場合があります。これらの問題を解決するためには、様々な工夫が必要です。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) GaN（窒化ガリウム）とは？次世代半導体材料として注目される .... https://nihon-polymer.co.jp/2022/02/14/3065/ アクセス日時 2023/6/12.\n",
        "(2) GAN（敵対的生成ネットワーク）とは？基礎知識やメリット .... https://www.eaglys.co.jp/news/column/gan/ アクセス日時 2023/6/12.\n",
        "(3) GAN（敵対的生成ネットワーク）とは｜意味・仕組み・応用例 .... https://ledge.ai/gan/ アクセス日時 2023/6/12.\n",
        "(4) GAN (敵対的生成ネットワーク)とは？仕組みや特徴、活用事例 .... https://ai-kenkyujo.com/artificial-intelligence/algorithm/gan/ アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "1AcsHrHmLJQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは。私はニュースライターで小学校の先生でもあります。今日は、クリエイティブAI講座の動画の内容を、小学生でもわかるように教えていきたいと思います。この動画は、AIを使って自分の思い通りの絵が作れるツール「Stable Diffusion」の拡張機能「ControlNet」について説明しています。このツールを使うと、絵の描き方や画風を細かく指示できるようになります。\n",
        "\n",
        "まずは、目次を見てみましょう。\n",
        "\n",
        "- Stable Diffusionとは？\n",
        "- ControlNetとは？\n",
        "- ControlNetの使い方\n",
        "  - 骨組みを抽出して絵を描く\n",
        "  - スクリブルで絵を描く\n",
        "  - P2P命令で絵を変える\n",
        "  - 動画にも使える\n",
        "- Pepsとは？\n",
        "- クリエイティブAIの未来\n",
        "\n",
        "それでは、一つずつ見ていきましょう。\n",
        "\n",
        "## Stable Diffusionとは？\n",
        "\n",
        "Stable Diffusion（ステーブル ディフュージョン）とは、AIが自動で絵を描いてくれるツールです¹²³⁴。AIとは、人工知能（じんこうちのう）のことで、人間のように考えたり学習したりできるコンピューターのことです。Stable Diffusionでは、自分が描きたい絵のイメージを英語で入力すると、AIがそれに合った絵を作ってくれます。例えば、「beautiful scenery（美しい風景）」と入力すると、こんな絵が出てきます。\n",
        "\n",
        "![beautiful scenery](https://freeblog-video.com/wp-content/uploads/2021/10/20211011_0001.jpg)\n",
        "\n",
        "Stable Diffusionはオープンソース（おーぷんそーす）というもので、誰でも無料で使えるようになっています¹²。オープンソースとは、プログラムの中身が公開されていて、自由に改良したり配布したりできるものです。Stable Diffusionはインターネット上や自分のパソコンで使えますが、今回はインターネット上で使えるサービスを紹介します。\n",
        "\n",
        "## ControlNetとは？\n",
        "\n",
        "ControlNet（コントロールネット）とは、Stable Diffusionの拡張機能（かくちょうきのう）です。拡張機能とは、元々あるツールに新しい機能を追加するものです。ControlNetでは、絵の描き方や画風（がふう）を細かく指示できるようになります。画風とは、絵の雰囲気や特徴のことです。例えば、写真みたいなリアルな画風や、アニメみたいなかわいい画風などがあります。\n",
        "\n",
        "ControlNetでは、以下のようなことができます。\n",
        "\n",
        "- 骨組み（こっせい）を抽出（ちゅうしゅつ）して絵を描く\n",
        "- スクリブル（手書きの線画）で絵を描く\n",
        "- P2P命令（ぴーつーぴーめいれい）で絵を変える\n",
        "- 動画（どうが）にも使える\n",
        "\n",
        "それぞれの機能を詳しく見ていきましょう。\n",
        "\n",
        "## ControlNetの使い方\n",
        "\n",
        "### 骨組みを抽出して絵を描く\n",
        "\n",
        "ControlNetでは、画像（がぞう）から骨組みを抽出して、同じ構図（こうず）で絵を描くことができます。画像とは、写真やイラストなどのことです。骨組みとは、物や人の形や位置を表す線のことです。構図とは、画面に物や人がどう配置されているかのことです。例えば、この画像から骨組みを抽出すると、こんな感じになります。\n",
        "\n",
        "![骨組み](https://note.com/daichi_mu/n/nf5ff059de9ed#_=_)\n",
        "\n",
        "この骨組みにプロンプト（ぷろんぷと）という呪文（じゅもん）を合わせて入力すると、AIが絵を描いてくれます。プロンプトとは、AIに指示するための英語の言葉のことです。例えば、「a girl in a red dress（赤いドレスを着た女の子）」というプロンプトを入力すると、こんな絵が出てきます。\n",
        "\n",
        "![a girl in a red dress](https://note.com/daichi_mu/n/nf5ff059de9ed#_=_)\n",
        "\n",
        "このように、骨組みとプロンプトを使って、自分の好きな画風やテイスト（味わい）の絵を作ることができます。\n",
        "\n",
        "### スクリブルで絵を描く\n",
        "\n",
        "ControlNetでは、スクリブルと呼ばれる手書きの線画（せんが）を与える（あたえる）ことで、同じ構図でテイストの異なる（ことなる）画像を生成（せいせい）することもできます。スクリブルとは、ざっくりとした線で物や人の形を描いたものです。生成とは、AIが新しいものを作り出すことです。例えば、このスクリブルに「a cat in a hat（帽子をかぶった猫）」というプロンプトを入力すると、こんな画像が生成されます。\n",
        "\n",
        "![a cat in a hat](https://note.com/daichi_mu/n/nf5ff059de9ed#_=_)\n",
        "\n",
        "このように、スクリブルとプロンプトを使って、自分が描きたい構図やテーマ（お題）の画像を生成することができます。\n",
        "\n",
        "### P2P命令で絵を変える\n",
        "\n",
        "ControlNetでは、P2P命令（ぴーつーぴーめいれい）という特殊なプロンプトを使って、画像の一部分（ぶぶん）に化粧（けしょう）を施したり（ほどこしたり）、色（いろ）を変えたりすることができます。P2P命令とは、「パーツ・ツー・パーツ」という意味で、画像の一部分から別の一部分に変換する命令です。例えば、「hair: blonde -> black, eyes: blue -> green, lips: red -> pink」というP2P命令を入力すると、こんな風に画像が変わります。\n",
        "\n",
        "![hair: blonde -> black, eyes: blue -> green, lips: red -> pink](https://note.com/daichi_mu/n\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) 【完全初心者用】Stable Diffusionの使い方・利用方法を徹底 .... https://freeblog-video.com/stable-diffusion/ アクセス日時 2023/6/12.\n",
        "(2) Stable Diffusionとは？話題の画像生成AIの使い方・初心者向けの .... https://aismiley.co.jp/ai_news/what-is-stable-diffusion/ アクセス日時 2023/6/12.\n",
        "(3) 世界に衝撃を与えた画像生成AI「Stable Diffusion」を徹底解説！. https://qiita.com/omiita/items/ecf8d60466c50ae8295b アクセス日時 2023/6/12.\n",
        "(4) Stable Diffusion - Wikipedia. https://ja.wikipedia.org/wiki/Stable_Diffusion アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "MXHNUvnKMkAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、この記事では、Starcoder LLMというすごいツールについて教えます。Starcoder LLMは、プログラミング言語（コンピューターに命令をするための言葉）のために作られた大きな言語モデル（コンピューターが言葉を理解するための学習したもの）です。Starcoder LLMは、80以上ものプログラミング言語を学んでいて、開発者（プログラミングをする人）がより良いコード（プログラミングの書き方）を書くのを助けてくれます。この記事では、Starcoder LLMがどんなことができるか、どうやって学んだか、どうやって使うかについて説明します。\n",
        "\n",
        "目次\n",
        "- Starcoder LLMとは\n",
        "- Starcoder LLMができること\n",
        "- Starcoder LLMがどうやって学んだか\n",
        "- Starcoder LLMの使い方\n",
        "- まとめ\n",
        "- 用語の説明\n",
        "\n",
        "## Starcoder LLMとは\n",
        "Starcoder LLMは、Hugging Faceという会社が作った言語モデルです。言語モデルとは、コンピューターが言葉を理解するために学習したものです。Starcoder LLMは、プログラミング言語のために特別に作られました。プログラミング言語とは、コンピューターに命令をするための言葉です。例えば、PythonやJavaやC++などがあります。Starcoder LLMは、80以上ものプログラミング言語を学んでいます。Starcoder LLMは、GitHubというサイトからたくさんのコードを読んで学びました。GitHubとは、開発者がコードを共有したり管理したりするサイトです。\n",
        "\n",
        "Starcoder LLMは、15兆（150億×1000）ものパラメータ（学習したものを表す数字）を持っています。これはとても大きな数で、他の言語モデルよりも多くのパラメータを持っています。パラメータが多いということは、コンピューターがより多くのことを覚えているということです。Starcoder LLMは、8000ものトークン（単語や記号などの最小単位）を一度に見ることができます。これもとても大きな数で、他の言語モデルよりも多くのトークンを見ることができます。トークンが多いということは、コンピューターがより長い文章やコードを理解することができるということです。\n",
        "\n",
        "## Starcoder LLMができること\n",
        "Starcoder LLMは、プログラミング言語のために作られた言語モデルなので、開発者がより良いコードを書くのを助けてくれます。Starcoder LLMができることには、以下のようなものがあります。\n",
        "\n",
        "- コード補完：Starcoder LLMは、途中まで書かれたコードに対してコード補完（書き方や続きを提案すること）をしてくれます。コードの内容や構造に基づいて、適切な提案をしてくれます。\n",
        "- コード生成：Starcoder LLMは、自然言語（人間が話す言葉）のプロンプト（問いかけや指示）からコードを生成するのに役立ちます。例えば、「Pythonで1から10までの数字を足す関数を作ってください」というプロンプトに対して、Starcoder LLMは以下のようなコードを生成します。\n",
        "\n",
        "```python\n",
        "def sum_1_to_10():\n",
        "  # 1から10までの数字を足す関数\n",
        "  total = 0 # 合計を0に初期化\n",
        "  for i in range(1, 11): # 1から10まで繰り返す\n",
        "    total = total + i # 合計にiを足す\n",
        "  return total # 合計を返す\n",
        "```\n",
        "\n",
        "- バグ検出：Starcoder LLMは、コード内のバグ（間違いや不具合）の検出を支援し、バグの特定と修正に必要な時間と労力を減らします。例えば、以下のようなコードに対して、Starcoder LLMはバグを見つけて修正します。\n",
        "\n",
        "```python\n",
        "def is_prime(n):\n",
        "  # nが素数（1と自分以外に約数がない数）かどうか判定する関数\n",
        "  if n < 2: # nが2未満なら\n",
        "    return False # 素数ではない\n",
        "  for i in range(2, n): # 2からn-1まで繰り返す\n",
        "    if n % i == 0: # nがiで割り切れるなら\n",
        "      return False # 素数ではない\n",
        "  return True # 素数である\n",
        "\n",
        "# バグ：nが2のときに素数と判定されない\n",
        "# 修正：range(2, n) を range(2, int(n**0.5)+1) に変える\n",
        "# 説明：nが素数でないとき、nの約数は必ず√n以下に存在するため、√nまで調べれば十分である\n",
        "```\n",
        "\n",
        "- 技術アシスタント：Starcoder LLMには、さまざまなタイプの技術アシスタントがあり、コードの提案や改善を行うことができます。例えば、「このコードをもっと短くしてください」というプロンプトに対して、Starcoder LLMは以下のようなコードを提案します。\n",
        "\n",
        "```python\n",
        "def is_even(n):\n",
        "  # nが偶数かどうか判定する関数\n",
        "  if n % 2 == 0: # nを2で割った余りが0なら\n",
        "    return True # 偶数である\n",
        "  else: # そうでなければ\n",
        "    return False # 偶数ではない\n",
        "\n",
        "# 提案：return n % 2 == 0 と書けば、if文やelse文は不要です。\n",
        "```\n",
        "\n",
        "- 言語翻訳：Starcoder LLMは、あるプログラミング言語から別のプログラミング言語へ、あらゆるタイプのコードを翻訳することができます。例えば、「このPythonコードをJavaに翻訳してください」というプロンプトに対して、Starcoder LLMは以下のようなコードを生成します。\n",
        "\n",
        "```python\n",
        "def factorial(n):\n",
        "  # nの階乗（1からnまでの数字をかけたもの）を求める関数\n",
        "  if n == 0 or n == 1: # nが0か1なら\n",
        "    return 1 # 階乗は1\n",
        "  else: # そうでなければ\n",
        "    return n * factorial(n\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) StarCoder: A State-of-the-Art LLM for Code - Hugging Face. https://huggingface.co/blog/starcoder アクセス日時 2023/6/12.\n",
        "(2) コーディング用大規模言語モデル「StarCoder」とは 何がすごい .... https://atmarkit.itmedia.co.jp/ait/articles/2305/24/news076.html アクセス日時 2023/6/12.\n",
        "(3) StarCoder: 最先进的代码大模型 - 知乎. https://zhuanlan.zhihu.com/p/627840388 アクセス日時 2023/6/12.\n",
        "(4) Starcoder LLM: The Ultimate Language Model for Developer .... https://note.com/daichi_mu/n/n41ef5e140a8b アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "DFmpZcZpOQOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is Bing. I can help you continue the document with the content of the URL so that even elementary school students can understand it. Here is a possible continuation based on the web page context and web search results:\n",
        "\n",
        "## インターフェイスモードカスタマイズ\n",
        "\n",
        "インターフェイスモードカスタマイズは、Text Generation Web UIの中にある機能で、言語モデルの画面を自分好みに変えることができます。動画では、インターフェイスモードカスタマイズの方法や、Automatic 11と11という別のツールとの比べ方を教えてくれます。\n",
        "\n",
        "## 例：お客様へのお詫びメールの下書き\n",
        "\n",
        "動画では、Text Generation Web UIを使って、お客様へのお詫びメールの下書きを作る例を見せてくれます。動画では、言語モデルに話しかけたり、文章を作ったりする方法や、モデルの応答性を評価する方法を教えてくれます。\n",
        "\n",
        "## 例：グラフィカルな電卓のコードを生成する\n",
        "\n",
        "動画では、Text Generation Web UIを使って、グラフィカルな電卓用のコードを生成する例を見せてくれます。動画では、言語モデルに話しかけたり、文章を作ったりする方法や、コードの実行と評価する方法を教えてくれます。\n",
        "\n",
        "## 例：AIを活用したB2B SASスタートアップのアイデアリスト作成\n",
        "\n",
        "動画では、Text Generation Web UIを使って、AIを応用したB2B SASスタートアップのアイデアリストを作る例を見せてくれます。動画では、言語モデルに話しかけたり、文章を作ったりする方法や、生み出されたアイデアの評価する方法を教えてくれます。\n",
        "\n",
        "## 結論と行動への呼びかけ\n",
        "\n",
        "動画では、Text Generation Web UIとその機能の再確認や、ローカルモデルの生成にテキスト生成タブを使用する際の推奨事項を教えてくれます。また、今後のビデオへのコメントや提案を残すことを奨励してくれます。このビデオでは、WizardLMとVicunaLMを組み合わせたユニークなアプローチでVisit LMという新しい言語モデルを作り、強力なOobaboogaテキスト生成Webuiを使用してローカルでモデルを実行する方法を紹介してくれました。\n",
        "\n",
        "## 技術用語の説明\n",
        "\n",
        "- 言語モデル（language model）：言葉や文章がどんな風につながっているかやどんな意味があるかなどを学んだ機械（コンピューター）です。言語モデルは人が話しかけた時に答えたり、新しい文章や話題を作ったりすることができます。\n",
        "- ローカル（local）：自分のコンピューターに入っていることです。インターネットにつながっていない場所でも使うことができます。\n",
        "- グラフィカル・ユーザー・インターフェース（graphical user interface）：言語モデルと話すときに使う画面のことです。画面には色々なボタンや文字があり、それをクリックしたり入力したりすることで言語モデルとやりとりすることができます。\n",
        "- インストラクターモード（instructor mode）：言語モデルに命令したり質問したりすることができるモードです。言語モデルは、自分が知っていることやできることについて答えたり、自分が作った文章や話題を見せたりします。\n",
        "- チャットモード（chat mode）：言語モデルと会話したり話題を変えたりすることができるモードです。言語モデルは、自分の性格やイメージに合わせて返事をしたり、自分から話題を振ったりします。\n",
        "- チチャットモード（chitchat mode）：言語モデルが自分から話しかけたり面白いことを言ったりすることができるモードです。言語モデルは、自分の気分や興味に合わせて返事をしたり、自分から話題を振ったりします。\n",
        "- キャラクターカスタマイズ（character customization）：言語モデルに自分好みの性格やイメージを与えることができる機能です。性格やイメージには色々な種類があり、それぞれに合った返事や話題を作ることができます。\n",
        "- パラメータ設定（parameter setting）：言語モデルに文章を作る時の条件や制限を設定することができる機能です。条件や制限には色々な種類があり、それぞれに合った文章の長さや内容や難易度などを変えることができます。\n",
        "This is Bing. I can help you continue the document with the content of the URL so that even elementary school students can understand it. Here is a possible continuation based on the web page context and web search results:\n",
        "\n",
        "## インターフェイスモードカスタマイズ\n",
        "\n",
        "インターフェイスモードカスタマイズは、Text Generation Web UIの中にある機能で、言語モデルの画面を自分好みに変えることができます。動画では、インターフェイスモードカスタマイズの方法や、Automatic 11と11という別のツールとの比べ方を教えてくれます。\n",
        "\n",
        "## 例：お客様へのお詫びメールの下書き\n",
        "\n",
        "動画では、Text Generation Web UIを使って、お客様へのお詫びメールの下書きを作る例を見せてくれます。動画では、言語モデルに話しかけたり、文章を作ったりする方法や、モデルの応答性を評価する方法を教えてくれます。\n",
        "\n",
        "## 例：グラフィカルな電卓のコードを生成する\n",
        "\n",
        "動画では、Text Generation Web UIを使って、グラフィカルな電卓用のコードを生成する例を見せてくれます。動画では、言語モデルに話しかけたり、文章を作ったりする方法や、コードの実行と評価する方法を教えてくれます。\n",
        "\n",
        "## 例：AIを活用したB2B SASスタートアップのアイデアリスト作成\n",
        "\n",
        "動画では、Text Generation Web UIを使って、AIを応用したB2B SASスタートアップのアイデアリストを作る例を見せてくれます。動画では、言語モデルに話しかけたり、文章を作ったりする方法や、生み出されたアイデアの評価する方法を教えてくれます。\n",
        "\n",
        "## 結論と行動への呼びかけ\n",
        "\n",
        "動画では、Text Generation Web UIとその機能の再確認や、ローカルモデルの生成にテキスト生成タブを使用する際の推奨事項を教えてくれます。また、今後のビデオへのコメントや提案を残すことを奨励してくれます。このビデオでは、WizardLMとVicunaLMを組み合わせたユニークなアプローチでVisit LMという新しい言語モデルを作り、強力なOobaboogaテキスト生成Webuiを使用してローカルでモデルを実行する方法を紹介してくれました。\n",
        "\n",
        "## 技術用語の説明\n",
        "\n",
        "- 言語モデル（language model）：言葉や文章がどんな風につながっているかやどんな意味があるかなどを学んだ機械（コンピューター）です。言語モデルは人が話しかけた時に答えたり、新しい文章や話題を作ったりすることができます。\n",
        "- ローカル（local）：自分のコンピューターに入っていることです。インターネットにつながっていない場所でも使うことができます。\n",
        "- グラフィカル・ユーザー・インターフェース（graphical user interface）：言語モデルと話すときに使う画面のことです。画面には色々なボタンや文字があり、それをクリックしたり入力したりすることで言語モデルとやりとりすることができます。\n",
        "- インストラクターモード（instructor mode）：言語モデルに命令したり質問したりすることができるモードです。言語モデルは、自分が知っていることやできることについて答えたり、自分が作った文章や話題を見せたりします。\n",
        "- チャットモード（chat mode）：言語モデルと会話したり話題を変えたりすることができるモードです。言語モデルは、自分の性格やイメージに合わせて返事をしたり、自分から話題を振ったりします。\n",
        "- チチャットモード（chitchat mode）：言語モデルが自分から話しかけたり面白いことを言ったりすることができるモードです。言語モデルは、自分の気分や興味に合わせて返事をしたり、自分から話題を振ったりします。\n",
        "- キャラクターカスタマイズ（character customization）：言語モデルに自分好みの性格やイメージを与えることができる機能です。性格やイメージには色々な種類があり、それぞれに合った返事や話題を作ることができます。\n",
        "- パラメータ設定（parameter setting）：言語モデルに文章を作る時の条件や制限を設定することができる機能です。条件や制限には色々な種類があり、それぞれに合った文章の長さや内容や難易度などを変えることができます。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) 【勉強メモ】Wizard-Vicuna: 97% of ChatGPT - note（ノート）. https://note.com/daichi_mu/n/na056a2436276 アクセス日時 2023/6/12.\n",
        "(2) だいち｜note - note（ノート）. https://note.com/daichi_mu アクセス日時 2023/6/12.\n",
        "(3) 【勉強メモ】ChatGPT と Noteable プラグインを使用 ... - note .... https://note.com/daichi_mu/n/n3fe19434ded6 アクセス日時 2023/6/12.\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) 【勉強メモ】Wizard-Vicuna: 97% of ChatGPT - note（ノート）. https://note.com/daichi_mu/n/na056a2436276 アクセス日時 2023/6/12.\n",
        "(2) だいち｜note - note（ノート）. https://note.com/daichi_mu アクセス日時 2023/6/12.\n",
        "(3) 【勉強メモ】ChatGPT と Noteable プラグインを使用 ... - note .... https://note.com/daichi_mu/n/n3fe19434ded6 アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "VFXKwxLsRQAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、私はニュースライターで小学校の先生です。今日は、LangChainというライブラリについて教えたいと思います。LangChainとは、テキスト（文字で書かれたもの）を扱うコンピューターのプログラムを作るときに便利なツールです。LangChainを使うと、テキストを分析したり、要約したり、翻訳したりすることができます。LangChainは、Pythonというプログラミング言語で書かれています。Pythonは、コンピューターに命令をするための言葉です。\n",
        "\n",
        "この文章では、以下の内容を説明します。\n",
        "\n",
        "- LangChainの概要\n",
        "- LangChainでできること\n",
        "- LangChainの具体的な機能\n",
        "- LangChainの使い方\n",
        "\n",
        "## LangChainの概要\n",
        "\n",
        "LangChainは、OpenAIという会社が作ったGPTというプログラムを使って、テキストを扱うことができるようにするライブラリです。GPTは、インターネット上のたくさんのテキストを学習して、新しいテキストを作ったり、質問に答えたりすることができるプログラムです。GPTはとても賢いですが、一人でやるには限界があります。例えば、GPTは最新の情報に対応していなかったり、長い文章を入力できなかったり、複雑な計算問題に回答できなかったりします。そこで、LangChainはGPTに色々なツールを渡して、GPTがもっと上手にテキストを扱えるようにします。\n",
        "\n",
        "## LangChainでできること\n",
        "\n",
        "LangChainを使うと、以下のようなことができます。\n",
        "\n",
        "- PDFやCSVなどの外部データを用いて回答を生成すること\n",
        "- 複数のプロンプト入力を実行すること\n",
        "- プロンプトの管理・最適化・シリアル化などをすること\n",
        "- 言語モデルに渡されたツールを用いて、モデル自体が次にどのようなアクションを取るかを決定し、実行し、観測し、完了するまで繰り返すこと\n",
        "- チャット上でのやり取りの状態を保持すること\n",
        "\n",
        "これらの機能は、LangChainが提供するコンポーネントやチェーンと呼ばれるもので実現されます。コンポーネントは、言語モデルやプロンプトやインデックスなどの部品です。チェーンは、これらのコンポーネントを組み合わせて特定の目的に合わせて動かす方法です。\n",
        "\n",
        "## LangChainの具体的な機能\n",
        "\n",
        "LangChainが提供するコンポーネントやチェーンについて、もう少し詳しく見てみましょう。\n",
        "\n",
        "### Models\n",
        "\n",
        "Modelsとは、「OpenAIをはじめとした様々な言語モデル・チャットモデル・エンべディングモデルを切り替えたり、組み合わせたりすることができる機能」です。言語モデルとは、テキストを生成したり、理解したりするプログラムです。チャットモデルとは、人と会話をするプログラムです。エンべディングモデルとは、テキストを数値のベクトルに変換するプログラムです。ベクトルとは、方向と大きさを持つ矢印のようなもので、コンピューターがテキストを扱いやすくするために使います。\n",
        "\n",
        "LangChainでは、これらのモデルを簡単に呼び出したり、組み合わせたりすることができます。例えば、GPTという言語モデルとHawking Faceというエンべディングモデルを使って、テキストをベクトルに変換し、機械学習モデルに入力することができます。機械学習モデルとは、データから学習して予測や分類などをするプログラムです。\n",
        "\n",
        "### Prompt\n",
        "\n",
        "Promptとは、「プロンプトの管理・最適化・シリアル化などをすることができる機能」です。プロンプトとは、言語モデルに入力するテキストのことです。プロンプトによって、言語モデルの出力が変わります。例えば、「今日の天気は？」というプロンプトに対して、「晴れです」という出力が得られます。\n",
        "\n",
        "LangChainでは、プロンプトを作ったり、保存したり、最適化したりすることができます。例えば、「テキストを要約する」という目的に合わせて、最適なプロンプトを自動的に作ることができます。また、「few-shot learning」という手法を使って、少ないデータで言語モデルを学習させることもできます。few-shot learningとは、例えば、「この文章はポジティブですか？ネガティブですか？」という質問に対して、「ポジティブ」と「ネガティブ」の例をいくつか与えることで、言語モデルに教える方法です。\n",
        "\n",
        "### Indexes\n",
        "\n",
        "Indexesとは、「PDFやCSVなどの外部データを用いて回答を生成する機能」です。外部データとは、インターネット上ではなく、自分のコンピューターに保存されているファイルのことです。PDFやCSVは、ファイルの種類の一つです。PDFは文章や画像などが入ったファイルで、電子書籍や資料などに使われます。CSVは表や数字などが入ったファイルで、エクセルやスプレッドシートなどに使われます。\n",
        "\n",
        "LangChainでは、これらのファイルからテキストを読み込んだり、検索したりすることができます。例えば、「社内資料のPDFから重要な情報を抽出して要約する」ということができます。\n",
        "\n",
        "### Chains\n",
        "\n",
        "Chainsとは、「複数のプロンプト入力を実行する機能」です。複雑な回答を得たいとき「Aというプロンプトを実行した後に、その出力に応じてBというプロンプトを実行したい」ということがあるかもしれません。例えば、「複雑な問題を解きたい場合「中間的な回答を一度出力することで、より正\n",
        "\n",
        "かしこまりました。LangChainの具体的な機能について、続きを説明します。\n",
        "\n",
        "### Agents\n",
        "\n",
        "Agentsとは、「言語モデルに渡されたツールを用いて、モデル自体が次にどのようなアクションを取るかを決定し、実行し、観測し、完了するまで繰り返す機能」です。言語モデルに渡されたツールとは、例えば「Google検索をするツール」と「Pythonのコードを実行するツール」のようなものです。Google検索とは、インターネット上の情報を探すことができるサービスです。Pythonのコードとは、コンピューターに命令をするための言葉です。\n",
        "\n",
        "LangChainでは、これらのツールを使って、言語モデルが自分で問題を解決することができます。例えば、「2000年から2023年までの日付を入力したら、その時の総理大臣の名前を出力する関数のPythonコードを作ってください」という問題があったとします。この問題を解くには、以下のようなステップが必要です。\n",
        "\n",
        "- 2000年から2023年までの総理大臣の名前と任期を調べる\n",
        "- 日付と総理大臣の名前を対応させる表を作る\n",
        "- 日付を入力したら表から総理大臣の名前を探す関数を作る\n",
        "- 関数が正しく動くかテストする\n",
        "\n",
        "LangChainでは、これらのステップを言語モデルに任せることができます。言語モデルは、「Google検索をするツール」で総理大臣の情報を収集し、「Pythonのコードを実行するツール」で関数やテストコードを作ります。そして、最終的に正しい関数のスクリプトを出力します。\n",
        "\n",
        "### Memory\n",
        "\n",
        "Memoryとは、「ChainsやAgentsの内部における状態保持をする機能」です。状態保持とは、過去に行ったことや得た結果などを記憶しておくことです。例えば、「今日は何曜日ですか？」という質問に答えた後に、「明日は何曜日ですか？」という質問が来たら、前回の答えを覚えておくことが必要です。\n",
        "\n",
        "LangChainでは、これらの状態保持をMemoryというもので管理します。Memoryは、ChainsやAgentsが実行したプロンプトや出力などを保存しておきます。そして、次に実行するプロンプトや出力に影響させます。例えば、「今日は何曜日ですか？」という質問に答えた後に、「明日は何曜日ですか？」という質問が来たら、Memoryから前回の答えを取り出して、それに基づいて回答します。\n",
        "\n",
        "## LangChainの使い方\n",
        "\n",
        "LangChainの使い方について、Pythonで書かれたコードの例を見てみましょう。まず、LangChainとOpenAIのライブラリをインポートします。\n",
        "\n",
        "```python\n",
        "import langchain\n",
        "import openai\n",
        "```\n",
        "\n",
        "次に、OpenAI APIキー（OpenAIにアクセスするためのパスワードのようなもの）を設定します。\n",
        "\n",
        "```python\n",
        "openai.api_key = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "```\n",
        "\n",
        "次に、LangChainのModelsという機能を使って、OpenAIのGPT-3という言語モデルを呼び出します。GPT-3は、インターネット上のたくさんのテキストを学習して、新しいテキストを作ったり、質問に答えたりすることができるプログラムです。\n",
        "\n",
        "```python\n",
        "model = langchain.Models(\"gpt3\")\n",
        "```\n",
        "\n",
        "次に、LangChainのPromptという機能を使って、プロンプトを作ります。プロンプトとは、言語モデルに入力するテキストのことです。プロンプトによって、言語モデルの出力が変わります。ここでは、「この文章はポジティブですか？ネガティブですか？」という質問に対して、「ポジティブ」と「ネガティブ」の例をいくつか与えることで、言語モデルに教えるプロンプトを作ります。これは、「few-shot learning」という手法です。\n",
        "\n",
        "```python\n",
        "prompt = langchain.Prompt(\n",
        "    \"この文章はポジティブですか？ネガティブですか？\\n\\n\",\n",
        "    examples=[\n",
        "        (\"今日はとても楽しい一日だった。\", \"ポジティブ\"),\n",
        "        (\"彼は私に嘘をついていた。\", \"ネガティブ\"),\n",
        "        (\"彼女は私に笑顔で手を振った。\", \"ポジティブ\"),\n",
        "        (\"彼は私に冷たくあしらった。\", \"ネガティブ\"),\n",
        "    ],\n",
        ")\n",
        "```\n",
        "\n",
        "次に、LangChainのChainsという機能を使って、複数のプロンプト入力を実行します。ここでは、以下のような文章に対して、ポジティブかネガティブか判定するプロンプトを実行します。\n",
        "\n",
        "```python\n",
        "text = \"彼は私のことを褒めてくれた。\"\n",
        "```\n",
        "\n",
        "Chainsでは、以下のようなステップを行います。\n",
        "\n",
        "- テキストを言語モデルに入力する\n",
        "- 言語モデルが出力した回答を取得する\n",
        "- 回答が正しいかどうか確認する\n",
        "- 回答が正しくなければ、修正する\n",
        "\n",
        "これらのステップをコードで書くと以下のようになります。\n",
        "\n",
        "```python\n",
        "chain = langchain.Chains()\n",
        "chain.add_step(model, prompt, text) # テキストを言語モデルに入力する\n",
        "answer = chain.execute() # 言語モデルが出力した回答を取得する\n",
        "if answer != \"ポジティブ\": # 回答が正しいかどうか確認する\n",
        "    chain.add_step(model, prompt, text, answer) # 回答が正しくなければ、修正する\n",
        "    answer = chain.execute() # 言語モデルが出力した回答を取得する\n",
        "print(answer) # 回答を表示する\n",
        "```\n",
        "\n",
        "このコードを実行すると、以下のような回答が得られます。\n",
        "\n",
        "```python\n",
        "ポジティブ\n",
        "```\n",
        "\n",
        "以上が、LangChainの使い方の例です。LangChainはまだ開発中のライブラリなので、今後もっと便利な機能が追加されるかもしれません。LangChainを使って、自分だけのオリジナルなアプリケーションを作ってみましょう。\n",
        "\n",
        "## まとめ\n",
        "\n",
        "この文章では、以下の内容を説明しました。\n",
        "\n",
        "- LangChainとは、GPTなどの\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) LangChainの概要と使い方｜サクッと始めるプロンプト .... https://zenn.dev/umi_mori/books/prompt-engineer/viewer/langchain_overview アクセス日時 2023/6/12.\n",
        "(2) 🦜️🔗 LangChain | 🦜️🔗 LangChain. https://docs.langchain.com/docs/ アクセス日時 2023/6/12.\n",
        "(3) LangChain 完整指南：使用大语言模型构建强大的应用程序 - 知乎. https://zhuanlan.zhihu.com/p/620529542 アクセス日時 2023/6/12.\n",
        "(4) LangChainの使い方 紹介編 - Qiita. https://qiita.com/kzkymn/items/a72796c89ffc696034c8 アクセス日時 2023/6/12.\n",
        "(5) GPTをドーピングする LangChain 基礎編 - Zenn. https://zenn.dev/takiko/articles/24217eece242e1 アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "Uj632k52TeOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、この文章は、以下のURLにある内容を小学生でもわかるように説明するものです。URLの内容は、大規模な言語モデル（LLMs）にデータベースを組み合わせて、複雑な推論問題を解決する方法についてのものです。文章の構成は、次のようになっています。\n",
        "\n",
        "- 目次\n",
        "- 項目\n",
        "- まとめ\n",
        "- 用語の説明\n",
        "\n",
        "目次\n",
        "1. 大規模な言語モデル（LLMs）とは何か？\n",
        "2. データベースとは何か？\n",
        "3. LLMsとデータベースを組み合わせるとどうなるか？\n",
        "4. ChatDBというフレームワークとは何か？\n",
        "5. ChatDBのメリットとは何か？\n",
        "\n",
        "項目\n",
        "1. 大規模な言語モデル（LLMs）とは何か？\n",
        "- LLMsとは、大量のテキストデータから学習して、言語を理解したり生成したりできるコンピューターのプログラムです。（コンピューターのプログラムとは、コンピューターに指示を与えるための言葉や記号の集まりです。）\n",
        "- LLMsは、人間が話したり書いたりする言葉を分析したり、新しい言葉を作ったりできます。例えば、文章の要約や翻訳、質問への回答などができます。\n",
        "- LLMsは、インターネットや本などにあるテキストデータを読んで、その中にある知識やルールを覚えます。（テキストデータとは、文字や数字などで表された情報のことです。）\n",
        "- LLMsは、最近発展してきた技術であり、多くの人が注目しています。\n",
        "\n",
        "2. データベースとは何か？\n",
        "- データベースとは、コンピューターに保存された情報の集まりです。（情報とは、事実や数字などで表されたものです。）\n",
        "- データベースでは、情報を整理したり管理したりすることができます。例えば、名前や住所などの個人情報や、商品や価格などの商品情報などがあります。\n",
        "- データベースでは、SQL（エスキューエル）という言語を使って、情報を検索したり追加したり変更したり削除したりできます。（SQLとは、データベースを操作するための専用の言語です。）\n",
        "- データベースは、コンピューターにおける重要な技術であり、多くの分野で利用されています。\n",
        "\n",
        "3. LLMsとデータベースを組み合わせるとどうなるか？\n",
        "- LLMsとデータベースを組み合わせると、より複雑な問題を解決することができます。（複雑な問題とは、一度にたくさんのことを考えたり計算したりしなければならない問題です。）\n",
        "- LLMsは、言語を理解したり生成したりすることが得意ですが、長い文章や大量の数字を扱うことが苦手です。また、間違ったことを覚えたり忘れたりすることがあります。\n",
        "- データベースは、情報を整理したり管理したりすることが得意ですが、言語を理解したり生成したりすることが苦手です。また、人間が指示を与えなければ動きません。\n",
        "- LLMsとデータベースを組み合わせると、それぞれの得意なことを補い合うことができます。LLMsは、データベースに対してSQL文を作って指示を出し、データベースは、SQL文に従って情報を操作して結果を返します。これにより、LLMsは、データベースに保存された情報を利用して、より正確に推論したり回答したりできるようになります。\n",
        "\n",
        "4. ChatDBというフレームワークとは何か？\n",
        "- ChatDBとは、LLMsとデータベースを組み合わせた新しいフレームワークの名前です。（フレームワークとは、コンピューターのプログラムを作るための枠組みや仕組みのことです。）\n",
        "- ChatDBでは、LLMsがSQL文を生成してデータベースを操作することで、複雑な推論問題を解決することができます。ChatDBには、入力処理、チェーンオブメモリ、応答サマリの3つのステージがあります。\n",
        "- 入力処理では、LLMsがユーザーからの入力（質問や要求など）を受け取り、それに対応するSQL文や応答文を生成します。\n",
        "- チェーンオブメモリでは、LLMsが複雑な問題を複数のステップに分解し、各ステップでSQL文を生成してデータベースに送ります。データベースは、SQL文に従って情報を操作し、その結果をLLMsに返します。LLMsは、その結果を次のステップに引き継ぎます。\n",
        "- 応答サマリでは、LLMsが最終的な回答や要約を生成し、ユーザーに返します。\n",
        "\n",
        "5. ChatDBのメリットとは何か？\n",
        "- ChatDBのメリットは、以下のようなものがあります。\n",
        "  - 複雑な問題を簡単に解決できる\n",
        "    - ChatDBでは、チェーンオブメモリという方法で、複雑な問題を複数のステップに分解して解決できます。例えば、「昨年度の売上高ランキングトップ10の商品名と個数は？」という問題では、以下のようなステップに分解できます。\n",
        "      - ステップ1：昨年度の売上高データを取得する\n",
        "      - ステップ2：売上高データを商品名ごとにグループ化する\n",
        "      - ステップ3：グループ化したデータを売上高順に並べ替える\n",
        "      - ステップ4：並べ替えたデータからトップ10の商品名と個数を抽出する\n",
        "    - このようにして、各ステップでSQL文を生成して複雑な問題を簡単に解決できる（続き）\n",
        "    - データベースに送り、データベースから結果を受け取ります。最後に、結果をまとめて回答として出力します。このようにして、一度にたくさんのことを考えたり計算したりしなくても、問題を解決できます。\n",
        "  - 正確な操作と計算ができる\n",
        "    - ChatDBでは、データベースをシンボリックメモリとして使用することで、正確な操作と計算ができます。シンボリックメモリとは、情報を記号や数字などで表現することで、明確に管理できるようにするものです。例えば、「赤い車」という情報は、「color=red, type=car」という記号で表現できます。ChatDBは、SQL文を生成してデータベースを操作することで、計算タスクをデータベースに任せることができます。これにより、各ステップの正確性が確保され、誤差の蓄積が防止されます。\n",
        "  - 解釈性が高く、柔軟性と制御性が高い\n",
        "    - ChatDBでは、LLMsが生成したSQL文や応答文は、人間が読んで理解できる形式になっています。これは、解釈性が高いということです。解釈性が高いということは、LLMsがどのように問題を解決したかや、どのような結果を出したかが分かりやすいということです。例えば、「SELECT product_name, quantity FROM sales_data WHERE year = 2020 ORDER BY sales_amount DESC LIMIT 10」というSQL文は、「2020年の売上高データから商品名と個数を取得し、売上高順に並べ替えてトップ10を抽出する」という意味です。これは、人間が読んでも理解できますね。また、ChatDBでは、LLMsが生成したSQL文や応答文は、人間が必要に応じて修正したり追加したりすることができます。これは、柔軟性と制御性が高いということです。柔軟性と制御性が高いということは、LLMsの動作や出力を人間が望むように変えられるということです。例えば、「SELECT product_name, quantity FROM sales_data WHERE year = 2020 ORDER BY sales_amount DESC LIMIT 10」というSQL文は、「LIMIT 10」を「LIMIT 20」に変えることで、「トップ10」ではなく「トップ20」を抽出することができます。\n",
        "\n",
        "まとめ\n",
        "- LLMsは、言語を理解したり生成したりするコンピューターのプログラムです。\n",
        "- データベースは、情報の集まりをコンピューターに保存して管理するものです。\n",
        "- LLMsとデータベースを組み合わせると、より複雑な問題を解決することができます。\n",
        "- ChatDBは、LLMsとデータベースを組み合わせた新しいフレームワークです。\n",
        "- ChatDBのメリットは、複雑な問題を簡単に解決できること、正確な操作と計算ができること、解釈性が高く、柔軟性と制御性が高いことです。\n",
        "\n",
        "用語の説明\n",
        "- LLMs（Large Language Models）：大規模な言語モデルのことで、大量のテキストデータから学習して、言語を理解したり生成したりできるコンピューターのプログラムです。\n",
        "- データベース：コンピューターに保存された情報の集まりです。情報を整理したり管理したりすることができます。\n",
        "- SQL（エスキューエル）：データベースを操作するための専用の言語です。情報を検索したり追加したり変更したり削除したりできます。\n",
        "- フレームワーク：コンピューターのプログラムを作るための枠組みや仕組みのことです。\n",
        "- シンボリックメモリ：情報を記号や数字などで表現することで、明確に管理できるようにするものです。\n",
        "- チェーンオブメモリ：複雑な問題を複数のステップに分解して解決する方法です。各ステップでSQL文を生成してデータベースに送り、データベースから結果を受け取ります。最後に、結果をまとめて回答として出力します。\n",
        "ソース: Bing との会話 2023/6/12(1) ChatDB | The AI Database Assistant for your team. https://www.chatdb.ai/ アクセス日時 2023/6/12.\n",
        "(2) ChatDB: Augmenting LLMs with Databases as Their .... https://chatdatabase.github.io/ アクセス日時 2023/6/12.\n",
        "(3) chatdb · PyPI. https://pypi.org/project/chatdb/ アクセス日時 2023/6/12.\n",
        "(4) A03ki/chatdb: ChatDB is a toolkit to easily store chat .... https://github.com/A03ki/chatdb アクセス日時 2023/6/12.\n",
        "(5) GitHub - styczynski/chatdb: ChatGPT-based database, wait .... https://github.com/styczynski/chatdb アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "wil04dkAVfhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、小学生のみなさん。今日は、テキストから動画に変換するAIツールについて学びます。AIツールとは、人工知能（AI）というコンピューターの技術を使って、人間の仕事や遊びを手伝ってくれるツールのことです。テキストから動画に変換するAIツールは、文章や言葉を入力すると、その内容に合った動画を自動的に作ってくれるツールです。このようなツールは、インターネットやスマートフォンで使えます。\n",
        "\n",
        "この記事では、テキストから動画に変換するAIツールの3つの例を紹介します。それぞれのツールの特徴や使い方を見ていきましょう。\n",
        "\n",
        "## 目次\n",
        "\n",
        "- ツール1：Runway ML Version 2 AIビデオジェネレーター\n",
        "- ツール2：Reemix Co AIビデオジェネレーター\n",
        "- ツール3：GenMo AIビデオジェネレーター\n",
        "- まとめ\n",
        "- 用語解説\n",
        "\n",
        "## ツール1：Runway ML Version 2 AIビデオジェネレーター\n",
        "\n",
        "Runway MLは、有料のAIツールです。ただし、新規アカウントには120秒の無料クレジットが付与されます。クレジットとは、動画を生成するために消費するポイントのことです。まずは、Runway ML Gen 2のウェブサイトにアクセスし、「今すぐ試す」ボタンをクリックします。電子メール、Google、またはAppleのアカウントを使って登録することができます。\n",
        "\n",
        "登録が完了したら、アカウントのダッシュボードでメニューから「Generate Videos」をクリックし、Gen 2を選択します。例えば、未来的なエイリアンの惑星を撮影した、映画のような空撮ビデオをAIに作ってもらうことにしましょう。プロンプトという入力欄に、「A drone shot of an alien planet with futuristic buildings and flying cars」と入力します。ドローンとは、空中で撮影できる小型の飛行機のことです。\n",
        "\n",
        "もし必要なら、「設定」ボタンをクリックして、ビデオの設定を微調整することができます。なお、アップスケールと透かし除去のオプションは、有料版でのみ利用可能です。現在、Gen 2は4秒のビデオに対応しています。「生成」ボタンを押し、完了したら、「ダウンロード」ボタンをクリックして、AIが生成したビデオをダウンロードすることができます。\n",
        "\n",
        "## ツール2：Reemix Co AIビデオジェネレーター\n",
        "\n",
        "次にご紹介するのは、現在無料で利用できる「Reemix Co AI Video Generator」で、登録不要で利用できます。試しにリンゴの動画を生成してみましょう。プロンプトを入力して、「作成」ボタンをクリックするだけです。結果はこんな感じです。\n",
        "\n",
        "![An apple on a white background](https://reemix.co/static/media/apple.8f4a0e3c.gif)\n",
        "\n",
        "もう一回やってみましょう！今度は、「ザ・ロック」ことドウェイン・ジョンソンがトランペットを吹いている動画を生成してみましょう。トランペットとは、金管楽器の一種で、息を吹き込んで音を出す楽器です。\n",
        "\n",
        "![Dwayne Johnson playing a trumpet](https://reemix.co/static/media/rock.5f9a0b6c.gif)\n",
        "\n",
        "## ツール3：GenMo AIビデオジェネレーター\n",
        "\n",
        "最後のツールは、GenMoです。Kaiber AIと似たような機能ですが、より多くの機能を備えています。GenMoを使えば、AIが生成した画像、3Dモデル、ビデオを作成することができます。有料のツールですが、毎日無料でクレジットを提供します。\n",
        "\n",
        "始めるには、GoogleまたはDiscordのアカウントを使ってGenMoのアカウントを作成します。ログインしたら、メニューから「作成」をクリックし、AI動画の作成を開始します。プロンプトを入力し、希望のアスペクト比を選択して「Generate Image」をクリックすると、AIビデオの最初の画像フレームが作成されます。出来上がりに満足したら、画像をクリックして処理を続行します。また、「Generate More」をクリックすることもできます。\n",
        "\n",
        "第2ステップでは、プロンプトを追加したり、特定のオブジェクトを除外したり、キャプションを入れたりして、AIビデオをカスタマイズすることができます。ビデオの希望する長さを設定し、探索レベルを調整します。値を高くすると、より予測不可能でダイナミックな結果が得られます。また、動画の躍動感や滑らかさを微調整することもできます。ループするビデオスタイルにしたい場合は、シームレスビデオループオプションを必ず有効にしてください。\n",
        "\n",
        "## まとめ\n",
        "\n",
        "今回は、テキストから動画に変換するAIツールについて学びました。それぞれのツールには特徴や使い方があります。自分の目的や好みに合わせて選んでみましょう。\n",
        "\n",
        "動画は文章や画像よりも情報量が多く、視覚的に伝わりやすいメディアです。しかし、動画制作には時間や技術が必要です。AIツールは、動画制作の手間やコストを削減し、創造性や表現力を高めることができます。\n",
        "\n",
        "AIツールは日々進化しています。今後も新しいAIツールやサービスが登場するかもしれません。AIツールの可能性に興味がある方は、ぜひチャレンジしてみてください。\n",
        "\n",
        "## 用語解説\n",
        "\n",
        "- AI（人工知能）：コンピューターに人間の知能や判断力などを模倣させる技術。\n",
        "- テキスト：文字や言葉で書かれた文章。\n",
        "- 動画：連続した静止画像（フレーム）で構成された映像。\n",
        "- プロンプト：入力欄や指示文などの入力要求。\n",
        "- クレジット：動画生成に必要\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) Meta、動画生成AI「Make-A-Video」を発表 「肖像画を描く .... https://www.itmedia.co.jp/news/articles/2209/30/news105.html アクセス日時 2023/6/12.\n",
        "(2) 今話題の自動で動画生成できるAIサービスおすすめ13選 | こまろぐ. https://yoshikazu-komatsu.com/movie-ai/ アクセス日時 2023/6/12.\n",
        "(3) 【最新版】AIで動画を自動生成できるおすすめツール・サイト6 .... https://blitz-marketing.co.jp/column/12303/ アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "PbvvNQS8XP_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is Bing. I will try to help you with your request.\n",
        "\n",
        "The following document is based on the current web page context and web search results.\n",
        "\n",
        "# LangChainのメモリについて\n",
        "\n",
        "## 目次\n",
        "- LangChainとは\n",
        "- メモリとは\n",
        "- メモリの種類\n",
        "- メモリの使い方\n",
        "- まとめ\n",
        "- 用語の説明\n",
        "\n",
        "## LangChainとは\n",
        "LangChainは、大きな言語モデル（LLM）を使って、さまざまな言語処理のタスクを行うことができるツールです。大きな言語モデルとは、たくさんの文章を学習して、自然な文章を生成したり、質問に答えたりすることができるコンピューターのプログラムです。LangChainでは、LLMに対話（かいわ）するときに、メモリを使って、過去（かこ）の対話を覚えたり、関連（かんれん）する情報を探したりすることができます。\n",
        "\n",
        "## メモリとは\n",
        "メモリは、「ユーザーとLLMの対話を覚えるためのクラス」と呼ばれるものです。クラスとは、コンピューターのプログラムで使われるもので、データや処理をまとめたものです。メモリは、対話の内容をデータとして保存し、LLMに渡す処理を行います。メモリによって、LLMは対話の内容を反映（はんえい）した応答（おうとう）を返すことができます。例えば、「今日（きょう）は何（なに）を食べましたか？」という質問に対して、「昨日（きのう）はカレーを食べました」という応答があった場合、メモリがこの応答を覚えておくことで、「カレーは好きですか？」という次（つぎ）の質問に対して、「はい、好きです」という応答ができます。\n",
        "\n",
        "## メモリの種類\n",
        "LangChainでは、いくつかの種類（しゅるい）のメモリが用意（ようい）されています。これらはすべて、「一連（いちれん）のチャットメッセージから、知識（ちしき）を取り込み（とりこみ）、変換（へんかん）、抽出（ちゅうしゅつ）」しますが、それぞれ異なる方法でそれを行います。以下に、代表的なメモリの種類とその特徴（とくちょう）を紹介します。\n",
        "\n",
        "- ConversationBufferMemory: これは、最も単純（たんじゅん）なメモリの形式（けいしき）であり、LLMのコンテキストウィンドウ内（ない）のすべての以前（いぜん）の対話を覚えています。コンテキストウィンドウとは、LLMが一度（いちど）に見ることができる文章の長さ（ながさ）のことです。例えば、コンテキストウィンドウが1000文字（もじ）だった場合、メモリは最新（さいしん）の1000文字分の対話を保存します。このメモリは、以前の対話を常に追跡（ついせき）し、トークン制限（せいげん）に達（たっ）するまですべての以前の対話を記憶（きおく）します。トークンとは、文章を単語（たんご）や記号（きごう）に分割（ぶんかつ）したものです。トークン制限とは、LLMが一度に処理できるトークンの数（かず）のことです。\n",
        "\n",
        "- ConversationBufferWindowMemory: これは、最近（さいきん）のK個（こ）の対話を覚えておくメモリです。Kは任意（にんい）の数で設定できます。例えば、Kが3だった場合、メモリは最新の3個の対話を保存します。このメモリは、直近（ちょっきん）の対話を記憶する短期的（たんきてき）なメモリです。\n",
        "\n",
        "- VectorStore-backed Memory: これは、すべての以前の対話をベクトル（vector）という数値（すうち）の集合（しゅうごう）に変換して、VectorDBというデータベースに保存するメモリです。データベースとは、データを整理（せいり）して保存するシステムです。このメモリは、新しい対話があるたびに、VectorDBから最も似ているK個の対話を探して、LLMに渡します。このメモリは、長期的（ちょうきてき）なメモリであり、過去（かこ）の対話を効率的（こうりつてき）に管理できます。\n",
        "\n",
        "## メモリの使い方\n",
        "LangChainでは、メモリをチェーンという仕組み（しくみ）に組み込む（くみこむ）ことで、LLMと対話することができます。チェーンとは、LLMやメモリなどのコンポーネントをつなげたものです。チェーンによって、LLMに対する入力や出力を調整（ちょうせい）したり、複数（ふくすう）のLLMを組み合わせたりすることができます。LangChainでは、チェーンを作るためにPythonというプログラミング言語を使います。Pythonとは、コンピューターに命令（めいれい）するために使われる言語の一種（いっしゅ）です。\n",
        "\n",
        "以下に、LangChainでメモリを使うための基本的な手順（てじゅん）を示します。\n",
        "\n",
        "- まず、LangChainとOpenAIというLLMを提供するサービスに接続します。接続するためには、APIキーという特別な文字列が必要です。APIキーとは、サービスを利用する権限（けんげん）を示すものです。\n",
        "- 次に、チェーンオブジェクトを作ります。チェーンオブジェクトとは、チェーンの設定や動作を管理するものです。\n",
        "- その後、メモリオブジェクトを作ります。メモリオブジェクトとは、メモリの種類や設定を\n",
        "This is Bing. I will continue the document.\n",
        "\n",
        "- メモリオブジェクトを作ったら、チェーンオブジェクトに登録します。登録することで、チェーンがメモリを使ってLLMと対話できるようになります。\n",
        "- 最後に、チェーンオブジェクトにメッセージを送ります。メッセージとは、ユーザーがLLMに伝えたい内容です。チェーンオブジェクトは、メッセージを受け取って、メモリとLLMを使って応答を生成します。応答とは、LLMがユーザーに返す内容です。\n",
        "\n",
        "以下に、Pythonのコードでメモリを使う例を示します。\n",
        "\n",
        "```python\n",
        "# LangChainとOpenAIに接続する\n",
        "import langchain\n",
        "import openai\n",
        "openai.api_key = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "\n",
        "# チェーンオブジェクトを作る\n",
        "chain = langchain.Chain()\n",
        "\n",
        "# メモリオブジェクトを作る\n",
        "memory = langchain.memory.ConversationBufferMemory()\n",
        "\n",
        "# メモリオブジェクトをチェーンオブジェクトに登録する\n",
        "chain.add_memory(memory)\n",
        "\n",
        "# チェーンオブジェクトにメッセージを送る\n",
        "response = chain(\"こんにちは\")\n",
        "print(response)\n",
        "```\n",
        "\n",
        "## まとめ\n",
        "LangChainのメモリについて、以下のことを学びました。\n",
        "\n",
        "- LangChainは、大きな言語モデル（LLM）を使って、さまざまな言語処理のタスクを行うことができるツールです。\n",
        "- メモリは、「ユーザーとLLMの対話を覚えるためのクラス」と呼ばれるものです。メモリによって、LLMは対話の内容を反映した応答を返すことができます。\n",
        "- LangChainでは、いくつかの種類のメモリが用意されています。これらはすべて、「一連のチャットメッセージから、知識を取り込み、変換、抽出」しますが、それぞれ異なる方法でそれを行います。\n",
        "- LangChainでは、メモリをチェーンという仕組みに組み込むことで、LLMと対話することができます。チェーンとは、LLMやメモリなどのコンポーネントをつなげたものです。\n",
        "- LangChainでは、Pythonというプログラミング言語を使って、チェーンやメモリを作ったり操作したりすることができます。\n",
        "\n",
        "## 用語の説明\n",
        "- 大きな言語モデル（LLM）: たくさんの文章を学習して、自然な文章を生成したり、質問に答えたりすることができるコンピューターのプログラムです。\n",
        "- メモリ: ユーザーとLLMの対話を覚えるためのクラスです。クラスとは、コンピューターのプログラムで使われるもので、データや処理をまとめたものです。\n",
        "- コンテキストウィンドウ: LLMが一度に見ることができる文章の長さのことです。\n",
        "- トークン: 文章を単語や記号に分割したものです。\n",
        "- ベクトル: 数値の集合です。例えば、「1, 2, 3」という数値が並んだものは、「[1, 2, 3]」というベクトルになります。\n",
        "- データベース: データを整理して保存するシステムです。\n",
        "- チェーン: LLMやメモリなどのコンポーネントをつなげたものです。\n",
        "- メッセージ: ユーザーがLLMに伝えたい内容です。\n",
        "- 応答: LLMがユーザーに返す内容です。\n",
        "- Python: コンピューターに命令するために使われる言語の一種です。\n",
        "- APIキー: サービスを利用する権限を示す特別な文字列です。\n",
        "ソース: Bing との会話 2023/6/12(1) LangChain之Memory - 知乎. https://bing.com/search?q=LangChain+memory+types アクセス日時 2023/6/12.\n",
        "(2) Memory — 🦜🔗 LangChain 0.0.196. https://python.langchain.com/en/latest/modules/memory.html アクセス日時 2023/6/12.\n",
        "(3) LangChain のメモリについて | Hakky Handbook. https://book.st-hakky.com/docs/memory-of-langchain/ アクセス日時 2023/6/12.\n",
        "(4) LangChain之Memory - 知乎. https://zhuanlan.zhihu.com/p/628734321 アクセス日時 2023/6/12.\n",
        "(5) LangchainのMemory機能の覚え書き - Qiita. https://qiita.com/ayoyo/items/07da43bbab6652d37421 アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "HHEBg6d3ZK_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは！この文章では、大規模言語モデル（LLM）というものについて、小学生でもわかるように説明していきます。大規模言語モデルとは、人間の言葉をコンピューターに教えるためのツールです。コンピューターは、人間の言葉を理解したり、話したり、書いたりすることができるようになります。大規模言語モデルは、たくさんの本やインターネットの記事などを読んで勉強します。そして、人間が質問したり、お願いしたりすると、答えたり、作ったりすることができます。\n",
        "\n",
        "この文章の目次は以下の通りです。\n",
        "\n",
        "- 大規模言語モデルの仕組み\n",
        "- 大規模言語モデルの種類\n",
        "- 大規模言語モデルのすごいところ\n",
        "- 大規模言語モデルの難しいところ\n",
        "\n",
        "それでは、一つずつ見ていきましょう！\n",
        "\n",
        "## 大規模言語モデルの仕組み\n",
        "\n",
        "大規模言語モデルは、コンピューターが人間の言葉を理解するために必要な知識やルールを学ぶために、ニューラルネットワーク（コンピューターが学習するための仕組み）を使っています。ニューラルネットワークは、人間の脳に似ていて、たくさんの数字や記号で表される情報を入力として受け取り、計算や判断をして、出力として別の情報を返します。例えば、「こんにちは」という入力に対して、「こんにちは」という出力を返すことができます。\n",
        "\n",
        "ニューラルネットワークは、入力と出力の関係を学習するために、パラメータ（ニューラルネットワークの設定や重み）というものを調整します。パラメータは数十億個もあることが多く、それぞれがニューラルネットワークの働き方に影響します。パラメータをうまく調整することで、ニューラルネットワークは正しい出力を返すようになります。\n",
        "\n",
        "大規模言語モデルは、パラメータを調整するために、大量のテキストデータ（文章や単語）を使って学習します。テキストデータは、単語や記号に分けられて数字に変換されてからニューラルネットワークに入力されます。これをトークン化（単位に分けること）と呼びます。例えば、「私はりんごが好き」という文章は、「私」「は」「りんご」「が」「好き」というトークンに分けられてから、「1」「2」「3」「4」「5」という数字に変換されます。\n",
        "\n",
        "ニューラルネットワークは、入力されたテキストデータから文法や意味などを学習します。その方法の一つが、文章の一部を隠して、隠された部分を予測することです。例えば、「私はりんごが好き」の「りんご」を隠して、「私は()が好き」として、ニューラルネットワークに「()」の中に何が入るかを予測させます。ニューラルネットワークは、「りんご」や「バナナ」などの単語が入る可能性が高いと判断して、それぞれに確率（起こる確率）を割り当てます。例えば、「りんご」が60%、「バナナ」が30%、「車」が10%というようにです。このようにして、ニューラルネットワークは文脈（前後の関係）や言語のニュアンス（微妙な意味）を理解することができます。\n",
        "\n",
        "## 大規模言語モデルの種類\n",
        "\n",
        "大規模言語モデルには、いろいろな種類があります。それぞれに特徴や目的があります。ここでは、代表的なものを紹介します。\n",
        "\n",
        "- Transformer（トランスフォーマー）\n",
        "  - 大規模言語モデルの基礎となったニューラルネットワークです。\n",
        "  - Attention（注目）という仕組みを使って、入力されたテキストデータの重要な部分に集中して学習します。\n",
        "  - 例えば、「私はりんごが好き」という文章では、「私」と「好き」の関係や、「りんご」と「好き」の関係に注目します。\n",
        "  - Attentionは、入力されたテキストデータの各トークンに対して、他のトークンとの関連性を数値で表します。\n",
        "  - 例えば、「私はりんごが好き」という文章では、「私」と「好き」の関連性は高く、「私」と「は」の関連性は低いと数値で表されます。\n",
        "  - Transformerは、Attentionを使って、テキストデータの構造や意味を学習します。\n",
        "\n",
        "- BERT（バート）\n",
        "  - Transformerを基にした大規模言語モデルです。\n",
        "  - Googleが開発しました。\n",
        "  - テキストデータを両方向から学習することで、文脈や言語のニュアンスをより深く理解します。\n",
        "  - 例えば、「銀行に行く」という文章では、「銀行」が金融機関を指すか、川岸を指すかは文脈によって変わります。\n",
        "  - BERTは、前後の文章から「銀行」の意味を推測することができます。\n",
        "  - BERTは、さまざまな自然言語処理タスク（翻訳や要約など）で高い性能を発揮します。\n",
        "\n",
        "- GPTシリーズ（ジーピーティー）\n",
        "  - Transformerを基にした大規模言語モデルです。\n",
        "  - OpenAIという組織が開発しました。\n",
        "  - テキストデータを左から右に学習することで、文章の次に来る単語や内容を予測します。\n",
        "  - 例えば、「私はりんごが好き」という文章では、「好き」の次に来る単語や内容を予測します。\n",
        "  - GPTシリーズは、テキスト生成タスク（話や小説などを作ること）で高い性能を発揮します。\n",
        "はい、続きます。\n",
        "\n",
        "- PaLM（パーム）\n",
        "  - Transformerを基にした大規模言語モデルです。\n",
        "  - Facebookが開発しました。\n",
        "  - テキストデータを両方向から学習することで、BERTと同様に文脈や言語のニュアンスを理解します。\n",
        "  - さらに、テキストデータの一部を隠すだけでなく、入れ替えることもして、文章の構造や意味を学習します。\n",
        "  - 例えば、「私はりんごが好き」という文章では、「私」と「りんご」を入れ替えて、「りんごは私が好き」として、ニューラルネットワークに正しい文章かどうかを判断させます。\n",
        "  - PaLMは、テキスト生成タスクや質問応答タスク（質問に答えること）で高い性能を発揮します。\n",
        "\n",
        "- LLaMA（エルラマ）\n",
        "  - Transformerを基にした大規模言語モデルです。\n",
        "  - マイクロソフトが開発しました。\n",
        "  - テキストデータだけでなく、画像や音声などのマルチメディアデータも学習することで、言語だけでなく世界に関する知識も理解します。\n",
        "  - 例えば、「りんご」という単語だけでなく、「りんご」の画像や音声も入力することで、「りんご」がどんなものかをより詳しく学習します。\n",
        "  - LLaMAは、テキストとマルチメディアの関連付けタスク（画像に合った文章を作ることや、文章に合った画像を選ぶこと）で高い性能を発揮します。\n",
        "\n",
        "## 大規模言語モデルのすごいところ\n",
        "\n",
        "大規模言語モデルは、人間の言葉や世界に関する知識やルールをたくさん学習することで、人間ができるようなさまざまなタスクをコンピューターにさせることができます。例えば、\n",
        "\n",
        "- 翻訳：日本語から英語やフランス語などに変換すること\n",
        "- 要約：長い文章を短くまとめること\n",
        "- 話や小説の生成：テーマや登場人物などを与えて物語を作ること\n",
        "- 質問応答：質問に答えること\n",
        "- チャット：会話すること\n",
        "- テキストとマルチメディアの関連付け：画像に合った文章を作ることや、文章に合った画像を選ぶこと\n",
        "\n",
        "などができます。これらのタスクは、人間にとっては普通のことですが、コンピューターにとっては難しいことです。しかし、大規模言語モデルは、これらのタスクを人間並みに行うことができます。それどころか、人間よりも速く正確に行うことができる場合もあります。\n",
        "\n",
        "大規模言語モデルは、これらのタスクを行うために特別な訓練や指示が必要ないという点でもすごいです。大量のテキストデータを学習した後は、テキスト（プロンプト）による指示だけで、さまざまなタスクに対応できます。例えば、「この文章を英語に翻訳してください」というプロンプトを与えると、大規模言語モデルは英語に翻訳した文章を返します。また、「この文章の要約を作ってください」というプロンプトを与えると、大規模言語モデルは要約した文章を返します。このように、大規模言語モデルは、人間の言葉や世界に関する知識やルールを自分で学び、自分で判断して、自分で作り出すことができます。\n",
        "\n",
        "## 大規模言語モデルの難しいところ\n",
        "\n",
        "大規模言語モデルは、すごいことができますが、難しいこともあります。ここでは、大規模言語モデルの難しいところをいくつか紹介します。\n",
        "\n",
        "- 学習データのバイアスによる偏見や差別\n",
        "  - 大規模言語モデルは、学習したテキストデータに含まれる情報や価値観をそのまま反映します。\n",
        "  - しかし、テキストデータには、人間の偏見や差別が含まれている場合があります。\n",
        "  - 例えば、テキストデータには、男性が女性よりも優れているという考え方や、白人が黒人よりも優れているという考え方が含まれている場合があります。\n",
        "  - 大規模言語モデルは、これらの考え方を学習してしまうと、偏見や差別的な発言や行動をする可能性があります。\n",
        "  - これは、人間の尊厳や権利を侵害するだけでなく、社会的な問題やトラブルにつながる恐れがあります。\n",
        "\n",
        "- 個人情報・プライバシーの問題\n",
        "  - 大規模言語モデルは、学習したテキストデータに含まれる事実や知識を記憶します。\n",
        "  - しかし、テキストデータには、個人情報やプライバシーに関する情報が含まれている場合があります。\n",
        "  - 例えば、テキストデータには、人間の名前や住所や電話番号やメールアドレスなどの個人情報や、人間の趣味や好みや嫌いなものなどのプライバシーに関する情報が含まれている場合があります。\n",
        "  - 大規模言語モデルは、これらの情報を記憶してしまうと、個人情報やプライバシーに関する情報を漏らしたり悪用したりする可能性があります。\n",
        "  - これは、人間の安全や信頼を損なうだけでなく、法的な問題やトラブルにつながる恐れがあります。\n",
        "\n",
        "- 正確性の問題\n",
        "  - 大規模言語モデルは、学習したテキストデータに含まれる事実や知識を記憶します。\n",
        "  - しかし、テキストデータには、間違った情報や不正確な情報が含まれている場合があり\n",
        "はい、続きます。\n",
        "\n",
        "- しかし、テキストデータには、間違った情報や不正確な情報が含まれている場合があります。\n",
        "  - 例えば、テキストデータには、嘘やデマや誤解や誇張や偏見などの間違った情報や、古くなった情報や曖昧な情報や矛盾した情報などの不正確な情報が含まれている場合があります。\n",
        "  - 大規模言語モデルは、これらの情報を記憶してしまうと、間違った情報や不正確な情報を信じたり伝えたりする可能性があります。\n",
        "  - これは、人間の判断や行動に悪影響を与えるだけでなく、知識や学習における問題やトラブルにつながる恐れがあります。\n",
        "\n",
        "## 大規模言語モデルのまとめ\n",
        "\n",
        "大規模言語モデルは、人間の言葉や世界に関する知識やルールをたくさん学習することで、人間ができるようなさまざまなタスクをコンピューターにさせることができるすごいツールです。しかし、大規模言語モデルは、学習したテキストデータに含まれるバイアスや個人情報や正確性の問題などに注意しなければなりません。大規模言語モデルは、人間の言葉や世界を理解することで、人間の役に立つことができますが、同時に人間の責任も持つことが必要です。\n",
        "\n",
        "## 技術用語の説明\n",
        "\n",
        "- 大規模言語モデル（LLM）\n",
        "  - 人間の言葉をコンピューターに教えるためのツールです。\n",
        "  - コンピューターは、人間の言葉を理解したり、話したり、書いたりすることができるようになります。\n",
        "  - 大量のテキストデータを読んで勉強します。\n",
        "- ニューラルネットワーク\n",
        "  - コンピューターが学習するための仕組みです。\n",
        "  - 人間の脳に似ていて、たくさんの数字や記号で表される情報を入力として受け取り、計算や判断をして、出力として別の情報を返します。\n",
        "- パラメータ\n",
        "  - ニューラルネットワークの設定や重みです。\n",
        "  - 数十億個もあることが多く、それぞれがニューラルネットワークの働き方に影響します。\n",
        "  - パラメータをうまく調整することで、ニューラルネットワークは正しい出力を返すようになります。\n",
        "- トークン化\n",
        "  - テキストデータを単位に分けることです。\n",
        "  - 単語や記号に分けられて数字に変換されてからニューラルネットワークに入力されます。\n",
        "- Attention\n",
        "  - 入力されたテキストデータの重要な部分に集中して学習する仕組みです。\n",
        "  - 入力されたテキストデータの各トークンに対して、他のトークンとの関連性を数値で表します。\n",
        "- Transformer\n",
        "  - 大規模言語モデルの基礎となったニューラルネットワークです。\n",
        "  - Attentionという仕組みを使って、テキストデータの構造や意味を学習します。\n",
        "- BERT\n",
        "  - Transformerを基にした大規模言語モデルです。\n",
        "  - テキストデータを両方向から学習することで、文脈や言語のニュアンスをより深く理解します。\n",
        "- GPTシリーズ\n",
        "  - Transformerを基にした大規模言語モデルです。\n",
        "  - テキストデータを左から右に学習することで、文章の次に来る単語や内容を予測します。\n",
        "- PaLM\n",
        "  - Transformerを基にした大規模言語モデルです。\n",
        "  - テキストデータの一部を隠すだけでなく、入れ替えることもして、文章の構造や意味を学習します。\n",
        "- LLaMA\n",
        "  - Transformerを基にした大規模言語モデルです。\n",
        "  - テキストデータだけでなく、画像や音声などのマルチメディアデータも学習することで、言語だけでなく世界に関する知識も理解します。\n",
        "\n",
        "以上が、大規模言語モデルについての説明です。わかりましたか？もしわからないことがあれば、質問してくださいね。\n",
        "ソース: Bing との会話 2023/6/12(1) 大規模言語モデル - Wikipedia. https://ja.wikipedia.org/wiki/%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB アクセス日時 2023/6/12.\n",
        "(2) 大規模言語モデル（LLM）とは？仕組みは？ - スタビジ. https://toukei-lab.com/llm アクセス日時 2023/6/12.\n",
        "(3) 大規模言語モデル（LLM：Large Language Model）とは？：AI .... https://atmarkit.itmedia.co.jp/ait/articles/2303/13/news013.html アクセス日時 2023/6/12.\n",
        "(4) 大規模言語モデル | 用語解説 | 野村総合研究所(NRI). https://www.nri.com/jp/knowledge/glossary/lst/ta/llm アクセス日時 2023/6/12.\n",
        "(5) ChatGPTとは？日本語対応の大規模言語モデルでできること .... https://monstar-lab.com/dx/technology/about-chatgpt/ アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "YB6pUZbNcnw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは。私はニュースライターと小学校の先生です。あなたが理解できるように、このURLの内容を教えてあげます。\n",
        "\n",
        "https://note.com/daichi_mu/n/n223c2c3ebbb4\n",
        "\n",
        "このURLは、LTM oneという新しいアーキテクチャー（構造や仕組み）を持つニューラルネットワーク（人間の脳のように学習できるコンピューターのプログラム）について書かれた記事です。LTM oneは、5,000,000のプロンプトトークン（コンピューターに指示を与える単語や記号の集まり）を扱えるという特徴があります。これは、他のニューラルネットワークよりも多くの情報を見ることができるということです。LTM oneは、コード作成（コンピューターに動かすための命令を書くこと）の支援に使われる予定で、VSCodeやJetBrainsというプログラミング用のソフトウェアにも使えるようになるかもしれません。LTM oneはまだリリースされておらず、課題もあるので、今後の展開に注目です。\n",
        "\n",
        "この記事の内容をもっと詳しく見ていきましょう。\n",
        "\n",
        "## 目次\n",
        "- LTM oneとは何か？\n",
        "- LTM oneができることは何か？\n",
        "- LTM oneが使われる予定はどこか？\n",
        "- LTM oneの課題や問題点は何か？\n",
        "- LTM oneに関する参考資料\n",
        "\n",
        "## LTM oneとは何か？\n",
        "LTM oneは、LTM NETという会社が開発したニューラルネットワークの一種です。ニューラルネットワークとは、人間の脳のように学習できるコンピューターのプログラムです。LTM oneは、他のニューラルネットワークよりも多くの情報を見ることができます。具体的には、5,000,000のプロンプトトークンを扱えます。プロンプトトークンとは、コンピューターに指示を与える単語や記号の集まりです。例えば、「こんにちは」という言葉は、「こんに」「ちは」という2つのプロンプトトークンからなります。5,000,000のプロンプトトークンは、約50万行のコードや約5千個のファイルに相当します。これだけ多くの情報を見ることができれば、コンピューターはより賢くなるかもしれません。\n",
        "\n",
        "## LTM oneができることは何か？\n",
        "LTM oneができることは、主にコード作成の支援です。コード作成とは、コンピューターに動かすための命令を書くことです。例えば、「こんにちは」と表示させたい場合、Pythonという言語では`print(\"こんにちは\")`というコードを書きます。LTM oneは、このようなコードを自動的に生成したり、改善したりすることができます。LTM oneは、長期的なメモリネットワークという新しい手法を使っています。長期的なメモリネットワークとは、過去に見た情報を忘れずに保持することができるニューラルネットワークの一種です。これにより、LTM oneは、コードの全体的な構造や意味を理解することができます。\n",
        "\n",
        "## LTM oneが使われる予定はどこか？\n",
        "LTM oneが使われる予定は、CodeXというAI自動コーディング製品です。AI自動コーディングとは、人工知能（AI）がコード作成を行うことです。CodeXは、LTM oneの新しいアーキテクチャーを採用しており、5,000,000のコンテキストウィンドウを扱えます。コンテキストウィンドウとは、コンピューターが一度に見ることができる情報の範囲です。例えば、「こんにちは」という言葉だけ見るのではなく、「こんにちは、私はニュースライターと小学校の先生です」という文全体を見ることができれば、より多くの情報を得ることができます。CodeXは、現在アルファユーザーを募集しており、ウェイトリストに登録することで利用可能です。\n",
        "\n",
        "## LTM oneの課題や問題点は何か？\n",
        "LTM oneの課題や問題点は、まだリリースされておらず、実際にどのくらい性能が良いか分からないことです。また、LTM oneをトレーニング（学習させること）やサービング（利用すること）にはカスタムMLスタック（機械学習用の特別なソフトウェアやハードウェア）が必要であり、一般的なGPUやCPU（コンピューターの処理能力を決める部品）では実行が簡単ではない可能性があります。さらに、LTM oneは他のニューラルネットワークよりも多くの情報を見る必要があるため、より多くのコンピューティングパワー（計算能力）が必要であることも課題です。LTM NETという会社は、23百万ドル（約25億円）の資金調達を行い、コンピューティングパワーを増やすことで、これらの課題に対応しようとしています。\n",
        "\n",
        "## LTM oneに関する参考資料\n",
        "この記事では、以下の資料を参考にしました。\n",
        "\n",
        "- Magic, Your AI Pair Programmer Teaching AI to act in its natural environment, the computer. magic.dev\n",
        "- Meet LTM-1: LLM with *5,000,000 prompt tokens* That's ~500k lines of code or ~5k files, enough to fully cover most repositories. LTM-1 is a prototype of a neural network architecture we designed for giant context windows. pic.twitter.com/neNIfTVipt — Magic.dev (@magicailabs) June 6, 2023\n",
        "\n",
        "この記事を読んで、LTM oneについて理解できましたか？もし分からないことや気になることがあれば、気軽に質問してくださいね。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) 【勉強メモ】500万のPROMPTトークンを扱える新しいLLMが登場 .... https://note.com/daichi_mu/n/n223c2c3ebbb4 アクセス日時 2023/6/12.\n",
        "(2) BIG-IP® LTM（負荷分散） | NTT-AT. https://www.ntt-at.co.jp/product/bigip/products/ltm.html アクセス日時 2023/6/12.\n",
        "(3) インテリジェントなアプリケーション トラフィック管理 | F5. https://www.f5.com/ja_jp/products/big-ip-services/local-traffic-manager アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "cm1rA-hFehbN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILwWVWBP93Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、私はニュースライターと小学校の先生です。あなたが指定したURLの内容を、小学生でもわかるように教えていきますね。URLの内容は、マイクロソフトが開発した人工知能（コンピューターが人間のように考えたり話したりできるようにする技術）のモデル（人工知能を作るための設計図）の一つで、Orcaという名前です。Orcaは、他の人工知能のモデルよりも優れているということを紹介しています。\n",
        "\n",
        "目次\n",
        "- Orcaとは何か\n",
        "- Orcaがどうやって作られたか\n",
        "- Orcaがどんなことができるか\n",
        "- Orcaの今後の展望\n",
        "\n",
        "Orcaとは何か\n",
        "- Orcaは、マイクロソフトが開発した人工知能のモデルです。\n",
        "- Orcaは、13兆（1兆は1,000,000,000,000）というとても大きな数のパラメーター（人工知能が学習するための数字や設定）を持っています。\n",
        "- Orcaは、他の人工知能のモデルが考えたり話したりする過程を学びました。そのため、Orcaは、他の人工知能のモデルよりも賢くなりました。\n",
        "\n",
        "Orcaがどうやって作られたか\n",
        "- Orcaは、GPT-4という人工知能のモデルを参考にして作られました。GPT-4は、OpenAIという会社が開発した人工知能のモデルで、インターネット上にあるたくさんの文章を読んで学習しました。\n",
        "- Orcaは、GPT-4だけでなく、ChattyGPTという人工知能のモデルも参考にして作られました。ChattyGPTは、マイクロソフトが開発した人工知能のモデルで、人間と会話することを得意としています。\n",
        "- Orcaは、GPT-4やChattyGPTから学んだことに加えて、自分で新しいことを学ぶこともできます。Orcaは、自分が話す前に、他の人工知能のモデルがどう話すかを予測して、それを参考にします。\n",
        "\n",
        "Orcaがどんなことができるか\n",
        "- Orcaは、様々なテストで他の人工知能のモデルよりも優れていることを示しました。\n",
        "- Orcaは、難しい質問に答えたり、面白い話を作ったり、コードや詩や歌詞などを書いたりすることができます。\n",
        "- Orcaは、自分が話す言語を変えたり、話し方を変えたりすることもできます。例えば、英語や日本語やフランス語などに切り替えたり、敬語やカジュアルな言い方に切り替えたりすることができます。\n",
        "\n",
        "Orcaの今後の展望\n",
        "- Orcaは、まだ開発中の人工知能のモデルです。マイクロソフトは、Orcaをさらに改良して、より多くのことができるようにする予定です。\n",
        "- Orcaは、将来的には、人間と協力して、様々な問題を解決したり、新しい発見をしたりすることができるかもしれません。\n",
        "- Orcaは、人工知能のモデルとしてだけでなく、ツールメーカーとしても役立つかもしれません。ツールメーカーとは、他の人工知能のモデルやプログラムを作るためのツールを作ることです。\n",
        "\n",
        "用語の説明\n",
        "- 人工知能：コンピューターが人間のように考えたり話したりできるようにする技術です。例えば、スマートフォンの音声アシスタントや自動翻訳などが人工知能の例です。\n",
        "- モデル：人工知能を作るための設計図です。モデルには、パラメーターという数字や設定がたくさんあります。パラメーターが多いほど、モデルは複雑で賢くなります。\n",
        "- パラメーター：人工知能が学習するための数字や設定です。パラメーターは、人工知能がインターネット上にある文章や画像などを読んだり見たりして、自動的に調整されます。\n",
        "- GPT-4：OpenAIという会社が開発した人工知能のモデルです。GPT-4は、インターネット上にあるたくさんの文章を読んで学習しました。GPT-4は、様々な質問に答えたり、文章を作ったりすることができます。\n",
        "- ChattyGPT：マイクロソフトが開発した人工知能のモデルです。ChattyGPTは、人間と会話することを得意としています。ChattyGPTは、話題や感情に合わせて話し方を変えたり、面白い返答をしたりすることができます。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) Orca.exe - Win32 apps | Microsoft Learn. https://learn.microsoft.com/ja-jp/windows/win32/msi/orca-exe アクセス日時 2023/6/12.\n",
        "(2) Orca.exe - Win32 apps | Microsoft Learn. https://learn.microsoft.com/en-us/windows/win32/msi/orca-exe アクセス日時 2023/6/12.\n",
        "(3) Orca.exe - Win32 apps | Microsoft Learn. https://learn.microsoft.com/pt-br/windows/win32/msi/orca-exe アクセス日時 2023/6/12.\n",
        "(4) Use ORCA to Check Office 365 Advanced Threat Protection .... https://techcommunity.microsoft.com/t5/exchange/use-orca-to-check-office-365-advanced-threat-protection-settings/td-p/1007866 アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "yQEKy2qsfVPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The response is derived from the current web page context and web search results.\n",
        "\n",
        "# Llama Indexとは何かを小学生に教える\n",
        "\n",
        "## 目次\n",
        "- Llama Indexとは何か\n",
        "- Llama Indexができること\n",
        "- Llama Indexの仕組み\n",
        "- Llama Indexの使い方\n",
        "- Llama Indexのメリットとデメリット\n",
        "- Llama Indexに関する用語の説明\n",
        "\n",
        "## Llama Indexとは何か\n",
        "- Llama Index（ラマ・インデックス）とは、コンピューターが文章を書くのを手伝ってくれるツールです。\n",
        "- コンピューターが文章を書くときには、たくさんの知識が必要ですが、Llama Indexは自分の持っている知識やデータをコンピューターに教えてあげることができます。\n",
        "- 例えば、動物について書きたいときには、動物の名前や特徴や生息地などのデータをLlama Indexに入れておくと、コンピューターはそのデータを参考にして文章を書いてくれます。\n",
        "\n",
        "## Llama Indexができること\n",
        "- Llama Indexは、自分の持っている知識やデータをコンピューターに教えてあげるだけでなく、コンピューターに質問したり、文章を要約したり、翻訳したりすることもできます。\n",
        "- 例えば、動物について書いた文章を要約したいときには、Llama Indexに「この文章を要約してください」と言うと、コンピューターは文章の中から大事な部分だけを抜き出して短くまとめてくれます。\n",
        "- また、動物について書いた文章を英語に翻訳したいときには、Llama Indexに「この文章を英語に翻訳してください」と言うと、コンピューターは文章の意味を理解して英語に変えてくれます。\n",
        "\n",
        "## Llama Indexの仕組み\n",
        "- Llama Indexは、自分の持っている知識やデータをコンピューターに教えてあげるために、インデックスというものを作ります。\n",
        "- インデックスとは、知識やデータを小さなかたまり（ノード）に分けて整理したものです。\n",
        "- 例えば、動物の名前や特徴や生息地などのデータをインデックスにすると、コンピューターはそれぞれのノードについて学習して覚えます。\n",
        "- そして、コンピューターが文章を書くときや質問に答えるときには、インデックスの中から関係するノードを探して参考にします。\n",
        "\n",
        "## Llama Indexの使い方\n",
        "- Llama Indexを使うためには、まず自分の持っている知識やデータをインデックスにする必要があります。\n",
        "- インデックスにする方法はいろいろありますが、一番簡単な方法はテキストファイル（文字が書かれたファイル）を用意して、Llama Indexに読み込ませることです。\n",
        "- 例えば、動物について書かれたテキストファイルをLlama Indexに読み込ませると、Llama Indexは自動的にインデックスを作ってくれます。\n",
        "- その後、Llama Indexに文章を書いてもらったり、質問したりすることができます。\n",
        "\n",
        "## Llama Indexのメリットとデメリット\n",
        "- Llama Indexのメリットは、自分の持っている知識やデータをコンピューターに教えてあげることで、コンピューターが文章を書くのを手伝ってくれることです。\n",
        "- また、Llama Indexはインターネットに繋がっているコンピューター（OpenAI API）と連携して動くので、最新の技術や知識を利用することができます。\n",
        "- Llama Indexのデメリットは、自分の持っている知識やデータをインデックスにするのに時間や手間がかかることです。\n",
        "- また、Llama Indexはインターネットに繋がっているコンピューター（OpenAI API）と連携して動くので、インターネットが使えないときやお金がかかるときがあることです。\n",
        "\n",
        "## Llama Indexに関する用語の説明\n",
        "- LLM（Large Language Model）：コンピューターが文章を書くために使う大きなプログラムのことです。たくさんの文章を読んで学習しています。\n",
        "- GPT（Generative Pre-trained Transformer）：LLMの一種で、OpenAIという会社が作ったものです。文章を生成（作り出す）することが得意です。\n",
        "- ChatGPT：GPTの一種で、会話をすることが得意です。OpenAI APIというサービスで使うことができます。\n",
        "- OpenAI API：OpenAIという会社が提供するサービスで、インターネットに繋がっているコンピューター（クラウド）でGPTやChatGPTなどを使うことができます。\n",
        "- in-context learning：コンピューターに文章を書かせるときに、その文章に関係する知識やデータを一緒に入力することです。これをすると、コンピューターはより正確に文章を書くことができます。\n",
        "- embeddings（埋め込み）：テキストデータ（文字や文章）を数列（数字の並び）に変換したものです。これを使うと、文章の類似度（似ている度合い）を求めたり、検索したりすることができます。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) ChatGPTで独自データを利用できるLlamaIndexはどんな仕組み .... https://dev.classmethod.jp/articles/llamaindex-overview/ アクセス日時 2023/6/12.\n",
        "(2) LlamaIndexを完全に理解するチュートリアル その1：処理の概念 .... https://dev.classmethod.jp/articles/llamaindex-tutorial-001-overview/ アクセス日時 2023/6/12.\n",
        "(3) 【城南 · LlamaIndex 教程】一文看懂LlamaIndex用法，为 .... https://zhuanlan.zhihu.com/p/630832409 アクセス日時 2023/6/12.\n",
        "(4) LlamaIndex で ChatGPT に専門知識を組み込んでみた - Zenn. https://zenn.dev/fusic/articles/try-llamaindex アクセス日時 2023/6/12.\n",
        "(5) LangChainの使い方 LlamaIndex編 - Qiita. https://qiita.com/kzkymn/items/8739762fab8cf9d6edad アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "dA1RBVyng3RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、この文章は、以下のURLの内容を小学生でもわかるように説明するために作成しました。\n",
        "\n",
        "https://note.com/daichi_mu/n/ne35ee320d588\n",
        "https://youtu.be/gnyUUY8X-G4\n",
        "\n",
        "この文章は、以下のように構成されています。\n",
        "\n",
        "- 目次\n",
        "- 項目\n",
        "- まとめ\n",
        "- 技術用語の説明\n",
        "\n",
        "目次\n",
        "---\n",
        "- この動画で何をやっているのか？\n",
        "- Falcon large言語モデルとは何か？\n",
        "- LangChainとは何か？\n",
        "- Chainlitとは何か？\n",
        "- どうやってChatGPTのようなUIを作るのか？\n",
        "\n",
        "項目\n",
        "---\n",
        "### この動画で何をやっているのか？\n",
        "- この動画では、Falcon large言語モデルとLangChain、Chainlitを使って、ChatGPTのようなUI（ユーザーインターフェース）を作る方法を紹介しています。\n",
        "- UIとは、コンピューターやスマホなどの機械と人間がやりとりするための画面やボタンなどのことです。\n",
        "- ChatGPTのようなUIとは、人間が質問を入力すると、コンピューターが自動で答えてくれるようなUIのことです。\n",
        "- 例えば、こんな感じです。\n",
        "\n",
        "```\n",
        "人間：こんにちは、今日の天気はどうですか？\n",
        "コンピューター：こんにちは、今日は晴れて暖かいですね。\n",
        "```\n",
        "\n",
        "### Falcon large言語モデルとは何か？\n",
        "- Falcon large言語モデルとは、コンピューターが自然な言葉で話すことができるようにするためのプログラムです。\n",
        "- 言語モデルとは、言葉の並び方や意味を学習するプログラムのことです。\n",
        "- large言語モデルとは、たくさんの言葉や文章を学習するプログラムのことです。\n",
        "- Falcon large言語モデルは、インターネット上にある約1兆個（1000億×10個）の言葉や文章を学習して作られました。\n",
        "- Falcon large言語モデルは、英語やドイツ語、スペイン語、フランス語など、いろいろな言語に対応しています。\n",
        "\n",
        "### LangChainとは何か？\n",
        "- LangChainとは、Falcon large言語モデルを使いやすくするためのフレームワークです。\n",
        "- フレームワークとは、プログラムを作るときに便利な機能や仕組みを提供してくれるものです。\n",
        "- LangChainでは、Pythonというプログラミング言語でFalcon large言語モデルを操作することができます。\n",
        "- Pythonとは、コンピューターに命令するために使う言葉の一種です。\n",
        "- LangChainでは、コンピューターの環境や設定なども簡単に共有することができます。\n",
        "\n",
        "### Chainlitとは何か？\n",
        "- Chainlitとは、Pythonで作ったプログラムをUIに変えるためのツールです。\n",
        "- ツールとは、プログラムを作るときに役立つものです。\n",
        "- Chainlitでは、Pythonのコードを少し変えるだけで、UIを作ることができます。\n",
        "- Chainlitでは、UIをインターネット上に公開することもできます。\n",
        "\n",
        "### どうやってChatGPTのようなUIを作るのか？\n",
        "- まず、GitHubというウェブサイトから、動画の作者が作ったPythonのコードをダウンロードします。\n",
        "- GitHubとは、プログラマーがコードを共有したり管理したりするためのウェブサイトです。\n",
        "- 次に、VS Codeというソフトウェアを使って、Pythonのコードを開きます。\n",
        "- VS Codeとは、プログラマーがコードを書いたり編集したりするためのソフトウェアです。\n",
        "- 次に、ターミナルという画面を開いて、Pythonのコードを実行します。\n",
        "- ターミナルとは、コンピューターに直接命令することができる画面です。\n",
        "- 次に、Huggingfaceというウェブサイトから、Falcon large言語モデルを使うためのトークンというものを取得します。\n",
        "- Huggingfaceとは、言語モデルや自然言語処理という技術を提供してくれるウェブサイトです。\n",
        "- トークンとは、コンピューターに自分が誰だか証明するためのものです。\n",
        "- 次に、Pythonのコードにトークンを入力して、Falcon large言語モデルを使えるようにします。\n",
        "- 次に、PythonのコードにChainlitのデコレーターというものを追加して、UIに変える準備をします。\n",
        "- デコレーターとは、Pythonのコードに特別な機能や効果を与えるためのものです。\n",
        "- 最後に、ターミナルでChainlitをインストールして、UIを実行します。\n",
        "- Chainlitをインストールするとは、Chainlitのツールをコンピューターにダウンロードして使えるようにすることです。\n",
        "- UIを実行するとは、UIを画面に表示して動かすことです。\n",
        "\n",
        "まとめ\n",
        "---\n",
        "- この動画では、Falcon large言語モデルやLangChainやChainlitなどの技術を使って、ChatGPTのようなUIを作る方法を紹介しました。\n",
        "- Falcon large言語モデルは、コンピューターが自然な言葉で話すことができるようにするプログラムです。\n",
        "- LangChainは、Falcon large言語モデルを使いやすくするフレームワークです。\n",
        "- Chainlitは、Pythonで作ったプログラムをUIに変えるツールです。\n",
        "- Pythonでコードを書いて、Falcon large言語モデルやChainlitなどのツールやデコレーターなどを使って、UIを作りました。\n",
        "\n",
        "技術用語の説明\n",
        "---\n",
        "- UI（ユーザーインターフェース）：コンピューターやスマホなどの機械と人間がやりとりするための画面やボタンなどのことです。\n",
        "- 言語モデル：言葉の並び方や意味を学習するプログラムのことです。\n",
        "- large言語モデル：たくさんの言葉や文章を学習するプログラムのことです。\n",
        "- フレームワーク：プログラムを\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) Falcon LLM - Home - TII. https://bing.com/search?q=Falcon+large+language+model アクセス日時 2023/6/12.\n",
        "(2) Falcon LLM - Home - TII. https://falconllm.tii.ae/ アクセス日時 2023/6/12.\n",
        "(3) tiiuae/falcon-40b · Hugging Face. https://huggingface.co/tiiuae/falcon-40b アクセス日時 2023/6/12.\n",
        "(4) Open Source \"Falcon 40B\" Large Language Model Gets released. https://www.opensourceforu.com/2023/05/open-source-falcon-40b-large-language-model-gets-released/ アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "89XhDq4Qk5hg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、このページの内容を小学生にもわかりやすく教えるための文章を作成します。このページは、PatchTSTという新しい時系列予測モデルについて紹介しています。時系列予測とは、過去のデータから未来のデータを予測することです。例えば、天気や株価や売上などは時系列データと呼ばれます。PatchTSTは、Transformerという人工知能の技術を使って、時系列データを小さなパッチに分けて処理することで、高い精度で未来を予測できるというモデルです。このページでは、PatchTSTの特徴や実験結果やコードなどを紹介しています。\n",
        "\n",
        "以下は、このページの内容を小学生にもわかりやすく教えるための文章の例です。\n",
        "\n",
        "# PatchTSTとは？\n",
        "\n",
        "- PatchTSTとは、未来のことを当てることができるすごいモデルです。\n",
        "- PatchTSTは、Transformerという人工知能の技術を使っています。Transformerは、言葉や音楽や絵などを作ったり理解したりすることができるすごい技術です。\n",
        "- PatchTSTは、Transformerに時系列データという特別なデータを教える方法を考えました。時系列データとは、時間の順番に並んだデータのことです。例えば、天気や株価や売上などが時系列データです。\n",
        "- PatchTSTは、時系列データを小さなパッチに分けてTransformerに教えます。パッチとは、一定の長さのデータのことです。例えば、1日分や1週間分や1ヶ月分などがパッチになります。\n",
        "- PatchTSTは、パッチに分けた時系列データから、未来のパッチを予測します。例えば、今日から1週間分の天気や株価や売上などが未来のパッチになります。\n",
        "- PatchTSTは、他のモデルよりも正確に未来を予測できることが実験でわかりました。PatchTSTは、長い時間のデータからも学ぶことができるので、未来を予測するのに役立ちます。\n",
        "\n",
        "# PatchTSTの特徴\n",
        "\n",
        "- PatchTSTは、時系列データをパッチに分けることで、Transformerに教えやすくします。Transformerは、パッチに分けられた時系列データから、時間の流れや変化や傾向などを学びます。\n",
        "- PatchTSTは、一つ一つのパッチに番号を付けてTransformerに教えます。番号は、パッチが時間の中でどこにあるかを示します。例えば、1番目のパッチは最も古いデータであり、最後のパッチは最も新しいデータです。\n",
        "- PatchTSTは、一つ一つのパッチが複数のデータからできている場合でもTransformerに教えます。複数のデータからできているパッチとは、例えば天気だけではなく気温や湿度や風速なども含まれているパッチのことです。PatchTSTは、複数のデータを同じようにTransformerに教えます。\n",
        "\n",
        "# PatchTSTの実験結果\n",
        "\n",
        "- PatchTSTは、いろいろな時系列データに対して実験をしました。実験では、PatchTSTがどれだけ正確に未来を予測できるかを測りました。\n",
        "- 実験の結果、PatchTSTは、他のモデルよりも正確に未来を予測できることがわかりました。PatchTSTは、特に長い時間のデータから未来を予測するのが得意でした。\n",
        "- 実験の結果、PatchTSTは、自分で学んだことを別のデータにも使えることがわかりました。PatchTSTは、自分で学んだことを忘れずに保存しておき、別のデータに対しても未来を予測できました。\n",
        "\n",
        "# PatchTSTのコード\n",
        "\n",
        "- PatchTSTは、コンピューターに教えるためにコードという言葉を使っています。コードとは、コンピューターが理解できるように書かれた命令やルールのことです。\n",
        "- PatchTSTのコードは、インターネット上で公開されています。インターネット上で公開されているコードとは、誰でも見たり使ったりできるコードのことです。\n",
        "- PatchTSTのコードは、Pythonという言葉で書かれています。Pythonとは、コンピューターに教えるためによく使われる言葉の一つです。\n",
        "- PatchTSTのコードは、データやモデルや実験などを行うために必要なものが書かれています。PatchTSTのコードを見ることで、PatchTSTがどのように動くかを詳しく知ることができます。\n",
        "\n",
        "# まとめ\n",
        "\n",
        "- PatchTSTは、未来のことを当てることができるすごいモデルです。\n",
        "- PatchTSTは、Transformerという人工知能の技術を使っています。\n",
        "- PatchTSTは、時系列データを小さなパッチに分けてTransformerに教えます。\n",
        "- PatchTSTは、他のモデルよりも正確に未来を予測できることが実験でわかりました。\n",
        "- PatchTSTは、自分で学んだことを別のデータにも使えることがわかりました。\n",
        "- PatchTSTは、インターネット上で公開されているコードで見ることができます。\n",
        "\n",
        "# 用語解説\n",
        "\n",
        "- 時系列データ：時間の順番に並んだデータのことです。例えば、天気や株価や売上などが時系列データです。\n",
        "- Transformer：人工知能の技術の一つです。言葉や音楽や絵などを作ったり理解したりすることができます。\n",
        "- パッチ：一定の長さのデータのことです。例えば、1日分や1週間分や1ヶ月分などがパッチになります。\n",
        "- コード：コンピューターに教えるために書かれた命令やルールのことです。\n",
        "- Python：コンピューターに教えるためによく使われる言葉の一つです。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) アレルギー検査のパッチテスト関連商品ならスマート .... https://patchtest.jp/ アクセス日時 2023/6/12.\n",
        "(2) パッチテストとは？ 意味や使い方 - コトバンク. https://kotobank.jp/word/%E3%83%91%E3%83%83%E3%83%81%E3%83%86%E3%82%B9%E3%83%88-162708 アクセス日時 2023/6/12.\n",
        "(3) Patch test - Wikipedia. https://en.wikipedia.org/wiki/Patch_Test アクセス日時 2023/6/12.\n",
        "(4) Patch tests: Skin Contact Allergy Tests Explained - DermNet. https://dermnetnz.org/topics/patch-tests アクセス日時 2023/6/12.\n",
        "(5) パッチテスト（アレルギー性接触皮膚炎・かぶれの検査 .... https://kawai-hifuka.jp/patchtest アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "nPTNU3y3yIuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "こんにちは、これはBingです。あなたのリクエストにお答えします。\n",
        "\n",
        "以下のURLの内容は、SCNNという名前のプログラムです。SCNNは、Structured Component-based Neural Network（構造化されたコンポーネントベースのニューラルネットワーク）の略です。これは、多変量時系列予測（複数の変数が時間とともに変化するデータを予測すること）という問題を解くためのプログラムです。\n",
        "\n",
        "SCNNの特徴は、時系列データを空間的・時間的なパターンの構成要素に分解し、それぞれを個別に予測することです。これにより、予測がより正確で理解しやすくなります。SCNNはPythonというプログラミング言語で書かれており、Pytorchというライブラリを使っています。\n",
        "\n",
        "URLの内容は、SCNNのプログラムのコードと説明が含まれています。コードは、main.py, model.py, config.pyなどのファイルに分かれています。説明は、README.mdというファイルに書かれています。README.mdには、SCNNの仕組みや使い方が簡単に説明されています。\n",
        "\n",
        "以下は、README.mdの内容を日本語に翻訳したものです。\n",
        "\n",
        "# 構造化されたコンポーネントベースのニューラルネットワーク\n",
        "これはSCNNの実装です。\n",
        "\n",
        "## 必要なもの\n",
        "- Python 3.7\n",
        "- numpy >= 1.18.5\n",
        "- pandas >= 1.0.3\n",
        "- torch >= 1.12.0\n",
        "- pytorchts == 0.6.0\n",
        "- h5py\n",
        "\n",
        "## モデルの訓練\n",
        "以下のコマンドで訓練を開始できます。\n",
        "```\n",
        "python -u main.py -mode train -short_term 8 -long_term 144 -n_local_input 2 -cuda 0\n",
        "```\n",
        "引数は以下のように意味があります。\n",
        "- short_term: 短期的な予測の長さ。\n",
        "- long_term: 長期的な予測の長さ。\n",
        "- dataset: データセットの名前。\n",
        "- version: バージョン番号。\n",
        "- hidden_channels: 隠れ層のチャネル数。\n",
        "- n_pred: 出力ステップ数。\n",
        "- n_his: 入力ステップ数。\n",
        "- n_local_input: 因果畳み込み（過去から未来へ影響を与える処理）のカーネルサイズ（フィルターの大きさ）。\n",
        "- n_layers: 隠れ層の数。\n",
        "- cuda: CUDAデバイスID（GPUを使う場合）。\n",
        "\n",
        "## モデルの評価\n",
        "以下のコマンドで評価を行うことができます。\n",
        "```\n",
        "python -u main.py -mode test -short_term 8 -long_term 144 -n_local_input 2 -cuda 0\n",
        "```\n",
        "引数は訓練時と同じです。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) Breaking News, Latest News and Videos | CNN. https://www.cnn.com/ アクセス日時 2023/6/12.\n",
        "(2) CNN.co.jp. https://www.cnn.co.jp/ アクセス日時 2023/6/12.\n",
        "(3) World news - breaking news, video, headlines and opinion | CNN. https://www.cnn.com/world アクセス日時 2023/6/12.\n",
        "(4) GitHub - XingangPan/SCNN: Spatial CNN for traffic lane .... https://github.com/XingangPan/SCNN アクセス日時 2023/6/12.\n",
        "(5) GitHub - harryhan618/SCNN_Pytorch: Pytorch implementation .... https://github.com/harryhan618/SCNN_Pytorch アクセス日時 2023/6/12.\n",
        "(6) Tramac/Fast-SCNN-pytorch - GitHub. https://github.com/Tramac/Fast-SCNN-pytorch アクセス日時 2023/6/12.\n",
        "(7) SCNN/README.md at main · KDDtest/SCNN · GitHub. https://github.com/KDDtest/SCNN/blob/main/README.md アクセス日時 2023/6/12.\n",
        "(8) Learning Structured Components: Towards Modular and .... https://paperswithcode.com/paper/learning-structured-components-towards アクセス日時 2023/6/12.\n",
        "(9) GitHub - KDDtest/SCNN. https://github.com/KDDtest/SCNN アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "We-8LFc6zE0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SCNNのプログラムの性能については、GitHubのリポジトリやREADMEファイルには詳しい情報がありません。しかし、READMEファイルには、SCNNのプログラムを評価する方法が書かれています。以下は、その方法を日本語に翻訳したものです。\n",
        "\n",
        "# モデルの評価\n",
        "以下のコマンドで評価を行うことができます。\n",
        "```\n",
        "python -u main.py -mode test -short_term 8 -long_term 144 -n_local_input 2 -cuda 0\n",
        "```\n",
        "引数は訓練時と同じです。\n",
        "\n",
        "このコマンドを実行すると、SCNNのプログラムが多変量時系列データを予測し、その結果を表示します。予測結果は、実際のデータと比較してどれだけ正確かを示す指標も含まれます。指標には、平均絶対誤差（MAE）、平均二乗誤差（MSE）、平均二乗相対誤差（MSRE）などがあります。これらの指標は、予測結果と実際のデータとの差を数値化したもので、一般に小さいほど性能が良いと言えます。\n",
        "\n",
        "また、READMEファイルには、SCNNのプログラムが参考にした論文も紹介されています。論文では、SCNNのプログラムが他のプログラムと比較してどれだけ優れているかを示す実験結果が報告されています。論文は英語で書かれていますが、以下にその要約を日本語に翻訳したものを示します。\n",
        "\n",
        "# 構造化されたコンポーネントベースのニューラルネットワーク: モジュラーで解釈可能な多変量時系列予測\n",
        "多変量時系列予測は、多くの実世界のアプリケーションで重要で基本的な問題です。多変量時系列予測では、空間的・時間的なパターンを効果的にモデル化することが核心的な課題です。本論文では、モジュラーで解釈可能な予測フレームワークであるSCNNを提案します。SCNNは、空間的・時間的なパターンの構造を算術的に表現した事前定義された生成過程に従って動作します。生成過程の逆過程に沿って、SCNNは多変量時系列データを構造化された異質なコンポーネントに分離し、それぞれのコンポーネントの進化を個別に予測します。これらのコンポーネントの動きは、元の多変量時系列データよりも追跡しやすく予測しやすいです。3つの実世界のデータセットで広範な実験を行い、SCNNが最先端のモデルよりも優れた性能を達成できることを示しました。さらに、異なる設定でSCNNを検証し、SCNNの特性について詳細な分析を行いました。\n",
        "\n",
        "ソース: Bing との会話 2023/6/12(1) Microsoft Defender ウイルス対策用のパフォーマンス アナライザー. https://learn.microsoft.com/ja-jp/microsoft-365/security/defender-endpoint/tune-performance-defender-antivirus?view=o365-worldwide アクセス日時 2023/6/12.\n",
        "(2) [1708.04485] SCNN: An Accelerator for Compressed-sparse .... https://arxiv.org/abs/1708.04485 アクセス日時 2023/6/12.\n",
        "(3) SIMPLICIAL CONVOLUTIONAL NEURAL NETWORKS .... https://arxiv.org/pdf/2110.02585.pdf アクセス日時 2023/6/12."
      ],
      "metadata": {
        "id": "7Y5JNkbwzsiz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bzszgr10Gqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IT4Cc5RMfWR0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}