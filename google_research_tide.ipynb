{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPWBnJG39UqfBeyr/FvsTkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumajirou/-daily-test/blob/main/google_research_tide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "„Ç¶„Çß„ÉñÊ§úÁ¥¢ÁµêÊûú„Å´„Çà„Çã„Å®„ÄÅlich99„Å´„Çà„ÇãTiDE„ÅÆ‰ΩøÁî®ÊñπÊ≥ï„ÇíÊó•Êú¨Ë™û„ÅßË™¨Êòé„Åô„Çã„Å®‰ª•‰∏ã„ÅÆ„Çà„ÅÜ„Å´„Å™„Çä„Åæ„Åô„ÄÇ\n",
        "\n",
        "- „Åæ„Åö„ÄÅGitHub„ÅÆ„É™„Éù„Ç∏„Éà„É™„ÇíËá™ÂàÜ„ÅÆ„É≠„Éº„Ç´„É´„Éû„Ç∑„É≥„Å´„ÇØ„É≠„Éº„É≥„Åó„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ„Çø„Éº„Éü„Éä„É´„ÇÑ„Ç≥„Éû„É≥„Éâ„Éó„É≠„É≥„Éó„Éà„Åß`git clone https://github.com/lich99/TiDE.git`„Å®„ÅÑ„ÅÜ„Ç≥„Éû„É≥„Éâ„Çí‰Ωø„ÅÜ„Åì„Å®„Åß„Åß„Åç„Åæ„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅÁèæÂú®„ÅÆ„Éá„Ç£„É¨„ÇØ„Éà„É™„Å´`TiDE`„Å®„ÅÑ„ÅÜ„Éï„Ç©„É´„ÉÄ„Åå‰ΩúÊàê„Åï„Çå„Åæ„Åô„ÄÇ\n",
        "- Ê¨°„Å´„ÄÅTiDE„ÅÆ„Åü„ÇÅ„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„Çí‰ΩúÊàê„Åó„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ„Çø„Éº„Éü„Éä„É´„ÇÑ„Ç≥„Éû„É≥„Éâ„Éó„É≠„É≥„Éó„Éà„Åß`python -m venv tide_env`„Å®„ÅÑ„ÅÜ„Ç≥„Éû„É≥„Éâ„Çí‰Ωø„ÅÜ„Åì„Å®„Åß„Åß„Åç„Åæ„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅÁèæÂú®„ÅÆ„Éá„Ç£„É¨„ÇØ„Éà„É™„Å´`tide_env`„Å®„ÅÑ„ÅÜ„Éï„Ç©„É´„ÉÄ„Åå‰ΩúÊàê„Åï„Çå„Åæ„Åô„ÄÇ\n",
        "- „Åù„Çå„Åã„Çâ„ÄÅ‰ªÆÊÉ≥Áí∞Â¢É„ÇíÊúâÂäπÂåñ„Åó„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ„Çø„Éº„Éü„Éä„É´„ÇÑ„Ç≥„Éû„É≥„Éâ„Éó„É≠„É≥„Éó„Éà„Åß`source tide_env/bin/activate`„Å®„ÅÑ„ÅÜ„Ç≥„Éû„É≥„Éâ„Çí‰Ωø„ÅÜ„Åì„Å®„Åß„Åß„Åç„Åæ„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅ„Éó„É≠„É≥„Éó„Éà„Åå`(tide_env)`„Å´Â§â„Çè„Çä„Åæ„Åô„ÄÇ\n",
        "- „Åù„ÅÆÂæå„ÄÅTiDE„Å´ÂøÖË¶Å„Å™‰æùÂ≠òÈñ¢‰øÇ„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ„Çø„Éº„Éü„Éä„É´„ÇÑ„Ç≥„Éû„É≥„Éâ„Éó„É≠„É≥„Éó„Éà„Åß`pip install -r requirements.txt`„Å®„ÅÑ„ÅÜ„Ç≥„Éû„É≥„Éâ„Çí‰Ωø„ÅÜ„Åì„Å®„Åß„Åß„Åç„Åæ„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅTiDE„ÅåÂãï‰Ωú„Åô„Çã„Åü„ÇÅ„Å´ÂøÖË¶Å„Å™Python„Éë„ÉÉ„Ç±„Éº„Ç∏„Åå„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Åæ„Åô„ÄÇ\n",
        "- ÊúÄÂæå„Å´„ÄÅ`TiDE`„Éï„Ç©„É´„ÉÄÂÜÖ„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„ÇÑ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„ÇíÂÆüË°å„Åß„Åç„Åæ„Åô„ÄÇ‰æã„Åà„Å∞„ÄÅ„Çπ„ÇØ„É™„Éó„Éà`tide.py`„ÇíÂÆüË°å„Åô„Çã„Å´„ÅØ„ÄÅ„Çø„Éº„Éü„Éä„É´„ÇÑ„Ç≥„Éû„É≥„Éâ„Éó„É≠„É≥„Éó„Éà„Åß`python tide.py`„Å®„ÅÑ„ÅÜ„Ç≥„Éû„É≥„Éâ„Çí‰Ωø„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅTiDE„Ç¢„É´„Ç¥„É™„Ç∫„É†„Åå„Çµ„É≥„Éó„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÈÅ©Áî®„Åï„Çå„ÄÅÁµêÊûú„ÅåË°®Á§∫„Åï„Çå„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ`notebooks`„Çµ„Éñ„Éï„Ç©„É´„ÉÄÂÜÖ„ÅÆ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„ÅØ„ÄÅJupyter Notebook„ÇÑGoogle Colab„Çí‰Ωø„Å£„Å¶„Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ„Å´ÂÆüË°å„Åß„Åç„Åæ„Åô„ÄÇ\n",
        "\n",
        "lich99„Å´„Çà„ÇãTiDE„ÅÆ‰Ωø„ÅÑÊñπ„ÅÆË™¨Êòé„ÅåÂΩπ„Å´Á´ã„Å¶„Å∞Âπ∏„ÅÑ„Åß„Åô„ÄÇüòä\n",
        "\n",
        "„ÇΩ„Éº„Çπ: Bing „Å®„ÅÆ‰ºöË©± 2023/6/11(1) . https://bing.com/search?q=translate+TiDE+by+lich99+instructions+to+Japanese „Ç¢„ÇØ„Çª„ÇπÊó•ÊôÇ 2023/6/11.\n",
        "(2) GitHub - lich99/TiDE: Unofficial Implementation of Long-term .... https://github.com/lich99/TiDE „Ç¢„ÇØ„Çª„ÇπÊó•ÊôÇ 2023/6/11.\n",
        "(3) Google Translate. https://translate.google.com/ „Ç¢„ÇØ„Çª„ÇπÊó•ÊôÇ 2023/6/11.\n",
        "(4) TiDE/README.md at main ¬∑ lich99/TiDE - GitHub. https://github.com/lich99/TiDE/blob/main/README.md „Ç¢„ÇØ„Çª„ÇπÊó•ÊôÇ 2023/6/11."
      ],
      "metadata": {
        "id": "-GTx_SlbI_6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíË¶ã„Çã„Å®„ÄÅ„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Åü„Éë„ÉÉ„Ç±„Éº„Ç∏„ÅåÊó¢„Å´„Ç§„É≥„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„Çã„Éë„ÉÉ„Ç±„Éº„Ç∏„Å®‰æùÂ≠òÈñ¢‰øÇ„ÅÆË°ùÁ™Å„ÇíËµ∑„Åì„Åó„Å¶„ÅÑ„Çã„Çà„ÅÜ„Åß„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅpip„ÅÆ‰æùÂ≠òÈñ¢‰øÇËß£Ê±∫Âô®„Åå„Ç§„É≥„Çπ„Éà„Éº„É´Ê∏à„Åø„ÅÆ„Éë„ÉÉ„Ç±„Éº„Ç∏„Çí„Åô„Åπ„Å¶ËÄÉÊÖÆ„Åó„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅ„Å´Áô∫Áîü„Åô„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åì„ÅÆÂïèÈ°å„ÇíËß£Ê±∫„Åô„Çã„Å´„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆÊâãÈ†Ü„ÇíË©¶„Åó„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "\n",
        "- „É©„É≥„Çø„Ç§„É†„ÇíÂÜçËµ∑Âãï„Åó„Å¶„ÄÅÊñ∞„Åó„Åè„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Åü„Éê„Éº„Ç∏„Éß„É≥„ÅÆ„Éë„ÉÉ„Ç±„Éº„Ç∏„Çí‰ΩøÁî®„Åß„Åç„Çã„Çà„ÅÜ„Å´„Åó„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ„É°„Éã„É•„Éº„Éê„Éº„ÅÆ„Äå„É©„É≥„Çø„Ç§„É†„Äç„Åã„Çâ„Äå„É©„É≥„Çø„Ç§„É†„ÇíÂÜçËµ∑Âãï„Äç„ÇíÈÅ∏Êäû„Åô„Çã„Åì„Å®„Åß„Åß„Åç„Åæ„Åô„ÄÇ\n",
        "- „Åù„Çå„Åß„ÇÇ„Ç®„É©„Éº„ÅåÂá∫„ÇãÂ†¥Âêà„ÅØ„ÄÅpip„ÅÆ„Ç¢„ÉÉ„Éó„Ç∞„É¨„Éº„Éâ„ÇíË°å„Å£„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Åì„Çå„ÅØ„ÄÅ„Çø„Éº„Éü„Éä„É´„ÇÑ„Ç≥„Éû„É≥„Éâ„Éó„É≠„É≥„Éó„Éà„Åß`pip install --upgrade pip`„Å®„ÅÑ„ÅÜ„Ç≥„Éû„É≥„Éâ„Çí‰Ωø„ÅÜ„Åì„Å®„Åß„Åß„Åç„Åæ„Åô„ÄÇ\n",
        "- „Åï„Çâ„Å´„Ç®„É©„Éº„ÅåÂá∫„ÇãÂ†¥Âêà„ÅØ„ÄÅ‰æùÂ≠òÈñ¢‰øÇ„ÅÆË°ùÁ™Å„ÇíËµ∑„Åì„Åó„Å¶„ÅÑ„Çã„Éë„ÉÉ„Ç±„Éº„Ç∏„ÅÆ„Éê„Éº„Ç∏„Éß„É≥„ÇíË™øÊï¥„Åó„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰æã„Åà„Å∞„ÄÅdask-ml„Ååscikit-learn>=1.2.0„ÇíË¶ÅÊ±Ç„Åó„Å¶„ÅÑ„Çã„ÅÆ„Å´ÂØæ„Åó„ÄÅscikit-learn 1.0.2„Åå„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØ„ÄÅ`pip install scikit-learn==1.2.0`„Å®„ÅÑ„ÅÜ„Ç≥„Éû„É≥„Éâ„Åßscikit-learn„ÅÆ„Éê„Éº„Ç∏„Éß„É≥„Çí‰∏ä„Åí„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇÂêåÊßò„Å´„ÄÅ‰ªñ„ÅÆ„Éë„ÉÉ„Ç±„Éº„Ç∏„ÇÇ„Éê„Éº„Ç∏„Éß„É≥„ÇíÂ§âÊõ¥„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ\n",
        "\n",
        "„Åì„Çå„Çâ„ÅÆÊâãÈ†Ü„Åß„Ç®„É©„Éº„ÅåËß£Ê∂à„Åï„Çå„Çã„Åì„Å®„ÇíÈ°ò„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇüòä"
      ],
      "metadata": {
        "id": "SKMU-VyHI0Mn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgPscrtVGvwr",
        "outputId": "9bcff6e2-33ac-4eb2-e613-e866200dec7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'google-research'...\n",
            "remote: Enumerating objects: 71035, done.\u001b[K\n",
            "remote: Counting objects: 100% (4169/4169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (965/965), done.\u001b[K\n",
            "remote: Total 71035 (delta 3404), reused 3743 (delta 3184), pack-reused 66866\u001b[K\n",
            "Receiving objects: 100% (71035/71035), 520.74 MiB | 17.19 MiB/s, done.\n",
            "Resolving deltas: 100% (43741/43741), done.\n",
            "Updating files: 100% (17750/17750), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/google-research/google-research.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYxG7OAoI8P4",
        "outputId": "331a5e21-0130-4ef9-d90f-76d812f9d75d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /\n",
        "%cd content/google-research/tide/scripts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdK84DP5Ormi",
        "outputId": "c00d6dde-5bf4-4d48-b850-18c9d278c725"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "/content/google-research/tide/scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd google-research/tide/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4YKV7znG0HV",
        "outputId": "0e8cd91a-7b47-4741-ca2b-34f7e29de57d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/google-research/tide/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash download_data.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPuImu5nHCmc",
        "outputId": "f262ed4e-765d-49e0-ed34-68aa9ac08271"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1alE33S1GmP5wACMXaLu50rDIoVzBM4ik\n",
            "To: /content/google-research/tide/datasets/all_six_datasets.zip\n",
            "100% 54.0M/54.0M [00:00<00:00, 221MB/s]\n",
            "Archive:  all_six_datasets.zip\n",
            "   creating: all_six_datasets/\n",
            "   creating: all_six_datasets/traffic/\n",
            "  inflating: __MACOSX/all_six_datasets/._traffic  \n",
            "  inflating: all_six_datasets/.DS_Store  \n",
            "  inflating: __MACOSX/all_six_datasets/._.DS_Store  \n",
            "   creating: all_six_datasets/illness/\n",
            "  inflating: __MACOSX/all_six_datasets/._illness  \n",
            "   creating: all_six_datasets/ETT-small/\n",
            "  inflating: __MACOSX/all_six_datasets/._ETT-small  \n",
            "   creating: all_six_datasets/weather/\n",
            "  inflating: __MACOSX/all_six_datasets/._weather  \n",
            "   creating: all_six_datasets/exchange_rate/\n",
            "  inflating: __MACOSX/all_six_datasets/._exchange_rate  \n",
            "   creating: all_six_datasets/electricity/\n",
            "  inflating: __MACOSX/all_six_datasets/._electricity  \n",
            "  inflating: all_six_datasets/traffic/.DS_Store  \n",
            "  inflating: __MACOSX/all_six_datasets/traffic/._.DS_Store  \n",
            "  inflating: all_six_datasets/traffic/traffic.csv  \n",
            "  inflating: all_six_datasets/illness/national_illness.csv  \n",
            "  inflating: all_six_datasets/ETT-small/ETTh1.csv  \n",
            "  inflating: all_six_datasets/ETT-small/ETTh2.csv  \n",
            "  inflating: all_six_datasets/ETT-small/ETTm1.csv  \n",
            "  inflating: all_six_datasets/ETT-small/ETTm2.csv  \n",
            "  inflating: all_six_datasets/weather/weather.csv  \n",
            "  inflating: all_six_datasets/exchange_rate/.DS_Store  \n",
            "  inflating: __MACOSX/all_six_datasets/exchange_rate/._.DS_Store  \n",
            "  inflating: all_six_datasets/exchange_rate/exchange_rate.csv  \n",
            "  inflating: __MACOSX/all_six_datasets/exchange_rate/._exchange_rate.csv  \n",
            "  inflating: all_six_datasets/electricity/.DS_Store  \n",
            "  inflating: __MACOSX/all_six_datasets/electricity/._.DS_Store  \n",
            "  inflating: all_six_datasets/electricity/electricity.csv  \n",
            "  inflating: __MACOSX/all_six_datasets/electricity/._electricity.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/google-research/tide\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JYjW_sYuHHZU",
        "outputId": "d606cbb4-df23-474c-b36f-05755d221914"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/google-research/tide\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.10.1 (from -r requirements.txt (line 1))\n",
            "  Downloading tensorflow-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.3.5 (from -r requirements.txt (line 2))\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.6 (from -r requirements.txt (line 3))\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.0.2 (from -r requirements.txt (line 4))\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1 (from -r requirements.txt (line 5))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.4.0)\n",
            "Collecting gdown==4.7.1 (from -r requirements.txt (line 7))\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (3.8.0)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (1.16.0)\n",
            "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (0.32.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.1->-r requirements.txt (line 7)) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.1->-r requirements.txt (line 7)) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.1->-r requirements.txt (line 7)) (4.11.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.1->-r requirements.txt (line 1)) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (3.4.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.7.1->-r requirements.txt (line 7)) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (3.2.2)\n",
            "Installing collected packages: keras, tqdm, tensorflow-estimator, tensorboard-data-server, protobuf, numpy, pandas, keras-preprocessing, scikit-learn, google-auth-oauthlib, gdown, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gdown-4.7.1 google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 numpy-1.21.6 pandas-1.3.5 protobuf-3.19.6 scikit-learn-1.0.2 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.1 tensorflow-estimator-2.10.0 tqdm-4.64.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy",
                  "pandas",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 tide.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGs52rCaHhqz",
        "outputId": "b421441f-abdb-4a8d-fbc3-e55f364411fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/google-research/tide/tide.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE73c5nfJ1RM",
        "outputId": "2392c8e5-e2d7-438b-8516-6696a5f085e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-11 06:52:04.818845: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-11 06:52:04.949293: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-06-11 06:52:04.987523: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-11 06:52:05.795284: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-11 06:52:05.795384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-11 06:52:05.795400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/bin/python3: Error while finding module specification for 'train.py' (ModuleNotFoundError: __path__ attribute not found on 'train' while trying to find 'train.py'). Try using 'train' instead of 'train.py' as the module name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÇíË¶ã„Çã„Å®„ÄÅ`KeyError: '/content/google-research/tide/datasets/electricity/electricity.csv'`„Å®„ÅÑ„ÅÜ„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ`DATA_DICT`„Å®„ÅÑ„ÅÜËæûÊõ∏„Å´`/content/google-research/tide/datasets/electricity/electricity.csv`„Å®„ÅÑ„ÅÜ„Ç≠„Éº„ÅåÂ≠òÂú®„Åó„Å™„ÅÑ„Åì„Å®„ÇíÊÑèÂë≥„Åó„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„ÄÅ‰ª•‰∏ã„ÅÆÂèØËÉΩÊÄß„ÅåËÄÉ„Åà„Çâ„Çå„Åæ„Åô„ÄÇ\n",
        "\n",
        "- `DATA_DICT`„Å®„ÅÑ„ÅÜËæûÊõ∏„ÅåÂÆöÁæ©„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂ†¥Âêà„ÄÇ„Åì„ÅÆÂ†¥Âêà„ÅØ„ÄÅ`DATA_DICT`„Å®„ÅÑ„ÅÜËæûÊõ∏„Çí‰ΩúÊàê„Åó„Å¶„ÄÅ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ„Éë„Çπ„Å®„Åù„ÅÆ‰ªñ„ÅÆÊÉÖÂ†±„Çí„Ç≠„Éº„Å®ÂÄ§„ÅÆ„Éö„Ç¢„Å®„Åó„Å¶ÁôªÈå≤„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰æã„Åà„Å∞„ÄÅ`DATA_DICT = {'/content/google-research/tide/datasets/electricity/electricity.csv': {'data_path': '/content/google-research/tide/datasets/electricity/electricity.csv', 'num_features': 8, 'num_classes': 1}}`„Å®„ÅÑ„ÅÜ„Çà„ÅÜ„Å´ÂÆöÁæ©„Åß„Åç„Åæ„Åô„ÄÇ\n",
        "- `DATA_DICT`„Å®„ÅÑ„ÅÜËæûÊõ∏„Å´`/content/google-research/tide/datasets/electricity/electricity.csv`„Å®„ÅÑ„ÅÜ„Ç≠„Éº„ÅåÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂ†¥Âêà„ÄÇ„Åì„ÅÆÂ†¥Âêà„ÅØ„ÄÅ`DATA_DICT`„Å®„ÅÑ„ÅÜËæûÊõ∏„Å´`/content/google-research/tide/datasets/electricity/electricity.csv`„Å®„ÅÑ„ÅÜ„Ç≠„Éº„ÇíËøΩÂä†„Åó„Å¶„ÄÅ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ„Éë„Çπ„Å®„Åù„ÅÆ‰ªñ„ÅÆÊÉÖÂ†±„ÇíÂÄ§„Å®„Åó„Å¶ÁôªÈå≤„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰æã„Åà„Å∞„ÄÅ`DATA_DICT['/content/google-research/tide/datasets/electricity/electricity.csv'] = {'data_path': '/content/google-research/tide/datasets/electricity/electricity.csv', 'num_features': 8, 'num_classes': 1}`„Å®„ÅÑ„ÅÜ„Çà„ÅÜ„Å´ËøΩÂä†„Åß„Åç„Åæ„Åô„ÄÇ\n",
        "- `DATA_DICT`„Å®„ÅÑ„ÅÜËæûÊõ∏„Å´ÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Çã„Ç≠„Éº„ÅåÂà•„ÅÆ„ÇÇ„ÅÆ„Å´„Å™„Å£„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÄÇ„Åì„ÅÆÂ†¥Âêà„ÅØ„ÄÅ`DATA_DICT`„Å®„ÅÑ„ÅÜËæûÊõ∏„Å´ÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Çã„Ç≠„Éº„ÇíÁ¢∫Ë™ç„Åó„Å¶„ÄÅÊ≠£„Åó„ÅÑ„ÇÇ„ÅÆ„Å´Â§âÊõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰æã„Åà„Å∞„ÄÅ`DATA_DICT['electricity'] = {'data_path': '/content/google-research/tide/datasets/electricity/electricity.csv', 'num_features': 8, 'num_classes': 1}`„Å®„ÅÑ„ÅÜ„Çà„ÅÜ„Å´ÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØ„ÄÅ„Ç≠„Éº„Çí`electricity`„Åã„Çâ`/content/google-research/tide/datasets/electricity/electricity.csv`„Å´Â§âÊõ¥„Åô„Çã„Åã„ÄÅ„Ç≥„Éû„É≥„Éâ„É©„Ç§„É≥ÂºïÊï∞„ÅßÊåáÂÆö„Åô„Çã„Éá„Éº„Çø„Çª„ÉÉ„ÉàÂêç„Çí`electricity`„Å´Â§âÊõ¥„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\n",
        "\n",
        "„Åì„Çå„Çâ„ÅÆÊâãÈ†Ü„Åß„Ç®„É©„Éº„ÅåËß£Ê∂à„Åï„Çå„Çã„Åì„Å®„ÇíÈ°ò„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇüòä"
      ],
      "metadata": {
        "id": "UMqMGePAMjBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/google-research/tide/scripts/electricity.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMNZUsJiLmqL",
        "outputId": "344fbe44-f6ee-4588-cff6-d360f609cbc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: No module named train\n",
            "/usr/bin/python3: No module named train\n",
            "/usr/bin/python3: No module named train\n",
            "/usr/bin/python3: No module named train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_-vuGS-O-fL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}