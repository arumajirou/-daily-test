{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPWBnJG39UqfBeyr/FvsTkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumajirou/-daily-test/blob/main/google_research_tide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã‚¦ã‚§ãƒ–æ¤œç´¢çµæœã«ã‚ˆã‚‹ã¨ã€lich99ã«ã‚ˆã‚‹TiDEã®ä½¿ç”¨æ–¹æ³•ã‚’æ—¥æœ¬èªã§èª¬æ˜ã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚\n",
        "\n",
        "- ã¾ãšã€GitHubã®ãƒªãƒã‚¸ãƒˆãƒªã‚’è‡ªåˆ†ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚·ãƒ³ã«ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚„ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§`git clone https://github.com/lich99/TiDE.git`ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã†ã“ã¨ã§ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«`TiDE`ã¨ã„ã†ãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã™ã€‚\n",
        "- æ¬¡ã«ã€TiDEã®ãŸã‚ã®ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚„ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§`python -m venv tide_env`ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã†ã“ã¨ã§ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«`tide_env`ã¨ã„ã†ãƒ•ã‚©ãƒ«ãƒ€ãŒä½œæˆã•ã‚Œã¾ã™ã€‚\n",
        "- ãã‚Œã‹ã‚‰ã€ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹åŒ–ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚„ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§`source tide_env/bin/activate`ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã†ã“ã¨ã§ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒ`(tide_env)`ã«å¤‰ã‚ã‚Šã¾ã™ã€‚\n",
        "- ãã®å¾Œã€TiDEã«å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚„ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§`pip install -r requirements.txt`ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã†ã“ã¨ã§ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€TiDEãŒå‹•ä½œã™ã‚‹ãŸã‚ã«å¿…è¦ãªPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã™ã€‚\n",
        "- æœ€å¾Œã«ã€`TiDE`ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚ä¾‹ãˆã°ã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆ`tide.py`ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚„ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§`python tide.py`ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€TiDEã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨ã•ã‚Œã€çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã¾ãŸã€`notebooks`ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€Jupyter Notebookã‚„Google Colabã‚’ä½¿ã£ã¦ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«å®Ÿè¡Œã§ãã¾ã™ã€‚\n",
        "\n",
        "lich99ã«ã‚ˆã‚‹TiDEã®ä½¿ã„æ–¹ã®èª¬æ˜ãŒå½¹ã«ç«‹ã¦ã°å¹¸ã„ã§ã™ã€‚ğŸ˜Š\n",
        "\n",
        "ã‚½ãƒ¼ã‚¹: Bing ã¨ã®ä¼šè©± 2023/6/11(1) . https://bing.com/search?q=translate+TiDE+by+lich99+instructions+to+Japanese ã‚¢ã‚¯ã‚»ã‚¹æ—¥æ™‚ 2023/6/11.\n",
        "(2) GitHub - lich99/TiDE: Unofficial Implementation of Long-term .... https://github.com/lich99/TiDE ã‚¢ã‚¯ã‚»ã‚¹æ—¥æ™‚ 2023/6/11.\n",
        "(3) Google Translate. https://translate.google.com/ ã‚¢ã‚¯ã‚»ã‚¹æ—¥æ™‚ 2023/6/11.\n",
        "(4) TiDE/README.md at main Â· lich99/TiDE - GitHub. https://github.com/lich99/TiDE/blob/main/README.md ã‚¢ã‚¯ã‚»ã‚¹æ—¥æ™‚ 2023/6/11."
      ],
      "metadata": {
        "id": "-GTx_SlbI_6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¦‹ã‚‹ã¨ã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæ—¢ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ä¾å­˜é–¢ä¿‚ã®è¡çªã‚’èµ·ã“ã—ã¦ã„ã‚‹ã‚ˆã†ã§ã™ã€‚ã“ã‚Œã¯ã€pipã®ä¾å­˜é–¢ä¿‚è§£æ±ºå™¨ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã™ã¹ã¦è€ƒæ…®ã—ã¦ã„ãªã„ãŸã‚ã«ç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®æ‰‹é †ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "- ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã—ã¦ã€æ–°ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã®ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€ã‹ã‚‰ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã€ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã§ãã¾ã™ã€‚\n",
        "- ãã‚Œã§ã‚‚ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ã€pipã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’è¡Œã£ã¦ã¿ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚„ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§`pip install --upgrade pip`ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã†ã“ã¨ã§ã§ãã¾ã™ã€‚\n",
        "- ã•ã‚‰ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ã€ä¾å­˜é–¢ä¿‚ã®è¡çªã‚’èµ·ã“ã—ã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’èª¿æ•´ã—ã¦ã¿ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€dask-mlãŒscikit-learn>=1.2.0ã‚’è¦æ±‚ã—ã¦ã„ã‚‹ã®ã«å¯¾ã—ã€scikit-learn 1.0.2ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€`pip install scikit-learn==1.2.0`ã¨ã„ã†ã‚³ãƒãƒ³ãƒ‰ã§scikit-learnã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä¸Šã’ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚åŒæ§˜ã«ã€ä»–ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã®æ‰‹é †ã§ã‚¨ãƒ©ãƒ¼ãŒè§£æ¶ˆã•ã‚Œã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚ğŸ˜Š"
      ],
      "metadata": {
        "id": "SKMU-VyHI0Mn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgPscrtVGvwr",
        "outputId": "9bcff6e2-33ac-4eb2-e613-e866200dec7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'google-research'...\n",
            "remote: Enumerating objects: 71035, done.\u001b[K\n",
            "remote: Counting objects: 100% (4169/4169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (965/965), done.\u001b[K\n",
            "remote: Total 71035 (delta 3404), reused 3743 (delta 3184), pack-reused 66866\u001b[K\n",
            "Receiving objects: 100% (71035/71035), 520.74 MiB | 17.19 MiB/s, done.\n",
            "Resolving deltas: 100% (43741/43741), done.\n",
            "Updating files: 100% (17750/17750), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/google-research/google-research.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYxG7OAoI8P4",
        "outputId": "331a5e21-0130-4ef9-d90f-76d812f9d75d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /\n",
        "%cd content/google-research/tide/scripts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdK84DP5Ormi",
        "outputId": "c00d6dde-5bf4-4d48-b850-18c9d278c725"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "/content/google-research/tide/scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd google-research/tide/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4YKV7znG0HV",
        "outputId": "0e8cd91a-7b47-4741-ca2b-34f7e29de57d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/google-research/tide/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash download_data.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPuImu5nHCmc",
        "outputId": "f262ed4e-765d-49e0-ed34-68aa9ac08271"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1alE33S1GmP5wACMXaLu50rDIoVzBM4ik\n",
            "To: /content/google-research/tide/datasets/all_six_datasets.zip\n",
            "100% 54.0M/54.0M [00:00<00:00, 221MB/s]\n",
            "Archive:  all_six_datasets.zip\n",
            "   creating: all_six_datasets/\n",
            "   creating: all_six_datasets/traffic/\n",
            "  inflating: __MACOSX/all_six_datasets/._traffic  \n",
            "  inflating: all_six_datasets/.DS_Store  \n",
            "  inflating: __MACOSX/all_six_datasets/._.DS_Store  \n",
            "   creating: all_six_datasets/illness/\n",
            "  inflating: __MACOSX/all_six_datasets/._illness  \n",
            "   creating: all_six_datasets/ETT-small/\n",
            "  inflating: __MACOSX/all_six_datasets/._ETT-small  \n",
            "   creating: all_six_datasets/weather/\n",
            "  inflating: __MACOSX/all_six_datasets/._weather  \n",
            "   creating: all_six_datasets/exchange_rate/\n",
            "  inflating: __MACOSX/all_six_datasets/._exchange_rate  \n",
            "   creating: all_six_datasets/electricity/\n",
            "  inflating: __MACOSX/all_six_datasets/._electricity  \n",
            "  inflating: all_six_datasets/traffic/.DS_Store  \n",
            "  inflating: __MACOSX/all_six_datasets/traffic/._.DS_Store  \n",
            "  inflating: all_six_datasets/traffic/traffic.csv  \n",
            "  inflating: all_six_datasets/illness/national_illness.csv  \n",
            "  inflating: all_six_datasets/ETT-small/ETTh1.csv  \n",
            "  inflating: all_six_datasets/ETT-small/ETTh2.csv  \n",
            "  inflating: all_six_datasets/ETT-small/ETTm1.csv  \n",
            "  inflating: all_six_datasets/ETT-small/ETTm2.csv  \n",
            "  inflating: all_six_datasets/weather/weather.csv  \n",
            "  inflating: all_six_datasets/exchange_rate/.DS_Store  \n",
            "  inflating: __MACOSX/all_six_datasets/exchange_rate/._.DS_Store  \n",
            "  inflating: all_six_datasets/exchange_rate/exchange_rate.csv  \n",
            "  inflating: __MACOSX/all_six_datasets/exchange_rate/._exchange_rate.csv  \n",
            "  inflating: all_six_datasets/electricity/.DS_Store  \n",
            "  inflating: __MACOSX/all_six_datasets/electricity/._.DS_Store  \n",
            "  inflating: all_six_datasets/electricity/electricity.csv  \n",
            "  inflating: __MACOSX/all_six_datasets/electricity/._electricity.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/google-research/tide\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JYjW_sYuHHZU",
        "outputId": "d606cbb4-df23-474c-b36f-05755d221914"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/google-research/tide\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.10.1 (from -r requirements.txt (line 1))\n",
            "  Downloading tensorflow-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.3.5 (from -r requirements.txt (line 2))\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.6 (from -r requirements.txt (line 3))\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.0.2 (from -r requirements.txt (line 4))\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1 (from -r requirements.txt (line 5))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.4.0)\n",
            "Collecting gdown==4.7.1 (from -r requirements.txt (line 7))\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (3.8.0)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (1.16.0)\n",
            "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (0.32.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.1->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.0.2->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.1->-r requirements.txt (line 7)) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.1->-r requirements.txt (line 7)) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.7.1->-r requirements.txt (line 7)) (4.11.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.1->-r requirements.txt (line 1)) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (3.4.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1))\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.7.1->-r requirements.txt (line 7)) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.7.1->-r requirements.txt (line 7)) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1->-r requirements.txt (line 1)) (3.2.2)\n",
            "Installing collected packages: keras, tqdm, tensorflow-estimator, tensorboard-data-server, protobuf, numpy, pandas, keras-preprocessing, scikit-learn, google-auth-oauthlib, gdown, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gdown-4.7.1 google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 numpy-1.21.6 pandas-1.3.5 protobuf-3.19.6 scikit-learn-1.0.2 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.1 tensorflow-estimator-2.10.0 tqdm-4.64.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy",
                  "pandas",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 tide.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGs52rCaHhqz",
        "outputId": "b421441f-abdb-4a8d-fbc3-e55f364411fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/google-research/tide/tide.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE73c5nfJ1RM",
        "outputId": "2392c8e5-e2d7-438b-8516-6696a5f085e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-11 06:52:04.818845: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-11 06:52:04.949293: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-06-11 06:52:04.987523: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-06-11 06:52:05.795284: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-11 06:52:05.795384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-06-11 06:52:05.795400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/bin/python3: Error while finding module specification for 'train.py' (ModuleNotFoundError: __path__ attribute not found on 'train' while trying to find 'train.py'). Try using 'train' instead of 'train.py' as the module name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¦‹ã‚‹ã¨ã€`KeyError: '/content/google-research/tide/datasets/electricity/electricity.csv'`ã¨ã„ã†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€`DATA_DICT`ã¨ã„ã†è¾æ›¸ã«`/content/google-research/tide/datasets/electricity/electricity.csv`ã¨ã„ã†ã‚­ãƒ¼ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ä»¥ä¸‹ã®å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "- `DATA_DICT`ã¨ã„ã†è¾æ›¸ãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„å ´åˆã€‚ã“ã®å ´åˆã¯ã€`DATA_DICT`ã¨ã„ã†è¾æ›¸ã‚’ä½œæˆã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã¨ãã®ä»–ã®æƒ…å ±ã‚’ã‚­ãƒ¼ã¨å€¤ã®ãƒšã‚¢ã¨ã—ã¦ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€`DATA_DICT = {'/content/google-research/tide/datasets/electricity/electricity.csv': {'data_path': '/content/google-research/tide/datasets/electricity/electricity.csv', 'num_features': 8, 'num_classes': 1}}`ã¨ã„ã†ã‚ˆã†ã«å®šç¾©ã§ãã¾ã™ã€‚\n",
        "- `DATA_DICT`ã¨ã„ã†è¾æ›¸ã«`/content/google-research/tide/datasets/electricity/electricity.csv`ã¨ã„ã†ã‚­ãƒ¼ãŒç™»éŒ²ã•ã‚Œã¦ã„ãªã„å ´åˆã€‚ã“ã®å ´åˆã¯ã€`DATA_DICT`ã¨ã„ã†è¾æ›¸ã«`/content/google-research/tide/datasets/electricity/electricity.csv`ã¨ã„ã†ã‚­ãƒ¼ã‚’è¿½åŠ ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã¨ãã®ä»–ã®æƒ…å ±ã‚’å€¤ã¨ã—ã¦ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€`DATA_DICT['/content/google-research/tide/datasets/electricity/electricity.csv'] = {'data_path': '/content/google-research/tide/datasets/electricity/electricity.csv', 'num_features': 8, 'num_classes': 1}`ã¨ã„ã†ã‚ˆã†ã«è¿½åŠ ã§ãã¾ã™ã€‚\n",
        "- `DATA_DICT`ã¨ã„ã†è¾æ›¸ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ãŒåˆ¥ã®ã‚‚ã®ã«ãªã£ã¦ã„ã‚‹å ´åˆã€‚ã“ã®å ´åˆã¯ã€`DATA_DICT`ã¨ã„ã†è¾æ›¸ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ã€æ­£ã—ã„ã‚‚ã®ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€`DATA_DICT['electricity'] = {'data_path': '/content/google-research/tide/datasets/electricity/electricity.csv', 'num_features': 8, 'num_classes': 1}`ã¨ã„ã†ã‚ˆã†ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ã‚­ãƒ¼ã‚’`electricity`ã‹ã‚‰`/content/google-research/tide/datasets/electricity/electricity.csv`ã«å¤‰æ›´ã™ã‚‹ã‹ã€ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§æŒ‡å®šã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã‚’`electricity`ã«å¤‰æ›´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "ã“ã‚Œã‚‰ã®æ‰‹é †ã§ã‚¨ãƒ©ãƒ¼ãŒè§£æ¶ˆã•ã‚Œã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚ğŸ˜Š"
      ],
      "metadata": {
        "id": "UMqMGePAMjBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/google-research/tide/scripts/electricity.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMNZUsJiLmqL",
        "outputId": "344fbe44-f6ee-4588-cff6-d360f609cbc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: No module named train\n",
            "/usr/bin/python3: No module named train\n",
            "/usr/bin/python3: No module named train\n",
            "/usr/bin/python3: No module named train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_-vuGS-O-fL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}