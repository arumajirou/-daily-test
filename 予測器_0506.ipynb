{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumajirou/-daily-test/blob/main/%E4%BA%88%E6%B8%AC%E5%99%A8_0506.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tNopN-r2uSS"
      },
      "source": [
        "# **<font color='Blue'>ライブラリ、関数定義**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-K5xO_cWJyQ",
        "outputId": "025f8079-cd1e-4337-a679-e298d1852e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/ColabNotebooks/forecast_loto\n",
            "ディレクトリ /content/drive/MyDrive/ColabNotebooks/forecast_loto/.git は存在しません。\n",
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/drive/MyDrive/ColabNotebooks/forecast_loto/.git/\n",
            "/content\n",
            "CPU times: user 101 ms, sys: 19.4 ms, total: 120 ms\n",
            "Wall time: 14.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title ドライブのマウント\n",
        "\n",
        "!pip install -q gitpython\n",
        "\n",
        "\n",
        "import os\n",
        "import pytz\n",
        "import shutil\n",
        "from datetime import datetime as dt\n",
        "from git import Repo\n",
        "import configparser\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ConfigParserオブジェクトの作成\n",
        "config = configparser.ConfigParser()\n",
        "config.read('/content/drive/MyDrive/config.ini')\n",
        "\n",
        "# Gitの設定\n",
        "git_username  = config['DEFAULT']['GIT_USERNAME']\n",
        "git_email = config['DEFAULT']['GIT_EMAIL']\n",
        "git_repository = config['DEFAULT']['GIT_REPOSITORY']\n",
        "git_token =  config['DEFAULT']['git_token']\n",
        "git_pass =  config['DEFAULT']['git_pass']\n",
        "%cd /content/drive/MyDrive/ColabNotebooks/forecast_loto/\n",
        "\n",
        "# ディレクトリのパスを指定\n",
        "dir_path = '/content/drive/MyDrive/ColabNotebooks/forecast_loto/.git'\n",
        "\n",
        "# ディレクトリが存在するかどうかを確認\n",
        "if os.path.exists(dir_path):\n",
        "    # ディレクトリを削除\n",
        "    shutil.rmtree(dir_path)\n",
        "    print(f'ディレクトリ {dir_path} は削除されました。')\n",
        "else:\n",
        "    print(f'ディレクトリ {dir_path} は存在しません。')\n",
        "\n",
        "!git init\n",
        "os.system(f\"git config --global user.email {git_email}\")\n",
        "os.system(f\"git config --global user.name  {git_username}\")\n",
        "os.system(f\"git config --global init.defaultBranch main\")\n",
        "os.system(\"git branch -m main\")\n",
        "\n",
        "!git add .\n",
        "# 現在の日付と時刻を取得（日本時間）\n",
        "now = dt.now(pytz.timezone('Asia/Tokyo'))\n",
        "# 日付と時刻を文字列に変換\n",
        "datetime_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "# コミットメッセージを作成\n",
        "commit_message = f\"Commit on {datetime_str}\"\n",
        "# git commitコマンドを実行\n",
        "os.system(f'git commit -m \"{commit_message}\"')\n",
        "%cd /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/\n",
        "%pwd\n",
        "import os\n",
        "import subprocess\n",
        "test =\"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\"\n",
        "# ディレクトリの存在を確認します\n",
        "if not os.path.exists(\"forecast_loto\"):\n",
        "    print(\"ディレクトリ forecast_loto が存在しません。\")\n",
        "else:\n",
        "    # ディレクトリに移動します\n",
        "    os.chdir(\"forecast_loto\")\n",
        "\n",
        "    # Gitリポジトリであることを確認します\n",
        "    if not os.path.exists(\".git\"):\n",
        "        print(\"現在のディレクトリはGitリポジトリではありません。\")\n",
        "    else:\n",
        "        commands = [\n",
        "            f\"git config --global user.email {git_email}\",\n",
        "            f\"git config --global user.name  {git_username}\",\n",
        "            \"git add .\",\n",
        "            \"git commit -m 'Added new file.'\",\n",
        "            f\"git remote set-url origin https://{git_username}:{test}@github.com/arumajirou/forecast_loto.git\",\n",
        "            \"git config pull.rebase false\",  # マージ戦略を選択\n",
        "            \"git pull --allow-unrelated-histories origin main\",  # 修正された行\n",
        "            \"git push -u origin main\"\n",
        "        ]\n",
        "\n",
        "\n",
        "        for command in commands:\n",
        "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            stdout, stderr = process.communicate()\n",
        "\n",
        "            if process.returncode != 0:\n",
        "                print(f\"エラーが発生しました：\\n{stderr.decode()}\")\n",
        "            else:\n",
        "                print(f\"成功：\\n{stdout.decode()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r2k9pwtK0wg",
        "outputId": "61e67e89-029c-4c2a-c3fb-5ebd4a267daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            "成功：\n",
            "\n",
            "成功：\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "git_repository"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W3xVP6zpO0WZ",
        "outputId": "46637838-71ad-49f4-b3f3-967550d06842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'forecast_loto'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"git remote set-url origin https://{git_username}:{git_token}@github.com/arumajirou/forecast_loto.git\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q1RCeLWOBvF",
        "outputId": "8f4dc130-831b-4b34-88bf-c69b51b6061d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "git remote set-url origin https://arumajirou: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@github.com/arumajirou/forecast_loto.git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "oXbMHVr2qJts",
        "outputId": "d01fd182-b1e3-4beb-e165-a467383f2425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " パッケージは既にインストールされています: scikit-optimize \u001b[1;36m0.10\u001b[0m.\u001b[1;36m1\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> パッケージは既にインストールされています: scikit-optimize <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.10</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 83.9 ms, sys: 3.32 ms, total: 87.2 ms\n",
            "Wall time: 5.57 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title **インストール**\n",
        "!pip install rich\n",
        "import pkg_resources\n",
        "from rich import print as dric\n",
        "# numbaがインストールされているか確認\n",
        "try:\n",
        "    dist = pkg_resources.get_distribution('scikit-optimize')\n",
        "    dric(f\" パッケージは既にインストールされています: {dist}\")\n",
        "except pkg_resources.DistributionNotFound:\n",
        "    dric(\"パッケージが見つかりませんでした。インストールを開始します。\")\n",
        "    !pip install numba\n",
        "    !pip install gputil\n",
        "    !pip install uv\n",
        "    !uv venv\n",
        "    # On macOS and Linux.\n",
        "    !source .venv/bin/activate\n",
        "\n",
        "    !uv pip install -U ydata-profiling\n",
        "    !uv pip install -U sweetviz\n",
        "\n",
        "    !pip install -U stumpy\n",
        "    !uv pip install -U sktime\n",
        "    !uv pip install -U statsmodels\n",
        "\n",
        "    !pip install -U tsfresh\n",
        "    !uv pip install -U featuretools\n",
        "\n",
        "    !uv pip install  -U modin\n",
        "    !uv pip install  -U andas==2.2.0\n",
        "    !uv pip install -U numpy\n",
        "\n",
        "    !uv pip install -U urllib3\n",
        "    !uv pip install -U pywavelets\n",
        "\n",
        "    !uv pip install -U scipy\n",
        "    !uv pip install -U scikit-learn\n",
        "    !uv pip install -U hmmlearn\n",
        "\n",
        "    !uv pip install -U seglearn\n",
        "    !uv pip install -U ripser\n",
        "    !uv pip install -U jpholiday\n",
        "\n",
        "    !uv pip install -U  tslearn\n",
        "\n",
        "    !uv pip install -U  autoviz\n",
        "    !uv pip install -U  dtale\n",
        "    !pip install -U dataprep\n",
        "\n",
        "    !pip install -U japanera\n",
        "    !pip install -U pyprobables\n",
        "\n",
        "    !pip install -U ray\n",
        "    !pip install -U neuralforecast\n",
        "    !pip install -U pytorch_lightning\n",
        "    !pip install -U virtualenv\n",
        "    !pip install -U arch\n",
        "    !pip install -U \"ray[data,train,tune,serve]\"\n",
        "    !pip install \"ray[tune]==2.2.0\"\n",
        "    !pip install \"hyperopt==0.2.7\"\n",
        "    !pip install \"bayesian-optimization==1.3.1\"\n",
        "    !pip install \"tensorflow>=2.9.0\"\n",
        "    !pip install -U ray[default]\n",
        "    !uv pip install -U ipyvuetify\n",
        "    !pip install -U scikit-optimize\n",
        "    !pip install -U ax-platform\n",
        "    !uv pip install -U shap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6oDaeNqFoua"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "mE2QJ6XjqByA",
        "outputId": "a0d05ed3-cb49-46ac-9c9d-a8ac3a8642e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.01 s, sys: 2.28 s, total: 11.3 s\n",
            "Wall time: 10 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title **インポート**\n",
        "import sys\n",
        "sys.path.append('/content/.venv/lib/python3.10/site-packages')\n",
        "\n",
        "# 標準ライブラリ\n",
        "# ファイルとディレクトリ操作に関するライブラリ\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import logging\n",
        "# 日付と時間に関するライブラリ\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# マルチプロセッシングに関するライブラリ\n",
        "\n",
        "import multiprocessing as mp\n",
        "import subprocess\n",
        "# メモリ上のテキストストリームを扱うためのライブラリ\n",
        "from io import StringIO\n",
        "\n",
        "# 型ヒントを提供するためのライブラリ\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "# トレースバック(エラー情報)を扱うためのライブラリ\n",
        "import traceback\n",
        "\n",
        "# サードパーティライブラリ\n",
        "# 数値計算とデータ分析に関するライブラリ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "\n",
        "# URLとHTTPクライアントを扱うためのライブラリ\n",
        "import urllib.request\n",
        "import urllib3\n",
        "\n",
        "# 進行状況を表示するためのライブラリ\n",
        "\n",
        "\n",
        "# ハイパーパラメータチューニングのためのライブラリ\n",
        "from ray import tune\n",
        "\n",
        "# リッチテキストと美しい出力を提供するライブラリ\n",
        "from rich import print as dric\n",
        "\n",
        "# 高速化のためのライブラリ\n",
        "from numba import jit\n",
        "\n",
        "# 日付と時間に関するライブラリ\n",
        "import pytz\n",
        "import jpholiday\n",
        "import japanera\n",
        "\n",
        "# 対話的なウィジェットと出力表示を制御するためのライブラリ\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# 特徴量生成と抽出を行うためのライブラリ\n",
        "import featuretools as ft\n",
        "from tsfresh import extract_features\n",
        "\n",
        "# 統計モデルと科学技術計算を行うためのライブラリ\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats, interpolate, fftpack, signal\n",
        "from scipy.stats import norm, poisson, expon\n",
        "from scipy.signal import find_peaks, find_peaks_cwt\n",
        "\n",
        "# 時系列データ分析のためのライブラリ\n",
        "import stumpy\n",
        "import sktime\n",
        "import pywt\n",
        "import hmmlearn.hmm as hmm\n",
        "import seglearn\n",
        "\n",
        "# ディープラーニングのためのライブラリ\n",
        "import torch\n",
        "\n",
        "# 機械学習のためのライブラリ\n",
        "from sklearn import datasets\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error\n",
        "\n",
        "# 時系列分析のためのライブラリ\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# データ可視化のためのライブラリ\n",
        "import plotly.express as px\n",
        "import plotly.subplots as sp\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# ニューラルネットワーク予測のためのライブラリ\n",
        "import neuralforecast.auto as nfa\n",
        "\n",
        "# データ準備と探索的データ解析のためのライブラリ\n",
        "from dataprep.datasets import load_dataset\n",
        "from dataprep.eda import create_report\n",
        "from ydata_profiling import ProfileReport\n",
        "import dtale\n",
        "\n",
        "# インスペクションと対話的なウィジェットのためのライブラリ\n",
        "import inspect\n",
        "from ipywidgets import interact, IntSlider, Checkbox\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.display.float_format = \"{:.2f}\".format\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import jpholiday\n",
        "import inspect\n",
        "import stumpy  # 確認したいモジュール名\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import stumpy\n",
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.arima_model import ARIMAResults\n",
        "from arch import arch_model\n",
        "\n",
        "from ray.util.multiprocessing import Pool\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "from tsfresh import select_features\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import webbrowser\n",
        "from google.colab import output\n",
        "import os\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import os\n",
        "import ipyvuetify as v\n",
        "import ipyvue as vue\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "import logging\n",
        "from tsfresh import select_features\n",
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "import ray\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.linear_model import LassoCV\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "from tqdm.notebook import tqdm\n",
        "from neuralforecast.auto import *\n",
        "from neuralforecast import NeuralForecast\n",
        "\n",
        "import plotly.express as px\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "GFlAfDlF-K3F",
        "outputId": "2bea9033-581f-48af-b6d8-9266d2eed57f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーが発生しました。\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーが発生しました。</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラー発生関数: git_save\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラー発生関数: git_save</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーメッセージ: Git push failed with error: remote: Support for password authentication was removed on August \u001b[0m\u001b[1;31m13\u001b[0m\u001b[31m,\u001b[0m\n",
              "\u001b[1;31m2021\u001b[0m\u001b[31m.\u001b[0m\n",
              "\u001b[31mremote: Please see \u001b[0m\n",
              "\u001b[4;31mhttps://docs.github.com/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls\u001b[0m\u001b[31m for \u001b[0m\n",
              "\u001b[31minformation on currently recommended modes of authentication.\u001b[0m\n",
              "\u001b[31mfatal: Authentication failed for \u001b[0m\u001b[31m'https://github.com/arumajirou/forecast_loto.git/'\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーメッセージ: Git push failed with error: remote: Support for password authentication was removed on August </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">13</span><span style=\"color: #800000; text-decoration-color: #800000\">,</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2021</span><span style=\"color: #800000; text-decoration-color: #800000\">.</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">remote: Please see </span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000; text-decoration: underline\">https://docs.github.com/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls</span><span style=\"color: #800000; text-decoration-color: #800000\"> for </span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">information on currently recommended modes of authentication.</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">fatal: Authentication failed for </span><span style=\"color: #800000; text-decoration-color: #800000\">'https://github.com/arumajirou/forecast_loto.git/'</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 14.3 ms, sys: 615 µs, total: 14.9 ms\n",
            "Wall time: 786 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<timed exec>\", line 1138, in git_save\n",
            "Exception: Git push failed with error: remote: Support for password authentication was removed on August 13, 2021.\n",
            "remote: Please see https://docs.github.com/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\n",
            "fatal: Authentication failed for 'https://github.com/arumajirou/forecast_loto.git/'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title　**関数の作成**\n",
        "%%time\n",
        "def copy_directories(src_dirs, dst_dir):\n",
        "    \"\"\"\n",
        "    指定されたソースディレクトリを宛先ディレクトリにコピーする関数\n",
        "    Args:\n",
        "        src_dirs (list): ソースディレクトリのパスのリスト\n",
        "        dst_dir (str): 宛先ディレクトリのパス\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 宛先ディレクトリが存在するかどうかを確認します\n",
        "        if not os.path.isdir(dst_dir):\n",
        "            dric(f\"[red bold]エラー: {dst_dir} は有効なディレクトリではありません。[/red bold]\")\n",
        "            return\n",
        "\n",
        "        for src_dir in src_dirs:\n",
        "            # ソースディレクトリが存在するかどうかを確認します\n",
        "            if os.path.isdir(src_dir):\n",
        "                dst_path = os.path.join(dst_dir, os.path.basename(src_dir))\n",
        "                shutil.copytree(src_dir, dst_path, dirs_exist_ok=True)\n",
        "                dric(f\"[green bold]{src_dir} を {dst_path} にコピーしました。[/green bold]\")\n",
        "            else:\n",
        "                dric(f\"[red bold]エラー: {src_dir} は有効なディレクトリではありません。[/red bold]\")\n",
        "    except FileNotFoundError:\n",
        "        dric(\"[red bold]エラー: ソースディレクトリが見つかりません。[/red bold]\")\n",
        "    except PermissionError:\n",
        "        dric(f\"[red bold]エラー: {dst_dir} への書き込み権限がありません。[/red bold]\")\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラー: 予期せぬエラーが発生しました: {e}[/red bold]\")\n",
        "\n",
        "@jit(nopython=True)\n",
        "def get_rokuyo(japanese_date) -> str:\n",
        "    \"\"\"\n",
        "    この関数は、日本の日付を受け取り、それを旧暦に変換し、対応する六曜を返します。\n",
        "\n",
        "    :param japanese_date: 変換する日本の日付。\n",
        "    :type japanese_date: JapaneseDate\n",
        "    :return: 対応する六曜。\n",
        "    :rtype: str\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 日本の日付を旧暦に変換します。\n",
        "        old_date = japanese_date.to_julian_date()\n",
        "\n",
        "        # 旧暦の日と月を足し算します。\n",
        "        month_day = int(old_date) % 100 + int(old_date * 100) % 100\n",
        "\n",
        "        # 足し算した結果を6で割った余りを計算します。\n",
        "        remainder = month_day % 6\n",
        "\n",
        "        # 六曜のリストを定義します。これは日本の伝統的なカレンダーシステムです。\n",
        "        rokuyo_list = [\"大安\", \"赤口\", \"先勝\", \"友引\", \"先負\", \"仏滅\"]\n",
        "\n",
        "        # 余りの数に対応する六曜をリストから選び、それを返します。\n",
        "        return rokuyo_list[remainder]\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラー: 予期せぬエラーが発生しました: {e}[/red bold]\")\n",
        "\n",
        "\n",
        "def make_numbers(num: int) -> pd.DataFrame:\n",
        "    '''\n",
        "    この関数は、指定したナンバーズ（数値型）をウェブから取得し、pandasのデータフレームに格納します。\n",
        "\n",
        "    :param num: ウェブから取得するナンバーズの種類を指定します。int型。\n",
        "    :return: 取得したナンバーズのデータを格納したデータフレーム。pandas.DataFrame型。\n",
        "    '''\n",
        "    try:\n",
        "        # 指定されたナンバーズのデータをウェブから読み込みます。読み込んだデータはshift-jisでエンコードされています。\n",
        "        df = pd.read_table('http://vvslot.com/download.php?m=777&f=numbers' + str(num) + '.txt', encoding=\"shift-jis\", sep=\",\", names=[\"part\", \"date\", \"week\", \"eto\", \"抽選数字\"], parse_dates=[1], dtype='object')\n",
        "\n",
        "        # 新たなカラム\"LOTO\"を作成し、\"num\"と指定したナンバーズの種類（num）を連結した文字列を格納します。\n",
        "        df[\"LOTO\"] = \"num\" + str(num)\n",
        "\n",
        "        # データフレームを\"date\"カラム（日付）に基づいてソート（並び替え）します。\n",
        "        df = df.sort_values(by='date')\n",
        "\n",
        "        # 抽選数字の各桁を新しいカラムに分割して格納します。例えば、抽選数字が\"1234\"の場合、\"N1\"には\"1\"、\"N2\"には\"2\"、\"N3\"には\"3\"、\"N4\"には\"4\"が格納されます。\n",
        "        for i in range(4):\n",
        "            df[\"N\" + str(i + 1)] = df[\"抽選数字\"].str[i]\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラーが発生しました: {e}[/red bold]\")\n",
        "        dric(\"*\"*100)\n",
        "        return None\n",
        "\n",
        "\n",
        "def make_Bin5() -> pd.DataFrame:\n",
        "    '''\n",
        "    この関数は、ビンゴ5のデータをウェブから取得し、pandasのデータフレームに格納します。\n",
        "\n",
        "    :return: 取得したビンゴ5のデータを格納したデータフレーム。pandas.DataFrame型。\n",
        "    '''\n",
        "    try:\n",
        "        # ビンゴ5のデータをウェブから読み込みます。このデータはHTMLのテーブル形式です。\n",
        "        url = 'http://vvslot.com/bingo5_data.php'\n",
        "        df_Bin5 = pd.read_html(url)\n",
        "\n",
        "        # 読み込んだデータ（HTMLのテーブル）の中から、10番目（インデックスは9）のテーブルを取得します。\n",
        "        # 不要なカラム（\"Ｎ5\",'1等', '2等', '3等'）を削除します。\n",
        "        df_Bin5 = df_Bin5[9].drop([\"Ｎ5\",'1等', '2等', '3等'], axis=1)\n",
        "\n",
        "        # データフレームのカラム名を新しく設定します。\n",
        "        df_Bin5.columns = ['part','date','N1','N2','N3','N4','N5','N6','N7','N8']\n",
        "\n",
        "        # 'date'カラムのデータを日付型に変換します。この際、日付の形式を指定します。\n",
        "        df_Bin5['date'] = pd.to_datetime(df_Bin5['date'], format='%Y年%m月%d日')\n",
        "\n",
        "        # 新たなカラム\"LOTO\"を作成し、その値として\"Bin5\"を格納します。これは、このデータフレームがビンゴ5のデータであることを示します。\n",
        "        df_Bin5[\"LOTO\"] = \"Bin5\"\n",
        "\n",
        "        return df_Bin5\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラーが発生しました。関数名: make_Bin5, エラーメッセージ: {str(e)}[/red bold]\\n{'*'*100}\")\n",
        "\n",
        "\n",
        "def make_loto(name: str = \"loto6\", col: int = 9, ln: int = 6, b: int = 1) -> pd.DataFrame:\n",
        "    '''\n",
        "    この関数は、指定されたロト（例：loto6）のデータをウェブから取得し、pandasのデータフレームに格納します。\n",
        "\n",
        "    :param name: 取得するロトの名前を指定します。デフォルトは\"loto6\"。str型。\n",
        "    :param col: 取得するカラムの数を指定します。デフォルトは9。int型。\n",
        "    :param ln: ナンバーの数を指定します。デフォルトは6。int型。\n",
        "    :param b: ボーナスの数を指定します。デフォルトは1。int型。\n",
        "    :return: 取得したロトのデータを格納したデータフレーム。pandas.DataFrame型。\n",
        "    '''\n",
        "    try:\n",
        "        # データフレームのカラム名を作成します。\"part\"、\"date\"、ナンバー(\"N1\"~\"N6\")、ボーナス(\"B1\")を含みます。\n",
        "        names = [\"part\", \"date\"] + [\"N\" + str(i) for i in range(1, ln + 1)] + [\"B\" + str(j) for j in range(1, b + 1)]\n",
        "\n",
        "        # 指定されたロトのデータをウェブから読み込みます。読み込んだデータはshift-jisでエンコードされています。\n",
        "        df = pd.read_table('https://' + name + '.thekyo.jp/data/' + name + '.csv', encoding=\"shift-jis\",\n",
        " sep=\",\", skiprows=1, usecols=list(range(col)), parse_dates=[1], names=names)  # datetimeの選択\n",
        "\n",
        "        # 新たなカラム\"LOTO\"を作成し、ロトの名前を格納します。これは、このデータフレームがどのロトのデータであることを示します。\n",
        "        df[\"LOTO\"] = name\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]エラーが発生しました。関数名: make_loto, エラーメッセージ: {str(e)}[/red bold]\\n{'*'*100}\")\n",
        "\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def one_hot_encode_week(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    '''\n",
        "    この関数は、データフレームの'week'カラムをワンホットエンコーディングします。\n",
        "\n",
        "    :param df: ワンホットエンコーディングを行うデータフレーム。pandas.DataFrame型。\n",
        "    :return: 'week'カラムをワンホットエンコーディングしたデータフレーム。pandas.DataFrame型。\n",
        "    '''\n",
        "    try:\n",
        "        # 'week'カラムの各値をワンホットエンコーディングします。これにより、'week'カラムの各値が新たなカラムとして追加されます。\n",
        "        week_dummies = pd.get_dummies(df['week'], prefix='week')\n",
        "\n",
        "        # オリジナルのデータフレームとワンホットエンコーディングしたデータフレームを連結します。\n",
        "        df = pd.concat([df, week_dummies], axis=1)\n",
        "\n",
        "        # 元の'week'カラムはもう必要ないので、データフレームから削除します。\n",
        "        df.drop('week', axis=1, inplace=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "        dric(\"[blue bold]関数名:[/blue bold] one_hot_encode_week\")\n",
        "        dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return df\n",
        "\n",
        "def remove_directory(dir_path):\n",
        "    \"\"\"\n",
        "    指定したディレクトリが存在する場合、それを削除します。\n",
        "\n",
        "    Parameters:\n",
        "    dir_path (str): 削除するディレクトリのパス\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if os.path.exists(dir_path):\n",
        "            shutil.rmtree(dir_path)\n",
        "            dric(f\"[green bold]{dir_path}は正常に削除されました。[/green bold]\")\n",
        "        else:\n",
        "            dric(f\"[red bold]{dir_path}にディレクトリが見つかりませんでした。[/red bold]\")\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "        dric(\"[blue bold]関数名:[/blue bold] remove_directory\")\n",
        "        dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "def select_columns(df, select_loto):\n",
        "    \"\"\"\n",
        "    指定したカラム名を持つデータフレームから、必要なカラムのみを選択します。\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): 入力のデータフレーム\n",
        "    select_loto (str): 選択するカラム名のリスト\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: 選択したカラムを持つデータフレーム\n",
        "    \"\"\"\n",
        "    try:\n",
        "        base_columns = ['part', 'date', 'week_月', 'week_木', 'week_水', 'week_火', 'week_金', 'eto_仏滅', 'eto_先勝', 'eto_先負', 'eto_友引', 'eto_大安', 'eto_赤口', 'is_hd_False', 'is_hd_True']\n",
        "        column_dict = {\n",
        "            'num3': ['N1', 'N2', 'N3'],\n",
        "            'num4': ['N1', 'N2', 'N3', 'N4'],\n",
        "            'Bin5': ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8'],\n",
        "            'mini': ['N1', 'N2', 'N3', 'N4', 'N5', 'B1'],\n",
        "            'loto6': ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'B1'],\n",
        "            'loto7': ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'B1', 'B2']\n",
        "        }\n",
        "        targets = base_columns + column_dict[select_loto]\n",
        "        return df[targets]\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "        dric(\"[blue bold]関数名:[/blue bold] select_columns\")\n",
        "        dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "def update_variables(df_leng, test_size, select_all_features):\n",
        "    \"\"\"\n",
        "    変数を更新する関数を定義します。\n",
        "\n",
        "    Parameters:\n",
        "    df_leng (int): データフレームの長さ\n",
        "    test_size (int): テストサイズ\n",
        "    select_all_features (bool): すべての特徴を選択するかどうか\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    global features_df_, Y_train_pre_df, Y_test_pre_df, feature, leng, horizon, freq\n",
        "    try:\n",
        "        dric(f\"df_leng={df_leng}, test_size={test_size}, select_all_features={select_all_features}\")\n",
        "        features_df_ = selected_loto_df.tail(df_leng)\n",
        "\n",
        "        # select_all_featuresがFalseの場合、'unique_id'、'y'、および'ds'のみを選択します\n",
        "        if not select_all_features:\n",
        "            Y_train_pre_df = features_df_.iloc[:-test_size]\n",
        "        if test_size == 0:\n",
        "            Y_test_pre_df = features_df_.iloc[-1:]\n",
        "            horizon = 1\n",
        "        else:\n",
        "            Y_test_pre_df = features_df_.iloc[-test_size:]\n",
        "            horizon = test_size\n",
        "        feature = len(Y_train_pre_df.columns)\n",
        "        leng = len(Y_train_pre_df)\n",
        "\n",
        "        freq = 'D'\n",
        "        dric(f\"[blue bold]df_leng:[/blue bold] {df_leng}, [blue bold]test_size:[/blue bold] {test_size}, [blue bold]feature:[/blue bold] {feature}, [blue bold]leng:[/blue bold] {leng}, [blue bold]horizon:[/blue bold] {horizon}, [blue bold]freq:[/blue bold] {freq}\")\n",
        "        dric(f\"selected_loto_dfからY_test_pre_dfとY_train_pre_dfを作成しました\")\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "        dric(\"[blue bold]関数名:[/blue bold] update_variables\")\n",
        "        dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def reshape_dataframe(df):\n",
        "    \"\"\"\n",
        "    データフレームを再形成する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        再形成する対象のデータフレーム\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    reshaped_df : pandas.DataFrame\n",
        "        再形成されたデータフレーム\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if df is None:\n",
        "            raise ValueError(\"データフレームが定義されていません。\")\n",
        "        #dric(f\"df.columns={df.columns}\")\n",
        "            # Check if df is a DataFrame\n",
        "        if not isinstance(df, pd.DataFrame):\n",
        "            raise TypeError(f\"Expected pandas.DataFrame but got {type(df)}\")\n",
        "        # Check if df has columns attribute\n",
        "        if not hasattr(df, 'columns'):\n",
        "            raise AttributeError(\"データフレームには 'columns' 属性が必要です。\")\n",
        "        # n_cols を動的に取得\n",
        "        n_cols = [col for col in df.columns if 'N' in col and '_MA' not in col and '_MS' not in col and '_DF' not in col and '_cum' not in col]\n",
        "        if not n_cols:\n",
        "            raise ValueError(\"n_cols が空です。'N' を含む列がデータフレームに存在しません。\")\n",
        "        # n_ma_cols と n_cumsum_cols を n_cols から作成\n",
        "        n_ma_cols = [f\"{col}_MA\" for col in n_cols]\n",
        "        n_ms_cols = [f\"{col}_MS\" for col in n_cols]\n",
        "        n_df_cols = [f\"{col}_DF\" for col in n_cols]\n",
        "        n_cumsum_cols = [f\"{col}_cum\" for col in n_cols]\n",
        "\n",
        "        dric(f\"n_cols={n_cols}\")\n",
        "        non_n_cols = [col for col in df.columns if col not in n_cols + n_ma_cols + n_ms_cols+ n_df_cols+ n_cumsum_cols]\n",
        "\n",
        "        reshaped_df = pd.DataFrame()\n",
        "        for i, (n, ma, ms, diff, cumsum) in tqdm(enumerate(zip(n_cols, n_ma_cols, n_ms_cols, n_df_cols, n_cumsum_cols))):\n",
        "\n",
        "            temp_df = df[non_n_cols + [n, ma, ms, diff, cumsum]].copy()\n",
        "            temp_df.rename(columns={n: 'N', ma: 'N_MA', ms: 'N_MS', diff: 'N_DF', cumsum: 'N_cum'}, inplace=True)\n",
        "            temp_df['unique_id'] = i\n",
        "            reshaped_df = pd.concat([reshaped_df, temp_df])\n",
        "\n",
        "        reshaped_df.reset_index(drop=True, inplace=True)\n",
        "        reshaped_df[\"No\"] =reshaped_df[\"N\"]\n",
        "        reshaped_df = pd.get_dummies(reshaped_df, columns=['N'])\n",
        "        cols = reshaped_df.columns.drop('date')\n",
        "        reshaped_df[cols] = reshaped_df[cols].astype(int)\n",
        "\n",
        "        # カラム名の置換を効率的に行う\n",
        "        replacements = {\n",
        "            'N_': '',\n",
        "            'eto_': '',\n",
        "            'week_': '',\n",
        "            'True': '1',\n",
        "            'False': '0'\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            reshaped_df.columns = reshaped_df.columns.to_series().replace(replacements, regex=True)\n",
        "            dric(\"カラム名の置換が成功しました。\")\n",
        "        except Exception as e:\n",
        "            dric(f\"カラム名の置換中にエラーが発生しました: {e}\")\n",
        "\n",
        "        cols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "        reshaped_df.columns = [int(col) if col in cols else col for col in reshaped_df.columns]\n",
        "        #dric(f\"reshaped_df.columns={reshaped_df.columns}\")\n",
        "\n",
        "        return reshaped_df\n",
        "    except ValueError as e:\n",
        "        dric(f\"[red bold]エラー: {e}[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "        return reshaped_df\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]予期しないエラー: {e}[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "        return reshaped_df\n",
        "\n",
        "# @jit(nopython=True)\n",
        "def filter_dataframe(change: dict = None) -> None:\n",
        " '''\n",
        " 選択された宝くじの種類に応じてデータフレームをフィルタリングする関数\n",
        "\n",
        " Args:\n",
        " change (dict, optional): ドロップダウンメニューの値が変更されたときに生成される辞書型のデータ。\n",
        " 'new'キーは新しく選択された値を表します。デフォルトはNone。\n",
        "\n",
        " Returns:\n",
        " None: この関数は何も返しません。ただし、グローバル変数filtered_dfが更新されます。\n",
        " '''\n",
        " # グローバル変数を参照します\n",
        " global filtered_df\n",
        " # ドロップダウンメニューで新しく選択された宝くじの種類を取得します\n",
        " # changeがNoneの場合、デフォルトで\"num4\"を選択します\n",
        " selected_column = change['new'] if change else \"num4\"\n",
        " # データフレームをフィルタリングします。\n",
        " # 選択された宝くじの種類の列が1の行だけを残します。\n",
        " try: # ここからエラーハンドリングを追加\n",
        "     filtered_df = df_encoded[df_encoded[selected_column] == 1]\n",
        " except NameError as e: # df_encodedが未定義の場合に発生する例外\n",
        "     dric(f\"データフレームdf_encodedが未定義です。{e}\")\n",
        "     traceback.print_exc()\n",
        "     raise e  # エラーを再度発生させてプログラムを終了します\n",
        "\n",
        " except KeyError as e: # 選択された宝くじの種類の列が存在しない場合に発生する例外\n",
        "     dric(f\"データフレームdf_encodedに{selected_column}という列がありません。{e}\")\n",
        "     traceback.print_exc()\n",
        "     raise e  # エラーを再度発生させてプログラムを終了します\n",
        " else: # 例外が発生しなかった場合に実行する処理\n",
        "     # フィルタリングされたデータフレームをHTMLテーブルとして表示します。\n",
        "     #display(HTML(filtered_df.head().to_html()))\n",
        "     pass\n",
        " finally: # 例外の有無に関わらず必ず実行する処理\n",
        "     dric(f\"{selected_column}でフィルタリングしました。\")\n",
        "\n",
        "\n",
        "def select_df():\n",
        "  '''\n",
        "  セレクトボックスを表示し、ユーザーが宝くじの種類を選択できるようにする関数\n",
        "\n",
        "  引数: なし\n",
        "  戻り値: なし\n",
        "  '''\n",
        "  try:\n",
        "      # セレクトボックスを表示します。ユーザーが選択するためのものです。\n",
        "      display(select_box)\n",
        "\n",
        "      # 選択された宝くじの種類が変わったときに上記の関数を呼び出すように設定します。\n",
        "      # この操作は「observe」と呼ばれ、ドロップダウンメニューの値が変更されるたびにfilter_dataframe関数が呼び出されるようにします。\n",
        "      select_box.observe(filter_dataframe, names='value')\n",
        "\n",
        "      # 初期状態でfilter_dataframe関数を呼び出し、デフォルトの\"Bin5\"でフィルタリングします。\n",
        "      filter_dataframe()\n",
        "  except Exception as e:\n",
        "      dric(\"[red bold]エラーが発生しました。詳細は以下の通りです。[/red bold]\")\n",
        "      dric(\"[blue bold]関数名:[/blue bold] select_df\")\n",
        "      dric(\"[blue bold]エラーメッセージ:[/blue bold]\", e)\n",
        "      traceback.print_exc()\n",
        "\n",
        "\n",
        "def add_sum_of_cols(df, cols, new_col_name):\n",
        "    \"\"\"\n",
        "    指定された複数のカラムの合計値を新しいカラムとしてデータフレームに追加する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        合計値を追加する対象のデータフレーム\n",
        "    cols : list of str\n",
        "        合計値を計算するためのカラムのリスト\n",
        "    new_col_name : str\n",
        "        新しく追加するカラムの名前\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if df is None:\n",
        "            raise ValueError(\"データフレームが定義されていません。\")\n",
        "        if not set(cols).issubset(df.columns):\n",
        "            raise ValueError(\"一つまたはそれ以上のカラムがデータフレームに存在しません。\")\n",
        "        df[new_col_name] = df.loc[:, cols].sum(axis=1)\n",
        "    except ValueError as e:\n",
        "        dric(f\"[red bold]エラー: {e}[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]予期しないエラー: {e}[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "#@title stumpyを追加\n",
        "def calculate_matrix_profile(df, target, window_sizes):\n",
        "    \"\"\"\n",
        "    指定された列のMatrix Profileを計算し、新しい列に追加する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        Matrix Profileを計算する対象のデータフレーム\n",
        "    target : str\n",
        "        Matrix Profileを計算する対象の列名\n",
        "    window_sizes : list of int\n",
        "        Matrix Profileを計算する際のウィンドウサイズのリスト\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df : pandas.DataFrame\n",
        "        Matrix Profileが計算され、新しい列が追加されたデータフレーム\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if df is None:\n",
        "            raise ValueError(\"データフレームが定義されていません。\")\n",
        "        if target not in df.columns:\n",
        "            raise ValueError(f\"{target}はデータフレームに存在しません。\")\n",
        "        if not isinstance(window_sizes, list) or not all(isinstance(i, int) for i in window_sizes):\n",
        "            raise ValueError(\"window_sizesは整数のリストでなければなりません。\")\n",
        "\n",
        "        # 'target'カラムのデータ型をnumpy.float64に変換\n",
        "        df[target] = df[target].astype(np.float64)\n",
        "\n",
        "        for window in tqdm(window_sizes):\n",
        "            matrix_profile = stumpy.stump(df[target], m=window)\n",
        "            df.loc[df.index[window - 1:], f'feature_{target}_window_{window}'] = matrix_profile[:, 0]\n",
        "\n",
        "        return df\n",
        "\n",
        "    except ValueError as e:\n",
        "        dric(f\"[red bold]エラー: {e}[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]予期しないエラー: {e}[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# カラムの可視化\n",
        "def plot_columns(df, columns, color='unique_id'):\n",
        "    \"\"\"\n",
        "    データフレームの指定されたカラムをプロットします。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        プロットするデータが含まれているデータフレーム\n",
        "    columns : list of str\n",
        "        プロットするカラムのリスト\n",
        "    color : str, default 'unique_id'\n",
        "        プロットの色を指定するカラムの名前\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # colorが\"0\"から\"9\"の文字列である場合に数値に変換\n",
        "        if str(color).isdigit() and 0 <= int(color) <= 9:\n",
        "            color = int(color)\n",
        "        # サブプロットの作成\n",
        "        fig = sp.make_subplots(rows=len(columns), cols=1)\n",
        "\n",
        "        # 各列のデータを追加\n",
        "        for i, column in enumerate(columns, start=1):\n",
        "            if column in df.columns:\n",
        "                for trace in px.line(df, x='date', y=column, color=color, title=column).data:\n",
        "                    fig.add_trace(trace, row=i, col=1)\n",
        "                fig.update_yaxes(title_text=\"値\", row=i, col=1)\n",
        "            else:\n",
        "                dric(f\"[red bold]\\n{'*' * 100}\\n関数plot_columns: {column}はデータフレームに存在しません。\\n{'*' * 100}[/red bold]\")\n",
        "\n",
        "        # タイトルの設定と自動サイズ調整\n",
        "        fig.update_layout(autosize=True, height=300*len(columns), title_text=\"時間経過による各カラムのサブプロット\")\n",
        "\n",
        "        # 日付の形式を年月日に変更\n",
        "        fig.update_xaxes(tickformat=\"%Y-%m-%d\")\n",
        "\n",
        "        # グラフの表示\n",
        "        fig.show()\n",
        "    except Exception as e:\n",
        "        dric(f\"[red bold]\\n{'*' * 100}\\n関数plot_columns: エラーが発生しました: {e}\\n{'*' * 100}[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def on_change(change):\n",
        "    \"\"\"\n",
        "    チェックボックスの値が変更されたときの動作を定義する関数。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    change : dict\n",
        "        チェックボックスの値が変更されたときのイベント情報。\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if change['type'] == 'change' and change['name'] == 'value':\n",
        "            # 選択されたモデルをmodelsに設定\n",
        "            global models\n",
        "            models = [pre_models[i] for i in range(len(pre_models)) if checkboxes[i].value]\n",
        "    except Exception as e:\n",
        "        dric(f\"{on_change.__name__}関数でエラーが発生しました。\\n{'*'*100}\\n{e}\\n{'*'*100}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def undefined_vars_check():\n",
        "    \"\"\"\n",
        "    この関数は、特定の変数が定義されているかどうかをチェックします。\n",
        "    定義されていない変数がある場合、その変数の名前を表示します。\n",
        "    \"\"\"\n",
        "    variables = ['horizon', 'cpus', 'gpus', 'verbose', 'backend', 'refit_with_val', 'num_samples', 'n_series']\n",
        "    undefined_vars = []\n",
        "\n",
        "    for var in variables:\n",
        "        try:\n",
        "            exec(f\"{var}\")\n",
        "        except NameError:\n",
        "            undefined_vars.append(var)\n",
        "\n",
        "    if undefined_vars:\n",
        "        dric(f\"[red bold]以下の変数が定義されていません: {', '.join(undefined_vars)}[/red bold]\")\n",
        "        return False\n",
        "    else:\n",
        "        dric(\"[green bold]すべての変数が正しく定義されています。[/green bold]\")\n",
        "        return True\n",
        "\n",
        "def process_data(df):\n",
        "    \"\"\"\n",
        "    データフレーム内の各カラムについて、移動平均、移動合計、差分、累積和を計算します。\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): 処理対象のデータフレーム。'N1', 'N2', 'N3', 'N4'の各カラムが必要です。\n",
        "\n",
        "    Returns:\n",
        "    df (pandas.DataFrame): 処理後のデータフレーム。元のデータフレームに新たなカラムが追加されます。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 'N1', 'N2', 'N3', 'N4'の各カラムについて処理\n",
        "        for column in n_cols:\n",
        "            df[column + '_MA'] = df[column].rolling(window=window).mean()\n",
        "            df[column + '_MS'] = df[column].rolling(window=window).sum()\n",
        "            df[column + '_DF'] = df[column].diff(window)\n",
        "            df[column + '_cum'] = df[column].cumsum()\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        dric(f\"エラーが発生しました: {e}\")\n",
        "        return None\n",
        "\n",
        "def worker(task):\n",
        "    \"\"\"\n",
        "    各タスクを実行する関数です。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        function, args = task\n",
        "        return function(*args)\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]worker関数でエラーが発生しました: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def make_df_parallel(tasks):\n",
        "    \"\"\"\n",
        "    複数のタスクを並列に実行し、結果をデータフレームとして返す関数です。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with mp.Pool(mp.cpu_count()) as pool:\n",
        "            results = pool.map(worker, tasks)\n",
        "        return pd.concat(results).sort_values('date')\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]make_df_parallel関数でエラーが発生しました: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def get_rokuyo(date):\n",
        "    \"\"\"\n",
        "    日付から六曜を計算する関数です。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        rokuyo = [\"大安\", \"赤口\", \"先勝\", \"友引\", \"先負\", \"仏滅\"]\n",
        "        return rokuyo[(date.year + date.month + date.day) % 6]\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]get_rokuyo関数でエラーが発生しました: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def calculate_kabbalah_number(date):\n",
        "    \"\"\"\n",
        "    日付からカバラ数を計算する関数です。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 日付を文字列に変換\n",
        "        date_str = date.strftime(\"%Y%m%d\")\n",
        "\n",
        "        # 各数字を足し合わせる\n",
        "        kabbalah_number = sum(int(digit) for digit in date_str)\n",
        "\n",
        "        # カバラ数が一桁になるまで足し合わせる\n",
        "        while kabbalah_number > 9:\n",
        "            kabbalah_number = sum(int(digit) for digit in str(kabbalah_number))\n",
        "\n",
        "        return kabbalah_number\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]calculate_kabbalah_number関数でエラーが発生しました: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def get_current_time_jst():\n",
        "    \"\"\"\n",
        "    日本時間で現在の日時を取得し、年月日時分秒の形式にフォーマットします。\n",
        "\n",
        "    Returns:\n",
        "        str: 年月日時分秒の形式にフォーマットされた現在の日時\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 日本時間のタイムゾーンを取得\n",
        "        jst = pytz.timezone('Asia/Tokyo')\n",
        "\n",
        "        # 現在の日本時間を取得\n",
        "        now = dt.now(jst)\n",
        "\n",
        "        # 年月日時分秒の形式にフォーマット\n",
        "        formatted_now = now.strftime('%Y_%m_%d')\n",
        "\n",
        "        return formatted_now\n",
        "    except Exception as e:\n",
        "        dric(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_dataframe(df, path):\n",
        "    \"\"\"\n",
        "    データフレームを指定したパスにCSVファイルとして保存します。\n",
        "    指定したパスにディレクトリが存在しない場合、新たにディレクトリを作成します。\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): 保存するデータフレーム\n",
        "        path (str): 保存先のパス\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ディレクトリのパスを取得\n",
        "        dir_name = os.path.dirname(path)\n",
        "\n",
        "        # ディレクトリが存在しない場合は作成\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "\n",
        "        # データフレームをCSVファイルとして保存\n",
        "        # df.to_csv(path)\n",
        "        df.to_csv(path, index=False)\n",
        "    except Exception as e:\n",
        "        dric(f\"エラーが発生しました: {e}\")\n",
        "\n",
        "def preprocess_dataframe(df,num=0.3):\n",
        "    try:\n",
        "        # part列でNaNになっているレコードを削除し、値がすべて同じカラムを削除\n",
        "        # NaNが含まれている列を削除し、レコードの値がすべてNaNのレコードを削除\n",
        "        # dateで昇順に並べ替え、次にunique_idで並べ替え\n",
        "        # インデックスをリセット\n",
        "        df = (\n",
        "            df.dropna(subset=['part'])\n",
        "            .loc[:, df.nunique() != 1]\n",
        "            .dropna(how='all')\n",
        "            .sort_values(by=['date', 'unique_id'])\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "    except Exception as e:\n",
        "        dric(f\"エラー: 前処理中に問題が発生しました: {e}\")\n",
        "\n",
        "    try:\n",
        "        # 各カラムのNaNの割合を計算し、NaNの割合が0.3以上のカラムを取得\n",
        "        columns_to_drop = (df.isnull().sum() / len(df))[lambda x: x > num].index\n",
        "    except Exception as e:\n",
        "        dric(f\"エラー: NaNの割合の計算中に問題が発生しました: {e}\")\n",
        "\n",
        "    try:\n",
        "        # これらのカラムを削除し、NaNが含まれるレコードを削除\n",
        "        df = (\n",
        "            df.drop(columns_to_drop, axis=1)\n",
        "            .dropna()\n",
        "        )\n",
        "    except Exception as e:\n",
        "        dric(f\"エラー: カラムとレコードの削除中に問題が発生しました: {e}\")\n",
        "\n",
        "    # NaNが含まれているか確認\n",
        "    if df.isnull().values.any():\n",
        "        dric(\"警告: 作成したデータフレームにはNaNが含まれています。\")\n",
        "\n",
        "    # インデックスを再度リセット\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "#ウィジェットの関数群##############################################################################################################################################\n",
        "class DataHolder:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        DataHolderクラスの初期化メソッドです。\n",
        "        このクラスはデータフレームを保持するためのクラスです。\n",
        "        初期化時には、df属性はNoneに設定されます。\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.df = None\n",
        "            self.check = None\n",
        "            self.filename = None\n",
        "        except Exception as e:\n",
        "            dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "            traceback.print_exc()\n",
        "            dric(\"*\"*100)\n",
        "data_holder = DataHolder()\n",
        "\n",
        "def on_checkbox_change(change):\n",
        "    \"\"\"\n",
        "    チェックボックスの値が変更されたときに呼び出されるイベントハンドラです。\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        data_holder.check = None\n",
        "        checkbox_value = change['new']\n",
        "        dric(\"[green]Checkbox value: {}[/green]\".format(checkbox_value))\n",
        "        if checkbox_value:\n",
        "            dropdown_widget = create_vuetify_dropdown(path)\n",
        "            dropdown_widget.observe(on_dropdown_value_change, names='v_model')  # ここでobserveを呼び出します\n",
        "            display(vue.Html(tag=\"h10\", children=[\"保存データのロード\"]), v.Spacer(height='100px'), dropdown_widget)\n",
        "            data_holder.check = checkbox_value\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "        traceback.print_exc()\n",
        "        dric(\"*\"*100)\n",
        "\n",
        "def create_vuetify_checkbox():\n",
        "    \"\"\"\n",
        "    ブール値による有効/無効の切り替えを行うチェックボックスを作成します。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ラベルを作成し、スタイルを設定\n",
        "        label = v.Html(tag='span', children=['load'], class_='d-inline-block', style_='font-size: 30px; vertical-align: middle;')\n",
        "\n",
        "        # チェックボックスの色を設定\n",
        "        checkbox = v.Checkbox(\n",
        "            v_model=False,\n",
        "            color='primary',\n",
        "            class_='ma-2 d-inline-block',\n",
        "            style_='width: 60px; height: 60px; font-size: 400px; font-family: Arial, sans-serif; vertical-align: middle;'  # フォントの種類を設定\n",
        "        )\n",
        "\n",
        "        # チェックボックスのv_modelが変更されたときにイベントハンドラを呼び出すように設定\n",
        "        checkbox.observe(on_checkbox_change, names='v_model')\n",
        "\n",
        "        # ラベルとチェックボックスを一緒に表示\n",
        "        return v.Layout(children=[label, checkbox])\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "        traceback.print_exc()\n",
        "        dric(\"*\"*100)\n",
        "\n",
        "def create_vuetify_dropdown(path):\n",
        "    \"\"\"\n",
        "    指定されたパス内のファイルからドロップダウンを作成します。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        files = os.listdir(path)\n",
        "        dropdown = v.Select(\n",
        "            items=files,\n",
        "            label='Select File',\n",
        "            style_='font-size: 25px; width: 1000px; height: 200px;',  # 幅と高さを設定\n",
        "            color='primary',  # ドロップダウンの色を設定\n",
        "            dense=True,\n",
        "            outlined=True,\n",
        "            item_color='primary',  # 選択した項目の色を設定\n",
        "            item_text_style='font-size: 25px;',  # ドロップダウンメニューの文字サイズを設定\n",
        "            v_model=None  # 初期値をNoneに設定\n",
        "        )\n",
        "        return dropdown\n",
        "    except Exception as e:\n",
        "        dric(f\"[red]エラーが発生しました: {str(e)}[/red]\")\n",
        "        dric(\"*\"*100)\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def on_dropdown_value_change(change):\n",
        "    \"\"\"\n",
        "    ドロップダウンの値が変更されたときに呼び出されるイベントハンドラです。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        filename = change['new']\n",
        "        dric(f\"{('*'*100)}\\nDropdown value changed to {filename}\")\n",
        "\n",
        "        # ファイルのパスを作成\n",
        "        file_path = os.path.join(path, filename)\n",
        "\n",
        "        # ファイルからデータフレームを作成\n",
        "        df = pd.read_csv(file_path)\n",
        "        if 'Unnamed: 0' in df.columns:\n",
        "            df = df.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "        # データフレームを表示（または返す）\n",
        "        display(df.tail())\n",
        "        display(f\"カラム数 {len(df.columns)}  \\n レコード数 {len(df)}\")\n",
        "        display(filename)\n",
        "        data_holder.df = None\n",
        "        data_holder.filename = None\n",
        "        # Store the DataFrame in the data_holder object\n",
        "        data_holder.df = df\n",
        "        data_holder.filename = path\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        dric(f\"{('*'*100)}\\n[red]Error occurred in function on_dropdown_value_change: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "#############################################################################################################################################\n",
        "# データフレームの成形を行う関数\n",
        "@ray.remote\n",
        "def reshape_df(filtered_df, other_columns, i):\n",
        "    try:\n",
        "        # 選択した列を取得します\n",
        "        col = other_columns[i]\n",
        "\n",
        "        # フィルタリングされたデータフレームから特定の列を選択します\n",
        "        temp_df = filtered_df[['part', 'date', col]]\n",
        "\n",
        "        # 列名を変更します\n",
        "        temp_df.columns = ['part', 'date', 'No']\n",
        "\n",
        "        # 新しい列を追加し、その値を設定します\n",
        "        temp_df['origin_column'] = f'N{i+1}'\n",
        "\n",
        "        # 'No'列の値に基づいてダミー変数を作成します\n",
        "        one_hot = pd.get_dummies(temp_df['No'])\n",
        "\n",
        "        # ダミー変数のデータ型を整数に変換します\n",
        "        one_hot = one_hot.astype(int)\n",
        "\n",
        "        # データフレームとダミー変数を結合します\n",
        "        temp_df = pd.concat([temp_df, one_hot], axis=1)\n",
        "\n",
        "        # 成形されたデータフレームを返します\n",
        "        return temp_df\n",
        "    except Exception as e:\n",
        "        # エラーメッセージを表示します\n",
        "        dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "        dric(\"*\"*100)\n",
        "        # どの関数でエラーが発生したかを表示します\n",
        "        dric(\"[red]エラーが発生した関数: reshape_df[/red]\")\n",
        "        traceback.print_exc()\n",
        "        dric(\"*\"*100)\n",
        "\n",
        "# @title データの成形　修正版 { run: \"auto\" }\n",
        "def select_columns_by_lottery_type(df_encoded, select_loto):\n",
        "    try:\n",
        "        # 宝くじの種類に応じて選択するカラムを定義\n",
        "        columns_dict = {\n",
        "            \"num4\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\"],\n",
        "            \"num3\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\"],\n",
        "            \"Bin5\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"N6\", \"N7\", \"N8\"],\n",
        "            \"loto6\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"B1\", \"N6\"],\n",
        "            \"loto7\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"B1\", \"N6\", \"N7\", \"B2\"],\n",
        "            \"miniloto\": [\"part\", \"date\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"B1\"]\n",
        "        }\n",
        "\n",
        "        # select_lotoカラムが1の行だけを抽出\n",
        "        df_filtered = df_encoded[df_encoded[select_loto] == 1]\n",
        "\n",
        "        # 選択された宝くじの種類に応じてカラムを選択\n",
        "        selected_columns = columns_dict[select_loto]\n",
        "\n",
        "        # 選択したカラムでデータフレームをフィルタリング\n",
        "        df_filtered = df_filtered[selected_columns]\n",
        "\n",
        "        return df_filtered\n",
        "    except Exception as e:\n",
        "        # エラーメッセージを表示します\n",
        "        dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "        dric(\"*\"*100)\n",
        "        # どの関数でエラーが発生したかを表示します\n",
        "        dric(\"[red]エラーが発生した関数: select_columns_by_lottery_type[/red]\")\n",
        "        traceback.print_exc()\n",
        "        dric(\"*\"*100)\n",
        "@ray.remote\n",
        "def process(unique_id):\n",
        "    \"\"\"\n",
        "    この関数は、指定されたユニークIDを持つデータをフィルタリングし、そのデータに対して様々な統計的処理を行います。\n",
        "    移動平均、移動合計、変化率、差分、自己相関、指数平滑化、ARIMAモデルのパラメータ、マトリックスプロファイルの計算が含まれます。\n",
        "\n",
        "    パラメータ:\n",
        "        unique_id (str): フィルタリングするデータのユニークID。\n",
        "\n",
        "    戻り値:\n",
        "        df_filtered (pd.DataFrame): 処理後のデータフレーム。\n",
        "\n",
        "    例外:\n",
        "        この関数は、処理中にエラーが発生した場合にエラーメッセージを表示します。\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        df_filtered = final_df[final_df['unique_id'] == unique_id]\n",
        "        # ユニークな日付の数を取得し、その長さの10%をｎとする\n",
        "        n = int(len(df_filtered['date'].unique()) * 0.05)\n",
        "        if n >30:\n",
        "            n=30\n",
        "        # for window in tqdm(range(3, n), file=sys.stderr):\n",
        "        df_filtered['cumsum'] = df_filtered[selected_column].cumsum()\n",
        "        for window in tqdm(range(3, n), desc='Processing windows', leave=False, file=sys.stderr):\n",
        "\n",
        "            # 移動平均\n",
        "            df_filtered[f'{selected_column}_rolling_mean_{window}'] = df_filtered[selected_column].rolling(window=window).mean()\n",
        "\n",
        "            # 移動合計\n",
        "            df_filtered[f'{selected_column}_rolling_sum_{window}'] = df_filtered[selected_column].rolling(window=window).sum()\n",
        "\n",
        "            # 変化率\n",
        "            df_filtered[f'{selected_column}_pct_change_{window}'] = df_filtered[selected_column].pct_change(window)\n",
        "\n",
        "            # 差分\n",
        "            df_filtered[f'{selected_column}_diff_{window}'] = df_filtered[selected_column].diff(window)\n",
        "\n",
        "            # 自己相関\n",
        "            acf_values = acf(df_filtered[selected_column], nlags=window)\n",
        "            acf_df = pd.DataFrame(acf_values, columns=[f'{selected_column}_acf_{window}'])\n",
        "            df_filtered = pd.concat([df_filtered, acf_df], axis=1)\n",
        "\n",
        "            # 指数平滑化\n",
        "            df_filtered[f'{selected_column}_ewm_{window}'] = df_filtered[selected_column].ewm(span=window).mean()\n",
        "\n",
        "            # ARIMAモデルのパラメータ（p, d, q）\n",
        "            model = ARIMA(df_filtered[selected_column], order=(1, 1, 1))\n",
        "            model_fit = model.fit()\n",
        "            df_filtered[f'{selected_column}_arima_params_{window}'] = model_fit.params\n",
        "\n",
        "            # stumpyを使用したマトリックスプロファイル\n",
        "            matrix_profile = stumpy.stump(df_filtered[selected_column].astype(np.float64), m=window)\n",
        "            df_filtered.loc[df_filtered.index[window - 1:], f'{selected_column}_matrix_profile_{window}'] = matrix_profile[:, 0]\n",
        "            df_filtered.reset_index(drop=True, inplace=True)  # インデックスをリセット\n",
        "            df_filtered = pd.concat([df_filtered, acf_df], axis=1)\n",
        "            df_filtered.reset_index(drop=True, inplace=True)  # インデックスをリセット\n",
        "        return df_filtered\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました[/red]\")\n",
        "        dric(f\"[red]エラーが発生した関数: {process.__name__}[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "def initialize_ray(lib_list=None):\n",
        "    \"\"\"\n",
        "    この関数は、Rayライブラリをシャットダウンし、次に初期化します。\n",
        "    初期化の際には、ダッシュボードの表示、使用可能なCPUとGPUの数、必要なパッケージのインストール、\n",
        "    ロギングレベルとフォーマットの設定などを行います。\n",
        "\n",
        "    戻り値:\n",
        "        なし\n",
        "\n",
        "    例外:\n",
        "        この関数は、初期化中にエラーが発生した場合にエラーメッセージを表示します。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Rayライブラリをシャットダウンします\n",
        "        ray.shutdown()\n",
        "\n",
        "        # Rayライブラリを初期化します\n",
        "        ray.init(include_dashboard=True ,\n",
        "                 num_cpus=mp.cpu_count(),\n",
        "                 num_gpus=torch.cuda.device_count(),\n",
        "                 runtime_env={\"pip\": lib_list},\n",
        "                 logging_level=logging.ERROR,\n",
        "                 logging_format=\"%(message)s\")\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました[/red]\")\n",
        "        dric(\"[red]エラーが発生した関数: initialize_ray[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "#寄与率の計算###############################################################################################################################################################################\n",
        "\n",
        "@ray.remote\n",
        "def compute_feature_importance(hyperparameters, model, features_df, target):\n",
        "    \"\"\"\n",
        "    特徴量の重要度を計算する関数です。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    hyperparameters : dict\n",
        "        モデルのハイパーパラメータを指定します。\n",
        "    model : object\n",
        "        学習するモデルのインスタンスを指定します。\n",
        "    features_df : pandas.DataFrame\n",
        "        特徴量を含むデータフレームを指定します。\n",
        "    target : str\n",
        "        目的変数のカラム名を指定します。\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        各種特徴量の重要度を計算した結果を返します。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        X = features_df.drop(target, axis=1)\n",
        "        y = features_df[target]\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 特徴量の重要度を計算\n",
        "        importances = model.feature_importances_\n",
        "\n",
        "        # Permutation Importance\n",
        "        perm_importance = permutation_importance(model, X, y, n_repeats=10, random_state=42)\n",
        "\n",
        "        # Mutual Information\n",
        "        mutual_info = mutual_info_regression(X, y)\n",
        "\n",
        "        # Correlation Coefficient\n",
        "        correlation_coef = X.corrwith(y)\n",
        "\n",
        "        # Lasso (L1) Regularization\n",
        "        lasso = LassoCV(cv=5).fit(X, y)\n",
        "        lasso_importance = np.abs(lasso.coef_)\n",
        "\n",
        "        return importances, perm_importance.importances_mean, mutual_info, correlation_coef, lasso_importance\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]関数 'compute_feature_importance' でエラーが発生しました: {e}[/red]\")\n",
        "        traceback.print_exc()\n",
        "#Git関係##########################################################################################################################################################\n",
        "\n",
        "def git_save(git_username, git_repository, git_pass):\n",
        "    \"\"\"\n",
        "    GitHubにコードを保存する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    git_username : str\n",
        "        GitHubのユーザー名\n",
        "    git_repository : str\n",
        "        GitHubのリポジトリ名\n",
        "    git_pass : str\n",
        "        GitHubのパスワード\n",
        "    \"\"\"\n",
        "    try:\n",
        "        os.chdir('/content/drive/MyDrive/ColabNotebooks/forecast_loto')\n",
        "        os.system('git add .')\n",
        "\n",
        "        # 現在の日付と時刻を取得（日本時間）\n",
        "        now = dt.now(pytz.timezone('Asia/Tokyo'))\n",
        "\n",
        "        # 日付と時刻を文字列に変換\n",
        "        datetime_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # コミットメッセージを作成\n",
        "        commit_message = f\"Commit on {datetime_str}\"\n",
        "\n",
        "        # git commitコマンドを実行\n",
        "        os.system(f'git commit -m \"{commit_message}\"')\n",
        "        os.system(f\"git push https://{git_username}:{git_pass}@github.com/{git_username}/{git_repository}.git\")\n",
        "        # .gitディレクトリのサイズを表示\n",
        "        dric(subprocess.getoutput('du -sh .git'))\n",
        "        os.chdir('/content/')\n",
        "        dric(\"✅ コードの保存が完了しました。\")\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]エラー発生関数: git_save[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def git_save(git_username, git_repository, git_token):\n",
        "    \"\"\"\n",
        "    GitHubにコードを保存する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    git_username : str\n",
        "        GitHubのユーザー名\n",
        "    git_repository : str\n",
        "        GitHubのリポジトリ名\n",
        "    git_token : str\n",
        "        GitHubのアクセストークン\n",
        "    \"\"\"\n",
        "    try:\n",
        "        os.chdir('/content/drive/MyDrive/ColabNotebooks/forecast_loto')\n",
        "        os.system('git add .')\n",
        "\n",
        "        # 現在の日付と時刻を取得（日本時間）\n",
        "        now = dt.now(pytz.timezone('Asia/Tokyo'))\n",
        "\n",
        "        # 日付と時刻を文字列に変換\n",
        "        datetime_str = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # コミットメッセージを作成\n",
        "        commit_message = f\"Commit on {datetime_str}\"\n",
        "\n",
        "        # git commitコマンドを実行\n",
        "        os.system(f'git commit -m \"{commit_message}\"')\n",
        "        push_command = f\"git push https://{git_username}:{git_token}@github.com/{git_username}/{git_repository}.git\"\n",
        "        push_result = subprocess.run(push_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "        if push_result.returncode != 0:\n",
        "            raise Exception(f\"Git push failed with error: {push_result.stderr.decode('utf-8')}\")\n",
        "\n",
        "        # .gitディレクトリのサイズを表示\n",
        "        dric(subprocess.getoutput('du -sh .git'))\n",
        "        os.chdir('/content/')\n",
        "        dric(\"✅ コードの保存が完了しました。\")\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]エラー発生関数: git_save[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "def git_log():\n",
        "    \"\"\"\n",
        "    この関数は、.gitディレクトリのサイズとgitのログを表示します。\n",
        "    現在の作業ディレクトリを'/content/drive/MyDrive/ColabNotebooks/forecast_loto'に変更し、\n",
        "    コマンドを実行した後、元のディレクトリに戻ります。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 元の作業ディレクトリを保存\n",
        "        original_dir = os.getcwd()\n",
        "\n",
        "        # 作業ディレクトリを変更\n",
        "        os.chdir('/content/drive/MyDrive/ColabNotebooks/forecast_loto')\n",
        "\n",
        "        # .gitディレクトリのサイズを表示\n",
        "        dric(subprocess.getoutput('du -sh .git'))\n",
        "\n",
        "        # gitのログを表示\n",
        "        dric(subprocess.getoutput('git log'))\n",
        "\n",
        "        # 作業ディレクトリを元に戻す\n",
        "        os.chdir(original_dir)\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]エラー発生関数：{git_log.__name__}[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ：{str(e)}[/red]\")\n",
        "        dric(\"[red]\" + \"*\" * 100 + \"[/red]\")\n",
        "        traceback.print_exc()\n",
        "#モデルの定義での関数###############################################################################################################################\n",
        "\n",
        "def on_select_all_change(change):\n",
        "    \"\"\"\n",
        "    全て選択/選択解除のチェックボックスが変更されたときに呼び出される関数\n",
        "    Args:\n",
        "        change: チェックボックスの状態変化\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 全てのチェックボックスの値を全て選択/選択解除のチェックボックスの値と同じに設定\n",
        "        for checkbox in checkboxes:\n",
        "            checkbox.value = select_all.value\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]関数名: on_select_all_change[/red]\")\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "def beep():\n",
        "  from google.colab import output\n",
        "  output.eval_js('new Audio(\\\n",
        "\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\")\\\n",
        ".play()')\n",
        "\n",
        "\n",
        "# git_log()\n",
        "git_username =\"arumajirou\"\n",
        "git_token =\"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\"\n",
        "\n",
        "git_save(git_username,git_repository,git_token)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks\n",
        "!git clone https://github.com/arumajirou/forecast_loto.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sFryB_lBE-P",
        "outputId": "5524a175-db5e-4b60-a14b-306b8b95b32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            "fatal: destination path 'forecast_loto' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gitpython\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdpst_JC5Xvf",
        "outputId": "9347b142-0b9b-437c-b10e-738a42713011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.10/dist-packages (3.1.43)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython) (4.0.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/ColabNotebooks/forecast_loto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZcbSpONl4S1",
        "outputId": "3cc6cefd-5367-4ca4-e6bc-592c7188737a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[red]エラーが発生しました。[/red]\n",
            "[red]エラー発生関数: git_save[/red]\n",
            "[red]エラーメッセージ: /content/drive/MyDrive/Colab Notebooks/forecast_loto[/red]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from git import Repo\n",
        "import os\n",
        "\n",
        "# 設定変数\n",
        "git_username  = config['DEFAULT']['GIT_USERNAME']\n",
        "git_email = config['DEFAULT']['GIT_EMAIL']\n",
        "git_repository = config['DEFAULT']['GIT_REPOSITORY']\n",
        "git_token =  config['DEFAULT']['git_token']\n",
        "\n",
        "# リポジトリのパス\n",
        "repo_dir = '/content/drive/MyDrive/ColabNotebooks/forecast_loto'\n",
        "\n",
        "# リポジトリの初期化\n",
        "repo = Repo.init(repo_dir)\n",
        "\n",
        "# 現在のブランチを確認\n",
        "print(\"現在のブランチ: \", repo.active_branch.name)\n",
        "\n",
        "# ブランチが存在するかどうかを確認\n",
        "branch_name = \"master\"  # ここにブランチ名を入力\n",
        "if branch_name in repo.branches:\n",
        "    print(f\"{branch_name} ブランチが存在します。\")\n",
        "else:\n",
        "    print(f\"{branch_name} ブランチが存在しません。\")\n",
        "\n",
        "# 正しいブランチに切り替え\n",
        "branch_name = \"main\"  # ここにブランチ名を入力\n",
        "if branch_name in repo.branches:\n",
        "    repo.git.checkout(branch_name)\n",
        "    print(f\"{branch_name} ブランチに切り替えました。\")\n",
        "else:\n",
        "    print(f\"{branch_name} ブランチが存在しません。\")\n",
        "\n",
        "# ファイルの追加\n",
        "repo.git.add(all=True)\n",
        "\n",
        "# コミット\n",
        "repo.git.commit('-m', 'commit message')\n",
        "\n",
        "# リモートリポジトリの設定\n",
        "try:\n",
        "    origin = repo.remotes.origin\n",
        "except AttributeError:\n",
        "    origin = repo.create_remote('origin', f'https://{git_pass}@github.com/{git_username}/{git_repository}.git')\n",
        "\n",
        "# プッシュ\n",
        "try:\n",
        "    repo.git.push(f'https://{git_pass}@github.com/{git_username}/{git_repository}.git')\n",
        "    print(f\"{branch_name} ブランチをプッシュしました。\")\n",
        "except Exception as e:\n",
        "    print(f\"エラー: {branch_name} ブランチをプッシュできませんでした。エラーメッセージ: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfNQme7-hFLd",
        "outputId": "01092e5d-113e-44b5-d29f-dbedfd4800fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "現在のブランチ:  main\n",
            "master ブランチが存在しません。\n",
            "main ブランチに切り替えました。\n",
            "エラー: main ブランチをプッシュできませんでした。エラーメッセージ: Cmd('git') failed due to: exit code(128)\n",
            "  cmdline: git push https://*****@github.com/arumajirou/forecast_loto.git\n",
            "  stderr: 'fatal: could not read Password for 'https://ZxAsQw1290QazWsx@github.com': No such device or address'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzPcnZfa0t2O"
      },
      "source": [
        "# **<font color='Blue'>各種設定**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "yuYLvxorTGrM",
        "outputId": "7676b0f0-6a1c-4ebb-f3ee-00fa80d8a0a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "backend: ray\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">backend: ray\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "num_samples: \u001b[1;36m20\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">num_samples: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "refit_with_val: \u001b[3;92mTrue\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">refit_with_val: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "verbose: \u001b[3;92mTrue\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">verbose: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "horizon: \u001b[1;36m1\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">horizon: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "cpus: \u001b[1;36m8\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cpus: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "gpus: \u001b[1;36m1\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">gpus: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[33mtarget\u001b[0m=\u001b[35mNo_O\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">target</span>=<span style=\"color: #800080; text-decoration-color: #800080\">No_O</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[33mfreq\u001b[0m=\u001b[35mD\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">freq</span>=<span style=\"color: #800080; text-decoration-color: #800080\">D</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[33mfeature_contribution\u001b[0m=\u001b[3;91mFalse\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">feature_contribution</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-05-06 02:49:05,202\tINFO worker.py:1740 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8265, \"\", \"https://localhost:8265\", window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m9.\u001b[0m0M    .git\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>0M    .git\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅ コードの保存が完了しました。\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ コードの保存が完了しました。\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 68.6 ms, sys: 142 ms, total: 210 ms\n",
            "Wall time: 3.19 s\n"
          ]
        }
      ],
      "source": [
        "# @title #**各種設定** { run: \"auto\" }\n",
        "%%time\n",
        "#@markdown ---\n",
        "#@markdown #####**ロトの種類**\n",
        "select_loto ='num4'# @param  [\"num4\", \"num3\", \"Bin5\", \"loto6\", \"loto7\", \"miniloto\"]\n",
        "#@markdown ---\n",
        "#@markdown #####**ターゲットカラム**\n",
        "#@markdown - 0or1(No_O)、0or9(No)\n",
        "target ='No_O'# @param [\"No_O\",\"No\"]\n",
        "#@markdown ---\n",
        "#@markdown #####**データフレームの形状を変換するか**\n",
        "#@markdown - **\"reshape\"**\n",
        "#@markdown  - 2段階のカスケード構造\n",
        "#@markdown - **origin**\n",
        "#@markdown  - 1段階のカスケード構造\n",
        "use_reshape_dataframe = \"reshape\" # @param [\"reshape\",\"origin\"]\n",
        "#@markdown ---\n",
        "#@markdown #####**頻度**\n",
        "#@markdown - 日次(D)、週次(W)、月次(M)、四半期(Q)、年次(Y)\n",
        "freq =  'D'# @param [\"D\",\"W\",\"M\",\"Q\",\"Y\"]\n",
        "#@markdown ---\n",
        "#@markdown ##### **学習量**\n",
        "training_volume=100 #@param {type:\"slider\", min:100, max:7000, step:100}\n",
        "#@markdown ---\n",
        "#@markdown #####**test_size**\n",
        "test_size = 1 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown ---\n",
        "#@markdown #####**特徴量の操作**\n",
        "#@markdown - 特徴量を全選択するかds,y,unique_idの3カラムのみにするか\n",
        "select_all_features = False #@param {type:\"boolean\"}\n",
        "# @title **backendとnum_samplesの設定**\n",
        "#@markdown ---\n",
        "#@markdown #####**ハイパーパラメータの探索空間を探索するために使用するバックエンド**\n",
        "#@markdown - **ray**\n",
        "#@markdown  - 大規模なデータセット、複雑なモデル\n",
        "#@markdown -**optuna**\n",
        "#@markdown  - 小規模、中規模なデータセット、シンプルなモデル\n",
        "backend=\"ray\"# @param [\"ray\", \"optuna\"]\n",
        "#@markdown ---\n",
        "#@markdown ##### **ハイパーパラメータ最適化のステップ数**\n",
        "#@markdown - **増やす場合**\n",
        "#@markdown  - 最適なハイパーパラメータを見つける可能性が高まります。\n",
        "#@markdown - **減らす場合**\n",
        "#@markdown  - 計算リソースと時間を節約できます。\n",
        "num_samples=20# @param {type:\"slider\", min:10, max:100, step:10}\n",
        "#@markdown ---\n",
        "#@markdown ##### **検証データセットを保持するかどうかを指定**\n",
        "#@markdown - **True**\n",
        "#@markdown  - モデルは未見のデータに対してより一般化する可能性があります\n",
        "#@markdown - **False**\n",
        "#@markdown  - モデルが訓練データに対して最適化され、過学習のリスクを減らすことができます\n",
        "refit_with_val=True  # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #####**最適化プロセスの進行状況の表示**\n",
        "#@markdown - **True**\n",
        "#@markdown  - 最適化プロセスの進行状況が表示されます\n",
        "#@markdown - **False**\n",
        "#@markdown  - 計算リソースやディスクスペースを節約できます\n",
        "verbose=True # @param {type:\"boolean\"}\n",
        "cpus = mp.cpu_count()\n",
        "gpus = torch.cuda.device_count()\n",
        "if test_size==0:\n",
        "    horizon=1\n",
        "else:\n",
        "    horizon=test_size\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #####**寄与率の計算**\n",
        "#@markdown - 特徴量の寄与率を計算\n",
        "feature_contribution = False # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #####**最適化プロセスの進行状況の表示**\n",
        "#@markdown - **True**\n",
        "#@markdown  - 最適化プロセスの進行状況が表示されます\n",
        "#@markdown - **False**\n",
        "#@markdown  - 計算リソースやディスクスペースを節約できます\n",
        "verbose=True # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #####**実行の有無**\n",
        "#@markdown\n",
        "#@markdown  **データフレームの作成**\n",
        "calculate_stats=True # @param {type:\"boolean\"}\n",
        "#@markdown  **データの成形**\n",
        "create_dataframe=True # @param {type:\"boolean\"}\n",
        "#@markdown  **統計計算**\n",
        "compute_statistics=True # @param {type:\"boolean\"}\n",
        "#@markdown  **特徴量の選択**\n",
        "select_features_process=True # @param {type:\"boolean\"}\n",
        "#@markdown  **カラム名の変更**\n",
        "rename_columns=True # @param {type:\"boolean\"}\n",
        "#@markdown  **モデルの再学習と予測の評価**\n",
        "retrain_and_evaluate_model=True # @param {type:\"boolean\"}\n",
        "#@markdown  **モデルの生成**\n",
        "create_model=True # @param {type:\"boolean\"}\n",
        "#@markdown  **EDA (Exploratory Data Analysis)**\n",
        "perform_eda=True # @param {type:\"boolean\"}\n",
        "# ラベルとスライダーを垂直に配置\n",
        "dric(f\"backend: {backend}\")\n",
        "dric(f\"num_samples: {num_samples}\")\n",
        "dric(f\"refit_with_val: {refit_with_val}\")\n",
        "dric(f\"verbose: {verbose}\")\n",
        "dric(f\"horizon: {horizon}\")\n",
        "dric(f\"cpus: {cpus}\")\n",
        "dric(f\"gpus: {gpus}\")\n",
        "dric(f\"target={target}\")\n",
        "dric(f\"freq={freq}\")\n",
        "dric(f\"feature_contribution={feature_contribution}\")\n",
        "# @title rayのURL { run: \"auto\" }\n",
        "try:\n",
        "    # rayが初期化されているかどうかを確認します\n",
        "    if ray.is_initialized():\n",
        "        # rayが初期化されている場合は、シャットダウンします\n",
        "        ray.shutdown()\n",
        "\n",
        "    # rayを初期化し、その出力を変数に格納します\n",
        "    ray_output = ray.init()\n",
        "\n",
        "    # URLの出力を変数に格納します\n",
        "    output.serve_kernel_port_as_window(8265, path=\"\")\n",
        "except Exception as e:\n",
        "    # エラーメッセージを表示します\n",
        "    dric(\"[red]エラーが発生しました: {}[/red]\".format(str(e)))\n",
        "    dric(\"*\"*100)\n",
        "    # どの関数でエラーが発生したかを表示します\n",
        "    dric(\"[red]エラーが発生した関数: {}[/red]\".format(traceback.print_exc()))\n",
        "    dric(\"*\"*100)\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQaE2MNI2YEd"
      },
      "source": [
        "# **<font color='Blue'>データの作成と成形**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "PFKuXP2h0IrT",
        "outputId": "fb8e3678-330d-4d56-f700-fba7fbdd7ee6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mdf_encoded はすでに作成済みなので処理をスキップしました\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">df_encoded はすでに作成済みなので処理をスキップしました</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      part       date  N1  N2  N3  N4  N5  N6  N7  N8  B1  B2  week_月  week_木  \\\n",
              "6458  6460 2024-05-02   3   1   3   0   0   0   0   0   0   0       0       1   \n",
              "1891  1892 2024-05-02   7   8   9  19  22  38   0   0  24   0       0       0   \n",
              "6460  6461 2024-05-03   1   3   2   3   0   0   0   0   0   0       0       0   \n",
              "6459  6461 2024-05-03   6   6   6   0   0   0   0   0   0   0       0       0   \n",
              "572    573 2024-05-03  11  12  18  19  23  26  31   0  15  25       0       0   \n",
              "\n",
              "      week_水  week_火  week_金  eto_仏滅  eto_先勝  eto_先負  eto_友引  eto_大安  eto_赤口  \\\n",
              "6458       0       0       0       0       0       0       1       0       0   \n",
              "1891       0       0       0       0       0       0       0       0       0   \n",
              "6460       0       0       1       0       0       1       0       0       0   \n",
              "6459       0       0       1       0       0       1       0       0       0   \n",
              "572        0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "      Bin5  loto6  loto7  mini  num3  num4  is_hd_False  is_hd_True  \n",
              "6458     0      0      0     0     1     0            1           0  \n",
              "1891     0      1      0     0     0     0            1           0  \n",
              "6460     0      0      0     0     0     1            0           1  \n",
              "6459     0      0      0     0     1     0            0           1  \n",
              "572      0      0      1     0     0     0            0           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c2b39ef-c96d-4136-a3ec-160dcb1fba46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>part</th>\n",
              "      <th>date</th>\n",
              "      <th>N1</th>\n",
              "      <th>N2</th>\n",
              "      <th>N3</th>\n",
              "      <th>N4</th>\n",
              "      <th>N5</th>\n",
              "      <th>N6</th>\n",
              "      <th>N7</th>\n",
              "      <th>N8</th>\n",
              "      <th>B1</th>\n",
              "      <th>B2</th>\n",
              "      <th>week_月</th>\n",
              "      <th>week_木</th>\n",
              "      <th>week_水</th>\n",
              "      <th>week_火</th>\n",
              "      <th>week_金</th>\n",
              "      <th>eto_仏滅</th>\n",
              "      <th>eto_先勝</th>\n",
              "      <th>eto_先負</th>\n",
              "      <th>eto_友引</th>\n",
              "      <th>eto_大安</th>\n",
              "      <th>eto_赤口</th>\n",
              "      <th>Bin5</th>\n",
              "      <th>loto6</th>\n",
              "      <th>loto7</th>\n",
              "      <th>mini</th>\n",
              "      <th>num3</th>\n",
              "      <th>num4</th>\n",
              "      <th>is_hd_False</th>\n",
              "      <th>is_hd_True</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6458</th>\n",
              "      <td>6460</td>\n",
              "      <td>2024-05-02</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>1892</td>\n",
              "      <td>2024-05-02</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>22</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6460</th>\n",
              "      <td>6461</td>\n",
              "      <td>2024-05-03</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6459</th>\n",
              "      <td>6461</td>\n",
              "      <td>2024-05-03</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>573</td>\n",
              "      <td>2024-05-03</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>23</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c2b39ef-c96d-4136-a3ec-160dcb1fba46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c2b39ef-c96d-4136-a3ec-160dcb1fba46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c2b39ef-c96d-4136-a3ec-160dcb1fba46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae4e4a9e-a32e-497d-9825-904b8f694631\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae4e4a9e-a32e-497d-9825-904b8f694631')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae4e4a9e-a32e-497d-9825-904b8f694631 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m9.\u001b[0m0M    .git\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>0M    .git\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅ コードの保存が完了しました。\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ コードの保存が完了しました。\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17.1 ms, sys: 7.57 ms, total: 24.7 ms\n",
            "Wall time: 287 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if calculate_stats:\n",
        "    #@title **データフレームの作成**\n",
        "    try:\n",
        "\n",
        "        # dfがすでに定義されていてNoneでない場合は、以下の処理をスキップ\n",
        "        if \"df_encoded\" not in locals() or df_encoded is None or df_encoded_len !=len(df_encoded):\n",
        "            import multiprocessing as mp\n",
        "            import pandas as pd\n",
        "\n",
        "            # タスクのリストを作成します\n",
        "            tasks = [\n",
        "                (make_numbers, (4,)),  # ナンバーズ4のデータフレームを作成\n",
        "                (make_numbers, (3,)),  # ナンバーズ3のデータフレームを作成\n",
        "                (make_Bin5, ()),  # ビンゴ5のデータフレームを作成\n",
        "                (make_loto, (\"miniloto\", 8, 5, 1)),  # ミニロトのデータフレームを作成\n",
        "                (make_loto, ()),  # ロト6のデータフレームを作成\n",
        "                (make_loto, (\"loto7\", 11, 7, 2))  # ロト7のデータフレームを作成\n",
        "            ]\n",
        "\n",
        "            # 並列化されたデータフレームの作成\n",
        "            df_sorted = make_df_parallel(tasks)\n",
        "\n",
        "\n",
        "            # '抽選数字'カラムは不要なので削除\n",
        "            df_sorted.drop('抽選数字', axis=1, inplace=True)\n",
        "\n",
        "            # データフレームを日付で並び替え\n",
        "            df_sorted = df_sorted.sort_values(by='date')\n",
        "            # dateカラムがdatetime型であることを確認\n",
        "            assert pd.api.types.is_datetime64_any_dtype(df_sorted['date']), \"dateカラムはdatetime型ではありません\"\n",
        "\n",
        "            # dateカラムをjpholidayで休日を判別し、新たなis_holidayカラムを作成\n",
        "            df_sorted['is_hd'] = df_sorted['date'].apply(jpholiday.is_holiday)\n",
        "            # カテゴリ変数をワンホットエンコーディング\n",
        "            df_encoded = pd.get_dummies(df_sorted, columns=['week', 'eto', 'LOTO','is_hd'])\n",
        "\n",
        "            # Convert the num1 to num8 columns to integer type\n",
        "            df_encoded[['part','N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7','N8','B1', 'B2']] = df_encoded[['part','N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7','N8','B1', 'B2']].replace('missing', 0).replace([np.inf, -np.inf], np.nan).fillna(0).astype(int)\n",
        "\n",
        "            # データの情報\n",
        "            df_encoded.columns = df_encoded.columns.str.replace('LOTO_', '')\n",
        "            df_encoded.rename(columns={'miniloto': 'mini'}, inplace=True)\n",
        "            df_encoded_len =len(df_encoded)\n",
        "            display(df_encoded.tail())\n",
        "            display(f\"カラム数 {len(df_encoded.columns)}  \\n レコード数 {len(df_encoded)}\")\n",
        "\n",
        "        else:\n",
        "            dric(\"[green bold]df_encoded はすでに作成済みなので処理をスキップしました\")\n",
        "            display(df_encoded.tail())\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold]エラーが発生しました。詳細は以下の通りです:[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "_6XcuB-81P5C",
        "outputId": "123bce73-b820-457d-806c-c8c464bfcf64"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36minitialize_ray\u001b[0;34m(lib_list)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m         \u001b[0;31m# handler. We still spawn a reaper process in case the atexit handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0;31m# isn't called.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         _global_node = ray._private.node.Node(\n\u001b[0m\u001b[1;32m   1643\u001b[0m             \u001b[0mray_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mray_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker, ray_init_cluster)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# Start processes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_head_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconnect_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/node.py\u001b[0m in \u001b[0;36mstart_head_processes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0mraise_on_api_server_failure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ray_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_dashboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m         self.start_api_server(\n\u001b[0m\u001b[1;32m   1367\u001b[0m             \u001b[0minclude_dashboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ray_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_dashboard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m             \u001b[0mraise_on_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_on_api_server_failure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/node.py\u001b[0m in \u001b[0;36mstart_api_server\u001b[0;34m(self, include_dashboard, raise_on_failure)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;34m\"dashboard\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[0;32m-> 1109\u001b[0;31m         self._webui_url, process_info = ray._private.services.start_api_server(\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0minclude_dashboard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mraise_on_failure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/services.py\u001b[0m in \u001b[0;36mstart_api_server\u001b[0;34m(include_dashboard, raise_on_failure, host, gcs_address, node_ip_address, temp_dir, logdir, session_dir, port, dashboard_grpc_port, fate_share, max_bytes, backup_count, redirect_logging, stdout_file, stderr_file)\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;31m# This is often on the critical path of ray.init() and ray start,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;31m# so we need to poll often.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;31m# Dashboard couldn't be started.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# @title **データの成形** { run: \"auto\" }\n",
        "if create_dataframe:\n",
        "    try:\n",
        "        filtered_df=select_columns_by_lottery_type(df_encoded, select_loto)\n",
        "        filtered_df=filtered_df.tail(training_volume)\n",
        "        initialize_ray(lib_list=None)\n",
        "\n",
        "        # 各カラムについてループ\n",
        "        other_columns = [col for col in filtered_df.columns if col not in ['part', 'date']]\n",
        "        futures = [reshape_df.remote(filtered_df, other_columns, i) for i in range(len(other_columns))]\n",
        "        merged_df = pd.concat(ray.get(futures), axis=0)\n",
        "\n",
        "        if use_reshape_dataframe ==\"reshape\":\n",
        "            # 2段階のカスケード構造を作成\n",
        "            final_df = pd.DataFrame()\n",
        "\n",
        "            if 'origin_column' in merged_df.columns:\n",
        "                for col in tqdm(merged_df.columns.drop(['part', 'date', 'No', 'origin_column'])):\n",
        "                    temp_df = merged_df[['part', 'date', 'No', 'origin_column', col]]\n",
        "                    temp_df.columns = ['part', 'date', 'No', 'origin_column', target]\n",
        "                    temp_df['origin_column2'] = col\n",
        "                    final_df = pd.concat([final_df, temp_df])\n",
        "\n",
        "                # origin_columnとorigin_column2の値を組み合わせてユニークIDカラムを作成\n",
        "                final_df['unique_id'] = final_df['origin_column'].astype(str) + '_' + final_df['origin_column2'].astype(str)\n",
        "\n",
        "                # origin_columnとorigin_column2のカラムを削除\n",
        "                final_df = final_df.drop(['origin_column', 'origin_column2'], axis=1)\n",
        "        else:\n",
        "            final_df = merged_df.copy()\n",
        "            # origin_columnをunique_idに変換\n",
        "            final_df.rename(columns={'origin_column': 'unique_id'}, inplace=True)\n",
        "            # Noの値をNo_Oのカラムに入れる\n",
        "            final_df['No_O'] = final_df['No']\n",
        "\n",
        "        dates = pd.date_range(start=final_df['date'].min(), end=final_df['date'].max())\n",
        "        holidays = {date: jpholiday.is_holiday(date) for date in dates}\n",
        "\n",
        "        # 辞書を使用してmap関数を適用\n",
        "        final_df['is_hd'] = final_df['date'].map(holidays)\n",
        "        # 日付範囲全体でカバラ数を計算\n",
        "        dates = pd.date_range(start=final_df['date'].min(), end=final_df['date'].max())\n",
        "        kabbalah_numbers = {date: calculate_kabbalah_number(date) for date in dates}\n",
        "\n",
        "        # 辞書を使用してmap関数を適用\n",
        "        final_df['kabbalah'] = final_df['date'].map(kabbalah_numbers)\n",
        "        # 日付をdatetime型に変換（既にdatetime型の場合は不要）\n",
        "\n",
        "        final_df['date'] = pd.to_datetime(final_df['date'])\n",
        "\n",
        "        # 年、月、日、曜日、週番号、四半期、年の日数、月の日数を一度に取得\n",
        "        date_features = {\n",
        "            \"year\": final_df['date'].dt.year,\n",
        "            \"month\": final_df['date'].dt.month,\n",
        "            \"day\": final_df['date'].dt.day,\n",
        "            \"week\": final_df['date'].dt.dayofweek,\n",
        "            \"week_of_year\": final_df['date'].dt.isocalendar().week,\n",
        "            \"quarter\": final_df['date'].dt.quarter,\n",
        "            \"day_of_year\": final_df['date'].dt.dayofyear,\n",
        "            \"day_of_month\": final_df['date'].dt.days_in_month,\n",
        "            'rokuyo': final_df['date'].apply(get_rokuyo)\n",
        "\n",
        "        }\n",
        "\n",
        "        # 新しい特徴量をデータフレームに追加\n",
        "        final_df = final_df.assign(**date_features)\n",
        "\n",
        "        # ワンホットエンコーディングを適用するカラムのリスト\n",
        "        columns_to_encode = ['month', 'week', 'quarter', 'is_hd', 'rokuyo']\n",
        "\n",
        "        # 各カラムに対してワンホットエンコーディングを適用\n",
        "        for column in tqdm(columns_to_encode):\n",
        "            one_hot = pd.get_dummies(final_df[column], prefix=column).astype(int)\n",
        "            final_df = pd.concat([final_df, one_hot], axis=1)\n",
        "        final_df['week_of_year'] = final_df['week_of_year'].astype('int64')\n",
        "\n",
        "        # 元のカラムを削除\n",
        "        final_df = final_df.drop(columns=columns_to_encode)\n",
        "        final_df = final_df.reset_index(drop=True)\n",
        "        display(final_df.tail())\n",
        "        display(f\"カラム数 {len(final_df.columns)}  \\n レコード数 {len(final_df)}\")\n",
        "\n",
        "        ray.shutdown()\n",
        "    except Exception as e:\n",
        "        dric(\"[red bold] \\n \\n エラーが発生しました。詳細は以下の通りです:[/red bold]\")\n",
        "        traceback.print_exc()\n",
        "    ray.shutdown()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "pkc_2X-XbVbh",
        "outputId": "b53d50dc-2141-4bbe-e37d-d0b12bdff7ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "15",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 60.7 ms, sys: 193 ms, total: 253 ms\n",
            "Wall time: 3.32 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%%capture\n",
        "#@title **統計計算**\n",
        "if compute_statistics:\n",
        "    try:\n",
        "        selected_column = target\n",
        "        unique_ids = final_df['unique_id'].unique()\n",
        "\n",
        "        initialize_ray(lib_list=None)\n",
        "\n",
        "        results = ray.get([process.options(num_cpus=mp.cpu_count(), num_gpus=torch.cuda.device_count(), runtime_env={\"pip\": [\"stumpy\",\"arch\"]}).remote(unique_id) for unique_id in tqdm(unique_ids, desc='Processing unique IDs', leave=False)])\n",
        "        final_df = pd.concat(results, ignore_index=True)\n",
        "\n",
        "        final_df = pd.concat(results)\n",
        "\n",
        "        processed_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/pre_processed/{use_reshape_dataframe}/pre_processed/pre_processed_df_{len(final_df.columns)}_{len(final_df)}_{get_current_time_jst()}.csv'\n",
        "        save_dataframe(final_df, processed_df_path)\n",
        "\n",
        "        cleaned_df =preprocess_dataframe(final_df,num=0.3)\n",
        "        cleaned_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/pre_processed/{use_reshape_dataframe}/cleaned/cleaned_df_{len(cleaned_df.columns)}_{len(cleaned_df)}_{get_current_time_jst()}.csv'\n",
        "        save_dataframe(cleaned_df, cleaned_df_path)\n",
        "        display(cleaned_df.tail())\n",
        "        display(f\"カラム数 {len(cleaned_df.columns)}  \\n レコード数 {len(cleaned_df)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました[/red]\")\n",
        "\n",
        "        dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    ray.shutdown()\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InYPQHJe1Ow4"
      },
      "source": [
        "# **<font color='Blue'>統計データをロード**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403,
          "referenced_widgets": [
            "1e817324ff0c4cdd8b0428953532722c",
            "6c7915c1fbed45689f279ebfd98ec936",
            "d7a2a06b29364c84bb52b9ceda58386e",
            "ba71d7a9fbc54fb48ac4621c169f9407"
          ]
        },
        "id": "wiC3VT6tgXZg",
        "outputId": "e194839e-0316-4cf1-c5ac-26a87a8320cf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Html(children=['統計結果の保存データのロード'], layout=None, tag='h2')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e817324ff0c4cdd8b0428953532722c"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Layout(children=[Html(children=['load'], class_='d-inline-block', layout=None, style_='font-size: 30px; vertic…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c7915c1fbed45689f279ebfd98ec936"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーが発生しました: \u001b[0m\u001b[1;31m[\u001b[0m\u001b[31mErrno \u001b[0m\u001b[1;31m2\u001b[0m\u001b[1;31m]\u001b[0m\u001b[31m No such file or directory: \u001b[0m\u001b[31m'/content/drive/MyDrive/Colab \u001b[0m\n",
              "\u001b[31mNotebooks/forecast_loto/num4/processed_data/pre_processed/reshape/cleaned'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーが発生しました: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">[</span><span style=\"color: #800000; text-decoration-color: #800000\">Errno </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">2</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">]</span><span style=\"color: #800000; text-decoration-color: #800000\"> No such file or directory: </span><span style=\"color: #800000; text-decoration-color: #800000\">'/content/drive/MyDrive/Colab </span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">Notebooks/forecast_loto/num4/processed_data/pre_processed/reshape/cleaned'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "****************************************************************************************************\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">****************************************************************************************************\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<timed exec>\", line 799, in create_vuetify_dropdown\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/forecast_loto/num4/processed_data/pre_processed/reshape/cleaned'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーが発生しました\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーが発生しました</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーメッセージ: \u001b[0m\u001b[31m'NoneType'\u001b[0m\u001b[31m object has no attribute \u001b[0m\u001b[31m'observe'\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーメッセージ: </span><span style=\"color: #800000; text-decoration-color: #800000\">'NoneType'</span><span style=\"color: #800000; text-decoration-color: #800000\"> object has no attribute </span><span style=\"color: #800000; text-decoration-color: #800000\">'observe'</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-114-e490a30edf10>\", line 15, in <cell line: 2>\n",
            "    dropdown_widget.observe(on_dropdown_value_change, names='v_model')\n",
            "AttributeError: 'NoneType' object has no attribute 'observe'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m9.\u001b[0m0M    .git\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>0M    .git\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅ コードの保存が完了しました。\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ コードの保存が完了しました。\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "#@title **<font color='Green'>統計データをロード**\n",
        "try:\n",
        "    cleaned_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/pre_processed/{use_reshape_dataframe}/cleaned'\n",
        "\n",
        "    path=cleaned_df_path\n",
        "    data_holder.df = None\n",
        "    data_holder.ckeck = None\n",
        "    data_holder.filename = None\n",
        "\n",
        "    # ipyvueのHtmlウィジェットを先に表示し、その後にipyvuetifyのウィジェットを表示します。\n",
        "    checkbox_widget = create_vuetify_checkbox()\n",
        "    display(vue.Html(tag=\"h2\", children=[\"統計結果の保存データのロード\"]), checkbox_widget)\n",
        "    # ipyvueのHtmlウィジェットを先に表示し、その後にipyvuetifyのウィジェットを表示します。\n",
        "    dropdown_widget = create_vuetify_dropdown(path)\n",
        "    dropdown_widget.observe(on_dropdown_value_change, names='v_model')\n",
        "except Exception as e:\n",
        "    dric(\"[red]エラーが発生しました[/red]\")\n",
        "    dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "    traceback.print_exc()\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "QHyW6ToFbYXu",
        "outputId": "905eeb78-6c49-43ee-cbf9-0a34b301005a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "条件1の結果: \u001b[3;91mFalse\u001b[0m \u001b[1m(\u001b[0mdata_holderに'filename'属性が存在し、その値がcleaned_pathと一致するかどうか\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">条件1の結果: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> <span style=\"font-weight: bold\">(</span>data_holderに'filename'属性が存在し、その値がcleaned_pathと一致するかどうか<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "条件2の結果: \u001b[3;91mFalse\u001b[0m \u001b[1m(\u001b[0mdata_holderに'check'属性が存在し、その値がTrueであるかどうか\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">条件2の結果: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> <span style=\"font-weight: bold\">(</span>data_holderに'check'属性が存在し、その値がTrueであるかどうか<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "条件3の結果: \u001b[3;91mFalse\u001b[0m \u001b[1m(\u001b[0mdata_holderに'df'属性が存在し、その値がNoneでないかどうか\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">条件3の結果: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> <span style=\"font-weight: bold\">(</span>data_holderに'df'属性が存在し、その値がNoneでないかどうか<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m特徴量の保存データのロードが失敗しました\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">特徴量の保存データのロードが失敗しました</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーが発生しました\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーが発生しました</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mエラーメッセージ: name \u001b[0m\u001b[31m'csv_cleaned_df'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">エラーメッセージ: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'csv_cleaned_df'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-115-87ac15f30f59>\", line 25, in <cell line: 3>\n",
            "    missing_columns = [col for col in required_columns if col not in csv_cleaned_df.columns]\n",
            "  File \"<ipython-input-115-87ac15f30f59>\", line 25, in <listcomp>\n",
            "    missing_columns = [col for col in required_columns if col not in csv_cleaned_df.columns]\n",
            "NameError: name 'csv_cleaned_df' is not defined\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m9.\u001b[0m0M    .git\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>0M    .git\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "✅ コードの保存が完了しました。\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ コードの保存が完了しました。\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title **<font color='Green'>統計結果を書き込む**\n",
        "\n",
        "try:\n",
        "    condition1 = hasattr(data_holder, 'filename') and data_holder.filename == cleaned_df_path\n",
        "    dric(f\"条件1の結果: {condition1} (data_holderに'filename'属性が存在し、その値がcleaned_pathと一致するかどうか)\")\n",
        "\n",
        "    condition2 = hasattr(data_holder, 'check') and data_holder.check is True\n",
        "    dric(f\"条件2の結果: {condition2} (data_holderに'check'属性が存在し、その値がTrueであるかどうか)\")\n",
        "\n",
        "    condition3 = hasattr(data_holder, 'df') and data_holder.df is not None\n",
        "    dric(f\"条件3の結果: {condition3} (data_holderに'df'属性が存在し、その値がNoneでないかどうか)\")\n",
        "\n",
        "    if condition1 and condition2 and condition3:\n",
        "        csv_cleaned_df = data_holder.df\n",
        "        display(csv_cleaned_df.tail())\n",
        "        display(f\"カラム数 {len(csv_cleaned_df.columns)}  \\n レコード数 {len(csv_cleaned_df)}\")\n",
        "\n",
        "    else:\n",
        "        dric(\"[red]特徴量の保存データのロードが失敗しました\")\n",
        "\n",
        "    # 必要なカラムのリストを作成します\n",
        "    required_columns = [target, 'date', 'unique_id']\n",
        "\n",
        "    # 存在しないカラムを確認します\n",
        "    missing_columns = [col for col in required_columns if col not in csv_cleaned_df.columns]\n",
        "\n",
        "    if len(missing_columns) > 0:\n",
        "        raise ValueError(f\"以下の必要なカラムがfeatures_dfに存在しません：{', '.join(missing_columns)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    dric(\"[red]エラーが発生しました[/red]\")\n",
        "    dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "    traceback.print_exc()\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8PYJS9k2gie"
      },
      "source": [
        "# **<font color='Blue'>特徴量の選択**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELdjKOQDTvUD"
      },
      "outputs": [],
      "source": [
        "initialize_ray(lib_list=None)\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGPNvhgYNKTH"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# @title **特徴量の選択 修正版** { run: \"auto\" }\n",
        "if select_features_process:\n",
        "\n",
        "    initialize_ray(lib_list=None)\n",
        "\n",
        "    if 'csv_cleaned_df' in globals() or 'csv_cleaned_df' in locals():\n",
        "        if not csv_cleaned_df.empty:\n",
        "            cleaned_df = csv_cleaned_df\n",
        "\n",
        "\n",
        "    # unique_idのユニーク値を取得\n",
        "    unique_ids = cleaned_df['unique_id'].unique()\n",
        "\n",
        "    # 空のデータフレームを作成\n",
        "    select_features_df = pd.DataFrame()\n",
        "    all_features_df = pd.DataFrame()\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Rayのプールを作成\n",
        "    with Pool() as pool:\n",
        "        for unique_id in tqdm(unique_ids):\n",
        "            dric(f\"unique_id={unique_id}\")\n",
        "            try:\n",
        "                # unique_idでデータをフィルタリング\n",
        "                df_filtered = cleaned_df[cleaned_df['unique_id'] == unique_id]\n",
        "                df_filtered_O = df_filtered.drop('unique_id', axis=1)\n",
        "                df_filtered_1=df_filtered.set_index('date')\n",
        "\n",
        "\n",
        "                # 特徴量の抽出\n",
        "                extracted_features = extract_features(df_filtered_O[[\"date\",target]], column_id=\"date\", column_sort=\"date\")\n",
        "\n",
        "                # 特徴量の補完\n",
        "                imputed_features = impute(extracted_features)\n",
        "\n",
        "                # df_filteredのtargetカラムをimputed_featuresにマージ\n",
        "                merged = imputed_features.merge(df_filtered_1, left_index=True, right_index=True, how='inner')\n",
        "                merged[\"date\"]=merged.index\n",
        "\n",
        "                # Xとyを定義\n",
        "                y = merged[target]\n",
        "\n",
        "                # 重複したインデックスを削除\n",
        "                y = y.loc[~y.index.duplicated(keep='first')]\n",
        "\n",
        "                # 全てのデータフレームのインデックスを一致させる\n",
        "                common_index = y.index.intersection(imputed_features.index)\n",
        "                y = y.loc[common_index]\n",
        "                imputed_features = imputed_features.loc[common_index]\n",
        "                dric(f\"y = {len(y)} imputed_features = {len(imputed_features)}\",\"\\n\",\"*\"*100)\n",
        "\n",
        "                # 特徴量選択\n",
        "                features_filtered = select_features(imputed_features, y)\n",
        "\n",
        "                # unique_idを追加\n",
        "                features_filtered = features_filtered.merge(df_filtered_1[\"unique_id\"], left_index=True, right_index=True, how='inner')\n",
        "                # データフレームをマージ\n",
        "                select_features_df = pd.concat([select_features_df, features_filtered])\n",
        "\n",
        "                # 全てのデータフレームをマージ\n",
        "                all_features_df = pd.concat([all_features_df, merged])\n",
        "\n",
        "            except Exception as e:\n",
        "                dric(f\"Error processing unique_id {unique_id}: {e}\")\n",
        "                raise e\n",
        "\n",
        "    # 処理終了時間を記録し、処理時間を計算\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    # 経過時間を hh:mm:ss の形式に変換\n",
        "    elapsed_time_formatted = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
        "    # select_features_dfからカラムを取得\n",
        "    columns = select_features_df.columns.tolist()\n",
        "\n",
        "    # target, date, unique_idカラムが存在するか確認\n",
        "    required_columns = [target, 'date', 'unique_id']\n",
        "    for col in required_columns:\n",
        "        if col not in columns:\n",
        "            columns.append(col)\n",
        "\n",
        "    select_features_df=all_features_df[columns]\n",
        "\n",
        "    select_features_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/{use_reshape_dataframe}/select_features/select_features_df_{len(select_features_df.columns)}_{len(select_features_df)}_{get_current_time_jst()}.csv'\n",
        "    save_dataframe(select_features_df, select_features_df_path)\n",
        "\n",
        "    all_features_df_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/{use_reshape_dataframe}/all_features/all_features_df_{len(all_features_df.columns)}_{len(all_features_df)}_{get_current_time_jst()}.csv'\n",
        "    save_dataframe(all_features_df, all_features_df_path)\n",
        "\n",
        "    display(select_features_df.tail())\n",
        "\n",
        "    ray.shutdown()\n",
        "git_save(git_username,git_repository,git_pass)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTewSG0o2lhG"
      },
      "source": [
        "# **<font color='Blue'>特徴量の格納**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6BUvhhcWWbpy"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title **<font color='Green'>特徴量のデータをロード**\n",
        "target_features ='特徴量選択'# @param [\"全選択\",\"特徴量選択\"]\n",
        "if target_features=='特徴量選択':\n",
        "    features =\"select_features\"\n",
        "else:\n",
        "    features =\"all_features\"\n",
        "\n",
        "features_path =f'/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/processed_data/{use_reshape_dataframe}/{features}'\n",
        "path =features_path\n",
        "data_holder.df = None\n",
        "data_holder.check = None\n",
        "data_holder.filename = None\n",
        "\n",
        "# ipyvueのHtmlウィジェットを先に表示し、その後にipyvuetifyのウィジェットを表示します。\n",
        "checkbox_widget = create_vuetify_checkbox()\n",
        "display(vue.Html(tag=\"h2\", children=[f\"特徴量の保存データのロード\"]), checkbox_widget)\n",
        "# ipyvueのHtmlウィジェットを先に表示し、その後にipyvuetifyのウィジェットを表示します。\n",
        "dropdown_widget = create_vuetify_dropdown(path)\n",
        "dropdown_widget.observe(on_dropdown_value_change, names='v_model')\n",
        "dric(path)\n",
        "# data_holder.dfの値の変化をチェック\n",
        "git_save(git_username,git_repository,git_pass)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vUATYqxjkuaH"
      },
      "outputs": [],
      "source": [
        "#@title **<font color='Green'>特徴量を格納**\n",
        "try:\n",
        "    dric(path)\n",
        "\n",
        "    condition1 = hasattr(data_holder, 'filename') and data_holder.filename == features_path\n",
        "    dric(f\"条件1の結果: {condition1} (data_holderに'filename'属性が存在し、その値がfeatures_pathと一致するかどうか)\")\n",
        "\n",
        "    condition2 = hasattr(data_holder, 'check') and data_holder.check is True\n",
        "    dric(f\"条件2の結果: {condition2} (data_holderに'check'属性が存在し、その値がTrueであるかどうか)\")\n",
        "\n",
        "    condition3 = hasattr(data_holder, 'df') and data_holder.df is not None\n",
        "    dric(f\"条件3の結果: {condition3} (data_holderに'df'属性が存在し、その値がNoneでないかどうか)\")\n",
        "\n",
        "    if condition1 and condition2 and condition3:\n",
        "        features_df = data_holder.df\n",
        "        features_df_copy=features_df.copy()\n",
        "        display(features_df.tail())\n",
        "    else:\n",
        "        dric(\"[red]特徴量の保存データのロードが失敗しました\")\n",
        "\n",
        "    # 必要なカラムのリストを作成します\n",
        "    required_columns = [target, 'date', 'unique_id']\n",
        "\n",
        "    # 存在しないカラムを確認します\n",
        "    missing_columns = [col for col in required_columns if col not in features_df.columns]\n",
        "\n",
        "    if len(missing_columns) > 0:\n",
        "        raise ValueError(f\"以下の必要なカラムがfeatures_dfに存在しません：{', '.join(missing_columns)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    dric(\"[red]エラーが発生しました[/red]\")\n",
        "    dric(f\"[red]エラーメッセージ: {str(e)}[/red]\")\n",
        "    traceback.print_exc()\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1Ne2e-uxq_O"
      },
      "outputs": [],
      "source": [
        "target ='No_O'# @param [\"No_O\",\"No\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djKrH8Oe1ks0"
      },
      "outputs": [],
      "source": [
        "#@title **特徴量の寄与率の計算**\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# 特徴量の重要度を計算する関数\n",
        "@ray.remote\n",
        "def compute_feature_importance(hyperparameters, model, features_df, target):\n",
        "    try:\n",
        "        X = features_df.drop(target, axis=1)\n",
        "        y = features_df[target]\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 特徴量の重要度を計算\n",
        "        importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "\n",
        "        # Permutation Importance\n",
        "        perm_importance = pd.Series(permutation_importance(model, X, y, n_repeats=10, random_state=42).importances_mean, index=X.columns)\n",
        "\n",
        "        # Mutual Information\n",
        "        mutual_info = pd.Series(mutual_info_regression(X, y), index=X.columns)\n",
        "\n",
        "        # Correlation Coefficient\n",
        "        correlation_coef = X.corrwith(y)\n",
        "\n",
        "        # Lasso (L1) Regularization\n",
        "        lasso = LassoCV(cv=5).fit(X, y)\n",
        "        lasso_importance = pd.Series(np.abs(lasso.coef_), index=X.columns)\n",
        "\n",
        "        return importances, perm_importance, mutual_info, correlation_coef, lasso_importance\n",
        "    except Exception as e:\n",
        "        dric(\"[red]エラーが発生しました。[/red]\")\n",
        "        dric(f\"[red]関数 'compute_feature_importance' でエラーが発生しました: {e}[/red]\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "# Rayの初期化\n",
        "initialize_ray()\n",
        "models = [RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor, XGBRegressor]\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "hyperparameters = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# 文字列が含まれているカラムを抽出\n",
        "categorical_cols = features_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# ワンホットエンコーディングを行う\n",
        "features_df = pd.get_dummies(features_df, columns=categorical_cols)\n",
        "\n",
        "# 相関分析を行い、予測に寄与する可能性のある特徴量だけを選択\n",
        "correlation_threshold = 0.001\n",
        "correlation = features_df.corrwith(features_df[target])\n",
        "selected_features = correlation[correlation.abs() > correlation_threshold].index\n",
        "features_df = features_df[selected_features]\n",
        "\n",
        "# グリッドサーチを用いて最適なハイパーパラメータを選択\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), hyperparameters, cv=5)\n",
        "grid_search.fit(features_df.drop(target, axis=1), features_df[target])\n",
        "best_hyperparameters = grid_search.best_params_\n",
        "\n",
        "# 各ハイパーパラメータに対して特徴量の重要度を計算\n",
        "total_tasks = len(models)\n",
        "progress_bar = tqdm(total=total_tasks, desc='Overall Progress')\n",
        "\n",
        "results = []\n",
        "start_time = time.time()\n",
        "for model in (models):\n",
        "    # XGBRegressorのインスタンス作成時にGPUを利用するように設定\n",
        "    if model == XGBRegressor:\n",
        "        # GPUが利用可能でない場合は、'hist'を使用\n",
        "        hyperparameters['tree_method'] = 'hist'\n",
        "    elif model == AdaBoostRegressor:\n",
        "        # DecisionTreeRegressorを基本推定器として設定し、max_depthとmin_samples_splitを設定\n",
        "        base_estimator = DecisionTreeRegressor(max_depth=best_hyperparameters['max_depth'], min_samples_split=best_hyperparameters['min_samples_split'])\n",
        "        best_hyperparameters['base_estimator'] = base_estimator\n",
        "        # max_depthとmin_samples_splitはもう必要ないので削除\n",
        "        del best_hyperparameters['max_depth']\n",
        "        del best_hyperparameters['min_samples_split']\n",
        "    model_instance = model(**best_hyperparameters)\n",
        "\n",
        "\n",
        "    result_id = compute_feature_importance.remote(best_hyperparameters, model_instance, features_df, target)\n",
        "    results.append(result_id)\n",
        "\n",
        "    # Update the progress bar\n",
        "    progress_bar.update()\n",
        "    elapsed_time = time.time() - start_time\n",
        "    remaining_time = (total_tasks - progress_bar.n) * (elapsed_time / progress_bar.n)\n",
        "    progress_bar.set_description(f\"Processing {model.__name__} with {best_hyperparameters}, Elapsed Time: {elapsed_time:.2f}s, Estimated Remaining Time: {remaining_time:.2f}s\")\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# プログレスバーを作成\n",
        "progress_bar = tqdm(total=len(results), desc='Fetching results')\n",
        "\n",
        "# すべての結果が利用可能になるまで待つ\n",
        "feature_importances = []\n",
        "while len(results) > 0:\n",
        "    ready, results = ray.wait(results)\n",
        "    for result_id in ready:\n",
        "        try:\n",
        "            feature_importances.append(ray.get(result_id))\n",
        "        except Exception as e:\n",
        "            dric(\"[red]エラーが発生しました。[/red]\")\n",
        "            dric(f\"[red]結果の取得中にエラーが発生しました: {e}[/red]\")\n",
        "            traceback.print_exc()\n",
        "        # プログレスバーを更新\n",
        "        progress_bar.update()\n",
        "    # 短いスリープ時間を設けて、他のタスクが進行するのを待つ\n",
        "    time.sleep(0.1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# 特徴量の重要度をデータフレームに保存\n",
        "feature_importances_df = pd.concat([result[0] for result in feature_importances], axis=1, keys=['Importance', 'Permutation_Importance', 'Mutual_Information', 'Correlation_Coefficient', 'Lasso_Importance'])\n",
        "\n",
        "# 特徴量の重要度が0のものを除外\n",
        "feature_importances_df = feature_importances_df.loc[:, (feature_importances_df != 0).any(axis=0)]\n",
        "\n",
        "# 各モデルと各重要度の計算のセットに対してプロットを作成\n",
        "for column in feature_importances_df.columns:\n",
        "    fig = px.histogram(feature_importances_df, x=column, title=f'{column} Distribution', nbins=50)\n",
        "    fig.update_layout(autosize=False, width=1000, height=800)\n",
        "    fig.show()\n",
        "\n",
        "# アンサンブル学習の結果を取得\n",
        "ensemble_importances = feature_importances_df.mean(axis=1)\n",
        "\n",
        "# アンサンブルした特徴量の重要度をデータフレームに保存\n",
        "ensemble_importances_df = ensemble_importances.to_frame(name='Ensemble_Importance')\n",
        "\n",
        "# アンサンブルした特徴量の重要度のプロットを作成\n",
        "non_zero_importances = ensemble_importances_df[ensemble_importances_df['Ensemble_Importance'] != 0]\n",
        "fig = px.histogram(non_zero_importances, x='Ensemble_Importance', title='Ensemble_Importance_Distribution', nbins=50)\n",
        "fig.update_layout(autosize=False, width=1000, height=800)\n",
        "fig.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hjhq-UTZD5M"
      },
      "outputs": [],
      "source": [
        "@ray.remote\n",
        "def compute_feature_importance(hyperparameters, model, features_df, target):\n",
        "    try:\n",
        "        X = features_df.drop(target, axis=1)\n",
        "        y = features_df[target]\n",
        "        model.fit(X, y)\n",
        "\n",
        "        # 特徴量の重要度を計算\n",
        "        importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "\n",
        "        # Permutation Importance\n",
        "        perm_importance = pd.Series(permutation_importance(model, X, y, n_repeats=10, random_state=42).importances_mean, index=X.columns)\n",
        "\n",
        "        # Mutual Information\n",
        "        mutual_info = pd.Series(mutual_info_regression(X, y), index=X.columns)\n",
        "\n",
        "        # Correlation Coefficient\n",
        "        correlation_coef = X.corrwith(y)\n",
        "\n",
        "        # Lasso (L1) Regularization\n",
        "        lasso = LassoCV(cv=5).fit(X, y)\n",
        "        lasso_importance = pd.Series(np.abs(lasso.coef_), index=X.columns)\n",
        "\n",
        "        # SHAP Values\n",
        "        explainer = shap.Explainer(model)\n",
        "        shap_values = explainer(X)\n",
        "        shap_importance = pd.Series(np.abs(shap_values.values).mean(axis=0), index=X.columns)\n",
        "\n",
        "        return importances, perm_importance, mutual_info, correlation_coef, lasso_importance, shap_importance\n",
        "    except Exception as e:\n",
        "        dric(\"エラーが発生しました。\")\n",
        "        dric(f\"関数 'compute_feature_importance' でエラーが発生しました: {e}\")\n",
        "        traceback.print_exc()\n",
        "# Rayの初期化\n",
        "initialize_ray([\"shap\"])\n",
        "models = [RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor, XGBRegressor]\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "hyperparameters = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 5],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# 文字列が含まれているカラムを抽出\n",
        "categorical_cols = features_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# ワンホットエンコーディングを行う\n",
        "features_df = pd.get_dummies(features_df, columns=categorical_cols)\n",
        "\n",
        "# 相関分析を行い、予測に寄与する可能性のある特徴量だけを選択\n",
        "correlation_threshold = 0.4\n",
        "correlation = features_df.corrwith(features_df[target])\n",
        "selected_features = correlation[correlation.abs() > correlation_threshold].index\n",
        "features_df = features_df[selected_features]\n",
        "\n",
        "# グリッドサーチを用いて最適なハイパーパラメータを選択\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), hyperparameters, cv=5)\n",
        "grid_search.fit(features_df.drop(target, axis=1), features_df[target])\n",
        "best_hyperparameters = grid_search.best_params_\n",
        "\n",
        "# 各ハイパーパラメータに対して特徴量の重要度を計算\n",
        "total_tasks = len(models)\n",
        "progress_bar = tqdm(total=total_tasks, desc='Overall Progress')\n",
        "\n",
        "# 各ハイパーパラメータに対して特徴量の重要度を計算\n",
        "total_tasks = len(models)\n",
        "progress_bar = tqdm(total=total_tasks, desc='Overall Progress')\n",
        "\n",
        "results = []\n",
        "start_time = time.time()\n",
        "for model in (models):\n",
        "    # XGBRegressorのインスタンス作成時にGPUを利用するように設定\n",
        "    if model == XGBRegressor:\n",
        "        # GPUが利用可能でない場合は、'hist'を使用\n",
        "        hp['tree_method'] = 'hist'\n",
        "    elif model == AdaBoostRegressor:\n",
        "        # max_depthとmin_samples_splitはもう必要ないので削除\n",
        "        del best_hyperparameters['max_depth']\n",
        "        del best_hyperparameters['min_samples_split']\n",
        "    model_instance = model(**best_hyperparameters)\n",
        "\n",
        "    result_id = compute_feature_importance.remote(best_hyperparameters, model_instance, features_df, target)\n",
        "    results.append(result_id)\n",
        "\n",
        "    # Update the progress bar\n",
        "    progress_bar.update()\n",
        "    elapsed_time = time.time() - start_time\n",
        "    remaining_time = (total_tasks - progress_bar.n) * (elapsed_time / progress_bar.n)\n",
        "    progress_bar.set_description(f\"Processing {model.__name__} with {best_hyperparameters}, Elapsed Time: {elapsed_time:.2f}s, Estimated Remaining Time: {remaining_time:.2f}s\")\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# プログレスバーを作成\n",
        "progress_bar = tqdm(total=len(results), desc='Fetching results')\n",
        "\n",
        "# すべての結果が利用可能になるまで待つ\n",
        "feature_importances = []\n",
        "while len(results) > 0:\n",
        "    ready, results = ray.wait(results)\n",
        "    for result_id in ready:\n",
        "        try:\n",
        "            feature_importances.append(ray.get(result_id))\n",
        "        except Exception as e:\n",
        "            dric(\"[red]エラーが発生しました。[/red]\")\n",
        "            dric(f\"[red]結果の取得中にエラーが発生しました: {e}[/red]\")\n",
        "            traceback.print_exc()\n",
        "        # プログレスバーを更新\n",
        "        progress_bar.update()\n",
        "    # 短いスリープ時間を設けて、他のタスクが進行するのを待つ\n",
        "    time.sleep(0.1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "# 特徴量の重要度をデータフレームに保存\n",
        "feature_importances_df = pd.concat([result[0] for result in feature_importances], axis=1, keys=['Importance', 'Permutation_Importance', 'Mutual_Information', 'Correlation_Coefficient', 'Lasso_Importance', 'SHAP_Importance'])\n",
        "# 特徴量の重要度が0のものを除外\n",
        "feature_importances_df = feature_importances_df.loc[:, (feature_importances_df != 0).any(axis=0)]\n",
        "\n",
        "# 各モデルと各重要度の計算のセットに対してプロットを作成\n",
        "for column in feature_importances_df.columns:\n",
        "    fig = px.histogram(feature_importances_df, x=column, title=f'{column} Distribution', nbins=50)\n",
        "    fig.update_layout(autosize=False, width=1000, height=800)\n",
        "    fig.show()\n",
        "\n",
        "# アンサンブル学習の結果を取得\n",
        "ensemble_importances = feature_importances_df.mean(axis=1)\n",
        "\n",
        "# アンサンブルした特徴量の重要度をデータフレームに保存\n",
        "ensemble_importances_df = ensemble_importances.to_frame(name='Ensemble_Importance')\n",
        "\n",
        "# アンサンブルした特徴量の重要度のプロットを作成\n",
        "non_zero_importances = ensemble_importances_df[ensemble_importances_df['Ensemble_Importance'] != 0]\n",
        "fig = px.histogram(non_zero_importances, x='Ensemble_Importance', title='Ensemble_Importance_Distribution', nbins=50)\n",
        "fig.update_layout(autosize=False, width=1000, height=800)\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMtPplcJ2-W_"
      },
      "source": [
        "# **<font color='Blue'>カラム名の変更**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LiZHI0wPK0K"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title **カラム名の変更と分割**\n",
        "features_df=features_df_copy\n",
        "\n",
        "# 必要なカラムとその対応する値を辞書として定義\n",
        "columns_dict = {\n",
        "    \"date\": \"ds\",\n",
        "    \"unique_id\": \"unique_id\",\n",
        "    target: \"y\"\n",
        "}\n",
        "\n",
        "try:\n",
        "\n",
        "    # 'ds'または'date'カラムが存在するか確認\n",
        "    if 'ds' in features_df.columns:\n",
        "        time_col = 'ds'\n",
        "    elif 'date' in features_df.columns:\n",
        "        time_col = 'date'\n",
        "    else:\n",
        "        raise ValueError(\"Neither 'ds' nor 'date' column is found in the DataFrame.\")\n",
        "\n",
        "    # 'ds'または'date'列がobject型の場合、タイムスタンプに変換\n",
        "    if features_df[time_col].dtype == 'object':\n",
        "        features_df[time_col] = pd.to_datetime(features_df[time_col])\n",
        "\n",
        "    # 再度、'ds'または'date'列のデータ型を確認\n",
        "    dric(features_df[time_col].dtype)\n",
        "\n",
        "    # カラム名と順序が既に変更されているか確認\n",
        "    if set(columns_dict.values()).issubset(set(features_df.columns)) and features_df.columns.tolist()[:3] == list(columns_dict.values()):\n",
        "        dric(\"カラム名と順序は既に変更されています。\")\n",
        "        dric(f\"features_dfの長さ: {len(features_df)}\")\n",
        "        unique_values = features_df['ds'].unique()\n",
        "        # unique_valuesから分割する日付を取得\n",
        "        split_date = unique_values[-test_size]\n",
        "\n",
        "        # split_dateを基にデータフレームを分割\n",
        "        Y_train_df = features_df[features_df['ds'] < split_date]\n",
        "        Y_test_df = features_df[features_df['ds'] >= split_date]\n",
        "\n",
        "        # インデックスをリセット\n",
        "        Y_train_df = Y_train_df.reset_index(drop=True)\n",
        "        Y_test_df = Y_test_df.reset_index(drop=True)\n",
        "\n",
        "        display(Y_train_df.head())\n",
        "        dric(f\"Y_train_dfの長さ{len(Y_train_df)} \\n Y_train_dfの特徴量 {len(Y_train_df.columns)}\")\n",
        "        display(Y_test_df.head())\n",
        "        dric(f\"Y_test_dffの長さ{len(Y_test_df)} \\n Y_test_dfの特徴量 {len(Y_test_df.columns)}\")\n",
        "\n",
        "    else:\n",
        "        # 各カラムを処理\n",
        "        for old_name, new_name in columns_dict.items():\n",
        "            # カラムが存在する場合のみリネーム\n",
        "            if old_name in features_df.columns:\n",
        "                features_df.rename(columns={old_name: new_name}, inplace=True)\n",
        "\n",
        "        # 'y', 'ds', 'unique_id'をカラムの先頭に移動\n",
        "        cols = ['ds', 'y', 'unique_id'] + [col for col in features_df.columns if col not in ['y', 'ds', 'unique_id']]\n",
        "        features_df = features_df[cols]\n",
        "\n",
        "        # 'unique_id'と'ds'の順でソート\n",
        "        features_df = features_df.sort_values(by=['unique_id', 'ds'])\n",
        "\n",
        "        # カラムの順序が正しいかチェック\n",
        "        if features_df.columns.tolist() == cols:\n",
        "            dric(\"カラムの順序は正しく変更されました。\")\n",
        "            dric(f\"features_dfの長さ: {len(features_df)}\")\n",
        "            unique_values = features_df['ds'].unique()\n",
        "            # unique_valuesから分割する日付を取得\n",
        "            split_date = unique_values[-test_size]\n",
        "\n",
        "            # split_dateを基にデータフレームを分割\n",
        "            Y_train_df = features_df[features_df['ds'] < split_date]\n",
        "            Y_test_df = features_df[features_df['ds'] >= split_date]\n",
        "\n",
        "            # インデックスをリセット\n",
        "            Y_train_df = Y_train_df.reset_index(drop=True)\n",
        "            Y_test_df = Y_test_df.reset_index(drop=True)\n",
        "\n",
        "            display(Y_train_df.head())\n",
        "            dric(f\"Y_train_dfの長さ{len(Y_train_df)} \\n Y_train_dfの特徴量 {len(Y_train_df.columns)}\")\n",
        "            display(Y_test_df.head())\n",
        "            dric(f\"Y_test_dffの長さ{len(Y_test_df)} \\n Y_test_dfの特徴量 {len(Y_test_df.columns)}\")\n",
        "\n",
        "        else:\n",
        "            dric(\"エラー: カラムの順序が正しくありません。\")\n",
        "except Exception as e:\n",
        "    dric(f\"エラー: カラムの処理に失敗しました。\")\n",
        "    dric(str(e))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yEC2sG4H1RX"
      },
      "source": [
        "# **<font color='Blue'>モデル定義**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeEKd1yE1cAC"
      },
      "outputs": [],
      "source": [
        "#@title **モデル定義**\n",
        "\n",
        "try:\n",
        "    n_series=len(features_df.unique_id.unique())\n",
        "    result = undefined_vars_check()\n",
        "    if not result:\n",
        "        dric(\"[red bold]*\"*50)\n",
        "        dric(\"[red bold]エラーが発生しました: 一部の変数が定義されていません\")\n",
        "\n",
        "    else:\n",
        "        dric(\"[green bold]*\"*50)\n",
        "        dric(\"[green bold]モデルを定義します\")\n",
        "        model_alias=f\"_horizon={horizon}_backend={backend}_refit_with_val={refit_with_val}_num_samples={num_samples}_features={len(features_df.columns)}_len_{len(features_df)}_shape_{use_reshape_dataframe}\"\n",
        "        pre_models =[\n",
        "        AutoRNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoR NN.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoTCN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoTCN.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoDeepAR(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoDeepAR.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoDilatedRNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoDilatedRNN.__name__}\"+model_alias\n",
        "                       ),\n",
        "        AutoBiTCN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoBiTCN.__name__}\"+model_alias\n",
        "                  ),\n",
        "        AutoMLP(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoMLP.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoNBEATS(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                #    alias=f\"{AutoNBEATS.__name__}\"+model_alias\n",
        "                   ),\n",
        "        AutoNBEATSx(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                    alias=f\"{AutoNBEATSx.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoNHITS(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                #   alias=f\"{AutoNHITS.__name__}\"+model_alias\n",
        "                  ),\n",
        "        AutoDLinear(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                    alias=f\"{AutoDLinear.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoNLinear(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                    alias=f\"{AutoNLinear.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoTFT(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                alias=f\"{AutoTFT.__name__}\"+model_alias\n",
        "                ),\n",
        "        AutoVanillaTransformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                               alias=f\"{AutoVanillaTransformer.__name__}\"+model_alias\n",
        "                               ),\n",
        "        AutoInformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                     alias=f\"{AutoInformer.__name__}\"+model_alias\n",
        "                     ),\n",
        "        AutoAutoformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                       alias=f\"{AutoAutoformer.__name__}\"+model_alias\n",
        "                       ),\n",
        "        AutoFEDformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                      alias=f\"{AutoFEDformer.__name__}\"+model_alias\n",
        "                      ),\n",
        "        AutoPatchTST(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                     alias=f\"{AutoPatchTST.__name__}\"+model_alias\n",
        "                     ),\n",
        "        AutoiTransformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                         alias=f\"{AutoiTransformer.__name__}\"+model_alias\n",
        "                         ),\n",
        "        AutoTimesNet(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,num_samples=num_samples,\n",
        "                     alias=f\"{AutoTimesNet.__name__}\"+model_alias\n",
        "                     ),\n",
        "        AutoStemGNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                    alias=f\"{AutoStemGNN.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoTSMixer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                    alias=f\"{AutoTSMixer.__name__}\"+model_alias\n",
        "                    ),\n",
        "        AutoTSMixerx(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                     alias=f\"{AutoTSMixerx.__name__}\"+model_alias\n",
        "                     ),\n",
        "        AutoMLPMultivariate(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=verbose,\n",
        "                backend=backend,refit_with_val=refit_with_val,n_series=n_series,num_samples=num_samples,\n",
        "                            alias=f\"{AutoMLPMultivariate.__name__}\"+model_alias\n",
        "                            ),\n",
        "        ]\n",
        "        dric(\"[green bold]*\"*50)\n",
        "        dric(\"[green bold]すべての変数が定義されています\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    dric(\"[red bold]*\"*50)\n",
        "    dric(f\"[red bold]エラーが発生しました: {str(e)}\")\n",
        "    traceback.print_exc()\n",
        "    # @title モデルの差分\n",
        "\n",
        "\n",
        "# 'Auto'が含まれる名前のモデルを抽出\n",
        "models_with_auto = [model for model in dir() if 'Auto' in model]\n",
        "pre_model_names = [model.__class__.__name__ for model in pre_models]\n",
        "models_with_auto\n",
        "# pre_model_namesとauto_namesの差分を見つける\n",
        "diff_models = list( set(models_with_auto)-set(pre_model_names))\n",
        "\n",
        "\n",
        "dric(f\"[green bold] neuralforecast.autoの中のAutoモデル \\n {set(models_with_auto)}\")\n",
        "dric(f\"[blue bold] \\n 定義済みのモデル \\n{set(pre_model_names)}\\n\")\n",
        "dric(f\"[red bold] neuralforecast.autoの中のAutoモデルと定義済みのモデルの差分　\\n {diff_models}\")\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEWzXlaiw1IO"
      },
      "outputs": [],
      "source": [
        "# @title **モデルの選択**  { run: \"auto\" }\n",
        "\n",
        "# モデルの名前を取得\n",
        "model_names = [model.__class__.__name__ for model in pre_models]\n",
        "\n",
        "# チェックボックスを作成\n",
        "checkboxes = [widgets.Checkbox(value=True, description=name) for name in model_names]  # 初期値をTrueに設定\n",
        "\n",
        "# 全て選択/選択解除のチェックボックスを作成\n",
        "select_all = widgets.Checkbox(value=True, description='全て選択/選択解除')\n",
        "\n",
        "# models変数を初期化\n",
        "models = pre_models.copy()\n",
        "\n",
        "# 各チェックボックスに変更イベントを追加\n",
        "for checkbox in checkboxes:\n",
        "    checkbox.observe(on_change)\n",
        "\n",
        "# 全て選択/選択解除のチェックボックスに変更イベントを追加\n",
        "select_all.observe(on_select_all_change)\n",
        "git_save(git_username,git_repository,git_pass)\n",
        "# チェックボックスを表示\n",
        "display(select_all)\n",
        "# チェックボックスを2列に表示\n",
        "widgets.HBox([widgets.VBox(checkboxes[:len(checkboxes)//2]), widgets.VBox(checkboxes[len(checkboxes)//2:])])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyQ0IO13LWsT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "kPjBWmIOD8m3"
      },
      "outputs": [],
      "source": [
        "#@title **モデルの再学習と予測の評価　関数**\n",
        "\n",
        "error_directories=[]\n",
        "error_directories2=[]\n",
        "def evaluate_models(parent_folder,select_loto,target,Y_train_df,y_test,gpus,cpus,retrain=False):\n",
        "    \"\"\"\n",
        "    この関数は、指定したディレクトリに保存されているモデルのパフォーマンスを評価します。\n",
        "    モデルを再学習するか、予測のためにだけロードするかを選択できます。\n",
        "\n",
        "    引数:\n",
        "    parent_folder (str): モデルが保存されている親ディレクトリ。\n",
        "    retrain (bool): Trueの場合、モデルは再学習されます。Falseの場合、モデルは予測のためにだけロードされます。\n",
        "\n",
        "    戻り値:\n",
        "    csv_path\n",
        "    \"\"\"\n",
        "    # 使用例\n",
        "    dir_path = \"/content/lightning_logs\"\n",
        "    # remove_directory(dir_path)\n",
        "    parent_directory = os.path.dirname(parent_folder)\n",
        "    save_folder_name = os.path.basename(parent_folder)\n",
        "    # 結果用のデータフレームを初期化\n",
        "    # results_df = pd.DataFrame(columns=['Model', 'MSE', 'MAE', 'R2', 'RMSE', 'MAPE', 'MedAE'])\n",
        "    results_df = pd.DataFrame(columns=['Model', 'MSE', 'MAE', 'R2', 'RMSE', 'MAPE', 'MedAE', 'Feature', 'Time', 'loto', 'N', '学習量'])\n",
        "\n",
        "    # ディレクトリ内のすべての項目をリストアップ\n",
        "    items = os.listdir(parent_folder)\n",
        "    dric(\"$\"*100,\"\\n\",f\"items={items}\")\n",
        "    # ディレクトリをフィルタリング\n",
        "    directories = [item for item in items if os.path.isdir(os.path.join(parent_folder, item)) and item != 'lightning_logs']\n",
        "    error_directories = []\n",
        "    error_directories2 = []\n",
        "    # 各ディレクトリ（モデル）に対してループ\n",
        "    for directory in tqdm(directories):\n",
        "        dric(\"*\"*100,\"\\n\",f\"ディレクトリ {directory} の処理を開始します。\")\n",
        "        dric(\"*\"*100,\"\\n\",f\"親ディレクトリ {save_folder_name} の処理を開始します。\")\n",
        "        try:\n",
        "            first_string = directory.split('_')[0]\n",
        "            save_directory = f'{parent_folder}/'\n",
        "            dric(\"-\"*100,\"\\n\",f\"save_directory ={save_directory}\")\n",
        "            # 現在の時刻を取得\n",
        "            start_time = time.time()\n",
        "             # モデルをロード\n",
        "            model_path = os.path.join(parent_folder, directory)\n",
        "            dric(\"-\"*100,\"\\n\",f\"model_path ={model_path}\")\n",
        "            nf = NeuralForecast.load( model_path)\n",
        "\n",
        "            # 指定された場合はモデルを再学習\n",
        "            if retrain:\n",
        "                dric(\"モデルの再学習を開始します...\")\n",
        "                nf.fit(df=Y_train_df)\n",
        "\n",
        "                # 現在の日時を取得\n",
        "                now = datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "                # 日時を文字列に変換（例：2024_04_14_00_29_50）\n",
        "                timestamp_str = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "\n",
        "                elapsed_time = time.time() - start_time\n",
        "                elapsed_time_str = str(dt.timedelta(seconds=int(elapsed_time)))\n",
        "                dric(f\"再学習にかかった時間: {elapsed_time_str}\")\n",
        "\n",
        "                save_directory = f\"{parent_directory}/{select_loto}_{target}_{len(Y_train_df.columns)}_{len(Y_train_df)}/\"\n",
        "                dric(\"-\"*100,\"\\n\",f\"save_directory ={save_directory}\")\n",
        "                save_path = save_directory +f'{save_folder_name}_{first_string}_{select_loto}_{target}_{len(Y_train_df.columns)}_{len(Y_train_df)}_{elapsed_time_str}'\n",
        "                dric(\".\"*100,\"\\n\",f\"save_path ={save_path}\")\n",
        "\n",
        "                dric(f\"{save_path}\\nにモデルを保存しています...\")\n",
        "                nf.save(path=save_path, overwrite=True)\n",
        "                dric(f\"{save_path}\\nにモデルの保存が完了しました。\")\n",
        "\n",
        "                dric(f\"{save_path}\\nのモデルを読み込んでいます...\")\n",
        "                nf = NeuralForecast.load(save_path)\n",
        "                dric(f\"{save_path}\\nのモデルの読み込みが完了しました。\")\n",
        "\n",
        "\n",
        "            # 予測を実行\n",
        "            start_time = time.time()\n",
        "            y_pred = nf.predict()\n",
        "            elapsed_time_pre = time.time() - start_time\n",
        "            elapsed_time_str_pre = str(dt.timedelta(seconds=int(elapsed_time_pre)))\n",
        "            #y_pred_values = round(y_pred.iloc[:, 1])\n",
        "            #y_pred_values = y_pred.values\n",
        "\n",
        "            # y_pred_values = y_pred.iloc[:, 1].values\n",
        "            y_pred_values = y_pred.iloc[:, 1].values.astype(int)\n",
        "\n",
        "            # 値を小数点以下2桁に丸める\n",
        "            #y_pred_values = [round(value, 2) for value in y_pred_values]\n",
        "            # 評価指標を計算\n",
        "            mse = mean_squared_error(y_test, y_pred_values)\n",
        "            mae = mean_absolute_error(y_test, y_pred_values)\n",
        "            r2 = r2_score(y_test, y_pred_values)\n",
        "            rmse = sqrt(mse)\n",
        "            mape = np.mean(np.abs((y_test - y_pred_values) / y_test)) * 100\n",
        "            medae = median_absolute_error(y_test, y_pred_values)\n",
        "\n",
        "            if retrain:\n",
        "                elapsed_time_str=elapsed_time_str\n",
        "            else:\n",
        "                elapsed_time_str=elapsed_time_str_pre\n",
        "\n",
        "\n",
        "            # 結果をデータフレームに追加\n",
        "            new_row = pd.DataFrame({\n",
        "                'Model': [directory],\n",
        "                'MSE': [mse],\n",
        "                'MAE': [mae],\n",
        "                'R2': [r2],\n",
        "                'RMSE': [rmse],\n",
        "                'MAPE': [mape],\n",
        "                'MedAE': [medae],\n",
        "                'Feature': [len(Y_train_df.columns)],\n",
        "                'Time': [elapsed_time_str],\n",
        "                'loto': [select_loto],\n",
        "                'N': [target],\n",
        "                '学習量': [len(Y_train_df)],\n",
        "                'Predicted': [y_pred_values.tolist()],\n",
        "                'Measured': [y_test.tolist()]\n",
        "            })\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "        except Exception as e:\n",
        "            dric(f\"ディレクトリ {directory} でエラーが発生しました: {e}\")\n",
        "            traceback.print_exc()\n",
        "            # エラーが発生したディレクトリの名前をリストに追加\n",
        "            error_directories.append(directory)\n",
        "            error_directories2.append(e)\n",
        "            continue\n",
        "\n",
        "    # 平均指標を計算\n",
        "    results_df['Average_All'] = results_df[['MSE', 'MAE', 'R2', 'RMSE', 'MAPE', 'MedAE']].mean(axis=1)\n",
        "    results_df['Average_MSE_RMSE'] = results_df[['MSE', 'RMSE']].mean(axis=1)\n",
        "\n",
        "    # 平均MSEとRMSEでソート\n",
        "    sorted_df = results_df.sort_values(by='Average_MSE_RMSE')\n",
        "    error_df = pd.DataFrame(list(zip(error_directories, error_directories2)), columns=['dir', 'error'])\n",
        "    error_csv_path = f\"{parent_folder}/error_directories.csv\"\n",
        "    error_df.to_csv(f\"{parent_folder}/error_directories.csv\", index=False)\n",
        "    try:\n",
        "        if retrain:\n",
        "            # コピー元のパス\n",
        "            src = \"/content/lightning_logs\"\n",
        "            dst= save_directory + f\"lightning_logs\"\n",
        "            dric(dst)\n",
        "            # ディレクトリをコピー\n",
        "            shutil.copytree(src, dst)\n",
        "            dric(f\"{src}\\\\nは {dst} に保存されました\")\n",
        "            csv_path=save_directory+f\"{save_folder_name}_{len(Y_train_df)}_{elapsed_time_str}.csv\"\n",
        "            dric(f\"retrain_csv_path ={csv_path}\")\n",
        "            # 結果をCSVファイルに保存\n",
        "            sorted_df.to_csv(csv_path, index=False)\n",
        "            dric(f\"{csv_path}\\\\nにモデルの評価CSVの保存が完了しました。\",\"\\\\n\",\"-\"*100,\"\\\\n\")\n",
        "        else:\n",
        "            csv_path=save_directory+f\"{save_folder_name}.csv\"\n",
        "            dric(f\"csv_path ={csv_path}\")\n",
        "            # 結果をCSVファイルに保存\n",
        "            sorted_df.to_csv(csv_path, index=False)\n",
        "\n",
        "    except FileNotFoundError as fnf_error:\n",
        "        dric(f\"ファイルが見つかりません: {fnf_error}\")\n",
        "        traceback.print_exc()\n",
        "        raise e\n",
        "\n",
        "    except Exception as e:\n",
        "        dric(f\"An error occurred: {e}\")\n",
        "        traceback.print_exc()\n",
        "        raise e\n",
        "    return csv_path,error_csv_path\n",
        "\n",
        "\n",
        "\n",
        "def get_directories(path, pattern):\n",
        "    \"\"\"\n",
        "    指定したパスの階層にある、指定したパターンという文字列が含まれたディレクトリの一覧を取得する関数\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "        ディレクトリのパス\n",
        "    pattern : str\n",
        "        検索するパターン\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        パターンに一致するディレクトリの一覧\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # パスとパターンを組み合わせて検索するパスを作成\n",
        "        search_path = os.path.join(path, pattern)\n",
        "        # パターンに一致するディレクトリの一覧を取得\n",
        "        directories = [d for d in glob.glob(search_path) if os.path.isdir(d)]\n",
        "        return directories\n",
        "    except Exception as e:\n",
        "        # エラーメッセージを表示\n",
        "        dric(f\"エラーが発生しました: {e}\")\n",
        "        return []\n",
        "        traceback.print_exc()\n",
        "\n",
        "\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djdCRjeYkPdE"
      },
      "source": [
        "# **モデルの生成**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaht61RHoZ3_"
      },
      "outputs": [],
      "source": [
        "retrain = True #@param {type:\"boolean\"}\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB0qO6MOakdk"
      },
      "outputs": [],
      "source": [
        "#@title **モデルの再学習、予測、評価**\n",
        "if retrain_and_evaluate_model:\n",
        "\n",
        "    y_test=Y_test_df.y.values\n",
        "\n",
        "    # テスト\n",
        "    path = \"/content/drive/MyDrive/\"\n",
        "    # pattern = f\"*{select_loto}_*_f*_h{horizon}*\"\n",
        "    pattern = f\"*25772*\"\n",
        "    # pattern = f\"*cumsum*\"\n",
        "    dric(pattern)\n",
        "    directories = get_directories(path, pattern)\n",
        "    dric(directories)\n",
        "    # 空のデータフレームを作成\n",
        "    model_evaluation_df = pd.DataFrame()\n",
        "    model_evaluation_df_error = pd.DataFrame()\n",
        "    # 各ディレクトリの処理\n",
        "    for i in tqdm(directories):\n",
        "        dric(\"#\"*100,\"\\n\",f\"ディレクトリ {i} の処理を開始します。\")\n",
        "        csv_path ,error_csv_path= evaluate_models(i,select_loto, target,\n",
        "                                Y_test_df, y_test,gpus,cpus,\n",
        "                                retrain=retrain)\n",
        "        dric(\"#\"*100,\"\\n\",f\"ディレクトリ {i} の処理が完了しました。\")\n",
        "\n",
        "        # select_lotoデータフレームを作成\n",
        "        model_performance_df = pd.read_csv(csv_path)\n",
        "        model_evaluation_df = pd.concat([model_evaluation_df,\n",
        "                                        model_performance_df])\n",
        "        # select_lotoデータフレームを作成\n",
        "        error_df_error = pd.read_csv(error_csv_path)\n",
        "        model_evaluation_df_error = pd.concat([model_evaluation_df_error,\n",
        "                                        error_df_error])\n",
        "    # 'Average_MSE_RMSE'カラムの値でソート\n",
        "    model_evaluation_df = model_evaluation_df.sort_values(by='Average_MSE_RMSE')\n",
        "\n",
        "    # 現在の日時を取得\n",
        "    now = datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "\n",
        "    # 日時を文字列に変換（例：2024_04_14_00_29_50）\n",
        "    timestamp_str = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "\n",
        "\n",
        "    # 結果を表示\n",
        "    model_evaluation_df_path =(\n",
        "        f'/content/drive/MyDrive/model_evaluation/'\n",
        "        f'model_evaluation_{select_loto}_{target}_{timestamp_str}.csv')\n",
        "\n",
        "    # ディレクトリが存在しない場合は作成\n",
        "    os.makedirs(os.path.dirname(model_evaluation_df_path), exist_ok=True)\n",
        "\n",
        "    model_evaluation_df.to_csv(model_evaluation_df_path,index=False)\n",
        "\n",
        "    # 結果を表示\n",
        "    model_evaluation_df.to_csv(model_evaluation_df_path,index=False\n",
        "    )\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRriQBFYpwDb"
      },
      "outputs": [],
      "source": [
        "#@title **評価結果**\n",
        "model_evaluation_df\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FdfNxsMLdHq"
      },
      "outputs": [],
      "source": [
        "for model in models:\n",
        "    dric(model.__class__.__name__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnHVEBdwLdwG"
      },
      "source": [
        "# <font color='Blue'>**モデルの生成**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryyx9uynqgP5"
      },
      "outputs": [],
      "source": [
        "#@title **モデルの生成**\n",
        "try:\n",
        "    if create_model:\n",
        "        feature =len(Y_train_df.columns)\n",
        "        leng =len(Y_train_df)\n",
        "        local_scaler_type=\"standard\"# Y_train_dfに欠損値があるかどうかを確認します\n",
        "        missing_values = Y_train_df.isnull().sum().sum()\n",
        "\n",
        "        # 必要なカラムが存在するか確認します\n",
        "        required_columns = ['ds', 'y', 'unique_id']\n",
        "        missing_columns = [col for col in required_columns if col not in Y_train_df.columns]\n",
        "\n",
        "        if len(missing_columns) > 0:\n",
        "            dric(f\"Y_train_dfには{', '.join(missing_columns)}カラムが欠けています。\")\n",
        "        else:\n",
        "            # 欠損値の数を計算します\n",
        "            missing_values = Y_train_df.isnull().sum().sum()\n",
        "\n",
        "            # 結果を表示します\n",
        "            if missing_values > 0:\n",
        "                dric(f\"Y_train_dfには{missing_values}個の欠損値があります。\")\n",
        "            else:\n",
        "                dric(\"Y_train_dfには欠損値はありません。\")\n",
        "\n",
        "                # エラーが発生したモデルとそのエラーメッセージを格納するためのデータフレームを作成\n",
        "                error_df = pd.DataFrame(columns=['model', 'error'])\n",
        "\n",
        "                # すでに存在するモデルのリストを取得\n",
        "                folder_name = f\"{select_loto}_{target}_f{feature}_h{horizon}_l{leng}_n{num_samples}_{backend}\"\n",
        "                if not os.path.exists(folder_name):\n",
        "                    os.makedirs(folder_name)\n",
        "                existing_models = [f.name for f in os.scandir(f'/content/{folder_name}') if f.is_dir()]\n",
        "                # ソースディレクトリのパスのリスト\n",
        "                src_dirs = [f\"/content/{folder_name}\", \"/content/lightning_logs\"]\n",
        "\n",
        "                # 宛先ディレクトリのパス\n",
        "                dst_dir = f\"/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/model/{use_reshape_dataframe}/{target}/{horizon}/\"\n",
        "                # ディレクトリが存在しない場合は作成\n",
        "                if not os.path.exists(dst_dir):\n",
        "                    os.makedirs(dst_dir)\n",
        "                # 新しい名前を抽出\n",
        "                new_names = [name.split('_')[0] for name in existing_models]\n",
        "\n",
        "                # 新しい名前を表示\n",
        "                dric(new_names)\n",
        "                error_list = []\n",
        "                try:\n",
        "                    pbar = tqdm(total=len(models), desc=\"モデルの処理\")\n",
        "                    # 空のリストを作成します\n",
        "                    model_results = []\n",
        "                    for model in models:\n",
        "                        dric(model)\n",
        "\n",
        "                        dst_dir1 = f\"/content/{folder_name}\"\n",
        "                        src_dirs1 = [\"/content/lightning_logs\"]\n",
        "\n",
        "                        # First, copy /content/lightning_logs to /content/{folder_name}\n",
        "                        copy_directories(src_dirs1, dst_dir1)\n",
        "\n",
        "                        # Then, copy /content/{folder_name} to /content/drive/MyDrive/\n",
        "                        dst_dir2 = dst_dir\n",
        "                        src_dirs2 = [f\"/content/{folder_name}\"]\n",
        "                        copy_directories(src_dirs2, dst_dir2)\n",
        "                        # すでに存在するモデルはスキップ\n",
        "                        if model.__class__.__name__ in new_names:\n",
        "                            dric(f\"モデル {model.__class__.__name__} はすでに存在します。スキップします。\")\n",
        "                            pbar.update(1)\n",
        "                            # continue\n",
        "\n",
        "                        try:\n",
        "                            model_name = model.__class__.__name__\n",
        "                            start_time = time.time()\n",
        "                            dric(\"+\"*100,f\"\\nモデル名: {model.__class__.__name__}\\n\",\"+\"*100)\n",
        "                            nf = NeuralForecast(models=[model], freq=freq, local_scaler_type=local_scaler_type)\n",
        "                            nf.fit(df=Y_train_df)\n",
        "                            elapsed_time = time.time() - start_time\n",
        "                            # elapsed_time_str = str(dt.timedelta(seconds=int(elapsed_time)))\n",
        "                            elapsed_time_str = str(datetime.timedelta(seconds=int(elapsed_time)))\n",
        "                            dric(f\"{model.__class__.__name__}の処理時間: {elapsed_time_str}\")\n",
        "                            path = f'/content/{folder_name}/{model.__class__.__name__}_{str(elapsed_time_str)}/'\n",
        "                            beep()\n",
        "                            nf.save(path=path, model_index=None, overwrite=True, save_dataset=True)\n",
        "                            if Path(path).exists():\n",
        "                                nf2 = NeuralForecast.load(path=path)\n",
        "                                prediction = nf2.predict().reset_index()\n",
        "                                prediction = prediction.iloc[:, 1].values.astype(int)\n",
        "                                dric(f'{path}のモデルによる予測: {prediction}')\n",
        "                                        # モデルの名前、予測結果、処理時間をリストに追加します\n",
        "                                model_results.append({\n",
        "                                    'model': model_name,\n",
        "                                    'prediction': prediction,\n",
        "                                    'elapsed_time': elapsed_time_str\n",
        "                                })\n",
        "                            # 関数の呼び出し\n",
        "                            copy_directories(src_dirs, dst_dir)\n",
        "                            pbar.update(1)\n",
        "                        except Exception as e:\n",
        "                            dric(f'モデル {model.__class__.__name__} のロード中にエラーが発生しました: {str(e)}')\n",
        "                            error_list.append({'model': model.__class__.__name__, 'error': str(e)})\n",
        "                            traceback.print_exc()\n",
        "                finally:\n",
        "                    pbar.close()\n",
        "\n",
        "                error_df = pd.DataFrame(error_list)\n",
        "                df_model_results = pd.DataFrame(model_results)\n",
        "                # データフレームを特定のディレクトリにCSVファイルとして保存\n",
        "                error_df.to_csv(f'{dst_dir}/{folder_name}/error_df.csv', index=False)\n",
        "                df_model_results.to_csv(f'{dst_dir}/{folder_name}/results_df.csv', index=False)\n",
        "\n",
        "    git_save(git_username,git_repository,git_pass)\n",
        "except Exception as e:\n",
        "    dric(f\"エラーが発生しました: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edSwNuazKpEA"
      },
      "outputs": [],
      "source": [
        "#@title **モデルの生成 修正版**\n",
        "\n",
        "if create_model:\n",
        "    feature =len(Y_train_df.columns)\n",
        "    leng =len(Y_train_df)\n",
        "    local_scaler_type=\"standard\"# Y_train_dfに欠損値があるかどうかを確認します\n",
        "    missing_values = Y_train_df.isnull().sum().sum()\n",
        "\n",
        "    # 必要なカラムが存在するか確認します\n",
        "    required_columns = ['ds', 'y', 'unique_id']\n",
        "    missing_columns = [col for col in required_columns if col not in Y_train_df.columns]\n",
        "\n",
        "    if len(missing_columns) > 0:\n",
        "        dric(f\"Y_train_dfには{', '.join(missing_columns)}カラムが欠けています。\")\n",
        "    else:\n",
        "        # 欠損値の数を計算します\n",
        "        missing_values = Y_train_df.isnull().sum().sum()\n",
        "\n",
        "        # 結果を表示します\n",
        "        if missing_values > 0:\n",
        "            dric(f\"Y_train_dfには{missing_values}個の欠損値があります。\")\n",
        "        else:\n",
        "            dric(\"Y_train_dfには欠損値はありません。\")\n",
        "\n",
        "            # エラーが発生したモデルとそのエラーメッセージを格納するためのデータフレームを作成\n",
        "            error_df = pd.DataFrame(columns=['model', 'error'])\n",
        "\n",
        "            # すでに存在するモデルのリストを取得\n",
        "            folder_name = f\"f{feature}_h{horizon}_le{leng}_n{num_samples}_{backend}\"\n",
        "            if not os.path.exists(folder_name):\n",
        "                os.makedirs(folder_name)\n",
        "            existing_models = [f.name for f in os.scandir(f'/content/{folder_name}') if f.is_dir()]\n",
        "            # ソースディレクトリのパスのリスト\n",
        "            src_dirs = [f\"/content/{folder_name}\", \"/content/lightning_logs\"]\n",
        "\n",
        "            # 宛先ディレクトリのパス\n",
        "            dst_dir = f\"/content/drive/MyDrive/ColabNotebooks/forecast_loto/{select_loto}/model/{use_reshape_dataframe}/{target}/{horizon}/\"\n",
        "            # ディレクトリが存在しない場合は作成\n",
        "            if not os.path.exists(dst_dir):\n",
        "                os.makedirs(dst_dir)\n",
        "            # 新しい名前を抽出\n",
        "            new_names = [name.split('_')[0] for name in existing_models]\n",
        "\n",
        "            # 新しい名前を表示\n",
        "            dric(new_names)\n",
        "            error_list = []\n",
        "\n",
        "            # 新しい名前を表示\n",
        "            dric(new_names)\n",
        "\n",
        "            # モデルの処理を開始します\n",
        "            pbar = tqdm(total=len(models), desc=\"モデルの処理\")\n",
        "            model_results = []  # 空のリストを作成します\n",
        "            for model in models:\n",
        "                dric(model)\n",
        "\n",
        "                # すでに存在するモデルはスキップ\n",
        "                if model.__class__.__name__ in new_names:\n",
        "                    dric(f\"モデル {model.__class__.__name__} はすでに存在します。スキップします。\")\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # モデルの名前を取得します\n",
        "                    model_name = model.__class__.__name__\n",
        "                    start_time = time.time()\n",
        "                    dric(\"+\"*100, f\"\\nモデル名: {model.__class__.__name__}\\n\", \"+\"*100)\n",
        "\n",
        "                    # モデルを訓練します\n",
        "                    nf = NeuralForecast(models=[model], freq=freq, local_scaler_type=local_scaler_type)\n",
        "                    nf.fit(df=Y_train_df)\n",
        "\n",
        "                    # 処理時間を計算します\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    elapsed_time_str = str(dt.timedelta(seconds=int(elapsed_time)))\n",
        "                    dric(f\"{model.__class__.__name__}の処理時間: {elapsed_time_str}\")\n",
        "                    # 宛先ディレクトリのパス\n",
        "                    dst_dir = f\"{dst_dir}/{select_loto}/model/{use_reshape_dataframe}/{target}/{horizon}/\"\n",
        "                    # ディレクトリが存在しない場合は作成\n",
        "                    if not os.path.exists(dst_dir):\n",
        "                        os.makedirs(dst_dir)\n",
        "                    # モデルを保存します\n",
        "                    path = f'{dst_dir}/{folder_name}/{model.__class__.__name__}_f{feature}_l{leng}_{bal}_t{elapsed_time_str}/'\n",
        "                    nf.save(path=dst_dir, model_index=None, overwrite=True, save_dataset=True)\n",
        "\n",
        "\n",
        "                    if Path(path).exists():\n",
        "                        # 保存されたモデルをロードします\n",
        "                        nf2 = NeuralForecast.load(path=path)\n",
        "                        # モデルを使って予測を行います\n",
        "                        prediction = nf2.predict().reset_index()\n",
        "                        prediction = prediction.iloc[:, 1].values.astype(int)\n",
        "                        dric(f'{path}のモデルによる予測: {prediction}')\n",
        "\n",
        "                        # モデルの名前、予測結果、処理時間をリストに追加します\n",
        "                        model_results.append({\n",
        "                            'model': model_name,\n",
        "                            'prediction': prediction,\n",
        "                            'elapsed_time': elapsed_time_str\n",
        "                        })\n",
        "\n",
        "                        # 関数の呼び出し\n",
        "                        copy_directories(src_dirs, dst_dir)\n",
        "                        pbar.update(1)\n",
        "\n",
        "                    # エラーリストをデータフレームに変換します\n",
        "                    error_df = pd.DataFrame(error_list)\n",
        "                    # モデルの結果をデータフレームに変換します\n",
        "                    df_model_results = pd.DataFrame(model_results)\n",
        "\n",
        "                    # データフレームを特定のディレクトリにCSVファイルとして保存します\n",
        "                    error_df.to_csv(f'{dst_dir}/{folder_name}/error_df.csv', index=False)\n",
        "                    df_model_results.to_csv(f'{dst_dir}/{folder_name}/results_df.csv', index=False)\n",
        "\n",
        "                    # gitに保存します\n",
        "                    git_save(git_username,git_repository,git_pass)\n",
        "                except Exception as e:\n",
        "                    # エラーが発生した場合は、エラーメッセージを保存します\n",
        "                    error_df = error_df.append({'model': model.__class__.__name__, 'error': str(e)}, ignore_index=True)\n",
        "                    dric(f\"モデル {model.__class__.__name__} の処理中にエラーが発生しました: {str(e)}\")\n",
        "                finally:\n",
        "                    # プログレスバーを更新します\n",
        "                    pbar.update(1)\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zULSMaCg2fb8"
      },
      "outputs": [],
      "source": [
        "#@title **EDA**\n",
        "\n",
        "bal=f\"{target}_{window}\"\n",
        "pdpf_report_path= f\"/content/drive/MyDrive/pdpf_{select_loto}_{bal}_f_{feature}_len_{leng}\"\n",
        "profile = ProfileReport(merged_str_df, title=f\"pdpf_{select_loto}_{bal}_f_{feature}_len_{leng}\")\n",
        "profile.to_file(f\"{pdpf_report_path}.html\")\n",
        "report =create_report(merged_df)\n",
        "dtp_report_path= f\"/content/drive/MyDrive/dtp_{select_loto}_{bal}_f_{feature}_len_{leng}\"\n",
        "report.save(dtp_report_path)\n",
        "git_save(git_username,git_repository,git_pass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpLvR3c2BsZX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH1twwtkBstP"
      },
      "outputs": [],
      "source": [
        "git_save(git_username,git_repository,git_pass)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1peeNSQYaPm7ZYWesWiHDWNHNTt4ITdHb",
      "authorship_tag": "ABX9TyMMvbIlVX+sVfx86U0PHqgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e817324ff0c4cdd8b0428953532722c": {
          "model_module": "jupyter-vue",
          "model_name": "HtmlModel",
          "model_module_version": "^1.11.1",
          "state": {
            "_dom_classes": [],
            "_events": [],
            "_jupyter_vue": "IPY_MODEL_ef883e9ab43743a9bae3ca996c56945a",
            "_model_module": "jupyter-vue",
            "_model_module_version": "^1.11.1",
            "_model_name": "HtmlModel",
            "_view_count": null,
            "_view_module": "jupyter-vue",
            "_view_module_version": "^1.11.1",
            "_view_name": "VueView",
            "attributes": {},
            "children": [
              "統計結果の保存データのロード"
            ],
            "class_": null,
            "layout": null,
            "slot": null,
            "style_": null,
            "tag": "h2",
            "v_model": "!!disabled!!",
            "v_on": null,
            "v_slots": []
          }
        },
        "6c7915c1fbed45689f279ebfd98ec936": {
          "model_module": "jupyter-vuetify",
          "model_name": "LayoutModel",
          "model_module_version": "^1.8.5",
          "state": {
            "_dom_classes": [],
            "_events": [],
            "_jupyter_vue": "IPY_MODEL_ef883e9ab43743a9bae3ca996c56945a",
            "_metadata": null,
            "_model_module": "jupyter-vuetify",
            "_model_module_version": "^1.8.5",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "jupyter-vuetify",
            "_view_module_version": "^1.8.5",
            "_view_name": "VuetifyView",
            "align_baseline": null,
            "align_center": null,
            "align_content_center": null,
            "align_content_end": null,
            "align_content_space_around": null,
            "align_content_space_between": null,
            "align_content_start": null,
            "align_end": null,
            "align_start": null,
            "attributes": {},
            "children": [
              "IPY_MODEL_d7a2a06b29364c84bb52b9ceda58386e",
              "IPY_MODEL_ba71d7a9fbc54fb48ac4621c169f9407"
            ],
            "class_": null,
            "column": null,
            "d_block": null,
            "d_contents": null,
            "d_flex": null,
            "d_grid": null,
            "d_inherit": null,
            "d_initial": null,
            "d_inline": null,
            "d_inline_block": null,
            "d_inline_flex": null,
            "d_inline_grid": null,
            "d_inline_table": null,
            "d_list_item": null,
            "d_none": null,
            "d_run_in": null,
            "d_table": null,
            "d_table_caption": null,
            "d_table_cell": null,
            "d_table_column": null,
            "d_table_column_group": null,
            "d_table_footer_group": null,
            "d_table_header_group": null,
            "d_table_row": null,
            "d_table_row_group": null,
            "fill_height": null,
            "id": null,
            "justify_center": null,
            "justify_end": null,
            "justify_space_around": null,
            "justify_space_between": null,
            "justify_start": null,
            "layout": null,
            "ma_0": null,
            "ma_1": null,
            "ma_2": null,
            "ma_3": null,
            "ma_4": null,
            "ma_5": null,
            "ma_auto": null,
            "mb_0": null,
            "mb_1": null,
            "mb_2": null,
            "mb_3": null,
            "mb_4": null,
            "mb_5": null,
            "mb_auto": null,
            "ml_0": null,
            "ml_1": null,
            "ml_2": null,
            "ml_3": null,
            "ml_4": null,
            "ml_5": null,
            "ml_auto": null,
            "mr_0": null,
            "mr_1": null,
            "mr_2": null,
            "mr_3": null,
            "mr_4": null,
            "mr_5": null,
            "mr_auto": null,
            "mt_0": null,
            "mt_1": null,
            "mt_2": null,
            "mt_3": null,
            "mt_4": null,
            "mt_5": null,
            "mt_auto": null,
            "mx_0": null,
            "mx_1": null,
            "mx_2": null,
            "mx_3": null,
            "mx_4": null,
            "mx_5": null,
            "mx_auto": null,
            "my_0": null,
            "my_1": null,
            "my_2": null,
            "my_3": null,
            "my_4": null,
            "my_5": null,
            "my_auto": null,
            "pa_0": null,
            "pa_1": null,
            "pa_2": null,
            "pa_3": null,
            "pa_4": null,
            "pa_5": null,
            "pa_auto": null,
            "pb_0": null,
            "pb_1": null,
            "pb_2": null,
            "pb_3": null,
            "pb_4": null,
            "pb_5": null,
            "pb_auto": null,
            "pl_0": null,
            "pl_1": null,
            "pl_2": null,
            "pl_3": null,
            "pl_4": null,
            "pl_5": null,
            "pl_auto": null,
            "pr_0": null,
            "pr_1": null,
            "pr_2": null,
            "pr_3": null,
            "pr_4": null,
            "pr_5": null,
            "pr_auto": null,
            "pt_0": null,
            "pt_1": null,
            "pt_2": null,
            "pt_3": null,
            "pt_4": null,
            "pt_5": null,
            "pt_auto": null,
            "px_0": null,
            "px_1": null,
            "px_2": null,
            "px_3": null,
            "px_4": null,
            "px_5": null,
            "px_auto": null,
            "py_0": null,
            "py_1": null,
            "py_2": null,
            "py_3": null,
            "py_4": null,
            "py_5": null,
            "py_auto": null,
            "reverse": null,
            "row": null,
            "slot": null,
            "style_": null,
            "tag": null,
            "v_model": "!!disabled!!",
            "v_on": null,
            "v_slots": [],
            "wrap": null
          }
        },
        "d7a2a06b29364c84bb52b9ceda58386e": {
          "model_module": "jupyter-vuetify",
          "model_name": "HtmlModel",
          "model_module_version": "^1.9.4",
          "state": {
            "_dom_classes": [],
            "_events": [],
            "_jupyter_vue": "IPY_MODEL_ef883e9ab43743a9bae3ca996c56945a",
            "_model_module": "jupyter-vuetify",
            "_model_module_version": "^1.9.4",
            "_model_name": "HtmlModel",
            "_view_count": null,
            "_view_module": "jupyter-vuetify",
            "_view_module_version": "^1.9.4",
            "_view_name": "VuetifyView",
            "attributes": {},
            "children": [
              "load"
            ],
            "class_": "d-inline-block",
            "layout": null,
            "slot": null,
            "style_": "font-size: 30px; vertical-align: middle;",
            "tag": "span",
            "v_model": "!!disabled!!",
            "v_on": null,
            "v_slots": []
          }
        },
        "ba71d7a9fbc54fb48ac4621c169f9407": {
          "model_module": "jupyter-vuetify",
          "model_name": "CheckboxModel",
          "model_module_version": "^1.8.5",
          "state": {
            "_dom_classes": [],
            "_events": [],
            "_jupyter_vue": "IPY_MODEL_ef883e9ab43743a9bae3ca996c56945a",
            "_metadata": null,
            "_model_module": "jupyter-vuetify",
            "_model_module_version": "^1.8.5",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "jupyter-vuetify",
            "_view_module_version": "^1.8.5",
            "_view_name": "VuetifyView",
            "append_icon": null,
            "attributes": {},
            "background_color": null,
            "children": [],
            "class_": "ma-2 d-inline-block",
            "color": "primary",
            "dark": null,
            "dense": null,
            "disabled": null,
            "error": null,
            "error_count": null,
            "error_messages": null,
            "false_value": null,
            "height": null,
            "hide_details": null,
            "hint": null,
            "id": null,
            "indeterminate": null,
            "indeterminate_icon": null,
            "input_value": null,
            "label": null,
            "layout": null,
            "light": null,
            "loading": null,
            "messages": null,
            "multiple": null,
            "off_icon": null,
            "on_icon": null,
            "persistent_hint": null,
            "prepend_icon": null,
            "readonly": null,
            "ripple": null,
            "rules": null,
            "slot": null,
            "style_": "width: 60px; height: 60px; font-size: 400px; font-family: Arial, sans-serif; vertical-align: middle;",
            "success": null,
            "success_messages": null,
            "true_value": null,
            "v_model": false,
            "v_on": null,
            "v_slots": [],
            "validate_on_blur": null,
            "value": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}