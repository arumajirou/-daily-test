{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumajirou/-daily-test/blob/main/01_forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFpx-zUOrc7T"
      },
      "source": [
        "**セットアップの説明**：このノートブックは、sktimeでサポートされている予測学習タスクのチュートリアルを提供します。バインダー上では、すぐに実行できるはずです。\n",
        "\n",
        "このノートブックを意図したとおりに実行するには、基本的な依存関係の要件を備えたsktimeがあなたのpython環境にインストールされていることを確認してください。\n",
        "\n",
        "このノートブックをローカル開発版のsktimeで実行するには、編集可能な開発者用インストールを推奨します。手順については、sktime開発者用インストールガイドを参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoUSjTvGrc7Z"
      },
      "source": [
        "# **sktime予測**\n",
        "予測では、過去のデータを使って、時系列の時間的な前方予測を行います。これは、scikit-learnや同様のライブラリでサポートされている表形式の予測タスクとは顕著に異なるものです。\n",
        "\n",
        "<img src=\"https://github.com/arumajirou/sktime/blob/main/examples/img/forecasting.png?raw=1\" width=750 />\n",
        "\n",
        "sktimeは、様々な古典的およびMLスタイルの予測アルゴリズムに、scikit-learnのような共通のインターフェースを提供し、パイプラインや複合 機械学習モデルを構築するツールとともに、時間チューニングスキームや、scikit-learn回帰因子のウォークフォワード適用といった削減を含む。\n",
        "\n",
        "セクション1では、sktimeがサポートする一般的な予測 工程の概要を説明します。\n",
        "\n",
        "セクション 2では、sktime で利用可能な予測器のファミリーについて説明する。\n",
        "\n",
        "セクション3では、パイプラインの構築、削減、チューニング、アンサンブル、およびautoMLを含む高度な構成パターンを説明します。\n",
        "\n",
        "セクション4では、sktimeインターフェースに準拠した カスタムエスティメータの書き方について紹介する。\n",
        "\n",
        "さらに参考文献があります。* 科学的な参考文献としては、sktimeの 予測モジュールについてより詳しく説明し、それを使ってM4の研究を再現・拡張している、sktimeによる予測に関する論文を ご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- この文章は、さまざまな種類の数学を使って未来予測をすることを支援するsktimeというライブラリについて述べています。\n",
        "\n",
        "- sktimeを使うと、古典的な機械学習や最新の機械学習で使われているような、さまざまな予測方法を簡単に使うことができる。\n",
        "- このライブラリには、予測モデルの構築と利用を支援するツールや、時間がデータに与える影響を考慮した予測を行うためのツールが用意されています。\n",
        "- テキストは4つのセクションに分かれています。\n",
        "\n",
        "- 最初のセクションでは、sktimeを使用して予測を行うためのさまざまな方法について概要を説明します。\n",
        "\n",
        "- 第2章では、sktimeで利用可能なさまざまなタイプの予測方法について説明します。\n",
        "\n",
        "- 第3章では、複数のステップで予測モデルを構築したり、予測を微調整するなど、より高度なsktimeの使用方法について説明する。\n",
        "\n",
        "- 第4章では、sktimeで動作する独自の予測方法を作成する方法について説明します。\n",
        "\n",
        "- 注意すべき追加情報\n",
        "\n",
        "- 予測は、機械学習の一手法である教師あり学習とは異なるものである。\n",
        "- 予測では、過去のデータに基づいて将来の出来事を予測することが目標であり、教師あり学習では、入力に基づいて出力を予測することが目標である。\n",
        "- このライブラリには科学的な参考文献があり、開発者はこのライブラリについてより詳しく論じた論文を発表している。\n",
        "\n",
        "- 簡単に言うと、sktimeは、様々な種類の数学とそれを簡単に使えるようにするツールを使って、人々が未来について予測するのを助けるライブラリである。\n",
        "- さまざまな種類の予測方法、高度な使い方、そしてライブラリと連動するカスタムメソッドを作成することも可能です。"
      ],
      "metadata": {
        "id": "HLT0-E4iLzck"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n14uoZ6rc7b"
      },
      "source": [
        "###1.基本的な予測工程\n",
        "\n",
        " - 1.1 データコンテナ形式\n",
        "\n",
        " - 1.2 基本的な展開の工程 - バッチ学習と予測\n",
        "\n",
        " - 1.2.1 基本的なデプロイの工程を簡単に説明する\n",
        "\n",
        " - 1.2.2 水平線が必要な予測器は ``fit`<#section_1_2>`__にすでにある\n",
        "\n",
        " - 1.2.3 異種データを活用できる予測器\n",
        "\n",
        " - 1.2.4 多変量解析予測器\n",
        "\n",
        " - 1.2.5 予測区間と分位値予測\n",
        "\n",
        " - 1.2.6 パネル予測、階層的予測\n",
        "\n",
        "- 1.3 基本的な評価工程 - グラウンドトゥルース観測に対する予測バッチの評価\n",
        "\n",
        " - 1.3.1 基本的なバッチ予測評価工程の概要 - 機能メトリック・インターフェース\n",
        "\n",
        " - 1.3.2 基本的なバッチ予測評価工程の概要 - メトリッククラスインターフェイス\n",
        "\n",
        "- 1.4 高度な展開工程：ローリングアップデートとフォーキャスト\n",
        "\n",
        " - 1.4.1 updateメソッドによる予測器の更新\n",
        "\n",
        " - 1.4.2 モデルを更新せずに「今」状態を移動させる\n",
        "\n",
        " - 1.4.3 バッチデータに対するウォークフォワード予測\n",
        "\n",
        "- 1.5 高度な評価工程：ローリングリサンプリングと集計誤差、ローリングバックテスティング\n",
        "\n",
        "### 2.sktimeの予測器 - 検索、タグ、共通ファミリー\n",
        "\n",
        "- 2.1 予測器検索 - レジストリ\n",
        "\n",
        "- 2.2 予測器・タグ\n",
        "\n",
        " - 2.2.1 能力タグ：多変量、確率的、階層的\n",
        "\n",
        " - 2.2.2 タグによる予報士の検索とリストアップ\n",
        "\n",
        " - 2.2.3 すべての予測器・タグのリストアップ\n",
        "\n",
        "- 2.3 一般的な予測器のタイプ\n",
        "\n",
        " - 2.3.1 指数平滑化、シータ予測器、statsmodelsからの自動ETS\n",
        "\n",
        " - 2.3.2 ARIMAとautoARIMA\n",
        "\n",
        " - 2.3.3 BATSとTBATS\n",
        "\n",
        " - 2.3.4 Facebookのプロフェット\n",
        "\n",
        " - 2.3.5 状態空間モデル(構造的時系列)\n",
        "\n",
        " - 2.3.6 StatsForecastからのAutoArima\n",
        "\n",
        "### 3.高度な構成パターン - パイプライン、リダクション、autoML など\n",
        "\n",
        "- 3.1 縮小：予測から回帰へ\n",
        "\n",
        "- 3.2 パイプ化、デトレンド、脱季節化\n",
        "\n",
        " - 3.2.1 基本的な予測パイプライン\n",
        "\n",
        " - 3.2.2 パイプラインの構成要素としてのデトレンダー\n",
        "\n",
        " - 3.2.3 複雑なパイプラインの複合材料とパラメータ検査\n",
        "\n",
        "- 3.3 パラメータチューニング\n",
        "\n",
        " - 3.3.1 ForecastingGridSearchCV を用いた基本的なチューニング\n",
        "\n",
        " - 3.3.2 複雑な複合材料のチューニング\n",
        "\n",
        " - 3.3.3 メトリクスの選択とスコアの取得\n",
        "\n",
        "- 3.4 autoML 別名：自動モデル選択、アンサンブル、ヘッジング\n",
        "\n",
        " - 3.4.1 autoML チューニング＋マルチプレクサによる自動モデル選択機能\n",
        "\n",
        " - 3.4.2 autoML: OptimalPassthroughによるトランスフォーマーの組み合わせの選択\n",
        "\n",
        " - 3.4.3 シンプルなアンサンブル戦略\n",
        "\n",
        " - 3.4.4 予測重み付きアンサンブルとヘッジアンサンブル\n",
        "\n",
        "### 4.拡張ガイド - 独自の予測器を実装する\n",
        "\n",
        "### 5.概要"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yqmxHcNVnm1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- AutoMLチューニングとマルチプレクサは、どちらも機械学習やコンピュータサイエンスの分野で使われているツールです。\n",
        "\n",
        "#### 類似している。\n",
        "\n",
        "- AutoMLチューニングとmultiplexerは、どちらも機械学習モデルの性能を向上させるために使用されます。\n",
        "- どちらも、機械学習プロセスにおける特定のタスクを自動化するために使用することができます。\n",
        "\n",
        "#### 相違点\n",
        "\n",
        "- AutoMLチューニングは、最適なパラメータセットを見つけるなど、機械学習モデルの設定を最適化するために使用されます。\n",
        "- Multiplexerは、複数のモデルや入力を1つにまとめるために使用される。\n",
        " - 例えば、異なるアルゴリズムを使って予測を行い、最適なものを選択するような場合である。\n",
        "\n",
        "### メリット\n",
        "\n",
        "- AutoMLチューニングは、最適なモデル設定を見つけるプロセスを自動化することで、時間とリソースを節約することができます。\n",
        "- Multiplexerは、複数のモデルや入力の長所を組み合わせることで、モデルの性能を向上させることができます。\n",
        "\n",
        "#### デメリット\n",
        "\n",
        "- AutoML チューニングは計算コストが高く、常に最適な設定が見つかるとは限りません。\n",
        "- Multiplexerは実装が複雑であり、必ずしも性能が向上するとは限らない。\n",
        "\n",
        "#### 起源\n",
        "\n",
        "- AutoMLチューニングは数年前から存在し、機械学習の分野で活発に研究されている分野である。\n",
        "- Multiplexerも比較的新しい概念ですが、機械学習の分野で人気を博しています。\n",
        "意味するところです。\n",
        "\n",
        "- AutoMLチューニングとは、モデルのハイパーパラメータのチューニングを自動化することである。\n",
        "- Multiplexerとは、複数のモデルや入力を組み合わせて性能を向上させることである。\n",
        "\n",
        "#### 関係性\n",
        "\n",
        "- AutoMLチューニングとMultiplexerは、機械学習モデルの性能を向上させるために一緒に使用することができます。\n",
        "\n",
        "#### 例\n",
        "\n",
        "- AutoMLのチューニング。グリッドサーチ、ランダムサーチ、ベイズ最適化\n",
        "- Multiplexer。アンサンブル手法、スタッキング、ブレンディング\n",
        "\n",
        "- AutoMLチューニングとマルチプレクサは、機械学習モデルの性能を向上させるためのツールであり、時間とリソースを節約できますが、実装が複雑で、必ずしも最良の結果につながるとは限りません。"
      ],
      "metadata": {
        "id": "O62WEOOQ7iff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"スーパーヒーロー・スイッチャー 機械学習におけるマルチプレクサの理解\"\n",
        "\n",
        "マルチプレクサは、「mux」とも呼ばれ、スーパーヒーローのスイッチャーのようなものです。\n",
        "スーパーヒーローが異なるコスチュームに着替えて異なる能力を発揮するように、マルチプレクサは異なる入力を切り替えて1つの特定の信号を出力することができるのです。\n",
        "機械学習の文脈では、マルチプレクサは、異なるアルゴリズムやモデルを切り替えて、特定のタスクの最適解を見つけるために使用されます。\n",
        "例えば、犯罪を解決しようとするスーパーヒーローの探偵団を想像してください。それぞれの刑事はユニークな超能力を持っていますが、チームリーダー（マルチプレクサ）は、持っている手がかりをもとに、どの刑事をミッションに送り込むかを決定しなければなりません。\n",
        "同様に、機械学習においても、マルチプレクサは異なるアルゴリズムを切り替えて、与えられたデータに対して最適なものを見つけることができます。\n",
        "マルチプレクサはシステムの「頭脳」として機能し、入力データに基づいてどのアルゴリズムやモデルを使用するかを決定します。\n",
        "要約：マルチプレクサは、機械学習において、異なる入力を切り替えて、どのアルゴリズムやモデルを使用するかを決定するのに役立つ、スーパーヒーローのスイッチャーのようなものである。"
      ],
      "metadata": {
        "id": "s8cA6m6Xosw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"マルチプレクサ \"とは、ラテン語で「多くの」を意味する \"multiplex \"と「編んだ」を意味する \"plexus \"を語源とする言葉である。マルチプレクサは、複数の入力を受け取り、1つの出力で送る装置です。\n",
        "\n",
        "要約すると\n",
        "- マルチプレクサは、ラテン語で「多数」を意味する「multiplex」と「編んだ」を意味する「plexus」からなる単語です。\n",
        "- マルチプレクサ装置は、多くの入力を取り、1つの出力で送る。\n"
      ],
      "metadata": {
        "id": "9oiaqIYMqFaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"スイッチウィザード マルチプレクサを理解する\"\n",
        "\n",
        "マルチプレクサは、「mux」とも呼ばれ、異なる入力を切り替えて1つの出力に送ることができる魔法使いのようなものです。\n",
        "\n",
        "多くの生徒を異なるクラスで受け持っている先生を想像してください。それぞれのクラスは入力のようなもので、教師は出力のようなものです。マルチプレクサが入力の切り替えをするように、教師はクラスの切り替えができるのです。\n",
        "もう一つの例は、テレビのリモコンです。マルチプレクサが入力の切り替えを行うように、リモコンは異なるチャンネルを切り替えることができます。\n",
        "コンピュータでは、マルチプレクサは異なるメモリ位置や異なるデータ入力間を切り替えるために使用することができます。\n",
        "利点\n",
        "\n",
        "マルチプレクサは、複数の入力を1つの出力に統合することで、スペースとリソースを節約することができます。\n",
        "また、入力間の切り替えを高速化することで、効率を高めることができる。\n",
        "デメリット\n",
        "\n",
        "入力が多すぎる場合、入力間の切り替えを迅速に行うことが困難な場合がある。\n",
        "まとめ：マルチプレクサは、異なる入力を切り替えて1つの出力に送ることができる魔法使いのようなものです。先生が授業を切り替えたり、リモコンでチャンネルを切り替えたりするのに使え、省スペースで効率を上げることができます。しかし、入力の数が多すぎると、素早く切り替えることが難しくなります。"
      ],
      "metadata": {
        "id": "B4_zm7ApoWMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"機械学習の微調整。マルチプレクサ、AutoML、最適パラメータへの子供向けガイド\"\n",
        "\n",
        "- マルチプレクサ、AutoMLのチューニング、最適なパラメータセット。\n",
        "\n",
        "#### マルチプレクサ。\n",
        "- マルチプレクサは、異なるアーティストの異なる楽曲を組み合わせて新しいユニークなトラックを作るDJのようなものだと考えてください。\n",
        "- 同様に、機械学習におけるマルチプレクサーは、異なるモデルの予測を取り、それらを組み合わせて最終的な予測を行う。\n",
        "\n",
        "#### AutoMLチューニング。\n",
        "- AutoMLチューニングは、機械学習モデルのパーソナルトレーナーだと考えてください。\n",
        "- パーソナルトレーナーが最適なエクササイズやウェイトを見つける手助けをするように、AutoMLチューニングはモデルが最適な設定（「パラメーター」と呼ばれます）を見つける手助けをします。\n",
        "\n",
        "#### 最適なパラメータセット \n",
        "- 最適なパラメータセットとは、特別な日のための完璧な衣装のようなものだと考えてください。\n",
        "- パーティーでベストな格好をしたいように、機械学習モデルも適切なパラメータで最高のパフォーマンスを発揮したいものです。\n",
        "\n",
        "### 類似点。\n",
        "- これらの手法はすべて、設定（または「パラメータ」）のさまざまな組み合わせを試して、モデルに最適なものを見つけるというものです。\n",
        "\n",
        "### 相違点 \n",
        "- マルチプレクサは異なるモデルの予測を組み合わせるが、AutoMLチューニングと最適なパラメータセットは、単一のモデルに対して最適な設定を見つけることに焦点を当てる。\n",
        "\n",
        "#### 利点\n",
        "-  マルチプレクサ、AutoMLチューニング、最適なパラメータセットを使用することで、機械学習モデルの性能を向上させることができます。\n",
        "\n",
        "#### デメリット \n",
        "- これらの手法は計算コストが高く、必ずしも性能が大幅に向上するとは限りません。\n",
        "\n",
        "#### 起源\n",
        "-  これらの手法は、機械学習と統計学の分野に由来しています。\n",
        "\n",
        "#### 意味\n",
        "-  機械学習モデルの性能を向上させるために、様々な設定の組み合わせを試し、異なるモデルの予測値を組み合わせる手法です。\n",
        "\n",
        "#### 関係性\n",
        "-  マルチプレクサ、AutoMLチューニング、最適なパラメータセットはすべて、機械学習モデルの性能を向上させるために一緒に使うことができるテクニックである。"
      ],
      "metadata": {
        "id": "Re-xwO5J-a_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoMLチューニングとマルチプレクサ手法は、機械学習モデルの性能を向上させるために用いることができる2つの異なる手法である。\n",
        "\n",
        "AutoMLチューニングは、機械学習モデルに最適なハイパーパラメータを選択するプロセスを自動化する技術です。探索アルゴリズムと機械学習を組み合わせて、与えられたデータセットとモデルに対して最適なハイパーパラメータのセットを見つけます。\n",
        "\n",
        "マルチプレクサ方式は、複数の機械学習モデルを組み合わせて予測を行う方法である。これは、データの異なるサブセットで複数のモデルを学習させるか、特徴の異なる組み合わせで異なるモデルを学習させることで行うことができます。\n",
        "\n",
        "AutoMLチューニングとマルチプレクサーの両方の手法を使うべきかどうかは、解決しようとしている特定の問題と、利用できるリソースに依存します。どちらの手法にも、それぞれ長所と短所があります。AutoMLチューニングは、与えられたモデルに最適なハイパーパラメータのセットを見つけるのに非常に効果的ですが、計算コストが高く、時間がかかる場合があります。Multiplexer法は、複数のモデルを組み合わせることによってモデルの性能を向上させることができますが、複雑で、効果的であるためには多くのデータを必要とすることもあります。\n",
        "\n",
        "要約\n",
        "-AutoMLチューニングは、機械学習モデルの最適なハイパーパラメータを選択するプロセスを自動化する技術である。\n",
        "-マルチプレクサ手法は、複数の機械学習モデルを組み合わせて予測を行う方法である。\n",
        "-AutoMLチューニングとマルチプレクサメソッドの両方を使うべきかどうかは、解決しようとしている特定の問題と、利用可能なリソースに依存します。"
      ],
      "metadata": {
        "id": "-JCn9POJroCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習の文脈における「マルチプレクサ」とは、複数のモデルをデータの異なるサブセットや特徴の異なる組み合わせで学習させる手法を指す。この手法は、モデルの「アンサンブル」を作成することで、機械学習システムの全体的な性能を向上させるために用いられる。\n",
        "\n",
        "マルチプレクサーの一例として「ブースティング」があり、一連の弱いモデルを組み合わせてより強いモデルを作成する。また、複数のモデルを異なるデータのサブセットで学習させ、その予測値を組み合わせる「バギング」もその一例である。\n",
        "\n",
        "一方、AutoMLチューニングは、機械学習モデルのパラメータを微調整するプロセスを自動化する手法である。グリッドサーチやランダムサーチなどの手法を用いて、与えられたモデルに対して最適なパラメータセットを見つけることができます。\n",
        "\n",
        "マルチプレクサ方式とAutoMLのチューニング方式には、それぞれ長所と短所があります。Multiplexer法は、機械学習システムの性能向上に役立ちますが、システムの複雑性を高める可能性もあります。AutoMLチューニングは、時間と労力を節約することができますが、常に最適なパラメータセットを見つけることができるわけではありません。\n",
        "\n",
        "結論として、両方の方法を使うか、どちらか一方だけを使うかは、解決しようとしている特定の問題と、利用可能なリソースに依存します。異なるアプローチを試し、その結果を比較することで、あなたの問題に最適な解決策を見出す価値があります。"
      ],
      "metadata": {
        "id": "4k6Tnt6mr_oA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"ビッグデータバランスアクト。Apache Spark、Hadoop、Daskが情報を維持する方法\"\n",
        "\n",
        "Apache Sparkは、大きなデータセットを「RDD（resilient distributed dataset）」と呼ばれる小さな塊に分割し、複数のマシンで同時に処理することで、分散データ処理と機械学習を可能にするものです。パズルを組み立てるように、大きな作業を分担して行う作業員のようなものだと考えてください。\n",
        "Hadoopも同様ですが、より分散型データストレージに重点を置いています。Hadoopは、大きなデータセットを複数のマシンに分散して保存し、並行して処理することができます。Hadoopは、大きな袋に入ったお菓子を友達同士で分けて食べるようなものだと考えてください。\n",
        "Daskは、SparkやHadoopと似たような原理で動作するライブラリですが、より柔軟で、より小さなデータセットでも動作することができます。パズルのピースが欠けているようなもので、Daskは欠けているピースを探して組み立てるのを助けてくれます。\n",
        "メリットは？\n",
        "\n",
        "これら3つのテクノロジーは、ワークロードを分散させることで、大規模なデータセットの処理と分析を高速化することを可能にします。\n",
        "また、フォールトトレランスも向上します。つまり、あるマシンがダウンしても、他のマシンでデータや処理を継続することができます。\n",
        "また、スケーラビリティも向上します。つまり、データセットが大きくなるにつれて、より多くのマシンを追加して作業負荷の増加に対応できるようになります。\n",
        "デメリット\n",
        "\n",
        "これらの技術は、セットアップやメンテナンスが複雑で、専門的な知識やリソースを必要とする場合があります。\n",
        "また、運用に必要なマシンや電気代など、コストが高くなる。\n",
        "また、適切な設定や保守を行わないと、データが消失する危険性もあります。\n",
        "結論として、Apache Spark、Hadoop、Daskは、大規模なデータセットを効率的かつ耐障害性高く処理できる強力な技術ですが、有効に活用するためには、専門的な知識やリソース、メンテナンスも必要です。"
      ],
      "metadata": {
        "id": "h7gZZTSLuSom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "フォールトトレランス（Fault tolerance）とは、工学の分野に由来し、ハードウェアやソフトウェアに障害が発生しても、システムが正常に機能し続ける能力を意味する言葉です。フォールトトレランスの目標は、故障やエラーが発生しても、システムが意図したサービスを提供し続けることができるようにすることです。耐故障性の概念は、航空機、発電所、医療機器など、故障が重大な影響を及ぼす可能性のあるシステムにおいて重要である。機械学習においては、特定のコンポーネントやデータポイントが故障したり利用できなくなったりしても、システムが学習を継続し、予測を行う能力を意味する。"
      ],
      "metadata": {
        "id": "5_DTT_OMufYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoMLのチューニング手法を用いた機械学習ライブラリやサービスがいくつか存在する。いくつかの例を挙げます。\n",
        "\n",
        "Google AutoML: これはGoogle Cloudが提供する機械学習サービス群で、AutoML Vision、AutoML Natural Language、AutoML Translation、AutoML Tablesが含まれる。これらのサービスにより、ユーザーは必要最低限の機械学習の専門知識でモデルを学習することができます。\n",
        "\n",
        "H2O.ai: H2O.aiは、Driverless AIと呼ばれるAutoMLプラットフォームを提供しており、特徴量エンジニアリング、アルゴリズム選択、モデルチューニングを自動化することができます。また、ユーザーがモデルを理解するためのインタプリタビリティ機能も提供する。\n",
        "\n",
        "DataRobot DataRobot社のAutoMLプラットフォームは、フィーチャーエンジニアリング、モデル選択、モデルチューニングの自動化などの機能を備えています。また、特定のタスクに合わせて微調整が可能な事前学習済みモデルのライブラリも提供されています。\n",
        "\n",
        "RapidMiner RapidMinerのAutoMLプラットフォームはRapidMiner Studioと名付けられ、データ準備、特徴選択、アルゴリズム選択、モデルチューニングのタスクを含むモデル構築と展開のプロセスを自動化します。\n",
        "\n",
        "これらは、利用可能な多くのAutoMLチューニングライブラリとサービスのほんの一例に過ぎません。どれを使うかは、特定のユースケースとユーザーの要件に依存します。"
      ],
      "metadata": {
        "id": "M7dZIx5Jt-YG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"フォールト・プルーフ学習 機械学習を軌道に乗せる\"\n",
        "\n",
        "耐障害性の向上とは、機械学習モデルが予期せぬ、あるいは異常な入力や状況に直面した場合でも、正しく機能し続けるために用いられる技術や戦略のことである。\n",
        "その一例が、複数のモデルやアンサンブル手法の使用である。アンサンブル手法とは、複数のモデルの予測を組み合わせて、より正確な全体予測を行う手法である。\n",
        "また、個々のノードの故障に対してモデルをより堅牢にするために、学習中にランダムにノードを脱落させるドロップアウトなどの手法を用いることも一例である。\n",
        "フォールトトレランスを向上させる利点としては、モデルの信頼性と精度の向上、実世界のシナリオにおける性能の向上、モデルの予測に対する信頼性の向上などが挙げられます。\n",
        "デメリットとしては、複雑さと計算コストの増大が考えられます。\n",
        "金融、自動運転車、医療など、小さなミスが大きな影響を与える業界で一般的。\n",
        "日常的な例 医師が病気を診断する場合、複数の医師が診断して同じ結論を出せば、それが正しい可能性が高くなる。"
      ],
      "metadata": {
        "id": "GtlMmFqDt23s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサ方式を利用した機械学習ライブラリやサービスはいくつかある。いくつかの例を挙げる。\n",
        "\n",
        "scikit-learn - SelectKBest や SelectFromModel などの特徴選択用のマルチプレクサメソッドを含む機械学習用の有名な Python ライブラリ。\n",
        "\n",
        "caret - R のパッケージで、Recursive Feature Elimination (RFE) や Boruta アルゴリズムなどの特徴選択とモデル選択のためのマルチプレクサメソッドが含まれています。\n",
        "\n",
        "Auto-Sklearn - Python 用の自動機械学習ライブラリ。モデルやハイパーパラメータの選択を最適化するためにマルチプレクサメソッドを使用する。\n",
        "\n",
        "TPOT - Python 用の自動機械学習ライブラリ。モデルとハイパーパラメータの選択を最適化するために遺伝的アルゴリズムを使用します。\n",
        "\n",
        "H2O - 分散型インメモリ機械学習のためのプラットフォームで、特徴選択とモデル選択のためのマルチプレクサ・メソッドを備えています。\n",
        "\n",
        "一般に、マルチプレクサメソッドは、特徴選択とモデル選択の機能を提供する機械学習ライブラリやサービスに含まれています。"
      ],
      "metadata": {
        "id": "EGhWpRD4sWM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"ミックスアンドマッチ機械学習。多重化、アンサンブル法、スタッキング、ブレンディングの子供向けガイド\"\n",
        "\n",
        "##### マルチプレキシング、アンサンブル法、スタッキング、ブレンディング\n",
        "\n",
        "#### マルチプレキシング。\n",
        "- 多重録音は料理のレシピのようなものだと考えてください。\n",
        "- レシピが異なる材料を組み合わせて料理を作るように、多重化も異なるモデルの予測を組み合わせて最終的な予測を行います。\n",
        "\n",
        "#### アンサンブル手法。\n",
        "- アンサンブル法をバンドのように考えてみてください。\n",
        "- バンドが異なるミュージシャンで異なる楽器を演奏するように、アンサンブル法では異なるモデルが異なる予測を行い、それらの予測を組み合わせて最終的な予測を行う。\n",
        "\n",
        "#### 積み重ね。\n",
        "- 積み木で塔を作るように、積み重ねを考えてください。\n",
        "- ブロックを積み上げて塔を作るように、スタッキングでは、複数のモデルの予測を別のモデルへの入力として使用し、最終的な予測を行うのです。\n",
        "\n",
        "#### ブレンド。\n",
        "- ブレンドは、絵の具を混ぜるようなものだと考えてください。\n",
        "- 異なる色の絵の具を混ぜて新しい色を作るように、ブレンドでは、データの異なるサブセットで異なるモデルを学習させ、それらの予測を組み合わせて最終的な予測を行うのです。\n",
        "\n",
        "#### 類似点\n",
        "-  これらの手法はすべて、最終的な予測を行うために複数のモデルを使用します。\n",
        "\n",
        "##### 相違点\n",
        "-  マルチプレキシングとアンサンブルでは、異なるモデルの予測を組み合わせますが、  \n",
        "- スタッキングとブレンディングでは、複数のモデルの予測を別のモデルへの入力として使用します。\n",
        "\n",
        "#### 利点\n",
        "-  マルチプレキシング、アンサンブル法、スタッキング、ブレンディングを使用すると、機械学習モデルのパフォーマンスを向上させることができます。\n",
        "\n",
        "#### デメリット\n",
        "-  これらの手法は計算コストが高く、必ずしも性能が大幅に向上するとは限りません。\n",
        "\n",
        "#### 起源\n",
        "-  これらの手法は、機械学習と統計学の分野に由来しています。\n",
        "\n",
        "#### 意味\n",
        "-  複数のモデルの予測を組み合わせることで、機械学習モデルの性能を向上させるための技術です。\n",
        "\n",
        "#### 関係性\n",
        "-  複数のモデルを用いて最終的な予測を行うという点で関連性があるが、それらのモデルをどのように組み合わせるかが異なる。"
      ],
      "metadata": {
        "id": "eMGUUqIO-S0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AutoMLのチューニング方法。素人のためのガイド\n",
        "\n",
        "#### グリッドサーチ。\n",
        "- この方法では、モデルを学習させるべき各ハイパーパラメータの値のセットを指定し、次にそれらの値の可能な限りの組み合わせでモデルを学習させます。\n",
        "- この方法はシンプルで実装が簡単ですが、可能な組み合わせの数が多い場合、非常に計算量が多くなります。\n",
        "\n",
        "#### ランダムサーチ。\n",
        "- この方法では、すべての組み合わせを試すのではなく、可能なハイパーパラメータ値の空間からランダムにサンプリングします。\n",
        "- グリッドサーチよりも効率的ですが、ハイパーパラメータ値の最適な組み合わせが見つからない可能性があります。\n",
        "\n",
        "#### ベイズ的最適化。\n",
        "- この方法では、ハイパーパラメータ値をモデルの性能に対応付ける関数をモデルで近似し、この近似値を用いて最適なハイパーパラメータ値の探索をガイドします。\n",
        "- この方法はグリッドサーチやランダムサーチよりも効率的ですが、実装が難しくなる可能性があります。\n",
        "\n",
        "#### マルチプレクサ、アンサンブル法、スタッキング、ブレンディング\n",
        "\n",
        "#### Multiplexer：\n",
        "- マルチプレクサ。この方法は、複数のモデルの予測を組み合わせて、最終的な予測を行います。\n",
        "- 予測値の単純平均をとるか、より複雑な組み合わせルールを用いることで実現します。\n",
        "\n",
        "#### アンサンブル手法。\n",
        "- この方法では、複数のモデルを学習させ、それらの予測値を組み合わせて最終的な予測値を作成します。\n",
        "- これは、予測値の単純な平均をとるか、より複雑な組み合わせルールを使用することによって行われます。\n",
        "\n",
        "#### スタッキング。\n",
        "- 複数のモデルを学習させ、それらのモデルの予測値を別のモデルの入力として使用し、最終的な予測を行う方法です。\n",
        "\n",
        "#### ブレンド。\n",
        "- この方法はスタッキングと似ていますが、データの異なるサブセットで複数のモデルを学習させ、それらのモデルの予測値を別のモデルの入力として使用し、最終的な予測を行います。\n",
        "\n",
        "#### メリットとデメリット\n",
        "\n",
        "- グリッドサーチとランダムサーチは実装が簡単ですが、特に大規模なデータセットの場合、計算コストが高くなることがあります。\n",
        "\n",
        "- ベイズ最適化はグリッドサーチやランダムサーチよりも効率的ですが、実装が難しくなる可能性があります。\n",
        "\n",
        "- アンサンブル法は、性能の向上につながりますが、計算コストがかかる場合があります。\n",
        "\n",
        "- スタッキングやブレンディングは、アンサンブル手法よりも効率的ですが、実装が困難な場合もあります。\n",
        "\n",
        "#### 起源、意味、およびそれらの間の関係。\n",
        "\n",
        "- グリッドサーチ、ランダムサーチ、ベイズ最適化、マルチプレクサ、アンサンブル法、スタッキング、ブレンディングは、いずれも機械学習モデルの性能を向上させるために用いられる手法である。\n",
        "\n",
        "- これらの手法の起源は、統計学や機械学習の分野までさかのぼることができる。\n",
        "\n",
        "- これらの手法は、複数のモデルを用いて最終的な予測を行うという点で関連しているが、それらのモデルをどのように組み合わせるかが異なる。\n",
        "\n",
        "- これらの手法の目的は、複数のモデルの予測を組み合わせることで、機械学習モデルの性能を向上させることである。\n",
        "\n",
        "- グリッドサーチはブロックごとに家を建てるようなもので、ブロックのあらゆる組み合わせを試す。\n",
        "- ランダムサーチはランダムにブロックを選び、それがフィットするかどうかで家を建てるようなもので、\n",
        "- ベイズ最適化は設計図を使って家を建てるようなもので、\n",
        "- マルチプレクサ、アンサンブル手法、積層、ブレンドは複数の建築家を使うか異なる材料を重ねるなど異なる技術で家を建てるようなものだ。"
      ],
      "metadata": {
        "id": "EwkjcnFw9PAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"ミキシングモデル \"のマジック。アンサンブル法、スタッキング、ブレンディング\"\n",
        "\n",
        "アンサンブル法、スタッキング、ブレンディングは、いずれも機械学習モデルの性能を向上させる方法である。これらは、複数のモデルの予測を組み合わせて、最終的な予測を行うことで機能します。\n",
        "\n",
        "アンサンブル法。複数のモデルを同じデータセットで学習させ、その予測値を組み合わせる方法。まるで、複数の人が協力して問題を解決するようなイメージです。\n",
        "\n",
        "スタッキング。複数のモデルをデータの異なるサブセットで学習させ、その予測値を組み合わせる方法です。これは、異なるブロックで塔を作るようなもので、各ブロックは異なるモデルを表します。\n",
        "\n",
        "ブレンド。複数のモデルを異なる特徴の組み合わせで学習させ、その予測を組み合わせることです。異なる色の絵の具を混ぜて新しい色を作るようなものです。\n",
        "\n",
        "メリット\n",
        "\n",
        "アンサンブル手法は、性能の向上とオーバーフィッティングの低減につながります。\n",
        "スタッキングは、互いに補完し合うモデルを組み合わせることで、性能の向上につながる。\n",
        "ブレンドは、異なるタスクを得意とするモデルを組み合わせることで、パフォーマンスを向上させることができる。\n",
        "デメリット\n",
        "\n",
        "アンサンブル手法は計算コストがかかる。\n",
        "スタッキングは実装が複雑である。\n",
        "ブレンドは解釈が難しい場合がある。\n",
        "例\n",
        "\n",
        "ランダムフォレストは、複数の決定木を使用するアンサンブル手法である。\n",
        "XGBoost：複数のグラディエントブースティングモデルを使用するアンサンブルメソッド。\n",
        "StackingRegressor: 回帰問題でモデルを積み重ねるための scikit-learn ライブラリ。\n",
        "BlendingClassifier は、分類問題でモデルをブレンドするための scikit-learn ライブラリです。\n",
        "結論として、アンサンブル法、スタッキング、ブレンディングは、複数のモデルの予測を組み合わせることによって、機械学習モデルの性能を向上させることができる強力な技術である。これらは機械学習の魔法の杖のようなもので、異なるモデルを混ぜることで予測や結果を改善することができるのです。"
      ],
      "metadata": {
        "id": "vD1gaPgywwOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "アンサンブル手法の実装を説明します。\n",
        "\n",
        "\"The Power of Many: アンサンブルメソッドの理解\"\n",
        "\n",
        "アンサンブルメソッドは、問題を解決するために協力し合うスーパーヒーローのチームのようなものです\n",
        "\n",
        "スーパーヒーローはそれぞれ独自のパワーと能力を持っているが、一緒に働くと、一人ではできないようなことを成し遂げることができる\n",
        "\n",
        "機械学習におけるアンサンブル手法もこれと同じように、複数のモデルの予測を組み合わせて、より正確な全体予測を作成する。\n",
        "\n",
        "積み重ね。\n",
        "ブロックを積み上げていくようなもので、各ブロックは異なるモデルの予測を表す。\n",
        "一番上のブロックが最終的な予測値で、その下にあるすべてのブロックの組み合わせとなる\n",
        "\n",
        "ブレンド。\n",
        "異なる色の絵の具を混ぜて新しい色を作るようなものです。\n",
        "各色は異なるモデルの予測を表し、新しい色が最終的な予測である。\n",
        "メリット\n",
        "\n",
        "複数のモデルの長所を組み合わせることで、予測の精度を向上させる\n",
        "個々のモデルの誤差を平均化することで、オーバーフィッティングを減らすことができる\n",
        "デメリット\n",
        "\n",
        "実装と解釈がより複雑になる\n",
        "計算コストが高くなる可能性がある\n",
        "アンサンブル手法のためのライブラリ\n",
        "\n",
        "scikit-learn\n",
        "mlens\n",
        "H2O\n",
        "xgboost\n",
        "lightgbm\n",
        "例"
      ],
      "metadata": {
        "id": "H7vulAYpxLEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# create the sub models\n",
        "estimators = []\n",
        "model1 = LogisticRegression()\n",
        "estimators.append(('logistic', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "estimators.append(('cart', model2))\n",
        "model3 = SVC()\n",
        "estimators.append(('svm', model3))\n",
        "\n",
        "# create the ensemble model\n",
        "ensemble = VotingClassifier(estimators)\n",
        "ensemble.fit(X_train, y_train)\n",
        "y_pred = ensemble.predict(X_test)\n"
      ],
      "metadata": {
        "id": "n9XMGROoxSl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この例では、scikit-learn の VotingClassifier クラスを使用して、ロジスティック回帰モデル、決定木モデル、サポートベクター機械モデルの予測値を組み合わせています。そして、このアンサンブルモデルを訓練データで学習させ、テストデータで予測を行うために使用します。"
      ],
      "metadata": {
        "id": "wSDrGXIexNj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "アンサンブル手法とは、機械学習手法の一種で、複数のモデルの予測値を組み合わせて全体の精度を向上させる手法である。スタッキングはアンサンブル手法の一種で、複数のモデルを学習させ、その予測値をメタモデルとして知られる最終モデルの入力として使用するものである。\n",
        "\n",
        "バギング。BaggingはBootstrap Aggregatingの略です。複数のモデルをデータの異なるサブセットで学習させ、その予測値を平均化することで、モデルの分散を減らすために使用される。\n",
        "\n",
        "ブースティング（Boosting）。ブースティングは、複数のモデルを順次学習させ、各モデルが前のモデルの誤りを修正することで、モデルの偏りを減らすために使用される。\n",
        "\n",
        "ランダムフォレスト ランダムフォレストはバギングを拡張したもので、特徴のランダム性も含んでいる。データと特徴の異なるサブセットに対して複数の決定木を学習させ、それらの予測値を組み合わせる。\n",
        "\n",
        "グラディエント・ブースティング ブースティングを拡張したもので、勾配降下法を用いてモデルを最適化する。\n",
        "\n",
        "スタッキング(Stacking) 複数のモデルを異なるデータのサブセットで、あるいは異なる特徴の組み合わせで学習させます。これらのモデルの予測値は、メタモデルとして知られる最終モデルの入力として使用され、最終的な予測を行う。\n",
        "\n",
        "以下は、scikit-learn ライブラリを使用してスタッキング・アンサンブルを実装する Python コードの一例です。\n",
        "\n",
        "Python\n",
        "\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LinearRegression （スカラーンリニアモデルインポートリニアレグレッション\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "estimators = [('lr', LinearRegression()), ('svr', SVR())] とする。\n",
        "reg = StackingRegressor(estimators=estimators)\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "このコードでは、線形回帰モデルとサポートベクトル回帰モデルを基本推定量として使用し、その予測値を用いてメタモデルを学習しています。"
      ],
      "metadata": {
        "id": "nlYxm5Jcx4Cv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ブースティングはアンサンブル手法の一種で、機械学習モデルの精度を向上させるために使用される。複数の弱いモデルを組み合わせて、より強く、より正確なモデルを形成することで機能する。ブースティングの代表的なアルゴリズムには、以下のようなものがある。\n",
        "\n",
        "AdaBoost。Adaptive Boosting：学習例の重みを反復的に調整し、誤分類された例をより重視する。\n",
        "\n",
        "勾配ブースティング（Gradient Boosting）。決定木のアンサンブルを使用する手法で、各決定木は前の決定木の誤りを修正する。\n",
        "\n",
        "XGBoost。勾配ブースティングの最適化された実装で、高速化とスケーラビリティを目的として設計されている。\n",
        "\n",
        "scikit-learn、XGBoost、LightGBM などの Python ライブラリは、ブースティングアルゴリズムの実装を提供します。\n",
        "\n",
        "以下は、scikit-learn ライブラリを用いた Python による AdaBoost アルゴリズムの実装の例です。\n",
        "\n",
        "Python\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0.X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0,\n",
        "                             random_state=0, shuffle=False)\n",
        "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(X, y)\n",
        "タイトル \"Boost Your Learning: ブースティング技術のパワーを解き放つ\"\n",
        "\n",
        "キャッチフレーズ: \"Boosting Techniquesでデータの真の可能性を解き放つ\""
      ],
      "metadata": {
        "id": "bW2h6F-tySUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \"もっといい模型をつくる。子供向けスタッキングメソッドガイド\"\n",
        "\n",
        "#### スタッキングメソッド\n",
        "\n",
        "- スタッキング法は、積み木で塔を作るようなものだと考えてください。\n",
        "- ブロックを積み上げて塔を作るように、積み上げ法では、いくつかのモデルの予測を入力として、別のモデルを作り、最終的な予測を行う。\n",
        "\n",
        "- 塔の中のブロックは、積み上げ方式におけるモデルのようなもので、それぞれが予測を行いますが、それらを組み合わせることで、より正確な最終的な予測を行うことができます。\n",
        "\n",
        "- スタッキングは、複数のモデルの予測を組み合わせることで、機械学習モデルの性能を向上させるために用いることができる。\n",
        "\n",
        "#### 類似点\n",
        "-  スタッキングはアンサンブル手法に関連しており、どちらも複数のモデルを用いて最終的な予測を行う。\n",
        "\n",
        "#### 相違点\n",
        "-  スタッキングは、複数のモデルの予測を別のモデルの入力として使用し、アンサンブル法は複数のモデルの予測を結合する。\n",
        "\n",
        "#### 利点\n",
        "-  スタッキングを使用すると、機械学習モデルのパフォーマンスを向上させることができます。\n",
        "\n",
        "#### デメリット\n",
        "-  この方法は計算コストが高く、また、必ずしも大幅な性能向上につながるとは限りません。\n",
        "\n",
        "#### 起源\n",
        "-  スタッキングは機械学習と統計学の分野から来ている。\n",
        "\n",
        "##### 意味は？\n",
        "- 複数のモデルの予測を別のモデルの入力として使用することにより、機械学習モデルの性能を向上させるために使用される。\n",
        "\n",
        "#### 関係性\n",
        "-  スタッキングはマルチプレキシング、アンサンブル法、ブレンディングと関連しており、これらの技術はすべて最終的な予測を行うために複数のモデルを使用するが、それらのモデルがどのように組み合わされるかが異なる。"
      ],
      "metadata": {
        "id": "aif3ZwLmC2tI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"機械学習におけるハーモニー。アンサンブル手法の子供向けガイド\"\n",
        "\n",
        "#### アンサンブルメソッド\n",
        "\n",
        "- アンサンブル法をバンドのように考えてみよう。\n",
        "- バンドが異なるミュージシャンが異なる楽器を演奏するように、アンサンブル法では異なるモデルが異なる予測を行う。\n",
        "\n",
        "- アンサンブルの各モデルは、バンドのミュージシャンのようなもので、それぞれが異なる楽器を演奏しますが、組み合わせると調和の取れた音になります。\n",
        "- 同様に、アンサンブルの各モデルは予測を行いますが、組み合わされるとより正確な最終的な予測が行われます。\n",
        "\n",
        "- アンサンブル手法は、複数のモデルの予測を組み合わせることで、機械学習モデルのパフォーマンスを向上させるために利用できる。\n",
        "\n",
        "- アンサンブル手法は、次のようなさまざまな方法で使用することができる。バギング、ブースティング、スタッキングなど。\n",
        "\n",
        "### 類似点。\n",
        "- これらの方法はすべて、最終的な予測を行うために複数のモデルを使用することを含む。\n",
        "\n",
        "#### 相違点\n",
        "-  Bagging、Boosting、Stackingはそれぞれ異なるアンサンブル手法で、モデルの予測を結合するために異なる技術を使用します。\n",
        "\n",
        "#### メリット\n",
        "-  アンサンブル手法の使用により、機械学習モデルのパフォーマンスを向上させることができる。\n",
        "\n",
        "#### デメリット\n",
        "-  これらの手法は計算コストが高く、必ずしもパフォーマンスが大幅に向上するとは限りません。\n",
        "\n",
        "#### 起源\n",
        "-  アンサンブル手法は、機械学習と統計学の分野に由来する。\n",
        "\n",
        "#### 意味は？\n",
        "- アンサンブル法は、複数のモデルの予測値を組み合わせることで、機械学習モデルの性能を向上させるために使用される。\n",
        "\n",
        "#### 関係性\n",
        "-  アンサンブル法は、多重化および混合に関連しており、これらの技術はすべて最終的な予測を行うために複数のモデルを使用することを含むが、それらのモデルを結合する方法が異なる。"
      ],
      "metadata": {
        "id": "rAl_I2kpCKph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"カラフルな組み合わせ。子どものための「ブレンド技法」ガイド \"\n",
        "\n",
        "#### ブレンドのテクニック\n",
        "\n",
        "- ブレンディングは、絵の具を混ぜるようなものだと考えてください。\n",
        "- 異なる色の絵の具を混ぜて新しい色を作るように、ブレンディングでは、データの異なるサブセットで異なるモデルを学習させ、それらの予測を組み合わせて最終的な予測を行うのです。\n",
        "\n",
        "- 絵の具の各色は、ブレンド技術におけるモデルのようなもので、それぞれがデータの異なるサブセットで学習されますが、それらを組み合わせることで、より正確な最終的な予測を行うことができるのです。\n",
        "\n",
        "- ブレンドは、複数のモデルの予測を組み合わせることで、機械学習モデルの性能を向上させるために使用することができます。\n",
        "\n",
        "#### 類似点\n",
        "-  ブレンドはアンサンブル手法、マルチプレキシング、スタッキングに関連しており、これらの手法はすべて、最終的な予測を行うために複数のモデルを使用することを含んでいる。\n",
        "\n",
        "#### 相違点\n",
        "-  ブレンド技術は、データの異なるサブセットで異なるモデルを学習させるが、アンサンブル法、マルチプレキシング、スタッキングは、複数のモデルの予測を結合する。\n",
        "\n",
        "#### 利点\n",
        "-  ブレンドの使用により、機械学習モデルのパフォーマンスを向上させることができます。\n",
        "\n",
        "#### デメリット\n",
        "-  この方法は計算コストが高く、必ずしも性能の大幅な向上につながるとは限りません。\n",
        "\n",
        "#### 起源\n",
        "-  ブレンディングは、機械学習と統計学の分野に由来する。\n",
        "\n",
        "#### 意味は？\n",
        "- 機械学習モデルの性能を向上させるために、データの異なるサブセットで異なるモデルを学習させ、その予測値を組み合わせること。\n",
        "\n",
        "#### 関係性\n",
        "-  ブレンドはアンサンブル手法、マルチプレキシング、スタッキングに関連しており、これらの手法はすべて最終的な予測を行うために複数のモデルを使用することを含むが、それらのモデルをどのように組み合わせるかが異なる。"
      ],
      "metadata": {
        "id": "9-wEYHXLD3JX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"音楽的な機械学習。アンサンブル法、スタッキング、ブレンディング、バギング、ブースティング、スタッキングへの子供の手引き\"\n",
        "\n",
        "#### アンサンブルメソッド\n",
        "\n",
        "- アンサンブル法をバンドのように考えてみてください。\n",
        "バンドが異なるミュージシャンが異なる楽器を演奏するように、アンサンブル法も異なるモデルが異なる予測を行う。\n",
        "#### スタッキング。\n",
        "\n",
        "- 積み木で塔を作るようなものだと考えてください。\n",
        "- ブロックを積み上げて塔を作るように、スタッキングでは、複数のモデルの予測を別のモデルの入力として使用し、最終的な予測を行うのです。\n",
        "ブレンド。\n",
        "\n",
        "#### ブレンドは、絵の具を混ぜるようなものだと考えてください。\n",
        "- 異なる色の絵の具を混ぜて新しい色を作るように、ブレンドでは、データの異なるサブセットで異なるモデルを学習させ、その予測を組み合わせて最終的な予測を行います。\n",
        "#### バギング。\n",
        "\n",
        "- バギングとは、異なる木から様々な果物を採取するようなものだと考えてください。\n",
        "- 異なる木から様々な果物を選んでバスケットを作るように、Baggingでは、データの異なるサブセットで異なるモデルを学習させ、その予測を組み合わせて最終的な予測を行います。\n",
        "#### ブースティング。\n",
        "\n",
        "- ブースティングは山登りのようなものだと考えてください。\n",
        "- 山を一歩一歩登っていくように、ブースティングでは、あるモデルをデータで学習させ、そのモデルの間違いを利用して、次のモデルを改良していくのです。\n",
        "\n",
        "####似たようなものです。\n",
        "- いずれも複数のモデルを用いて最終的な予測を行う。\n",
        "\n",
        "#### 相違点\n",
        "-  アンサンブル手法、スタッキング、ブレンディング、バギング、ブースティングはそれぞれ異なる手法であり、モデルの予測を組み合わせるためにそれぞれ異なる方法を使用します。\n",
        "\n",
        "#### 利点\n",
        "-  アンサンブル手法、スタッキング、ブレンディング、バギング、ブースティングを使用すると、機械学習モデルのパフォーマンスを向上させることができる。\n",
        "\n",
        "#### デメリット\n",
        "-  これらの手法は計算コストが高く、必ずしも性能の大幅な向上につながるとは限りません。\n",
        "\n",
        "##### 起源\n",
        "-  これらの手法は、機械学習と統計学の分野に由来する。\n",
        "\n",
        "#### 意味\n",
        "-  複数のモデルの予測を組み合わせることで、機械学習モデルの性能を向上させるための技術です。\n",
        "\n",
        "#### 関係性\n",
        "-  アンサンブル法、スタッキング、ブレンディング、バギング、ブースティングはすべて、機械学習モデルの性能を向上させるために一緒に使うことができる技術である。\n",
        "- いずれも複数のモデルを用いて最終的な予測を行うが、それらのモデルをどのように組み合わせるかが異なる。"
      ],
      "metadata": {
        "id": "zGOsL5_tFNhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Breimanは1994年に、Boostingは90年代前半にFreundとSchapireによって紹介された。スタッキングという言葉は1992年にWolpertによって初めて使われ，ブレンディングはより最近の言葉で，同様のアンサンブル方法を表すのに使われる。\n",
        "\n",
        "ヒント\n",
        "\n",
        "Baggingとは何かを思い出すには、分散を減らすために複数のモデルの予測を「平均化」する方法だと考えてください。\n",
        "Boostingとは、複数のモデルを順次学習させ、以前のモデルの誤りを修正することによって、モデルの性能を「向上」させる方法であるとお考えください。\n",
        "スタッキングとは、複数のモデルを「積み重ねる」方法であり、あるモデルの出力を次のモデルの入力として使用する、と考えてください。\n",
        "ブレンドとは、異なる色の塗料を混ぜ合わせるように、複数のモデルの予測を「ブレンド」する方法だと考えてください。\n",
        "ランダムフォレストとは何かというと、決定木の「森」であり、それぞれの木はデータのランダムな部分集合に対して学習されると考えてください。\n",
        "投票分類器とは、複数のモデルを学習させ、その予測値を多数決で組み合わせる「投票」システムであると考えればよいでしょう。\n",
        "また、例題やサンプルコードを使って、いろいろな方法を試し、その結果を比較しながら練習してみるのもよいでしょう。そうすることで、概念をよりよく覚え、理解することができます。"
      ],
      "metadata": {
        "id": "XRWc9isP0c89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagging (Bootstrap Aggregating)。バギングとはアンサンブル手法の一つで、データの異なるサブセットに対して複数のモデルを独立して学習させ、その予測値を平均化または投票するものである。バギングの主な考え方は、複数のモデルの予測値を平均化することで、モデルの分散を小さくすることです。\n",
        "\n",
        "ブースティング。ブースティングはアンサンブル手法の一つで、複数のモデルを順次学習させ、各モデルが前のモデルの誤りを修正しようとするものである。ブースティングの主な考え方は、複数のモデルの予測値を組み合わせることによって、モデルの偏りを減らすことです。\n",
        "\n",
        "スタッキング。スタッキングはアンサンブル手法の一つで、複数のモデルを独立して学習させ、その予測値をメタモデルの入力として使用する。スタッキングの主な考え方は、複数のモデルの予測値を組み合わせることによって、モデルの性能を向上させることです。\n",
        "\n",
        "Blending（ブレンド）。BlendingはStackingと似ていますが、データの異なるサブセットに対してモデルを学習させ、その予測値をメタモデルの入力として使用するものです。Blendingの主な考え方は、データの異なるサブセットで学習した複数のモデルの予測値を組み合わせることで、モデルの性能を向上させることです。\n",
        "\n",
        "アンサンブル手法を覚えるためのニーモニックデバイス。\"BAGS \"です。Bagging、AdaBoost、Gradient Boosting、Stackingの頭文字をとったもの。\n",
        "\n",
        "アンサンブル手法を覚えるための頭字語。\"BEST\": Bagging、Boosting、Ensemble、Stacking、Tacklingの頭文字をとったもの。\n",
        "\n",
        "可視化。アンサンブル手法は、専門家集団が協力して意思決定を行うようなものだとイメージするとよいでしょう。専門家はそれぞれ専門知識を持っており、その知識を組み合わせることで、より正確な意思決定を行うことができる。\n",
        "\n",
        "関連づけ。アンサンブル手法は、\"two heads are better than one \"というフレーズと関連付けることができます。複数のモデルの予測を組み合わせることで、アンサンブル手法はモデルの性能を向上させることができる。\n",
        "\n",
        "語源 アンサンブルの語源はフランス語の \"ensemble \"で、\"一緒に \"という意味である。アンサンブル手法は、複数のモデルを学習させ、その予測値を組み合わせることから、そう呼ばれている。"
      ],
      "metadata": {
        "id": "gIMslSAJ1Czc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習におけるアンサンブル手法の主な目的は何ですか？\n",
        "アンサンブル法におけるバギングとブースティングはどう違うのですか？\n",
        "スタッキング・アンサンブル手法の利用が有効な実問題の例を挙げてください。\n",
        "投票アンサンブルにおけるハード投票とソフト投票の違いは何ですか？\n",
        "アンサンブル手法で使用するベースモデルの最適な数をどのように決定しますか？\n",
        "説明\n",
        "\n",
        "アンサンブル法は、機械学習アルゴリズムの全体的なパフォーマンスを向上させるために複数のモデルを組み合わせます。主な目的は、精度の向上とオーバーフィッティングの低減です。\n",
        "バギングとは、データの異なるサブセットに対して複数のモデルを学習させ、その予測値を結合する手法である。ブースティングは、データの異なるサブセットに対して複数のモデルを学習させ、その性能に基づいて各モデルに重みを付けて予測を組み合わせる手法である。\n",
        "スタッキング・アンサンブル手法の利用が有効な問題の実例としては、画像の異なる特徴について学習した複数のモデルを組み合わせて最終的な予測を行う、画像分類が考えられます。\n",
        "ハードボーリングアンサンブルは多数決で予測を行い、ソフトボーリングアンサンブルは加重平均で予測を行うものである。\n",
        "アンサンブル手法で使用するベースモデルの最適な数は、さまざまな数を試し、アンサンブルのパフォーマンスを評価することで決定できます。"
      ],
      "metadata": {
        "id": "QrybrcNl2ces"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習におけるアンサンブル手法の目的は何ですか？\n",
        "アンサンブル法におけるバギング手法とブースティング手法はどう違うのですか？\n",
        "よく使われるアンサンブル手法のアルゴリズムの例を教えてください。\n",
        "アンサンブル法はどのようにして単一モデルの性能を向上させるのですか？\n",
        "アンサンブル法を利用するメリットとデメリットは何ですか？\n",
        "答えてください。\n",
        "\n",
        "機械学習におけるアンサンブル手法の目的は、複数のモデルの予測を組み合わせて、予測の全体的な性能と精度を向上させることです。\n",
        "バギング法は、データの異なるサブセットで学習することにより、複数のバージョンのモデルを作成し、ブースティング法は、誤って分類されたデータポイントに多くの重みを与えることにより、モデルの性能を向上させます。\n",
        "ランダムフォレストは、一般的なアンサンブル手法のアルゴリズムの一例である。\n",
        "アンサンブル法は、分散、バイアスを低減し、モデルの全体的な精度を向上させることによって、単一のモデルのパフォーマンスを向上させます。\n",
        "アンサンブル法の利点は、性能の向上とオーバーフィッティングの低減ですが、欠点は複雑さと計算コストの増加です。"
      ],
      "metadata": {
        "id": "Lo8BfxxX3Nlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習におけるアンサンブル手法の主な目的は何でしょうか？\n",
        "複数のモデルを組み合わせることで、単一のモデルの性能を向上させること。\n",
        "(複数のモデルを組み合わせて性能を向上させる)\n",
        "一般的なアンサンブル手法にはどのようなものがあるか？\n",
        "Bagging、Boosting、Stacking、Blendingです。\n",
        "(バギング、ブースティング、スタッキング、ブレンディング)\n",
        "BaggingとBoostingはどう違うのか？\n",
        "Bagging はランダムサンプリングを使ってトレーニングセットの複数のバージョンを作成し、各バージョンでモデルをトレーニングする。一方 Boosting はモデルを反復的に改善するために誤分類されたオブザベーションでのトレーニングに焦点を当てる。\n",
        "(ランダムサンプリング vs. 誤分類されたオブザベーションでのトレーニング)\n",
        "アンサンブル法は分類と回帰の両方のタスクに使用できますか？\n",
        "はい、アンサンブル法は分類と回帰の両方のタスクに使用できます。\n",
        "(はい)\n",
        "アンサンブル法におけるハードボーティングとソフトボーティングの違いは何ですか？\n",
        "ハードボーティングはモデルによって予測された多数決のクラスを採用し、ソフトボーティングはモデルによって予測されたクラス確率の平均を採用します。\n",
        "(多数決 vs クラス確率の平均)"
      ],
      "metadata": {
        "id": "xTfMQQk83jQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習においてバギング・アンサンブル法を用いる主な目的は何ですか？\n",
        "バギング・アンサンブル法の主な目的は、複数のモデルを学習データの異なる部分集合で学習させ、その予測値を平均化または投票することにより、1つのモデルの予測値の分散を小さくすることです。\n",
        "バギング・アンサンブル法を使用する際の学習データの分割方法は？\n",
        "バギング・アンサンブル法を使用する場合、学習データは通常、同じサイズの複数のサブセットに分割され、それぞれのサブセットは別々のモデルを学習するために使用されます。\n",
        "バギング・アンサンブル法で使用できる一般的な機械学習アルゴリズムの例にはどのようなものがありますか？\n",
        "バギング・アンサンブル法で使用できる一般的な機械学習アルゴリズムの例としては、決定木、ランダムフォレスト、ニューラルネットワークなどがあります。\n",
        "バギング・アンサンブル手法を使用する利点は、単一モデルを使用する場合と比較してどのような点ですか？\n",
        "バギング・アンサンブル手法の利点は、汎化性能の向上、オーバーフィットに対するロバスト性の向上、予測値の分散の減少などです。\n",
        "バギング・アンサンブル法を使用した場合、最終的な予測はどのように行われるのですか？\n",
        "最終的な予測は、通常、トレーニングデータのサブセットでトレーニングされた各モデルによる予測を平均化または投票することによって行われます。(平均化または投票)"
      ],
      "metadata": {
        "id": "Evr4wDO64CWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"ミックス＆マッチ機械学習。子供のための混合技法ガイド\"\n",
        "\n",
        "#### ブレンドのテクニック\n",
        "\n",
        "- ブレンドは、絵の具を混ぜるようなものだと考えてください。\n",
        "- 異なる色の絵の具を混ぜて新しい色を作るように、ブレンドでは、データの異なるサブセットで異なるモデルを学習させ、それらの予測を組み合わせて最終的な予測を行うのです。\n",
        "\n",
        "- 絵の具の各色は、ブレンド技術におけるモデルのようなもので、それぞれがデータの異なるサブセットで学習されますが、それらを組み合わせることで、より正確な最終的な予測を行うことができるのです。\n",
        "\n",
        "- ブレンドは、複数のモデルの予測を組み合わせることで、機械学習モデルの性能を向上させるために使用することができます。\n",
        "\n",
        "#### 類似点\n",
        "-  ブレンドはアンサンブル手法、マルチプレキシング、スタッキングと関連しており、これらの手法はすべて、最終的な予測を行うために複数のモデルを使用することを含んでいます。\n",
        "\n",
        "#### 相違点 \n",
        "- ブレンド技術は、データの異なるサブセットで異なるモデルを学習させるが、アンサンブル法、マルチプレキシング、スタッキングは、複数のモデルの予測を組み合わせる。\n",
        "\n",
        "#### 利点\n",
        "-  ブレンドの使用により、機械学習モデルのパフォーマンスを向上させることができます。\n",
        "\n",
        "#### デメリット\n",
        "-  この方法は計算コストが高く、必ずしも性能が大幅に向上するとは限りません。\n",
        "\n",
        "#### 起源\n",
        "-  ブレンディングは、機械学習と統計学の分野に由来する。\n",
        "\n",
        "#### 意味は？\n",
        "- 機械学習モデルの性能を向上させるために、データの異なるサブセットで異なるモデルを学習させ、その予測値を組み合わせること。\n",
        "\n",
        "#### 関係性\n",
        "-  ブレンドはアンサンブル手法、マルチプレキシング、スタッキングに関連しており、これらの手法はすべて最終的な予測を行うために複数のモデルを使用することを含むが、これらのモデルをどのように組み合わせるかが異なる。\n",
        "\n",
        "#### 例 \n",
        "- 例：分類問題では、訓練データ集合でモデルを訓練し、検証データ集合で別のモデルを訓練し、両方のモデルの予測を組み合わせて最終的な予測を行うために、ブレンディングを使用することができます。\n",
        "- 別の例では、同じ問題に対して2つの異なるアルゴリズムをブレンドし、1つのアルゴリズムはデータのサブセットで、もう1つは残りのデータで訓練し、両方のアルゴリズムの予測を組み合わせて、最終的な予測を行います。"
      ],
      "metadata": {
        "id": "ca2_VoFRGmai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"フルーツバスケットの機械学習。子供のためのバギング入門\"\n",
        "\n",
        "####バギング（Bagging）\n",
        "\n",
        "- バギングとは、異なる木から様々な果物を摘み取るようなものだと考えてほしい。\n",
        "- 異なる木から様々な果物を選んでバスケットを作るように、バギングでは、データの異なるサブセットに対して異なるモデルを学習させ、それらの予測を組み合わせて最終的な予測を行うのです。\n",
        "\n",
        "- バスケットの中のそれぞれの果物は、バギング技術におけるモデルのようなもので、それぞれがデータの異なるサブセットで学習されますが、それらを組み合わせることで、より正確な最終的な予測を行うことができるのです。\n",
        "\n",
        "- バギングは、複数のモデルの予測を組み合わせることで、機械学習モデルのパフォーマンスを向上させるために使用することができます。\n",
        "\n",
        "#### 類似点\n",
        "- Baggingはアンサンブル手法、マルチプレキシング、ブレンディング、スタッキングに関連しており、\n",
        "- これらの手法はすべて、最終的な予測を行うために複数のモデルを使用することを含んでいる。\n",
        "\n",
        "#### 相違点\n",
        "- Baggingはデータの異なるサブセットで異なるモデルをトレーニングし、アンサンブル法、マルチプレキシング、ブレンディング、スタッキングは複数のモデルの予測を異なる方法で組み合わせます。\n",
        "\n",
        "#### 利点\n",
        "-  バギングを使用すると、機械学習モデルのパフォーマンスを向上させることができる。\n",
        "\n",
        "#### デメリット\n",
        "-  この方法は計算コストが高く、必ずしも性能の大幅な向上につながらない可能性がある。\n",
        "\n",
        "#### 起源\n",
        "-  バギングは機械学習と統計学の分野に由来する。\n",
        "\n",
        "#### 意味は？\n",
        "- Baggingは、データの異なるサブセットで異なるモデルを学習させ、その予測を組み合わせることで、機械学習モデルのパフォーマンスを向上させるために使用される。\n",
        "\n",
        "#### 関係性\n",
        "-  Baggingはアンサンブル手法、マルチプレキシング、ブレンディング、スタッキングに関連しており、これらの手法はすべて最終的な予測を行うために複数のモデルを使用することを含むが、これらのモデルをどのように組み合わせるかが異なる。\n",
        "\n",
        "#### 例\n",
        "-  分類問題では、バギングを使用して、データの異なるサブセットで複数のモデルを学習させることができます。\n",
        "- 各サブセットは、元のデータを置換してランダムにサンプリングして作成され、すべてのモデルの予測値を組み合わせて最終的な予測値とします。\n",
        "- 別の例としては、データの異なるサブセットで複数のモデルを学習させ、その予測値を平均して最終的な予測値とする方法があります。"
      ],
      "metadata": {
        "id": "yAIheO6BHV2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### \"データミックスアップ機械学習。子どものための「さまざまなデータのサブセット」ガイド \"\n",
        "\n",
        "#### データの異なるサブセット\n",
        "\n",
        "- データの異なるサブセットは、アイスクリームの異なるフレーバーのようなものだと考えてください。\n",
        "- アイスクリームにたくさんのフレーバーがあるように、データにもたくさんのサブセットがある。\n",
        "\n",
        "- アイスクリームの各フレーバーはデータのサブセットのようなもので、それぞれがユニークですが、組み合わせるとより正確な予測になります。\n",
        "\n",
        "- データの異なるサブセットを使ってモデルを訓練することで、機械学習モデルの性能を向上させることができる。\n",
        "\n",
        "#### 類似性。\n",
        "- すべてのデータのサブセットは、元のデータセットの一部であるが、異なるバリエーションである。\n",
        "\n",
        "#### 相違点\n",
        "- データのサブセットは、ランダムサンプリング、層別サンプリング、系統的サンプリングなど、様々な方法で作成することができる。\n",
        "\n",
        "#### 利点\n",
        "-  異なるデータのサブセットを使用することで、機械学習モデルのパフォーマンスを向上させることができる。\n",
        "\n",
        "#### デメリット\n",
        "-  この方法は計算コストが高く、必ずしも性能が大きく向上するとは限らない。\n",
        "\n",
        "#### 起源\n",
        "-  データの異なるサブセットを使用することは、機械学習と統計学の分野に由来している。\n",
        "\n",
        "#### 意味するところ。\n",
        "- データの異なるサブセットを使用して、データの異なるバリエーションでモデルを学習させることにより、機械学習モデルの性能を向上させる。\n",
        "\n",
        "#### 関係性。\n",
        "- 異なるデータの部分集合は、アンサンブル手法、多重化、ブレンド、バギング、スタッキングに関連しており、これらの手法はすべて、異なる部分集合を使用することを含む。"
      ],
      "metadata": {
        "id": "Cf4iTwmdIHGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"データパズル機械学習。子供向けガイド：さまざまなデータのサブセット \"\n",
        "\n",
        "データの異なるサブセット\n",
        "\n",
        "データの異なるサブセットをパズルのように考えてみよう。パズルに多くのピースがあるように、データにも多くのサブセットがある。\n",
        "\n",
        "パズルのピースはデータのサブセットと同じで、それぞれがユニークだが、組み合わせるとより正確な予測ができる。\n",
        "\n",
        "データの異なるサブセットを使ってモデルを学習させることで、機械学習モデルの性能を向上させることができる。\n",
        "\n",
        "例\n",
        "\n",
        "ランダムサンプリング。ランダムサンプリングは、パズルのピースをランダムに選んで新しいパズルを作るようなものだと考えてほしい。ランダムサンプリングでは、元のデータセットから無作為にデータを選び、新しいデータセットを作成する。\n",
        "\n",
        "層別サンプリング。層別サンプリングは、特定の特徴を持つパズルのピースを選ぶようなものだと考えてください。層別サンプリングでは、データを特定の特徴に基づいて異なるグループに分け、各グループからサンプルを選択して、新しいデータのサブセットを作成します。\n",
        "\n",
        "システマティック・サンプリング。系統的サンプリングは、パズルのピースを特定のパターンで選ぶようなものだと考えてください。系統的サンプリングでは、元のデータセットからn個目のピースを選んで、新しいデータ部分集合を作成する。\n",
        "\n",
        "類似性: すべてのデータ・サブセットは、元のデータ・セットの一部であるが、異なるバリエーションを持つ。\n",
        "\n",
        "相違点 データのサブセットは、ランダムサンプリング、層別サンプリング、系統的サンプリングなど、さまざまな方法で作成することができ、それぞれの方法には利点と欠点があります。\n",
        "\n",
        "メリット データのサブセットを使い分けることで、機械学習モデルの性能を向上させることができる。\n",
        "\n",
        "デメリット この方法は計算コストが高く、必ずしも性能の大幅な向上につながらない場合がある。\n",
        "\n",
        "起源 データの異なるサブセットを使用することは、機械学習と統計学の分野に由来している。\n",
        "\n",
        "意味するところ。データの異なるサブセットを使用して、データの異なるバリエーションでモデルを学習させることにより、機械学習モデルの性能を向上させる。\n",
        "\n",
        "関係性。異なるデータのサブセットは、アンサンブル法、多重化、ブレンド、バギング、スタッキングに関連し、これらの技術はすべて、機械学習モデルの性能を向上させるためにデータの異なるサブセットを使用することを含む。"
      ],
      "metadata": {
        "id": "ccKO7Eb_JNfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\"オートチューニングで勝負！\"\n",
        "- AutoMLのチューニングとマルチプレクサによる自動モデル選択機能は、あなたのデータに対するパーソナルシェフのようなものです。\n",
        "- シェフが様々な食材やテクニックを使って最高の料理を作るように、AutoMLも様々なモデルやパラメータを使って、データに最適なものを見つけます。\n",
        "\n",
        "- 例えば、来週の天気を予測する場合を考えてみましょう。\n",
        " - 基本的なモデルでは、気温と湿度しか考慮されないかもしれません。\n",
        " - しかし、AutoMLのモデルでは、より正確な予測をするために、風向き、気圧、過去の天気パターンも考慮するかもしれません。\n",
        "\n",
        "- 他の例としては、画像認識があります。\n",
        " - AutoMLモデルは、ディープラーニングモデルが画像内のオブジェクトを正確に識別するために、レイヤーとパラメーターの最適な組み合わせを自動的に選択することができます。\n",
        "\n",
        "- マルチプレクサで言えば、厨房にそれぞれ得意な料理や技術を持ったシェフのチームがいて、最高の料理を作るために協力し合うようなものです。\n",
        " - マルチプレクサによって、AutoMLアルゴリズムは複数のモデルを一度に検討し、特定のデータセットに基づいて最適なモデルを選択することができます。\n",
        "\n",
        "- AutoMLとマルチプレクサを使用するデメリットは、計算コストと時間がかかることです。\n",
        "- しかし、全体としては、長期的には時間を節約し、結果を向上させることができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "Q06gPehWYpNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"マルチプルチョイスマシン\"**\n",
        "- マルチプレクサとは、異なる選択肢を選ぶことができる機械のようなもので、異なる種類のスナックを出すことができる自動販売機のようなものです。\n",
        "- 自動販売機には異なるスナックのボタンがあるように、マルチプレクサには異なる「入力」があり、そこから選択して「出力」に送ることができる。\n",
        "- これは、特定の条件に基づいて異なるオプションを選択する必要があるコンピュータ・システムで有用です。\n",
        "- 例えば、自動車のブレーキシステムのマルチプレクサは、ドライバーがペダルを踏む強さに応じて、通常のブレーキと緊急ブレーキを選択することができます。\n",
        "- また、サウンドシステムでは、CDプレーヤー、ラジオ、スマートフォンなど、さまざまなオーディオ入力を選択できるマルチプレクサがあります。\n",
        "\n"
      ],
      "metadata": {
        "id": "N8mmtUzKZLTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"バランシング・アクト予測的重み付けアンサンブルとヘッジングアンサンブル \"**\n",
        "\n",
        "- 細いワイヤーの上でバランスを取ろうとする綱渡り師を想像してほしい。\n",
        " - 彼らは長い棒を使ってバランスを取り、直立を保つことができる。\n",
        " - 同様に、予測においては、予測重み付けアンサンブルとヘッジング・アンブルは、複数のモデルを使ってバランスを取り、予測の精度を向上させます。\n",
        "\n",
        "- 予測荷重アンサンブルは、複数のモデルを組み合わせて使用し、それぞれが予測値のセットを持ちます。\n",
        " - これらの予測は、過去にどれだけ正確であったかに基づいて重み付けされ、または異なるレベルの重要性が与えられます。\n",
        " - このようにして、アンサンブルは個々のモデルすべての予測を考慮することで、より正確な最終予測を行うことができます。\n",
        "\n",
        "- 一方、ヘッジアンサンブルは、複数のモデルを使用して、潜在的なエラーに対する「ヘッジ」またはセーフティネットを作成します。\n",
        " - 複数のモデルを使用することで、アンサンブルは複数の視点を考慮し、より正確な予測を行うことができる。\n",
        "\n",
        "- これらのアンサンブル手法は、いずれも複数のモデルを考慮することで予測精度を向上させるという利点があります。\n",
        " - しかし、計算コストが高くなり、複数のモデルを学習させるために、より多くのデータを必要とすることもあります。\n",
        "\n"
      ],
      "metadata": {
        "id": "QcqQ2yROZnKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **ミックスアンドマッチ・アンサンブル戦略**\n",
        "- シェフが異なる材料を混ぜて料理を作ることを思い浮かべてください。\n",
        "- 同じように、単純なアンサンブル戦略では、より正確な予測をするために、異なる予測モデルを一緒に組み合わせます。\n",
        "- 例えば、夏の暑い日にお店で売られるアイスクリームのコーンの数を予測するとします。\n",
        " - あるモデルでは気温から売上を予測し、別のモデルではその日にビーチに来る人の数から売上を予測するかもしれません。\n",
        " - この2つのモデルの予測を組み合わせることで、アイスクリームコーンの売上をより正確に予測することができるのです。\n",
        "- もう一つの例は、クラスプロジェクトで、学生のグループが与えられたトピックについてプレゼンテーションをするよう命じられた場合です。\n",
        " - グループの各メンバーは、特定のトピックを研究し、発表するよう割り当てられます。\n",
        " - 各メンバーのリサーチとプレゼンテーションを組み合わせることで、より包括的で正確なプレゼンテーションができるようになります。\n",
        "\n",
        "### **\"投票合体作戦\" **\n",
        "- 食べに行く店を決めようとするグループを想像してください。\n",
        " - 一人一人が違うレストランを提案し、どのレストランに行くか投票する。\n",
        " - 同じように、投票アンサンブル戦略では、異なるモデルの予測を使用し、最終的な予測は、大多数によって最も良いと投票されたモデルに基づいて選択されます。\n",
        "- 例えば、株式市場を予測するとします。3つの異なるモデルを使用し、各モデルは株式市場に何が起こるかについて異なる予測をします。\n",
        " - 投票アンサンブル戦略では、大多数のモデルが同意した予測を選択することになる。\n",
        "\n",
        "### **「重み付きアンサンブル戦略」 **\n",
        "- 一方の側の各項目に異なる重みまたは重要性があるスケールを思い浮かべてください。 \n",
        " - 同じように、重み付きアンサンブル戦略では、各モデルに異なる重みまたは重要性を割り当て、最終的な予測はすべての予測の加重平均に基づきます。\n",
        "- 例えば、ある美術館の来館者数を予測するとしよう。\n",
        " - あるモデルは学校団体の訪問者数に基づいて訪問者数を予測し、別のモデルは都市を訪れる観光客の数に基づいて訪問者数を予測し、3番目のモデルは博物館のマーケティング活動に基づいて訪問者数を予測する、3つの異なるモデルを使用します。\n",
        " - 重み付きアンサンブル戦略では、各モデルに、その信頼性に基づいて異なる重みを割り当てることになる。\n",
        "\n"
      ],
      "metadata": {
        "id": "pc5e_E9KbnR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"アンサンブル予測\"**\n",
        "- 複数のモデルの予測を組み合わせて、全体的な予測精度を向上させること。\n",
        "\n",
        "- 一例として、野球チームが、強弱の異なる様々な選手で構成されていることが挙げられます。\n",
        " - チームが状況に応じて選手を使い分けるように、アンサンブル予測では予測の部分ごとに異なるモデルを使用します。\n",
        " - 例えば、あるモデルは短期的なトレンドの予測に優れ、別のモデルは長期的なトレンドの予測に優れているかもしれません。\n",
        " - 両方のモデルの予測を組み合わせることで、アンサンブル予測は全体としてより正確なものになります。\n",
        "\n",
        "- もう一つの例は、料理のレシピで、ユニークな味を作るために異なるスパイスの組み合わせを呼び出すことです。\n",
        "- 同様に、アンサンブル予測は、それぞれが長所と短所を持つ複数のモデルの予測を組み合わせることで、より正確な全体的な予測を作成します。\n",
        "\n",
        "- また、「予測荷重アンサンブル」とは、複数のモデルによる予測を、それぞれの予測の過去の実績に基づいて重み付けして組み合わせる手法です。\n",
        " - これは、シェフが過去の経験に基づいてレシピに使用する最適なスパイスを選択するのと似ています。\n",
        "\n",
        "- 一方、「ヘッジ・アンサンブル」は、複数の予測を作成し、全体の予測誤差が少なくなるように組み合わせる方法です。\n",
        "- これは、金融投資家がリスクを減らすためにポートフォリオを分散させるのと似ています。\n"
      ],
      "metadata": {
        "id": "Cfa_mFd9aZ80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"バランシング・アクト\"。予測荷重アンサンブル**\n",
        "- 一度に複数のアイテムのバランスを取ろうとする綱渡りのようなものです。\n",
        " - 綱渡りが異なる物のバランスを慎重に取るように、負荷予測アンサンブルは複数の予測のバランスを取って、より正確な予測を行います。\n",
        "\n",
        "- 例えば、来年の夏にアイスクリームスタンドで販売するアイスクリームコーンの数を予測するとします。\n",
        " - このとき、過去の販売データを見たり、天候のパターンを考慮したりと、複数の異なる予測方法を用いて予測を行うかもしれません。\n",
        " - 予測荷重アンサンブルは、これらの異なる予測をすべて取り込み、それらを組み合わせてより正確な予測を行うものです。\n",
        "\n",
        "- 予測負荷アンサンブルを使用する利点としては、精度が向上すること、複数の要因を考慮できることなどが挙げられます。\n",
        "- しかし、作成と維持がより複雑になり、時間がかかることもあります。\n",
        "\n",
        "- 負荷予測アンサンブルの具体例としては、レーダー、温度センサー、地元の気象台など、複数のソースからのデータを組み合わせて、より正確な予測を行う天気予報が挙げられます。\n",
        "\n",
        "- この方法では、複数の予測のアンサンブルを、過去の実績に応じて重み付けすることで、より精度の高い予測を導き出すことができます。\n",
        "- このアンサンブルを利用して予測を行うのですが、変数、項、係数、定数は各予測のパラメータであり、アンサンブルで使用する重みと組み合わせ方法です。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r9KtN11NayFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### \"AutoML \"モデル選択を簡単にする\" \n",
        "- 自動モデル選択、アンサンブル、ヘッジは、機械学習における予測の精度とロバスト性を向上させるために使用される技術です。\n",
        "- 自動的なモデル選択の一例として、教師がクラスの過去のテストの成績に基づいて、どのテストを行うかを決めようとすることがあります。\n",
        "- 教師はコンピュータ・プログラムを使ってクラスの成績を分析し、プログラムが予測するクラスの成功率が最も高いテストを選択することができる。\n",
        "- もう一つのアンサンブルの例は、シェフが複数の食材を使って料理を作ることです。\n",
        "- シェフは、どの組み合わせが最も美味しい料理になるか、様々な食材の組み合わせを試すことができます。\n",
        "- ヘッジは、金融におけるポートフォリオの多様化に似ています。\n",
        "- 例えば、農家は複数の作物を植えて、天候不順や病気が作物の1つに影響を与えるリスクをヘッジすることができます。\n",
        "- AutoMLは、これらの技術をすべて組み合わせて、最適なモデル、アンサンブル、ヘッジを自動的に選択し、予測の精度とロバスト性を向上させます。\n",
        "\n"
      ],
      "metadata": {
        "id": "lmhVJMe0XZsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **スマートなモデル選択。効率的で正確な予測を実現するautoMLの活用**\n",
        "\n",
        "autoMLの活用例として、天気予報のウェブサイトで、場所と時期に応じて天気を予測するための最適なモデルを自動的に選択するものがあります。このウェブサイトでは、夏と冬、あるいは国内の異なる地域の天気を予測するために、異なるモデルを使用するかもしれません。また、使用するモデルを、最近のパフォーマンスに基づいて自動的に調整することも可能です。このようにして、最も正確な天気予報を提供することができるのです。\n",
        "\n",
        "また、カメラやライダーなどの複数のセンサーを使って、道路上の物体を検知・識別する自動運転車もその一例です。このクルマのコンピューターシステムは、日中や夜間、天候などの状況に応じて、最適なセンサーやセンサーの組み合わせを自動で選択する「autoML（オートエムエル）」を使っています。これにより、クルマは安全かつ効率的に走行することができるのです。\n",
        "\n",
        "また、AutoMLは医療用画像処理にも応用でき、画像の種類や患者の情報に基づいて、特定の病気や状態を検出するのに最適なアルゴリズムを自動的に選択することができます。これにより、手動でアルゴリズムを選択する場合と比較して、時間を節約し、精度を向上させることができます。\n",
        "\n",
        "本手法を一言で表すキャッチフレーズは、\"Automated model selection for optimized results\"（最適な結果を得るための自動モデル選択）です。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PO2tj-KPXu_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"アベレージアップ 数学的平均のさまざまな種類を理解する \"\n",
        "\n",
        "平均値。集合の中のすべての数の合計を集合の中の数の数で割ったもの。統計学やデータ分析でよく使われる。*例 例：1、2、3の平均は2（1+2+3=6、6/3=2）。\n",
        "中央値。数字の集合を順番に並べたとき、その中の真ん中の数字。データセットの中心値を求めるのに使用する。*例 例：1、2、3、4、5の中央値は3である。\n",
        "最頻値。最頻値: 数値の集合の中で最も頻繁に出現する数字。統計やデータ解析でよく使われる。*例 例：1、2、2、3、4、5 の最頻値は 2 である。\n",
        "範囲。ある集合の中の最大値と最小値の差。データセットの広がりを測定するために使用される。*例 例：1、2、3、4、5の数値の範囲は4（5-1＝4）である。\n",
        "加重平均。平均の一種で、集合内の各数値の重要度または重みを考慮する。*例 例：ある生徒のクラスでの成績は、テストの点数（50％）、宿題（30％）、参加度（20％）の加重平均である。\n",
        "Harmonic Mean（調和平均）。平均の一種で、集合の中の数字が率や比率である場合に使用される。*例 例：2、4、8の調和平均は4（12/(1/2+1/4+1/8)=4）。\n",
        "幾何平均。平均の一種で、集合の中の数字が成長率や乗法関係を表す場合に使用される。*例 例：2、4、8の幾何平均は4（sqrt(2x4x8)=4)\n",
        "これらは、存在するさまざまな種類の数学的平均のほんの一例に過ぎません。それぞれ固有の使用例があり、文脈に応じてデータセットに異なる洞察を与えることができる。分析に最適なものを選ぶには、それぞれの類似点と相違点、そしてメリットとデメリットを理解することが重要です。"
      ],
      "metadata": {
        "id": "iyQOmDzJ60OA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pythonでは、さまざまな種類の平均を計算する方法がいくつかあります。以下はその例です。\n",
        "\n",
        "幾何平均。幾何平均は、n個の数値の積のn乗根です。Pythonでは、scipy.stats.gmean()関数を使用して、数値のリストの幾何平均を計算することができます。例えば\n",
        "python\n",
        "コピーコード\n",
        "from scipy.stats import gmean\n",
        "\n",
        "数値 = [1, 2, 3, 4, 5］\n",
        "print(gmean(numbers))\n",
        "加重平均 加重平均は、各値に対応する重みをかけ、重みの合計で割ることによって計算されます。Pythonでは、数値のリストの加重平均を計算するために、numpy.average()関数をweightsパラメータで使用することができます。例えば\n",
        "python\n",
        "コピーコード\n",
        "numpyをnpとしてインポートする\n",
        "\n",
        "値 = [1, 2, 3, 4, 5］\n",
        "ウェイト = [1, 2, 3, 4, 5].\n",
        "print(np.average(values, weights=weights))\n",
        "調和平均(Harmonic mean)。調和平均は、数値の集合の逆数の算術平均の逆数である。Pythonでは、数値のリストの調和平均を計算するために、scipy.stats.hmean()関数を使用することができます。たとえば\n",
        "python\n",
        "コピーコード\n",
        "from scipy.stats import hmean\n",
        "\n",
        "数値 = [1, 2, 3, 4, 5］\n",
        "print(hmean(numbers))\n",
        "単純平均 単純平均は、数値の集合の合計を数値の数で割ったものです。pythonでは、pythonの組み込み関数sum()とlen()を使って平均を計算することができます。\n",
        "python\n",
        "コピーコード\n",
        "numbers = [1, 2, 3, 4, 5] (数字)\n",
        "平均値 = sum(数字)/len(数字)\n",
        "print(平均)\n",
        "上記のすべての関数は、入力が空でない数値のリストである場合にのみ適用されることに注意してください。また、scipy.stats.hmean()関数を使用する場合、調和平均は0でない数値のリストに対してのみ定義されることに留意することが重要です。"
      ],
      "metadata": {
        "id": "fjwFLcuA9b6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Averages 101: Understanding different ways to measure 'average'\" （平均を測るさまざまな方法を理解する）\"\n",
        "\n",
        "単純平均。これは、一連の数値の「平均」を求める最も一般的な方法である。すべての数値を足し、数値の数で割って求めます。例えば、リンゴ3個とオレンジ4個がある場合、単純平均は (3+4)/2 = 3.5となる。\n",
        "\n",
        "幾何平均。一組の数字を掛け合わせ、平方根（2個の場合）、立方根（3個の場合）などを取ることで平均値を求める方法である。数値が時間の経過に伴う成長率を表す場合に有効である。例えば、ある年に10％、次の年に20％成長する投資がある場合、幾何平均は（1.1 * 1.2）^(1/2) = 11.4％となります。\n",
        "\n",
        "加重平均。これは、一連の数値の平均を求める方法だが、各数値に「重み」または乗数を与えてから足し算、割り算を行う。ある数値が他の数値よりも重要であったり、関連性があったりする場合に使用される。例えば、あなたが5つの質問と質問1が2点の価値があり、他のものは1点の価値があるテストを持っている場合、加重平均は（2 *質問1のスコア+質問2のスコア+質問3のスコア+質問4のスコア+質問5のスコア）/ 5であろう。\n",
        "\n",
        "調和平均。集合の数の平均を求める方法で、集合の中の数の逆数の和で割る。マイル/時などの速度を比較するときによく使われる。例えば、ある車の速度を3つの区間で平均しようとした場合、1マイルは時速60マイル、2マイルは時速70マイル、3マイルは時速80マイルとすると、調和平均は (3)/(1/60 + 1/70 + 1/80) = 69.1mph となる。\n",
        "\n",
        "単純平均。一組の数字の平均を求める方法で、数字を足してその数で割る。\n",
        "\n",
        "幾何平均。2つの数を掛け合わせ、平方根（2つの数の場合）または立方根（3つの数の場合）などを取ることによって、一連の数の平均を求める方法。\n",
        "\n",
        "加重平均。加算と除算の前に各数値に重みまたは倍率を与えることによって、一連の数値の平均を求める方法。\n",
        "\n",
        "調和平均。集合の中の数の逆数の和で割ることによって、集合の数の平均を求める方法。\n",
        "\n",
        "単純平均。\"割り算 \"と \"割り算\"\n",
        "\n",
        "幾何学的平均値 \"倍数と根\"\n",
        "\n",
        "加重平均(Weighted Mean) \"加重平均\"\n",
        "\n",
        "調和平均(Harmonic Mean) \"逆平均\" (Reciprocal Average)\n",
        "\n",
        "Simple Mean（単純平均）。ピザを皆に平等に分けるようなもの。\n",
        "\n",
        "幾何学的平均。ピザを焼くたびに、ピザの大きさを掛け合わせるようなもの。\n",
        "\n",
        "加重平均。あるピザに他のピザより多くのトッピングやチーズをのせるようなもの。\n",
        "\n",
        "調和的平均。ピザを食べる速さを測定するようなもの。\n",
        "\n",
        "単純平均。平均的な成績、打率、気温の平均などを求めるのに使う。\n",
        "\n",
        "幾何平均。平均成長率、株式市場のリターンなどを求めるのに使用する。\n",
        "\n",
        "加重平均。テストの平均点、調査結果などを求めるのに使用する。\n",
        "\n",
        "調和平均。平均的な速度、レートなどを求めるのに使用される。"
      ],
      "metadata": {
        "id": "C6S4BvkF9etB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは、それぞれのタイプの平均がどのように異なるシナリオで使用されるのか、いくつかの例を示します。\n",
        "\n",
        "幾何平均。株式市場のポートフォリオの成長率を追跡することを想像してください。幾何平均はポートフォリオのリターンの複利効果を考慮しており、リターンが不安定な場合には特に重要です。これにより、ポートフォリオ全体の成長率をより正確に把握することができます。\n",
        "\n",
        "加重平均。クラスのテストの点数を平均化するとします。しかし、各テストは最終的な成績を決定する上で異なる重みを持っています。加重平均では、各テストに異なる加重を割り当て、より重要なテストが最終評点に大きな影響を与えるようにすることができます。\n",
        "\n",
        "調和平均。旅行中の車の平均速度を計算しようとしているが、各停留所で費やした時間も考慮したいと想像してください。調和平均では、車が速く移動した部分はより重視され、停止した部分はより重視されないので、旅行全体の速度をより反映したものとなります。\n",
        "\n",
        "単純平均。ある都市の気温を1ヶ月間平均することを想像してください。単純平均は算術平均とも呼ばれ、すべての気温を足して日数で割るだけで、各日に等しい重みを与える。\n",
        "\n",
        "それぞれの平均値には利点と欠点があり、使用するデータのシナリオと文脈に依存することに留意することが重要です。また、場合によっては、より全体像を把握するために、複数のタイプの平均を使用することがより適切であることも知っておくとよいでしょう。"
      ],
      "metadata": {
        "id": "EZR-51qyCXpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"バランシング・アクト 加重平均を使用する理由を理解する \"\n",
        "\n",
        "Weighted Averageは、ある値が他の値よりも重要であったり、重みがあったりする場合に、全体の平均を決定するために使用されます。\n",
        "\n",
        "たとえば、5つの質問からなるテストで、質問1が80%、質問2が90%、質問3が70%、質問4が60%、質問5が90%で、質問5は他の質問の2倍の価値があるとすると、加重平均は (801 + 901 + 701 + 601 + 90*2)/(1+1+1+1+2) = 80% となります。\n",
        "\n",
        "加重平均は、異なる項目の価値が同じではなく、いくつかの項目が他の項目よりも重要である場合に使用されます。\n",
        "\n",
        "たとえば、5 つの質問があるアンケートに回答しているとします。各質問は 1 ポイントの価値がありますが、最後の質問には 2 ポイントの価値があります。これは、最後の質問が他の質問よりも重要であり、全体の平均スコアにおいてより大きなウェイトを占めることを意味します。\n",
        "\n",
        "加重平均は、より重要な値や項目により多くの重みを与えるので、「優先順位平均」のようなものです。\n",
        "\n",
        "例えば、5つの材料からなるレシピを作るとします。各材料は1点の価値がありますが、最後の材料は2点の価値があります。これは、最後の材料が他の材料よりも重要であり、全体のレシピの中でより多くの重みを持つことを意味します。\n",
        "\n",
        "加重平均は、それぞれの値や項目の重要性を考慮するため、「バランスの取れた平均」のようなものです。\n",
        "\n",
        "例えば、あなたが友人とトランプゲームをしているとします。各カードは 1 ポイントの価値がありますが、最後のカードは 2 ポイントの価値があります。これは、最後のカードが他のカードよりも重要であり、ゲーム全体においてより多くの重みを持つことを意味します。\n",
        "\n",
        "加重平均は、異なる価値や項目の「重要度」を測定するようなものです。\n",
        "\n",
        "例えば、あなたが大学の専攻を選んでいるところを想像してください。各専攻は1点の価値がありますが、最後の専攻は2点の価値があります。これは、最後の専攻が他の専攻よりも重要であり、全体的な決定においてより多くの重みを持つことを意味します。"
      ],
      "metadata": {
        "id": "EhAh261V_xBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"強くなる \"ために。Geometric Meansを使う理由を理解する\"\n",
        "\n",
        "幾何平均は、株式市場のリターンや人口増加のように、値を掛け合わせたときの平均的な成長率を求めるために使われます。\n",
        "\n",
        "例えば、ある銘柄の3年間のリターンが2%、5%、10%だった場合、幾何平均リターンは (1.02 * 1.05 * 1.1)^(1/3) - 1 = 5.32% となります。\n",
        "\n",
        "幾何平均は、値を掛け合わせたときに使用され、成長率やリターンの平均を示します。\n",
        "\n",
        "例えば、植物の成長を追跡しているとしよう。この植物は3日間で1インチ、2インチ、3インチと成長します。幾何平均の成長率は、1日あたり(123)^(1/3)=2インチとなります。\n",
        "\n",
        "幾何平均は、時間の経過による成長を考慮するため、「複合平均」のようなものです。\n",
        "\n",
        "例えば、あなたが銀行口座にお金を貯めていると想像してください。金利は2％、5％、3年後に10％です。幾何平均の金利は、(1.02 * 1.05 * 1.1)^(1/3) - 1 = 5.32% となります。\n",
        "\n",
        "幾何平均は、値が掛け合わされることを考慮するので、「掛け合わせ平均」のようなものです。\n",
        "\n",
        "例えば、サイコロゲームをしているとします。サイコロを振って、2、5、10の3つの目が出たとします。幾何平均の出目は (2510)^(1/3) = 5.32 となります。\n",
        "\n",
        "幾何平均は、異なる値や項目の「複合成長率」を測定するようなものです。\n",
        "\n",
        "たとえば、ある都市の人口増加を追跡しているとする。人口は3年間で2％、5％、10％成長する。幾何平均の人口成長率は、(1.02 * 1.05 * 1.1)^(1/3) - 1 = 5.32% となります。"
      ],
      "metadata": {
        "id": "g4DEA9hgAVXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\" スピーディーな平均値。調和平均を使用する理由を理解する\"\n",
        "\n",
        "調和平均は、複数の異なる速度や速度の全体的な平均を求めようとするときに、速度や速度の平均を求めるために使用されます。\n",
        "\n",
        "例えば、時速60マイルで1時間、時速70マイルで2時間、時速80マイルで3時間走行した場合、調和平均は（3）/（1/60 + 1/70 + 1/80） = 69.1mph となります。この場合、3つの速度の単純平均を取るよりも、より正確な速度の全体平均が得られます。\n",
        "\n",
        "調和平均は、各速度での滞在時間を考慮するため、速度などの割合の平均を求めたい場合に使用します。\n",
        "\n",
        "例えば、1分間に2周のスピードで5分間、1分間に4周のスピードで10分間、1分間に6周のスピードで15分間泳いだ場合、調和平均は (30)/(5/2 + 10/4 + 15/6) = 3.6 laps per minuteとなります。\n",
        "\n",
        "調和平均は、遅い速度やスピードに重きを置いているので、速い速度やスピードに「引きずられる」ことがなく、「公平な平均」のようなものです。\n",
        "\n",
        "例えば、あなたが友人と一緒にレースを走っているとします。友人はレース中ずっと時速10マイルで走っているが、あなたは前半は時速8マイル、後半は時速12マイルで走っている。調和平均は、前半の時速8マイルの遅いペースをより重視し、レース中のあなたのスピードの全体的な平均をより公正にします。\n",
        "\n",
        "調和平均は「時間加重平均」のようなもので、各レートやスピードで費やした時間が考慮されます。\n",
        "\n",
        "例えば、ケーキを焼くことを想像してみてください。低速で5分、中速で10分、高速で5分と材料を混ぜていきます。調和平均は、各スピードで費やした時間を考慮し、より正確な全体平均ミキシングスピードを算出することができます。\n",
        "\n",
        "調和平均は、異なるレートやスピードの「公平さ」を測定するようなものである。\n",
        "\n",
        "例えば、あなたが友人とミニゴルフをしているとします。友達は各ホールで異なるスコアを持っていますが、調和平均は各ホールの難易度を考慮した公平な全体平均スコアを出すでしょう。"
      ],
      "metadata": {
        "id": "ef6rL24o_fBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **完璧を目指すファインチューニングパラメータチューニング**\n",
        "- 機械学習モデルの設定を調整し、その性能を最適化することである。\n",
        "\n",
        "- 例えば、クッキーを焼くレシピを想像してください。\n",
        " - レシピには、小麦粉、砂糖、卵などの材料と、それぞれの材料の使用量、クッキーを焼く時間などが書かれている。\n",
        " - レシピは機械学習モデルのようなもので、材料はモデルのパラメーターのようなものです。\n",
        " - パン屋さんが砂糖の量や焼く時間を調整してクッキーをより甘くしたり、よりサクサクにしたりするように、データサイエンティストは機械学習モデルのパラメータを調整して性能を向上させることができるのです。\n",
        "\n",
        "- 例えば、自動車のエンジンには、混合気、点火時期、バルブタイミングなど、性能を向上させるために調整可能なさまざまな設定があります。\n",
        "- それと同じように、機械学習モデルにも、性能を向上させるために調整可能なさまざまなパラメータがある。\n",
        "\n",
        "- つまり、レシピの材料や車のエンジンの設定を調整するように、機械学習モデルの設定を調整して性能を最適化することが、パラメーターチューニングである。\n",
        "\n"
      ],
      "metadata": {
        "id": "rBTpxCccWE9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"精度のための微調整\"ForecastingGridSearchCV \"**\n",
        "\n",
        "- 予測モデルの最適なパラメータセットを見つけるためのメソッドです。\n",
        "\n",
        "- 完璧なケーキを作りたいが、砂糖、小麦粉、卵をどれくらい使えばいいのか分からないと想像してください。\n",
        "- いろいろなケーキを作っていろいろな組み合わせを試すこともできますが、それでは時間がかかり、無駄が多くなります。\n",
        "- その代わり、ForecastingGridSearchCVを使えば、材料の様々な組み合わせを素早くテストして、最適なレシピを見つけることができます。\n",
        "\n",
        "- 同様に，予測では，使用する過去のデータ点の数や適合させるトレンドの種類など，異なるパラメータを使用するモデルがあるかもしれません．\n",
        "- ForecastingGridSearchCVは、これらのパラメーターの様々な組み合わせを素早くテストし、正確な予測を行うための最適なセットを見つけることができます。\n",
        "- しかし、計算コストがかかる可能性があることに注意することが重要です。\n"
      ],
      "metadata": {
        "id": "UXsQfzo5Weds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサは、パイプラインにおいて、特定の条件に基づいてパイプラインの異なるステージ間でデータをルーティングするためによく使用されます。ここでは、パイプラインにおけるマルチプレクサの具体的な使用例と事例をいくつか紹介します。\n",
        "\n",
        "プリプロセッシング。マルチプレクサは、入力データの種類に応じて異なる前処理工程にデータをルーティングするために使用されます。例えば、入力データが画像の場合、マルチプレクサはそのデータを画像処理ステップにルーティングし、入力データがテキストの場合、マルチプレクサはそのデータをテキスト処理ステップにルーティングすることができます。\n",
        "\n",
        "特徴量の選択。マルチプレクサは、入力データの種類に応じて異なる特徴選択方式にデータをルーティングするために使用される。例えば、入力データが時系列であれば、時系列特徴選択手法にルーティングし、入力データが表形式データであれば、表形式データ特徴選択手法にルーティングすることができる。\n",
        "\n",
        "モデル選択 マルチプレクサは、入力データの種類に応じて異なるモデルにデータをルーティングするために使用される。例えば、入力データが時系列であれば時系列モデルへ、表形式データであれば表形式データモデルへルーティングさせることができる。\n",
        "\n",
        "ハイパーパラメータのチューニング。マルチプレクサは、入力データの種類に応じて異なるハイパーパラメータチューニング手法にデータをルーティングするために使用される。例えば、入力データが時系列である場合、マルチプレクサはデータを時系列のハイパーパラメータチューニング手法にルーティングし、入力データが表形式データである場合、マルチプレクサはデータを表形式データのハイパーパラメータチューニング手法にルーティングすることが可能である。\n",
        "\n",
        "マルチプレクサは、if else 条件、switch case など、さまざまな方法で実装できることに留意することが重要です。実装方法は、要件と特定のユースケースに依存する。\n",
        "\n",
        "まとめると、マルチプレクサは、前処理、特徴選択、モデル選択、ハイパーパラメータチューニングといったパイプラインの様々な段階で使用でき、特定の条件に基づいてパイプラインの異なる段階にデータをルーティングし、パイプラインをより柔軟かつ効率的にすることができる。"
      ],
      "metadata": {
        "id": "0_YOfsVG1v6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサは、パイプラインを流れるデータの流れを制御するために使用されるツールです。特定の条件に基づいて、パイプラインの異なる部分にデータを誘導することで機能します。ここでは、その使用例をいくつか紹介します。\n",
        "\n",
        "プリプロセッシング。画像やテキストなど、異なるタイプのデータがある場合、マルチプレクサを使用してデータを適切な場所に送り、処理することができます。\n",
        "\n",
        "特徴量の選択。時系列や表などの異なるタイプのデータがある場合、マルチプレクサを使用して、重要な特徴を抽出するためにデータを適切な場所に送ることができます。\n",
        "\n",
        "モデルの選択。時系列や表などの異なるタイプのデータがある場合、マルチプレクサを使用して、予測に適したモデルへデータを送ることができます。\n",
        "\n",
        "ハイパーパラメータのチューニング。時系列や表などの異なるタイプのデータがある場合、マルチプレクサを使用して、モデルのパラメータを微調整するために適切な場所にデータを送信することができます。\n",
        "\n",
        "簡単に言えば、マルチプレクサはデータの交通整理のようなもので、適切なタイミングで適切な場所にデータを送り、パイプラインをより柔軟かつ効率的にする。マルチプレクサは、要件と特定のユースケースに応じて、さまざまな方法で実装することができます。"
      ],
      "metadata": {
        "id": "HtNr2kZ82X_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサとパイプラインの文脈では、ルーティングとは、特定の条件に基づいてパイプラインの異なる部分にデータを指示または送信するプロセスを指します。これは、交通整理員が目的地に基づいて車を別の方向に誘導するようなものです。\n",
        "\n",
        "例えば、異なる種類のデータを処理するパイプラインでは、マルチプレクサを使用してテキストデータをテキスト前処理モジュールにルーティングし、画像データを画像前処理モジュールにルーティングすることができます。同様に、予測に複数のモデルを使用するパイプラインでは、マルチプレクサを使用して、データの種類や実行される特定のタスクに基づいて、適切なモデルにデータをルーティングすることができます。\n",
        "\n",
        "このように、ルーティングはパイプラインの柔軟性を高め、データが最も適切な方法で処理されるようにすることで、パイプラインの性能を最適化するのに役立ちます。"
      ],
      "metadata": {
        "id": "R7vUKLuU3KSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサは、レストランの厨房における料理長のようなものであると考えることができます。シェフが異なる料理人に異なる時間に異なる料理を作るように、マルチプレクサはパイプラインの異なる部分に異なる時間にデータを送ります。\n",
        "\n",
        "パイプラインは料理のレシピのようなものだと考えることができます。レシピが生の材料を使い、完成した料理に仕上げるように、パイプラインは生のデータを使い、有用な情報に仕上げる。\n",
        "\n",
        "モデルは、シェフの秘密のレシピのようなものだと考えることができます。モデルは、生データを有用な情報に変える方法をパイプラインに指示する一連の命令である。\n",
        "\n",
        "データは、料理に使われる原材料と考えることができる。原材料がレシピの入力であるように、データはパイプラインの入力である。\n",
        "\n",
        "学習は、料理を完成させるためのプロセスと考えることができます。シェフが時間をかけてレシピを実験し、洗練させていくように、機械学習アルゴリズムも新しいデータから学習することで、時間とともに性能を向上させていく。\n",
        "\n",
        "この文脈では、マルチプレクサは、いつ、どんな料理を作るかを厨房のスタッフに指示する料理長のような役割を果たします。同様にマルチプレクサは、状況に応じてデータをパイプラインの異なる部分に誘導します。パイプラインはレシピのようなもので、生のデータをどのように有用な情報に変えるかを指示する一連の命令である。モデルはシェフの秘密のレシピのようなもので、パイプラインにデータをどのように処理するかを指示する一連の指示です。データは料理の原材料のようなものであり、学習は時間をかけてレシピを実験し改良していくようなものです。"
      ],
      "metadata": {
        "id": "rEzI7T0v34Id"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサは、交通整理の警官のようなものと考えることができます。トラフィックコップが異なる時間に異なるレーンに異なる車を誘導するように、マルチプレクサは異なる時間にパイプラインの異なる部分にデータを誘導するのです。\n",
        "\n",
        "パイプラインは、工場の組立ラインと考えることができます。パイプラインは、工場の組立ラインのようなもので、原料を集めて完成品にするように、生データを集めて有用な情報に変える。\n",
        "\n",
        "モデルは、設計図と考えることができます。設計図が工場で製品の組み立て方を指示するように、モデルはパイプラインに生データを有用な情報に変える方法を指示する一連の命令である。\n",
        "\n",
        "データは、組立ラインで使用される原材料と考えることができます。原材料が組立ラインの入力であるように、データはパイプラインの入力である。\n",
        "\n",
        "学習は、組立ラインを改良する過程と考えることができる。工場が失敗から学ぶことで時間をかけて生産工程を改善するように、機械学習アルゴリズムも新しいデータから学ぶことで時間をかけて性能を向上させる。\n",
        "\n",
        "この文脈では、マルチプレクサは交通整理のような役割を果たし、状況に応じて交通を別の車線に誘導する。同様に、マルチプレクサは状況に応じてパイプラインの別の部分にデータを誘導する。パイプラインは工場の組立ラインのようなもので、生データをどのように有用な情報に変えるかを指示する一連の命令である。モデルは設計図のようなもので、パイプラインにデータをどのように処理するかを指示する命令書のセットです。データは工場の組立ラインで使われる原材料のようなものであり、学習は組立ラインを時間をかけて改良するようなものである。"
      ],
      "metadata": {
        "id": "UYKmt6HR42us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサは、部門管理者のようなものだと考えることができます。部長が異なる仕事を異なる時間に異なる従業員に割り当てるように、マルチプレクサは異なる時間にパイプラインの異なる部分にデータを誘導する。\n",
        "\n",
        "パイプラインは、企業のワークフローと考えることができます。企業のワークフローが生の資源を取り込んで完成品にするように、パイプラインは生のデータを取り込んで有用な情報に変える。\n",
        "\n",
        "モデルとは、企業の戦略のようなものです。企業の戦略が社員に生資源をどのように完成品に変えるかを指示するように、モデルはパイプラインに生データをどのように有用な情報に変えるかを指示する一連の命令である。\n",
        "\n",
        "データは、ワークフローで使用される生のリソースと考えることができます。ちょうど、会社のワークフローのインプットが原材料であるように、パイプラインのインプットとなるのです。\n",
        "\n",
        "学習は、ワークフローを洗練させるプロセスと考えることができる。企業が失敗から学ぶことで時間をかけて生産プロセスを改善するように、機械学習アルゴリズムも新しいデータから学ぶことで時間をかけてパフォーマンスを向上させる。\n",
        "\n",
        "この文脈では、マルチプレクサは、状況に応じて異なるタスクを異なる従業員に割り当てる部長のような役割を果たします。同様に、マルチプレクサは、状況に応じてデータをパイプラインの異なる部分に誘導します。パイプラインは企業のワークフローのようなもので、生データをどのように有用な情報に変えるかを指示する一連の命令である。モデルは企業の戦略のようなもので、パイプラインにどのようにデータを処理するかを指示する命令セットです。データは企業のワークフローで使用される原材料のようなものであり、学習はワークフローを時間をかけて洗練させるようなものである。"
      ],
      "metadata": {
        "id": "jf3789ce5D_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサは、特定の条件や状況に応じて、パイプラインの異なる部分にデータを誘導することを決定します。これらの条件や状況は、データの種類、希望する結果、パイプラインの現在の状態など、さまざまな要因に基づくことができます。\n",
        "\n",
        "例えば、パイプラインが数値データとカテゴリーデータの両方を処理するように設計されているとします。この場合、マルチプレクサは、数値データを線形回帰モデルで処理するパイプラインの一部に、カテゴリーデータを決定木モデルで処理するパイプラインの別の一部に導くようにプログラムすることができる。\n",
        "\n",
        "別の例として、パイプラインが画像データを扱うように設計されている場合、マルチプレクサを使用して、画像のサイズや解像度に応じてパイプラインの異なる部分に画像を誘導することができます。画像が高解像度であれば、マルチプレクサは画像を深層学習モデルに導いてさらに処理させることができますし、画像が低解像度であれば、マルチプレクサは画像をより単純なモデルに導いて処理させることができるのです。\n",
        "\n",
        "これは交通整理の警官のように、交通状況に応じて交通を異なる方向に誘導するのと同じで、マルチプレクサはデータの状況に応じてパイプラインの異なる部分にデータを誘導する。"
      ],
      "metadata": {
        "id": "sdk6c3zQ588C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "機械学習の文脈では、パイプラインとは一般に、モデリングや分析のために入力データに適用される一連のステップや変換を指す。これらのステップには、データの前処理、特徴の選択または抽出、次元の削減、およびモデルのトレーニングまたは評価などのタスクが含まれることがあります。また、パイプラインには複数のモデルやアルゴリズムが含まれることもあり、これらは順番に学習・評価される。パイプラインを使用する背景には、機械学習モデルの構築と評価のプロセスを自動化して合理化し、結果の再現を容易にし、パイプラインのさまざまなバリエーションを試して最もパフォーマンスの高いものを見つけるという考えがある。"
      ],
      "metadata": {
        "id": "CDXEK-pU75m5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"強いパイプラインを作る。異種材料の組み合わせによる性能向上\"**\n",
        "\n",
        "- ビルが鉄とコンクリートといった異なる種類の材料を使うことでより強くなるように、予測パイプラインも異なる手法や技術を組み合わせることでより強くすることができます。\n",
        " - 例えば、パイプラインは指数平滑化を使って予測を行いますが、データ中の長期的な傾向を取り除くためのトレンド除去のステップも含まれるかもしれません。\n",
        "\n",
        "- 同様に、自転車もアルミニウムとカーボンファイバーといった異なる素材を組み合わせることで、より強くすることができます。\n",
        "- また、鉛筆は黒鉛と粘土を組み合わせることで、より強くすることができます。\n",
        "\n",
        "- パイプラインを構築する際には、それぞれの手法や技法の長所と短所、そしてそれらがどのように作用して性能を向上させるのかをよく検討することが重要です。\n",
        " - これは、エンジニアが建物や自転車を設計するときに、さまざまな材料の特性を考慮しなければならないのと同じです。\n",
        " - また、検査官が建物や自転車の品質をチェックするように、パイプラインのパラメータを検査し、可能な限りうまく機能していることを確認することも重要です。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v1KJV-YzVgYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "指数平滑化とは、過去のデータから将来の事象や傾向を予測する時系列予測手法の一つです。金融、経済、工学などの分野でよく利用される。機械学習では、指数平滑化手法をパイプラインの一段階として取り入れることができる。\n",
        "\n",
        "パイプラインは、データの前処理、特徴量の抽出、モデルの選択と学習、モデルの評価といった複数のステップをまとめることで、機械学習のプロセスを効率化することができる。パイプラインのステップとして指数平滑化法を含めることで、ユーザーはこの方法をデータに簡単に適用し、他のステップと組み合わせて予測を行うことができる。\n",
        "\n",
        "例えば、時系列予測のためのパイプラインには、データクリーニング、特徴抽出、そして指数平滑化法を適用して予測を行うステップを含めることができる。このパイプラインは、異なるデータセットに対して容易に再利用、微調整が可能であり、プロセスの効率化、利便性を高めることができる。"
      ],
      "metadata": {
        "id": "gkWqm7KS_7N_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XtvWEizMBFml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Define the columns to be used in the multiplexer\n",
        "numerical_cols = ['column1', 'column2', 'column3']\n",
        "categorical_cols = ['column4']\n",
        "\n",
        "# Create the multiplexer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(), categorical_cols)])\n",
        "\n",
        "# Define the steps in the pipeline\n",
        "steps = [('preprocessor', preprocessor),\n",
        "         ('regressor', LinearRegression())]\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "X_train = df.drop('target', axis=1)\n",
        "y_train = df['target']\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Use the pipeline to predict on new data\n",
        "X_test = pd.read_csv(\"test_data.csv\")\n",
        "predictions = pipeline.predict(X_test)\n",
        "print(predictions)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "v0w8YlNiBGAa",
        "outputId": "b0408a01-7030-466a-a42f-c2c673d709a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a7b6938b7cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the data into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define the columns to be used in the multiplexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のコードは、時系列分析におけるマルチプレクサとパイプラインの使用方法を示すPythonのサンプルコードです。\n",
        "\n",
        "まず、必要なライブラリをインポートします。データの読み込みと処理には pandas、マルチプレクサとパイプラインの作成にはそれぞれ sklearn.compose と sklearn.pipeline の ColumnTransformer と Pipeline、数値データとカテゴリデータの処理には sklearn.preprocessing の StandardScaler と OneHotEncoder、回帰分析には sklearn.linear_model の LinearRegression が使用されています。\n",
        "\n",
        "データは read_csv() 関数を用いて pandas DataFrame にロードされ、multiplexer で使用するカラムは numerical_cols と categorical_cols として定義されています。\n",
        "\n",
        "マルチプレクサは、変換子のリストを受け取る ColumnTransformer を使って作成されます。各変換器は、文字列（変換器の名前）、推定量、変換器を適用する列のリストを含むタプルである。この場合、数値列は StandardScaler を用いて標準化され、カテゴリ列は OneHotEncoder を用いてワンホットエンコードされる。\n",
        "\n",
        "マルチプレクサは、パイプラインのステップのリストの最初のステップとして渡され、2番目のステップはLinearRegression estimatorとなります。パイプラインはPipelineクラスで作成し、ステップを渡します。\n",
        "\n",
        "そして、fit()メソッドを用いて、パイプラインを学習データにフィットさせます。学習データは、ターゲットカラムのないデータフレームとターゲットカラムのあるデータフレームをそれぞれ使用します。\n",
        "\n",
        "最後に、predict()メソッドを用いて新しいデータに対してパイプラインが予測され、その予測値が出力されます。\n",
        "\n",
        "機械学習においてマルチプレクサとパイプラインを使用する利点は以下の通りです。\n",
        "\n",
        "1つの変換器で数値データとカテゴリデータの両方を扱えること。\n",
        "モデルに渡す前に、データに複数の前処理を簡単に適用できる。\n",
        "テストや比較のために、パイプラインの異なる部分を簡単に切り替えることができる。\n",
        "このコードは、マルチプレクサとパイプラインを時系列分析に使用する方法の具体例ですが、このコンセプトは他の種類の機械学習タスクにも適用できます。マルチプレクサとパイプラインを様々な種類のデータやモデルで使用する他の例は、scikit-learn のドキュメントで見ることができます。"
      ],
      "metadata": {
        "id": "pYoBrw6mCh4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "マルチプレクサとパイプラインを含むPythonのサンプルコードです。この例では、時系列データセットに対して線形回帰分析を実行するコードになっています。データはpandas DataFrameにロードされ、分析に使用する数値列とカテゴリー列を指定することでマルチプレクサが定義されます。次に、数値列を標準化し、カテゴリ列をワンホットエンコーディングすることで、マルチプレクサがデータを変換するために使用されます。パイプラインは、第一段階としてマルチプレクサを、第二段階として線形回帰モデルを指定することにより定義される。そして、パイプラインを学習データにフィットさせ、パイプラインを使用して新しいデータで予測を行います。これは単なるサンプルであり、データファイルのパスは自分のものに置き換える必要があることに留意してください。"
      ],
      "metadata": {
        "id": "v14oHM-iB8j0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "指数平滑化のPython実装のサンプルは以下の通りです。\n",
        "\n",
        "Python\n",
        "コピーコード\n",
        "def exponential_smoothing(series, alpha):\n",
        "    result = [シリーズ[0]]. # 最初の値は series と同じ\n",
        "    for n in range(1, len(series)):\n",
        "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
        "    結果を返す\n",
        "\n",
        "- # 使用例\n",
        "alpha = 0.1\n",
        "series = [3, 10, 12, 13, 12, 10, 12] のようになります。\n",
        "smooth = exponential_smoothing(series, alpha)\n",
        "print(smooth)\n",
        "このコードは、時系列と平滑化係数(alpha)を入力とする関数exponential_smoothing()を定義しています。これは、元の系列の最初の値で新しいリストを初期化し、forループを使用して残りの値に指数関数的平滑化を適用します。この関数は，平滑化された系列を返します．\n",
        "\n",
        "使用例では、アルファ値0.1が使用され、exponential_smoothing()関数がサンプル系列に適用されています。そして、平滑化された系列が表示されます。\n",
        "\n",
        "alpha が 0 に近い場合、モデルは過去の観測値をより重視し、1 に近い場合、直近の観測値をより重視します。"
      ],
      "metadata": {
        "id": "wI5RbuLQw25g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_smoothing(series, alpha):\n",
        "    result = [series[0]] # first value is same as series\n",
        "    for n in range(1, len(series)):\n",
        "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "alpha = 0.1\n",
        "series = [3, 10, 12, 13, 12, 10, 12]\n",
        "smooth = exponential_smoothing(series, alpha)\n",
        "print(smooth)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wahM5Kpyx0xH",
        "outputId": "9fbd7048-f30e-4ab0-fd5e-e99744e73210"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 3.7, 4.53, 5.377, 6.0393, 6.43537, 6.991833]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OCZ0j_BsyUAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#　@title パイプラインのPythonコード例 \n",
        "from sklearn.pipeline import Pipeline # Pipeline クラスをインポート from sklearn.pipeline\n",
        "from sklearn.preprocessing import StandardScaler # StandardScaler クラスをインポート from sklearn.preprocessing\n",
        "from sklearn.linear_model import LinearRegression # LinearRegression クラスをインポート from sklearn.linear_model\n",
        "\n",
        "# パイプラインのステップを定義する\n",
        "# パイプラインのステップはタプルのリストで定義され、各タプルの最初の要素は文字列（すなわち、名前）である。\n",
        "# 各タプルの最初の要素は文字列(すなわち名前)であり，2番目の要素は対応する変換器または推定器クラスのインスタンスである．\n",
        "steps = [('scaler', StandardScaler()), # 最初のステップは'scaler'で，StandardScalerのインスタンスである．\n",
        "         ('regressor', LinearRegression())] # 二番目のステップは 'regressor' である．# 第二段階は 'regressor' で、LinearRegression のインスタンスである\n",
        "\n",
        "# パイプラインの作成\n",
        "pipeline = Pipeline(steps) # ステップのリストを渡してパイプラインオブジェクトを作成する。\n",
        "\n",
        "# 訓練データにパイプラインを当てはめる\n",
        "X_train = [[1, 2], [3, 4], [5, 6], [7, 8]] # 訓練データ。# 学習データ\n",
        "y_train = [1, 2, 3, 4] # トレーニングラベル\n",
        "pipeline.fit(X_train, y_train) # トレーニングデータにパイプラインをフィットさせる。\n",
        "\n",
        "# パイプラインを使って新しいデータを予測する\n",
        "X_test = [[9, 10], [11, 12]] # 新しいデータで予測を行う。# 新しいデータで予測を行う\n",
        "predictions = pipeline.predict(X_test) # 予測を行う。\n",
        "print(predictions) # 予測結果を表示する\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwJnVdbByUzS",
        "outputId": "91f3b6e2-a60b-4436-98f4-b51d1bc5244c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5. 6.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードでは、sklearn.pipeline の Pipeline クラスを使用して、単純な線形回帰モデル用のパイプラインを作成します。パイプラインは、入力データを標準化するStandardScalerステップと、モデルを適合させるLinearRegressionステップの2つのステップから構成されています。\n",
        "\n",
        "パイプラインのステップはタプルのリストで定義され、各タプルの最初の要素は文字列（すなわち名前）、2番目の要素は対応する変換器または推定器クラスのインスタンスである。\n",
        "\n",
        "パイプラインは，このステップリストをPipelineクラスに渡すことで作成される．そして、Pipelineオブジェクトのfit()メソッドを呼び出すことで、パイプラインを学習データにフィットさせる。そして、predict()メソッドがパイプラインオブジェクト上で呼び出され、新しいデータに対して予測を行います。\n",
        "\n",
        "この例では、パイプラインを使って学習データに線形回帰モデルをあてはめ、新しいデータ（X_test）に対して予測を行い、その予測を出力しています。\n",
        "\n",
        "なお、実際にはGridSearchCVやRandomizedSearchCVと組み合わせてパイプラインを使用し、ハイパーパラメータのチューニングを行うことが一般的です。"
      ],
      "metadata": {
        "id": "YP_1rzNmyaHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上のコードは、scikit-learnのパイプラインを使用して、機械学習のワークフローで複数のステップを連結する方法の例を示しています。パイプラインはステップのリストを渡すことで作成され、各ステップは文字列（ステップ名）と変換器または推定器クラスのインスタンスを含むタプルとして定義されます。\n",
        "\n",
        "この例では，2つのステップから構成されている．\n",
        "\n",
        "StandardScaler: 入力データを標準化する前処理ステップ。\n",
        "LinearRegression: データに線形回帰モデルをフィットさせる機械学習ステップ\n",
        "そして、パイプラインオブジェクトのfit()メソッドが呼ばれ、パイプラインを学習データにフィットさせます。フィットしたパイプラインは、predict()メソッドを呼び出すことで、新しいデータに対する予測に利用することができます。\n",
        "\n",
        "パイプラインを使用する利点は以下の通りです。\n",
        "\n",
        "機械学習モデルの構築・評価プロセスの簡素化\n",
        "機械学習ワークフローの複数のステップを1つのオブジェクトにカプセル化する。\n",
        "トレーニングデータとテストデータに同じ前処理を適用することで、データ漏洩のリスクを低減します。\n",
        "Scikit-learnライブラリは広く使われている機械学習ライブラリで、分類、回帰、クラスタリングなどの機械学習タスクのための様々な機能を提供します。\n",
        "\n",
        "注目すべきは、実際にはGridSearchCVやRandomizedSearchCVと組み合わせてパイプラインを使用し、ハイパーパラメータのチューニングを行うことが一般的である点です。これらのクラスは、指定されたパラメータ空間を探索し、クロスバリデーションを用いて最適なパイプラインを自動的に適合させる簡単な方法を提供します。\n"
      ],
      "metadata": {
        "id": "8Qv0IvfzzbSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"デトレンダー \"でスムーズな航海を。その利点と限界を理解する\"**\n",
        "\n",
        "- デトレンダーはグラフの消しゴムのようなものです。\n",
        "- 消しゴムで紙の上の鉛筆の跡を消すように、トレンド除去ツールを使えば、データの中の基本的な傾向を反映していないパターンを取り除くことができます。\n",
        " - 例えば、おもちゃの車の売上を時系列で表したグラフがあるとします。\n",
        " - しかし、その売上は毎年行われるプロモーションの影響を受けています。\n",
        " - デトレンダーは、このプロモーションの影響を取り除き、おもちゃの車の売上げの真の傾向を見ることができます。\n",
        "\n",
        "- デトレンダーは、カメラでいうところのフィルターです。フィルターを使って写真から特定の色や形を取り除くのと同じように、デトレンダーはデータから特定のパターンを取り除くのに使うことができます。\n",
        " - 例えば、ある都市の気温の経時変化のグラフがあったとします。\n",
        " - しかし、気温は季節の変化の影響を受けています。\n",
        " - デトレンダーは、季節の影響を取り除き、気温の真の傾向を見ることができるようにします。\n",
        "\n",
        "- デトレンダーは、庭の熊手のようなものです。\n",
        " - 熊手で庭の落ち葉やゴミを取り除くように、デトレンダはデータから不要なパターンを取り除くために使うことができるのです。\n",
        "- 例えば、あるWebサイトの訪問者数を時系列で表したグラフがあるとします。\n",
        " - しかし、訪問者数は休日の影響を受けています。\n",
        " - デトレンダーは、休日の影響を取り除き、訪問者数の真の傾向を見ることができるようにします。\n",
        "\n",
        "- デトレンダーを使用する利点としては、データの基本的な傾向をより良く特定できること、予測の向上、分析の精度の向上などが挙げられます。\n",
        "- しかし、デトレンダーには、データが過剰に補正される可能性や、情報が失われる可能性などの限界もあります。\n",
        "\n"
      ],
      "metadata": {
        "id": "erLDRRiOUuk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"段階的な予測構築\"**\n",
        "- 一例として、ロボットの組み立てがあります。\n",
        "- ロボットビルダーは、基本的なフレームから始めて、車輪、モーター、バッテリーなどさまざまなパーツを追加していきます。\n",
        "- 各パーツは構築プロセスのステップであり、最終的な成果物は動くロボットです。\n",
        "- 同様に、予測パイプラインでは、データのクリーニングと前処理、特徴の選択と変換、モデルの学習と評価を行い、各ステップが前のステップの上に構築されて最終的な予測が作成されます。\n",
        "\n"
      ],
      "metadata": {
        "id": "rFlNafxwT6jy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- パイプライン化とは、\n",
        " - ある工程の複数のステップを1つのパイプラインにまとめ、工程を効率化する手法です。\n",
        " - 例えば、おもちゃの車を作っている工場を想像してみてください。\n",
        " - パイプラインには、プラスチックの成形、車の塗装、車輪の取り付けなど、おもちゃの車を作るのに必要なすべての工程が含まれます。\n",
        " - 各工程は決まった順番で行われ、パイプラインの最後にはおもちゃの車が出来上がります。\n",
        "\n",
        "- デトレンドとは、\n",
        " - 時系列データからトレンドを除去する手法で、データのパターンをより明確にすることができる。\n",
        " - 例えば、子供の身長を時系列で表したグラフを想像してください。\n",
        " - 子供の身長が伸びるにつれて、身長は時間の経過とともに伸びていきます。\n",
        " - もし、子供の身長が伸びるという傾向を取り除くと、ある年齢でより早く伸びるなど、子供の成長のパターンをよりよく見ることができます。\n",
        "\n",
        "- 脱季節性とは、\n",
        " - 時系列データの季節成分を取り除くことで、データのパターンをより明確にすることができる手法です。\n",
        " - 例えば、あるお店で1年間に売れたアイスクリームコーンの個数のグラフを想像してください。\n",
        " - アイスクリームコーンの販売個数は、冬よりも夏の方が多いでしょう。\n",
        " - もし、データの季節的な要素を取り除けば、週末にお客さんが多いかどうかなど、データのパターンをよりよく見ることができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "NevVGl7rTOFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"プロセスの合理化 \"**\n",
        "を実現するパイプライン、リダクション、autoMLなどの「**Advanced Composition Patterns**」は、\n",
        "- モデルの構築とテストのプロセスを簡略化し、自動化するための方法です。\n",
        "\n",
        "- 例えば、ケーキを焼くことを想像してみてください。\n",
        "- パイプラインは、順番に必要な手順と必要な材料をすべて記したレシピのようなものだ。\n",
        "- リダクションは、いくつかのステップを省いたり、材料を少なくしたりしてレシピを簡略化するようなものです。\n",
        "- AutoMLは、あなたがケーキのデコレーションに集中している間に、あなたに代わってケーキを混ぜたり焼いたりする副料理長を持つようなものです。\n",
        "\n",
        "- 同様に、機械学習においても、パイプラインはモデル構築の全工程を容易に把握し、リダクションはモデルをよりシンプルかつ高速にするのに役立ち、AutoMLは最適なモデルの選択とチューニングのプロセスを自動化することができるのです。\n"
      ],
      "metadata": {
        "id": "OlfUxxHxSQlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"シータで過去と現在をバランスさせる\"**\n",
        "- 指数平滑化の文脈では、シータは予測において最近のオブザベーションに与えられる重みを制御するパラメータです。\n",
        " - これは「忘却係数」に似ています。\n",
        " - シータが1に近いほど、最近のオブザベーションに多くの重みが与えられ、\n",
        " - 0に近いほど、過去のデータに多くの重みが与えられます。\n",
        "\n",
        "- シータの具体的な動作例としては、翌日の気温の予測があります。\n",
        " - シータを高い値、例えば0.9に設定すると、予測は現在の気温に大きく依存し、過去数日の気温にはあまり依存しなくなる。\n",
        " - もしθが低い値、例えば0.1に設定されると、予測は過去の気温に大きく依存し、現在の気温にはあまり依存しなくなります。\n",
        "\n",
        "- 他の例として、株式市場の予測では、高いシータ値は最近の株価に重きを置き、低いシータ値は過去の株価に重きを置くと考えられます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_lMInwSIR8ZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"Unlocking Hidden Patterns\"隠れたパターンを解明する**\n",
        "- 状態空間モデル State-Space Models (Structural Time Series)\" は、推理小説で何が起こったのかを解明しようとする探偵のようなものです。\n",
        "- 探偵が犯罪を理解するためにさまざまな手がかりを見るように、状態空間モデルは時系列データのパターンを理解するためにさまざまなデータ点を見ます。\n",
        "\n",
        "- 例えば、ある店が毎日何人の客が来るかを予測しようとする場合を想像してください。 - このような場合、天候、休日、過去の売上に関するデータを調べて、顧客の行動パターンを理解することができます。\n",
        "- 状態空間モデルは、これらの要因のうち、どの要因が客数に最も大きな影響を与えるかを把握し、より正確な予測を行うために使用することができます。\n",
        "\n",
        "- 別の例として、天気予報では、状態空間モデルを使用して、気温、気圧、風のデータを時系列で分析し、将来の天気パターンを予測することができます。\n",
        "\n",
        "- 状態空間モデルの長所は、複雑で非線形な関係を扱えること、複数の不確実性の原因を考慮できることです。\n",
        " - デメリットとしては、大量のデータが必要であること、モデルの推定が複雑であることなどが挙げられる。\n",
        "\n",
        "- 要約すると、状態空間モデルは、データを使って隠れたパターンを発見し、予測を行う探偵のようなものである。\n",
        " - 時系列データを分析するための強力なツールですが、多くのデータを必要とし、設定も複雑です。\n",
        "\n"
      ],
      "metadata": {
        "id": "RWuPTsBXPl2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\"Facebook Prophetを使った予測\" \n",
        "- Facebook Prophetは、人々が将来の出来事について予測を立てるのを助けるツールである。\n",
        " - まるで物語やゲームの中で次に何が起こるかを推測するようなものです。\n",
        " - Facebook Prophetは、物語やゲームからヒントを得て推測するのと同じように、過去の情報を使って未来を予測します。\n",
        "\n",
        "- 例えば、来週末に行われる学校のカーニバルに何人の人が来るか予測したいとします。\n",
        " - 過去のカーニバルの来場者数、来週末の天気予報、近くで大きなイベントが開催されるかどうかなどを調べます。\n",
        " - Facebook Prophetは、同様の情報を使って、ウェブサイトのトラフィック、売上、株価などの予測を行います。\n",
        "\n",
        "- Facebook Prophetと他の予測ツールとの違いは、時系列データ（時間をかけて収集されたデータ）を扱うために特別に設計されている点です。\n",
        " - また、予測に影響を与える可能性のある休日やその他の特別なイベントを処理するための機能も組み込まれています。\n",
        "\n",
        "- 全体として、Facebook Prophetは予測をするのに便利なツールですが、あくまでツールの一つであり、特定のタスクに対して常にベストな選択とは限らないということを覚えておくことが重要です。\n",
        " - さらに、Facebookが開発・所有しているツールであり、すべての種類のデータやビジネス状況に適しているとは限りません。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V6L78R1yPH7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### \"指数平滑化で順風満帆\" \n",
        "- 指数平滑化は、将来の予測をするために使われる方法です。\n",
        " - あなたが来週の天気を予測しようとしているところを想像してみてください。\n",
        " - 今日は晴れだと分かっていますが、明日の天気がどうなるかは分かりません。\n",
        " - 指数平滑化では、今日と過去数日間の天気を考慮して、明日の天気を予測します。\n",
        " - 天気図を見て推測するようなものです。\n",
        "\n",
        "#### 「シータ予測：正しい方向を指し示す」 \n",
        "- シータ予測は、予測を行うために使用される数式の一種です。\n",
        "- スポーツの試合の勝敗を予想することを想像してください。\n",
        " - シータ予測は、チームや選手の過去のパフォーマンスを考慮して、どちらが勝つかを予測するものです。\n",
        " - 統計を見て推測するようなものです。\n",
        "\n",
        "####  \"Automatic ETS from statsmodels: 究極の予測ツール\" \n",
        "- Statsmodelsからの自動ETSは、将来についての予測を行うために使用される手法です。\n",
        "- あるWebサイトを来月何人が訪れるかを予測することを想像してください。\n",
        "- Automatic ETS from statsmodelsは、過去のウェブサイトのトラフィックやその他の要因を考慮し、将来のウェブサイトのトラフィックについて予測を行います。\n",
        "- まるで水晶玉で未来を見るようなものです。\n",
        "\n",
        "- これらの方法は、統計学やコンピュータサイエンスの分野で、予測を行うために使用されています。\n",
        "- これらの手法で使われる数式は複雑で、データ分析によって決定される変数や係数を含んでいます。\n",
        "- しかし、基本的な考え方は、過去の情報を使って未来を予測することである。\n",
        "\n"
      ],
      "metadata": {
        "id": "PDRmvlVELQJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"ARIMAとautoARIMAによる予測\"**\n",
        " - ARIMAとautoARIMAは、過去のデータに基づいて将来のイベントについての予測を行うために使用される方法です。\n",
        "- 例えば、あるお店では、過去数ヶ月の来客数から来月の来客数を予測するためにARIMAを使用することがあります。\n",
        "- autoARIMAは、ARIMAモデルの最適なパラメータを自動的に選択する手法である。\n",
        " - 天気予報のように、将来の事象について予測するのに役立ちますが、常に100％正確というわけではありません。\n",
        "- 例えるなら、農家が過去数シーズンの気象データを使って、次のシーズンの天気を予測しようとするようなものです。\n",
        "- ビジュアル面では、異なる予測や実際のデータポイントを表す複数の線を持つグラフに例えることができます。\n",
        "\n",
        "- ARIMAとautoARIMAの大きな違いは、ARIMAがモデルのパラメータをユーザーが手動で選択する必要があるのに対し、autoARIMAは最適なパラメータを自動的に選択することである。\n",
        "- autoARIMAはより便利で効率的であると考えられています。\n",
        "\n",
        "\n",
        "### **\"オートチューニングによる時系列予測。ARIMAとautoARIMAの違い\"**\n",
        "\n",
        "- レースで走らせたいおもちゃの車があると想像してください。\n",
        " - ARIMAでは、車を速く走らせるために、車輪、ギア、エンジンなどを手動で調整する必要がある。\n",
        " - autoARIMAでは、これらの調整を車が自動的に行うので、レースがしやすくなり、速く走れる可能性があります。\n",
        "\n",
        "- ARIMAもautoARIMAも、株価や天気などの時系列データを予測するための手法である。\n",
        "- ARIMAは「Auto-Regressive Integrated Moving Average」の略で、データを定常状態にするための差分回数、自己回帰項数、移動平均項数の3つのパラメータを手動で選択し、微調整を行うもので、ARIMAは「Auto-Regressive Integrated Moving Average」の略で、移動平均項数は「Auto-Recregressive Integrated Moving Average」の略\n",
        "\n",
        "- 一方、autoARIMAは、さまざまな組み合わせを試し、データに最も合うものを見つけることで、これらのパラメータを選択するプロセスを自動化します。\n",
        "- これは時間を節約し、予測プロセスをより効率的にすることができますが、同時に使用される特定のパラメータをよりコントロールしにくくなることを意味します。\n",
        "\n",
        "- メリットとデメリットを比較すると、ARIMAは予測プロセスをよりコントロールしやすくなりますが、パラメーターを微調整するためにより多くの時間と専門知識を必要とすることも事実です。\n",
        "- AutoARIMAはより早く、より簡単に使用できますが、データに最適なパラメータを常に見つけられるとは限りません。\n",
        "\n"
      ],
      "metadata": {
        "id": "OJBP-mlhMDv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"予測器検索 - レジストリ\"**\n",
        "- 予測器検索 - レジストリとは、本の図書館のようなものです。\n",
        " - 図書館にさまざまなテーマの本があるように、予測変数の登録にはさまざまなことを予測するツールがあります。\n",
        "\n",
        " - 例えば、ある予測ツールは明日の天気を予測できるかもしれませんし、別の予測ツールは人がお店でどれくらいのお金を使うかを予測できるかもしれません。\n",
        " - 図書館の本がそれぞれ独自のストーリーと情報を持っているように、予測ツールもそれぞれ独自のルールと能力を持っているのです。\n",
        "\n",
        "- 予測変数のレジストリを使用する利点は、仕事に適したツールを簡単に見つけることができ、ゼロから新しいツールを作成する必要がないため、時間を節約できることである。\n",
        "- デメリットは、特定のタスクにどのツールを使用するのが最適なのかが分かりにくいことです。\n",
        "- このデメリットを克服するために、「予測探索」と呼ばれる技術を使って、レジストリ内のツールの中から、そのタスクに最適なものを見つけ出すことができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "_dD2XpNO9qH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"複雑さを解きほぐす。**- BATSとTBATSの違い\"\n",
        "- BATSとTBATSは、過去のパターンに基づいて将来の事象を予測する時系列予測で使用される2つの方法です。\n",
        " - 来年の夏、ビーチスタンドでアイスクリームコーンが何個売れるかを予測したいと想像してください。\n",
        " - BATSとTBATSを使えば、そのような予測が可能になる。\n",
        "\n",
        "- BATSとは、\"Bayesian Additive Trends and Seasonality \"の略で、「ベイズ加法トレンドと季節性」を意味します。\n",
        " - アイスクリームコーンが平日より週末に多く売れるかどうかなど、データの傾向やパターンを探し、その情報を使って将来を予測する方法です。\n",
        " - ある種の数学を使って予測するので「ベイズ型」と呼ばれています。\n",
        "\n",
        "- TBATSとは、\"Exponential smoothing state space model with Box-Cox transformation, ARMA errors, Trend and Seasonal components \"の略です。\n",
        " - データのトレンドやパターンを探すという点ではBATSと似ていますが、天候など予測に影響を与えうる他の要因も考慮します。\n",
        "\n",
        "- BATSとTBATSの違いの一つは、\n",
        " - BATSはノイズの多いデータを扱うのが得意で、\n",
        " - TBATSは季節性（週末にアイスクリーム・コーンが多く売れるように、一定の間隔で繰り返されるパターンを意味する）の多いデータを扱うのが得意な点である。\n",
        "- また、BATSはトレンドやパターンの種類に柔軟性があるのに対し、TBATSはある種のトレンドやパターンを想定しており、より硬直的であるという違いもある。\n",
        "\n",
        "- まとめると、BATSとTBATSは、過去のパターンに基づいて将来の事象を予測するために用いられる2つの手法です。\n",
        "- BATSはノイズの多いデータを扱うのが得意で柔軟性があり、TBATSは季節性の多いデータを扱うのが得意で硬直的である。\n"
      ],
      "metadata": {
        "id": "--NYhTggN922"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"弱点を見抜く\"**\n",
        "\n",
        "- ダーツのゲームで、的の真ん中にあるブルズアイに当てることを想像してください。\n",
        " - ダーツが上手な人は、その的を狙い、正確に投げることができます。\n",
        " - モデルも同じように機能します。目標は、可能な限り正確な予測をすることです。\n",
        " - しかし、ダーツプレイヤーが投げたダーツがブルズアイに当たらないことがあるように、モデルも正確でない予測をすることがあります。\n",
        " - モデルの潜在的な弱点を特定することは、ダーツがブルズアイを外した原因を突き止め、プレーヤーが狙いを定めるのを改善するようなものです。\n",
        "- もう一つの例は、医者が患者の病気を診断しようとする場合です。\n",
        " - 医師は、血液検査、X線検査、身体検査など、複数の検査を行って診断を下します。\n",
        " - それぞれの検査は患者さんの健康に関する情報を提供しますが、ある検査は他の検査よりも正確かもしれません。\n",
        " - 診断プロセスにおける潜在的な弱点を特定することは、どの検査が正確な情報を提供していないのかを見つけ出し、医師が診断を改善できるようにするようなものです。\n",
        "- メトリクスの面では、モデルの性能を精度、精度、再現性、F1スコアなどのメトリクスで評価し、弱点がないかどうかを見抜き、モデルのパラメータを調整することでそれらを修正し、予測精度を向上させることができる。\n"
      ],
      "metadata": {
        "id": "hp8A2Ucd8Os0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **タギングで整理整頓**\n",
        "- タグ  とも呼ばれる予測変数は、データを分類し整理するために使用されます。\n",
        " - 例えば、図書館で本が「フィクション」「科学」「歴史」などの異なるタグでラベル付けされていると想像してください。\n",
        " - このようなタグを使用すると、主題ごとに整理されるため、特定の書籍を簡単に見つけることができます。\n",
        " - 同様に、予測変数は、コンピュータプログラムのデータを整理し、分類するために使用することができます。\n",
        " - これにより、データの検索や分析がより効率的に行えるようになります。\n",
        " - 図書館員がタグを使って本を見つけやすくするように、プログラマーは予測変数を使ってデータを見つけやすく、使いやすくするのです。\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- \"予測因子によるデータの分類\"。\n",
        " - 予測変数は、物事を整理するために貼るラベルやタグのようなものだと考えることができます。\n",
        " - 私たちがフォルダーにラベルを貼って書類を整理するのと同じように、予測変数はコンピュータ・プログラムのデータを整理するのに役に立ちます。\n",
        " - 例えば、大きな箱に入った車のおもちゃを色別に分類する場合を考えてみましょう。\n",
        " - 「赤」「青」「緑」などの予測変数を使って、車を異なるグループに分けることができます。\n",
        " - これにより、欲しい車を簡単に見つけることができ、また、データをより効率的に分析することができます。\n",
        "\n",
        "- また、図書館で本をジャンル別、著者別、出版日別などに分類する例もあります。\n",
        "- これにより、本を簡単に取り出すことができ、また蔵書全体の分析も可能になります。\n",
        "\n",
        "- この方法論のキャッチフレーズは、\"データを整理・分析するためのタグ付け \"と言えるかもしれない。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PnguTnTz-Fkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"高度な評価方法ローリングリサンプリングと集計誤差、ローリングバックテスティング\"**\n",
        "\n",
        "- ローリング・リサンプリングは、ガムを一枚取って指で転がし、まだ噛みごたえがあり、伸縮性があることを確認するようなものです。\n",
        "- 同様に、機械学習において、ローリング・リサンプリングは、データの異なる部分を用いて繰り返しテストすることで、モデルの性能を検証する方法である。\n",
        "- 集計誤差は、科目によって成績が異なる通知表のようなものである。機械学習では、集計誤差は、異なる測定基準にわたってモデルのパフォーマンスを見ることによって、モデルの全体的なパフォーマンスを測定する方法です。\n",
        "- ローリングバックテストは、数手先しか見えないチェスのゲームのようなものです。\n",
        " - 同様に、機械学習において、ローリングバックテストは、過去にそのモデルを使用した場合にどのようなパフォーマンスが得られたかをシミュレートすることによって、モデルのパフォーマンスをテストする方法である。\n",
        "\n"
      ],
      "metadata": {
        "id": "4--Q7_UM8ygJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ウォークフォワード予測とは**\n",
        "- 「ウォークフォワード予測とは、予測モデルの性能を評価するために、新しいデータに対して繰り返しテストを行う手法のことです。\n",
        " - この概念を説明するために、いくつかの例を挙げます。\n",
        "\n",
        " - ある農家が、毎月のトウモロコシの収穫量を予測することを考えます。\n",
        " - 彼はまず、前年のデータを使ってモデルを学習させます。\n",
        " - しかし、一度にすべてのデータを使用するのではなく、その時点で利用可能な情報（例えば、前年の最初の数ヶ月間の気象データや作物収量）だけを使用して、データを「前方に」移動させるのである。\n",
        " - こうすることで、リアルタイムでモデルを使用した場合の性能を確認することができるのです。\n",
        "\n",
        "- もう一つの例は、どの銘柄が値上がりするか、あるいは値下がりするかを予測したい株式トレーダーです。\n",
        "- 彼はまず、過去の株価からモデルを学習させます。\n",
        "- しかし、一度にすべてのデータを使うのではなく、その時点で利用可能な情報（例えば、その月の最初の数日間の株価と取引量）だけを使い、データを「前倒し」にしていきます。\n",
        "- こうすることで、リアルタイムでモデルを使用した場合のパフォーマンスを確認することができるのです。\n",
        "\n",
        "- 最後に、気象予報士は翌日の気温を予測したいので、過去の気象データでモデルを学習することから始めます。\n",
        "- しかし、一度にすべてのデータを使うのではなく、その時点で利用可能な情報（例えば、その日の最初の数時間の気温、降水量、風速）のみを使って、データを「前倒し」で学習させるのだ。\n",
        "- こうすることで、リアルタイムでモデルを使用した場合の性能を確認することができるのです。\n",
        "\n",
        "- 要約すると、「ウォークフォワード予測」は、モデルがリアルタイムでどのように動作したかをシミュレートして、モデルの性能をテストする方法である。\n",
        "- これは、新しいデータに対するモデルの汎化能力を評価し、モデル性能の潜在的な弱点を特定するのに役立ちます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L1F2b5JU7NMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **ローリングアップデート**\n",
        " - パレードの山車が一斉に更新されるのではなく、一つずつ更新されていく様子を想像してください。\n",
        " - これはローリングアップデートに似ており、ソフトウェアのアップデートは一度に行われるのではなく、システムやネットワーク上で徐々に実施されます。\n",
        " - これにより、ダウンタイムが少なくなり、新しいソフトウェアへの移行もスムーズになります。\n",
        " -  このコンセプトのキャッチフレーズは、\"slow and steady wins the race\"（ゆっくり着実に、競争に勝つ）です。\n",
        "\n",
        "### **予測**\n",
        "- 天気予報士が明日の天気を予想するのを想像してください。\n",
        "- 天気予報士は、過去のデータとパターンを使って、天気がどうなるかを推測します。\n",
        "- 同様に、高度な導入プロセスでは、過去のデータとパターンに基づいて、将来のパフォーマンスやシステムの使用状況を予測するために、フォーキャスティングが使用されます。\n",
        "- これは、計画立案や、スケーリングやリソース割り当てに関する意思決定に役立てることができます。\n",
        "- このコンセプトのキャッチフレーズは、\"forewarned is forearmed(先んずれば人を制す)\"です。\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "- \"ローリングアップデート \"\n",
        " - 「新しい家を建てている工事現場を想像してください。\n",
        " - 新しい区画を建設する間、現場全体を閉鎖してすべての作業を停止するのではなく、作業員は一度に1つの小さな区画だけを閉鎖して作業します。\n",
        " - こうすることで、現場全体を混乱させることなく、工事を継続し、新しいセクションを追加することができます。\n",
        " - これは、ソフトウェアのローリングアップデートの仕組みに似ています。\n",
        " - システム全体を停止して一度にすべてのソフトウェアを更新するのではなく、小分けにして更新することで、システムを継続的に稼働させることができ、ダウンタイムが少なくなるのです。\n",
        "\n",
        "- \"フォーキャスト\"。\n",
        " - 「天気予報士が翌日の天気を予想することを思い浮かべてください。\n",
        " - 天気予報士は、現在の天気と過去の天気予報のデータから、将来の天気を推測します。\n",
        " - これは、ソフトウェアのアップデートにおける予測に似ています。\n",
        " - 過去のアップデートのデータを分析することで、エンジニアは潜在的な問題を予測し、問題が起こる前に計画を立てることができます。\n",
        " - \"ダウンタイムを減らし、新しいソフトウェアへの移行を容易にすることができます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3rj2O0Tc5ihs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"モデルの性能を測る\" - メトリックスクラスのインターフェースは、**\n",
        "- モデルがどの程度予測を行うことができるかを測るための方法です。\n",
        "\n",
        "- 精度はバスケットボール選手のシュート率のようなものです。\n",
        " - モデルがどれだけ頻繁に正しい予測をすることができるかを測るものです。\n",
        " - 精度の例としては、天気を予測する気象モデルがあり、ほとんどの場合、それが正しければ、精度が高いとみなされます。\n",
        "\n",
        "- 精度とは、射撃の名人の狙いのようなものです。\n",
        " - モデルの予測のうち、いくつが実際に正しいかを測定します。\n",
        " - 精度の例としては、患者がある病気に罹っているかどうかを予測する医療診断テストがあり、その病気の患者を特定するのが正確であれば、それは精度が高いとみなされます。\n",
        "\n",
        "- リコールは、野球選手の打率のようなものです。モデルがどれだけ多くの真のケースを識別できたかを測定します。\n",
        "- リコールの例は、スパムメールを識別するスパムフィルターで、もしスパムメールのほとんどを識別することができれば、高いリコールを有するとみなされます。\n",
        "\n",
        "- F1スコアは、学生の総合得点のようなものです。\n",
        " - 真陽性率と陽性予測値の両方を考慮し、精度と想起のバランスをとるものである。\n",
        "\n",
        "- 視覚的なものでは、\n",
        " - 精度はバスケットボール選手のシュート率、\n",
        " - 精度は射撃手の狙い、\n",
        " - 想起は野球選手の打率、\n",
        " - F1スコアは総合スコアのようなものです。\n",
        "- 文系で言えば、\n",
        " - 精度はモデルがどれだけの頻度で正しいかを示す指標、\n",
        " - 精度はモデルの予測のうちどれだけが正しいかを示す指標、\n",
        " - 想起はモデルがどれだけの真のケースを識別できたかを示す指標、\n",
        " - F1スコアは精度と想起のバランスを示すものです。\n",
        "- 物理的な面では、\n",
        " - 精度はモデルがどれだけ正しいかを示す指標、\n",
        " - 精度はモデルの予測がどれだけ正しいかを示す指標、\n",
        " - 想起はモデルがどれだけ多くの真性ケースを識別できたかを示す指標、\n",
        " - F1スコアは精度と想起のバランスを示す指標となります。\n",
        "\n",
        "- キャラクターや人間の特性に例えると、\n",
        " - 正確さは常に正しい人、\n",
        " - 精密さは非常に具体的な人、\n",
        " - 想起は徹底的な人、\n",
        " - F1スコアはバランスのとれた人のようなものである。\n",
        "- 社会では、医療、天気予報、スパムフィルタリングなど、さまざまな分野で精度、正確さ、想起、F1スコアが使われている。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wmW900BZ3sm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **基本的なバッチ予測評価工程の概要 - 機能メトリック・インターフェースの概要**\n",
        "- 機械学習やデータサイエンス、特に予測モデルの評価で使われるプロセスのことを指します。\n",
        "- モデルの性能を評価するために、特定のメトリクスとインターフェースを使用することが含まれます。\n",
        "\n",
        "- プロセスの概要には、データの準備、モデルのトレーニング、モデルのテスト、モデルの性能評価、モデルの微調整といったいくつかのステップが含まれる。\n",
        "- 各ステップは、モデルが正確で信頼できるものであることを確認するために重要であり、それぞれの役割を担っています。\n",
        "\n",
        "- 機能メトリックとインターフェースは、モデルの性能を測定し、モデルが意図したとおりに動作していることを確認するために使用されます。\n",
        "- これらのメトリクスには、精度、正確さ、再現性、F1 スコアなどがあり、モデルが正しく予測する能力を測定し、偽陽性と偽陰性を識別するために使用されます。\n",
        "\n",
        "- 一方、インターフェースは、モデルとの対話、データの入力、モデルの出力の受信に使用されます。\n",
        "\n",
        "- ビジュアル面では、プロセスはレシピに例えることができ、最終的な料理が美味しくなるように各ステップが重要である。\n",
        "- 文献的には、機械学習やデータサイエンス、特に予測モデルの評価で使われるプロセスとして説明されている。\n",
        "- 動的には、データの準備、モデルの訓練、モデルのテスト、モデルの性能評価、モデルの微調整など、いくつかのステップを含む。\n",
        "- 物理的には、コンピュータの中で行われる仮想的なプロセスである。\n",
        "- 登場人物や人間の特徴で言えば、プロセスを設計・実行するデータサイエンティスト、\n",
        "- 社会で言えば、技術やイノベーションと結びつくためポジティブな意味合いを持ち、\n",
        "- 人間の想像力やファンタジーで言えば、データに基づく予測や意思決定を行うための強力なツールと捉えることができる。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z4_qrvAdx4xw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **指標の概要**\n",
        "- 精度、正確さ、再現性、F1スコアは、予測モデルの性能を評価するために用いられる指標である。\n",
        "\n",
        "- 精度は、モデルがどれだけ頻繁に正しい予測を行うかを示す指標で、数学のテストで何問正解したかに基づいて点数を得るのと似ています。\n",
        "\n",
        "- 精度とは、モデルが予測した中で実際に正しいものがどれだけあるかを示す指標で、テストで正解とマークした答えの中で実際に正しいものがどれだけあるかを示すのと似ています。\n",
        "\n",
        "- 再現性とは、モデルの予測が時間とともにどれだけ一貫性を持つかを示す尺度であり、学生のテストのスコアが時間とともにどれだけ一貫性を持つかに似ています。\n",
        "\n",
        "- F1スコアは精度と再現性を組み合わせた指標で、成績表が複数のテストの点数を組み合わせたものであるのと同じです。\n",
        "\n",
        "- これらの指標は、モデルが正しく予測する能力を測定し、偽陽性と偽陰性を識別するために使用されます。\n",
        " - これらの指標は、モデルの性能の高さを理解し、改善すべき領域を特定する上で重要です。\n",
        "\n",
        "- 精度は、数学のテストで何問正解したかに基づいて点数が決まるのと同じです。\n",
        "- 精度は、テストで正解とマークした答えのうち、いくつが実際に正解であったかに例えることができます。\n",
        "- 反復性は、学生のテストのスコアが時間と共にどれだけ一貫しているかということと比較することができます。\n",
        "- F1スコアは、成績表が複数のテストのスコアをどのように組み合わせているかを比較することができます。\n",
        "\n",
        "- 文献的には、これらの測定基準は、予測モデルの性能を評価するために使用されます。- ダイナミックでは、モデルが正しく予測する能力を測定し、偽陽性と偽陰性を識別するために使用されます。\n",
        "- 物理的には、仮想的な測定や計算である。\n",
        "\n",
        "- キャラクターや人間の特性という意味では、これらの指標はデータサイエンティストや機械学習エンジニアがモデルの評価に使用するものであり、社会的にはテクノロジーやイノベーションと関連するためポジティブな意味合いを持ち、人間の想像力やファンタジーという意味では、データに基づく予測や意思決定を行うための強力なツールと捉えることができる。\n",
        "\n"
      ],
      "metadata": {
        "id": "11PUwuJgywXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **インターフェイスの概要**\n",
        "- インターフェイスとは、ユーザーがモデルと対話し、データを入力するための手段であり、自動車のハンドルやペダルが、ドライバーが自動車と対話し、その動きを制御するための手段であるのと同様です。\n",
        " - 友人とチャットでコミュニケーションをとるのと同じように、モデルとコミュニケーションをとる手段です。\n",
        "\n",
        "- インターフェイスが重要なのは、ユーザーが理解しやすく使いやすい方法でデータを入力し、モデルの出力を受け取れるようにするためです。\n",
        "- インターフェースには、\n",
        "- グラフィカル・ユーザー・インターフェース（GUI）、\n",
        "- コマンドラインインターフェース（CLI）\n",
        "- 、アプリケーション・プログラミング・インターフェース（API）\n",
        "のいずれかを使用することができます。\n",
        "\n",
        "- GUIは、ユーザーがモデルや入力データを簡単に操作できるように、グラフィックや画像を使用したインターフェースです。\n",
        " - GUIは、レストランで料理の注文を簡単にするためのビジュアルメニューと同じようなものです。\n",
        "\n",
        "- CLIは、テキストベースのコマンドを使用して、モデルや入力データを操作するインターフェースです。\n",
        " - レストランでシェフがウェイターから注文を受けるのに似ている。\n",
        "\n",
        "- APIは、異なるソフトウェアプログラムが互いに通信できるようにするためのインターフェースです。\n",
        " - レストランでシェフが厨房のスタッフとコミュニケーションをとるのに似ている。\n",
        "\n",
        "- 視覚的には、自動車のハンドルやペダルに例えることができる。\n",
        "- 文献的には、インターフェースは、ユーザーがモデルと対話し、データを入力するための手段である。\n",
        "- 動的なものでは、ユーザーがデータを入力し、理解しやすく使いやすい方法でモデルの出力を受け取ることができます。\n",
        "- 物理的なものでは、仮想的なもので、ユーザーがモデルとコミュニケーションする方法です。\n",
        "\n",
        "- キャラクターや人間の特性という点では、インターフェースは、それを作成・維持するデザイナーや開発者と関連付けられることがあり、社会的には、技術やイノベーションと関連付けられることからポジティブな意味合いを持ち、人間の想像力やファンタジーという点では、データに基づく予測や意思決定を行うための強力なツールと見なすことができるだろう。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gcj-CYTszvKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- GUI、CLI、APIはすべて、コンピュータ・プログラムやシステムと対話するために使用される、異なるタイプのインターフェースです。\n",
        "\n",
        "- GUI（グラフィカル・ユーザー・インターフェース）とは、ユーザーがプログラムやシステムと簡単にやり取りできるように、グラフィックや画像を使用したインターフェースのことです。\n",
        " - GUIは、レストランで料理の注文を簡単にするためのビジュアルメニューと同じようなものです。\n",
        "\n",
        "- CLI（コマンドラインインターフェース）は、テキストベースのコマンドを使用して、プログラムやシステムと対話するインターフェースです。\n",
        " - レストランでシェフがウェイターから注文を受けるのに似ています。\n",
        "\n",
        "- API（アプリケーション・プログラミング・インターフェース）は、異なるソフトウェア・プログラムが互いに通信できるようにするインターフェースです。\n",
        " - レストランでシェフが厨房のスタッフとコミュニケーションをとるのと同じようなものです。\n",
        "\n",
        "- GUIは車のダッシュボードに例えるなら、ボタンやアイコン、インジケータで車を操作するもの、\n",
        "- CLIはシェフがウェイターに指示を出し、ウェイターがそれに応えるもの、\n",
        "- APIはシェフがキッチンスタッフとコミュニケーションをとり、シェフが指示を出し、キッチンスタッフがそれを実行するものと、\n",
        "- ビジュアル面では例えることができるだろう。\n",
        "\n",
        "- 文献上では、GUIはグラフィックや画像を使ってユーザーが対話しやすいようにしたインターフェース、\n",
        "- CLIはテキストベースのコマンドを使ったインターフェース、\n",
        "- APIは異なるソフトウェアプログラム同士が通信できるようにしたインターフェースとされています。\n",
        "\n",
        "- 動的には、GUIはユーザーがプログラムやシステムと対話するのを容易にし、\n",
        "- CLIはテキストベースのコマンドを使用し、\n",
        "- APIは異なるソフトウェアプログラムが互いに通信するのを可能にする。\n",
        "\n",
        "- 物理的には、GUI、CLI、APIは仮想的なインターフェースであり、ユーザーがシステムと通信する方法である。\n",
        "\n",
        "- キャラクターや人間の特性で言えば、GUIは技術に詳しくないユーザー、CLIは開発者、APIはそれらを構築・保守するソフトウェア開発者をイメージすることができる。\n",
        "- 社会的には、GUIは対話が容易なことから広く使われ、技術や革新を連想させることからポジティブな意味合いを持ち、CLIとAPIは主に開発者やソフトウェアエンジニアに使われます。\n",
        "- 人間の想像力やファンタジーの観点から、GUI、CLI、APIは、テクノロジーとのコミュニケーションやインタラクションを可能にする強力なツールとして捉えることができる。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3MSLwPrM1hK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **調和平均**\n",
        "- \"平均のバランス感覚\" - ハーモニック平均は平均の一種で、互いに大きく異なる値をバランスさせるために使われる。\n",
        "\n",
        "- 調和平均の一例として、ドライブ旅行中に何度か停車する車の平均速度がある。調和平均は、総距離と、停車時間を含む総時間を考慮する。\n",
        " - つまり、ある車が2時間で100マイル走行し、30分ずつの停車を2回行った場合、調和平均速度は（100マイル）/（2時間+30分+30分）=50mphとなります。\n",
        "\n",
        "- 調和平均のもう一つの例は、簡単なクラスと難しいクラスが混在している学生の成績平均値（GPA）である。\n",
        " - 調和平均では、授業の難易度と受けた成績を考慮するので、易しいクラスでA、難しいクラスでCを取った学生は、両方のクラスでBを取った学生より調和平均GPAが高くなります。\n",
        "\n",
        "- 視覚的には、調和平均は天秤に例えることができ、一方には重い重りが、もう一方には軽い重りがあり、両者が等しくなったときに天秤はバランスに達する。\n",
        "- 文学的には、調和平均は平均の一種で、互いに大きく異なる値をバランスさせるために使われる。\n",
        "- 力学的には、平均値のバランスをとること。\n",
        "- 物理では仮想計算。\n",
        "\n",
        "- 文字や人間の特性で言えば、調和平均は学生やGPAと関連付けることができます。\n",
        "- 社会的には、教育や研究で広く使われている。\n",
        "- 人間の想像力や空想力という点では、調和平均は異なる価値観に基づいて公平でバランスの取れた決定を下すための強力なツールと見なすことができる。\n",
        "\n"
      ],
      "metadata": {
        "id": "tgFErK7Q2Qng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **F1スコアの概要**\n",
        "- F1スコアは、予測モデルのパフォーマンスを評価するために使用される指標です。\n",
        " - これは、成績表が複数のテストの点数を組み合わせるのと同じように、精度と再現率を組み合わせた指標です。\n",
        "\n",
        "- 精度とは、モデルの予測値のうち、いくつが実際に正しいかを示す指標であり、テストで正解とマークした答えのうちいくつが実際に正しかったかに似ています。\n",
        "\n",
        "- リコールは、モデルによって予測された実際の正のケースのいくつかを示す尺度であり、テストで正解した問題のいくつかに似ています。\n",
        "\n",
        "- F1スコアは、精度とリコールの調和平均を取ることによって計算されます。\n",
        " - 調和平均は平均の一種で、ゼロに近い値ほど重みがある。\n",
        "\n",
        "- F1スコアは、データが不均衡な場合、つまり、あるクラスのデータが他のクラスよりはるかに多い場合に使用するのに適した指標です。\n",
        " - また、偽陽性や偽陰性のコストが高い場合にも有効な指標である。\n",
        "\n",
        "- 視覚的には、F1スコアは複数のテストの点数を組み合わせた成績表と比較することができる。\n",
        "- 文献的には、予測モデルの性能を評価するために使われる指標です。\n",
        "- 動的には、精度とリコールを組み合わせた指標です。\n",
        "- 物理的には、仮想的な測定・計算である。\n",
        "\n",
        "- F1スコアは、文字や人間の特性で言えば、データサイエンティストや機械学習エンジニアがモデルの評価に用いるもの、\n",
        "- 社会で言えば、技術やイノベーションに関連するものとしてポジティブな意味合いを持ち、\n",
        "- 人間の想像力やファンタジーで言えば、データに基づく予測や意思決定を行うための強力なツールと捉えることができるだろう。\n",
        "\n"
      ],
      "metadata": {
        "id": "AgZPnvzx0ogg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### \"適切なツールの選択\" \n",
        "- GUI、CLI、APIはすべて、コンピュータプログラムやシステムと対話するための異なる方法です。\n",
        "\n",
        "- GUI（グラフィカル・ユーザー・インターフェース）は、車のダッシュボードのようなものです。\n",
        " - ボタンやアイコン、メニューがあり、それをクリックすることでプログラムを操作します。\n",
        " - GUIは使いやすく分かりやすいですが、必要なオプションや設定がすべて揃っているとは限りません。\n",
        " - GUIの例としては、デスクトップやモバイルデバイスが挙げられます。\n",
        " - これらのデバイスにはアイコン、ボタン、メニューがあり、これらをクリックしてデバイスと対話することができます。\n",
        "\n",
        "- CLI（コマンドラインインターフェイス）は、車のマニュアルトランスミッションのようなものです。\n",
        " - CLI（コマンドラインインターフェイス）は、車のマニュアルトランスミッションのようなもので、使うのに手間がかかりますが、その分、コントロールと精度が高くなります。\n",
        " - CLIの例としては、コンピュータのコマンドプロンプトやターミナルがあり、コンピュータと対話するためにコマンドを入力する必要があります。\n",
        "\n",
        "- API（アプリケーション・プログラミング・インターフェース）は、道具箱のようなものです。\n",
        " - 開発者が特定のシステムやサービスで動作するプログラムを作成するために使用する命令やツールのセットです。\n",
        " - API の例としては、天気に関する情報を提供する天気予報 API があり、開発者はこの API を使って天気予報アプリを作成することができます。\n",
        "\n",
        "- ビジュアル面では、GUIは車のダッシュボード、CLIはマニュアルトランスミッション、APIは工具箱のようなものです。文学的な面では、GUIは使いやすく、CLIはより精密で制御しやすく、APIは指示の集合体である。\n",
        "- 動的には、GUIはシンプルで使いやすく、CLIはより複雑で、APIは開発者のためのツールである。\n",
        "- 物理的な面では、GUIは視覚的なインターフェース、CLIはコマンドベースのインターフェース、APIはシステムとの対話のための命令セットである。\n",
        "\n",
        "- キャラクターや人間の特性で言えば、GUIはシンプルなものを好む人、CLIはよりコントロールしやすく精密なものを好む人、APIはものを作るのが好きな人のようなものである。\n",
        "- 社会的には、GUIは日常生活で広く使われ、CLIはパワーユーザーや開発者が使い、APIは開発者が使う。\n",
        "- 人間の想像力やファンタジーという点では、GUIは物事を簡単にする魔法の杖、CLIはよりコントロールできる強力な呪文、APIは新しいものを生み出す力を与えてくれる呪符のようなものだと思います。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "61EU87ik2qky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **多変量予測変数の概要**\n",
        "\n",
        "- 多変量予測変数は、複数の変数を用いて予測を行う方法です。\n",
        "- それは、パズルを解くために、1つだけでなく複数の手がかりを持つようなものです。\n",
        "- これらの手がかりは、より正確な予測をするのに役立ちます。\n",
        "- しかし、1つの手がかりだけでなく、複数の手がかりを使うことは、より複雑になる可能性もあります。\n",
        "- 探偵が多くの容疑者や証拠がある事件を解決しようとするように、余分な情報に惑わされず、適切な手がかりを使うことが重要です。\n",
        "- 定規と重りを使って物の大きさや重さを測るように、複数の器具を使って何かを測るのと似ていますね。\n",
        "- しかし、同時に複数の地図を読もうとするような難しさもあります。\n",
        "- 強力なツールではありますが、慎重に使う必要があります。\n"
      ],
      "metadata": {
        "id": "ItKqhrdezuoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **予測区間と分位値予測の要約**\n",
        "\n",
        "- 予測区間と分位値予測は、どちらも変数の将来値を予測するために使われますが、その方法は異なります。\n",
        "\n",
        "- 予測区間は、ある日に予想される気温の範囲を教えてくれる天気予報のようなものです。\n",
        " - 天気予報が60度から80度の間と言うように、予測区間は、変数の将来の値がどうなるかの範囲を与えます。\n",
        "\n",
        "- 分位値予測は、レストランでのメニューのようなものです。\n",
        "- メニューが食事にどんな選択肢があり、いくらかかるかを教えてくれるように、分位値予測は変数にどんな結果の可能性があり、それぞれの結果がどの程度の可能性があるかを教えてくれるのです。\n",
        "\n",
        "- 予測区間は、起こり得る結果の範囲を知りたいが、各結果がどの程度の可能性があるかという情報がない場合に有用です。\n",
        "- 分位値予測は、可能性のある結果の範囲と各結果の可能性を知りたいときに有用です。\n",
        "\n",
        "- 予測間隔は、1日の気温の範囲を示す天気予報に似ています。\n",
        " - 一方、分位値予測は、どのような選択肢があり、それぞれの選択肢がどの程度の可能性があるのかを示すメニューに似ています。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cJa_MCfH0QVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **予測区間の要約**\n",
        "- 予測区間は、天気予報のようなものです。\n",
        "- 天気予報がある日に予想される気温の範囲を教えてくれるように、予測区間は将来の出来事や予測に対して起こりうる結果の範囲を教えてくれるのです。\n",
        "\n",
        "- これは、予測にまつわる不確実性の尺度です。\n",
        "- これは、過去のデータとモデルの不確実性を使って計算されます。\n",
        "- これは、予測された結果が入る可能性のある値の範囲を示しています。\n",
        "- 値の範囲として、または確率分布として表すことができます。\n",
        "- 点での予測ではなく、可能な範囲での予測です。\n",
        " - 例えば、暑い夏の日にアイスクリームの販売数を予測する場合、予測区間は90％の確率で100個から200個の間に収まると言うかもしれませんが、正確に何個売れるかは言えません。\n",
        "\n"
      ],
      "metadata": {
        "id": "5BYZtUNt1EPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **分位値予測の概要**\n",
        "\n",
        "- 分位値予測は、変数の将来の値について予測を行う方法ですが、1つの予測値を与えるのではなく、可能な値の範囲と各値が発生する可能性を与えます。\n",
        "- 天気予報士のグループが明日の最高気温を予測しようとしているのを想像してください。\n",
        " - それぞれの予報士が自分の予想を出し、一緒になって起こりうる気温の範囲を作成します。\n",
        " - ある温度は他の温度より起こりやすく，分位数予測はどの予測がより起こりやすいかを示すのに役立ちます．\n",
        "- 天気予報と同様に、分位値予測は、天候に合わせた服装や商品の値段を決めるなどの意思決定に役立てることができます。\n",
        "- 予測区間もまた予測の範囲であるが，それは将来の結果のもっともらしい範囲ではなく，1点の予測の不確実性の推定である．\n",
        "- 予測区間は、どちらも可能な値の範囲を提供するという点で、分位予測に似ていますが、分位予測は各値が発生する可能性を提供することで、より詳細な予測です。\n"
      ],
      "metadata": {
        "id": "e_q840_u1yuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **パネル予測と階層型予測の概要**\n",
        "\n",
        "#### パネル予測。\n",
        "- これは、多くの異なる時系列データ（異なる製品の売上や異なる都市の気温など）をすべて同時に見る予測方法です。\n",
        "- 同じ日に異なる場所の多くの異なる天気予報を見るようなものです。\n",
        "\n",
        "#### 階層的予測。\n",
        "- これは構造または階層を持つ時系列データを見る予測方法です。\n",
        "- 例えば、異なる店舗で異なる商品の売上を見るようなものです。\n",
        "- 異なる都市の天気予報を見るだけでなく、その都市の中の異なる地域の天気予報を見るようなものです。\n",
        "\n",
        "#### 類似点\n",
        "- パネル予測も階層型予測も複数の時系列データを見ることを含みます。\n",
        "\n",
        "#### 相違点\n",
        "\n",
        "- パネル予測は多くの異なる時系列データを同時に見ますが、\n",
        "- 階層予測は構造や階層を持った時系列データを見ます。\n",
        "\n",
        "- パネル予測は、同じ日の異なる場所の多くの異なる天気予報を見るようなものです。\n",
        "- 一方、階層的予測は、異なる都市とその都市の中の異なる地域の天気予報を見るようなものです。\n",
        "\n",
        "- パネル予測は、互いに独立した複数の時系列データがある場合に使われます。\n",
        "- 階層的予測は、複数の時系列データがあり、それらが互いに関連している場合に使われます。\n",
        "\n",
        "#### 利点\n",
        "\n",
        "- パネル予測は、異なる時系列データの全体的なトレンドについてより完全な画像を提供できます。\n",
        "- 階層的予測は、異なる時系列データのトレンドについてより詳細な画像を提供し、データ内のパターンを識別するのに役立ちます。\n",
        "\n",
        "#### 不利な点\n",
        "\n",
        "- パネル予測は実施と分析がより複雑になる可能性があります。\n",
        "- 階層的予測は、より時間がかかり、正確な予測をするためにはより多くのデータを必要とします。\n",
        "\n",
        "#### 役割\n",
        "\n",
        "- パネル予測は、多くの異なる時系列データを同時に見たいときに使います。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4-ApbRC-2mY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **\"パネルと階層的予測の比較\"**\n",
        "\n",
        "##### パネル予測は、\n",
        "- 関連する時系列データの複数のグループや「パネル」があり、それを同時に予測したい場合に使用します。\n",
        " - それぞれが独自のデータを持つ複数の生産ラインを持つ工場を想像してください。\n",
        " - パネル予測を使って、各生産ラインについて個別に、また工場全体について予測することができます。\n",
        "\n",
        "##### 階層予測は、\n",
        "- 時系列データの「階層」があり、その階層の各レベルがその上下のレベルに関連している場合に使用されます。\n",
        " - 例えば、ある企業の売上データが、地域別、店舗別、商品別に分類されているとします。\n",
        " - 階層予測を使って、上下のレベルの情報を考慮しながら、各階層の予測を行うことができます。\n",
        "- パネル予測も階層予測も、データの構造と何を予測しようとしているかに応じて、異なる状況で役に立つことがあります。\n",
        "- パネル予測は、複数の関連する時系列データを同時に予測したい場合に有効です。\n",
        "- 階層予測は、複数レベルの階層を持つ時系列データを予測したい場合に有用です。\n",
        "- パネル予測は、複数の独立した時系列データを予測する必要がある場合に適しており、\n",
        "- 一方、階層予測は、共通の構造を持つ複数の従属時系列データを予測する必要がある場合に適しています。\n",
        "- 精度に関しては、データの構造と使用されるモデルによりますが、パネル予測も階層予測も正しく使用すれば、精度は高くなります。\n",
        "\n",
        "###### メタファー（隠喩）。\n",
        "\n",
        "- パネル予測は、教師が異なるクラスの複数のテストを同時に採点するようなものです。\n",
        "- 階層予測は、教師が学校内の異なるレベルのクラス（例えば、1年生、2年生、3年生）のテストを採点し、\n",
        " - 各クラスの成績を他のクラスとの関係で考慮するようなものです。\n",
        " \n",
        "- \"パネル予報 \"は、たくさんの異なる絵が描かれた大きな壁のようなものです。\n",
        " - それぞれの絵は、研究対象である異なるグループや物事を表しています。\n",
        " - 例えば、ある絵は、食料品店で何個のリンゴが売られているか、別の絵は、ディーラー で何台の車が売られているか、などです。\n",
        " - パネル予測は、壁に貼られたさまざまな絵をすべて見て、それぞれのグループの人々や物事が将来どうなるかを予測しようとするものである。\n",
        "\n",
        "\"階層予測\"は、多くの異なるフロアを持つ大きなビルのようなものです。\n",
        " - それぞれの階は、研究対象である人々や物事の異なるグループを表しています。\n",
        " - 例えば、ある階は食料品店、別の階は自動車販売店、といった具合です。\n",
        " - 階層的予測の背後にある考え方は、建物内の異なる階をすべて見て、それぞれのグループの人々や物事について将来何が起こるかを予測しようとすることです。\n",
        "\n",
        "\n",
        "\n",
        "#### パネル予測に適したデータ\n",
        "\n",
        "- 複数の関連する時系列データを見る\n",
        "##### 例\n",
        "- 異なる店舗の売上データ、異なる都市の交通データなど\n",
        "- 異なる時系列間のパターンやトレンドを特定するために使用される\n",
        "- リソースをどのように配分するかの意思決定に有用である\n",
        "\n",
        "\n",
        "#### 階層的予測に適したデータ\n",
        "\n",
        "- 1つの時系列データを複数の階層で見ます。\n",
        "#### 例\n",
        "- 地域別、店舗別、商品別に分類された売上データ\n",
        "- 異なるレベルの時系列データからパターンやトレンドを特定するために使用します。\n",
        "- 企業や組織内のリソースをどのように配分するかの意思決定に有用である。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FTNgZN805rn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"パネル予測　複雑なデータを理解する\"**\n",
        "\n",
        "- パネル予測は、異なるピースを持つ大きなパズルを見るようなものです。\n",
        " - それぞれのピースは、異なる情報やデータを表しています。\n",
        " - すべてのピースを組み合わせることで、将来起こるかもしれないことについて予測することができます。\n",
        "\n",
        "- 例えば、ある店のオーナーが、夏にどれくらいのアイスクリームが売れるかを予測したいとします。\n",
        " - その場合、気温、町の観光客数、近隣のアイスクリーム店の数など、さまざまな情報の断片に注目し、パネル予測を使用することが考えられます。\n",
        " - これらの情報をすべて一緒に見ることで、アイスクリームがどのくらい売れるかについて、より正確な予測を立てることができます。\n",
        "\n",
        "- パネル予測の利点の1つは、予測に影響を与える可能性のある多くの異なる要因を考慮できることです。\n",
        " - これにより、予測をより正確にすることができます。\n",
        " - しかし、パネル予測を作成し、理解することはより複雑になります。\n",
        "\n",
        "- それは、夏にどれだけアイスクリームが売れるかを予測しようとする店主のようなものです。\n",
        "- 彼らはパネル予測を使って、気温、町の観光客数、近くのアイスクリーム店の数など、さまざまな情報を調べるかもしれません。\n",
        "- これらの情報をすべて一緒に見ることで、アイスクリームがどのくらい売れるかについて、より正確な予測を立てることができます。\n",
        "\n",
        "- パネル予測の利点の1つは、予測に影響を与える可能性のある多くの異なる要因を考慮できることです。\n",
        "- これにより、予測をより正確にすることができます。しかし、パネル予測を作成し、理解することはより複雑になります。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EAbukIT7353q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **\"階層的予測全体像を把握する\"**\n",
        "\n",
        "- 階層的予測は、多くの階を持つ大きな建物を見るようなものです。\n",
        " - 各階は、会社の異なる部署や国の異なる地域など、異なるレベルやデータ・グループを表しています。\n",
        " - ビル全体について予測するには、各階を別々に見て、すべての予測を組み合わせる必要があります。\n",
        " - こうして、各階の特徴を考慮することで、より正確なビル全体の予測が可能になるのです。\n",
        "\n",
        "- 大きな予測問題をより小さく、より管理しやすい部分に分割することができます。\n",
        "- 企業内の異なる部門や国の異なる地域など、異なるレベルのデータを考慮します。\n",
        "- 異なるレベルの予測を組み合わせることで、全体としてより正確な予測を行うことができます。\n",
        "- これは、階数の多いビルを見ているようなもので、各階が異なるレベルやデータ・グループを表しています。\n",
        "\n"
      ],
      "metadata": {
        "id": "a2xMU3Qp41mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **予測評価の概要**\n",
        "\n",
        "- 予測評価とは、予測値と実際に発生した値を比較するプロセスです。\n",
        " - 予測モデルがどの程度機能しているかを理解し、改善が必要な部分を特定するのに役立ちます。\n",
        " - ここでは、予測評価の方法をいくつか、簡単な例とともに説明します。\n",
        "\n",
        "- 平均絶対誤差（MAE）。\n",
        " - 瓶の中にゼリービーンズが何個あるか推測していると想像してください。\n",
        " - MAEは、あなたの推測と実際のジェリービーンズの数との平均的な差のようなものです。\n",
        " - MAEが小さいほど、あなたの推測が実際の数字に近いことを意味します。\n",
        "\n",
        "- 平均絶対誤差（MAPE）:Mean Absolute Percentage Error\n",
        " - あるおもちゃの値段を推測するとします。MAPEは、実際の費用に対する割合として、あなたの推測とおもちゃの実際の費用との間の平均差のようなものです。\n",
        " - MAPEが小さいほど、あなたの推測が実際のコストに近いことを意味します。\n",
        "\n",
        "- RMSE（Root Mean Squared Error：二乗平均平方根誤差）\n",
        " - リンゴの袋の重さを推測することを想像してください。\n",
        " - RMSEは、推測と実際のリンゴの重量の平均差を二乗し、平方根にしたようなものです。\n",
        " - RMSEが小さいほど、あなたの推測が実際の重量に近いことを意味します。\n",
        "\n",
        "- 相関性\n",
        " - 異なる日の都市の気温を推測するとします。\n",
        " - 相関は、あなたの推測が実際の気温とどの程度密接に関連しているかを測定する。\n",
        " - 相関が1であれば、あなたの推測は実際の気温と完全に関連しており、相関が0であれば、関係がないことを意味し、負の相関はあなたの推測が実際の気温と負に関連していることを意味します。\n",
        "\n",
        "- モデルの予測値と実際の観測値を比較することで、モデルの精度がどの程度なのか、また、どのように改善すればよいのかを知ることができるのです。\n",
        "\n",
        "\n",
        "\n",
        "- 見通し評価\n",
        "\n",
        "- MAE（Mean Absolute Error：平均絶対誤差）\n",
        " - クッキーを焼くときに、砂糖を加えなければならないが、誤って砂糖を加えすぎてしまったとする。\n",
        " - MAEは、加えようとした砂糖の量と実際に加えた量を比較することで、どれくらいの誤差で砂糖を加えたかを測定するようなものです。\n",
        " - 予測が実際のデータからどれだけ外れていたかを測る方法です。\n",
        "- RMSE（Root Mean Squared Error：二乗平均平方根誤差）\n",
        " - ダーツゲームをしていて、大当たりを出そうとするところを想像してください。\n",
        " - RMSEは、ダーツがブルズアイからどれだけ離れているかを測定するようなもので、ブルズアイからの各ダーツの距離を二乗して、その二乗距離の平均を求めます。\n",
        " - これは、予測の全体的な誤差を測定する方法です。\n",
        "- 相関関係\n",
        " - 天気を予測しようとしているときに、2つの異なる天気予報を利用することを想像してください。\n",
        " - 相関は、2つの予報がどの程度一致しているかを見ることで、お互いにどれだけ近いかを測定するようなものです。\n",
        " - 予測が実際のデータとどの程度一致しているかを測定する方法です。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- 平均絶対誤差（MAE）とは、\n",
        " - 予測が実際の値からどの程度外れているかを測定する方法です。\n",
        " - これは、予測と実際の値の差の絶対値をとり、それらの差のすべてを平均することによって計算されます。\n",
        " - 例えば、瓶の中にゼリービーンズが何個入っているかを推測することを想像してみてください。\n",
        " - もしあなたが100個と推測したが、実際には110個のジェリービーンズがあったとしたら、あなたのMAEは10になります。\n",
        "\n",
        "- 二乗平均平方根誤差（RMSE）は、\n",
        " - 予測が実際の値からどれだけ外れているかを測定するもう一つの方法です。\n",
        " - これは、予測と実際の値の差を取り、それを二乗し、さらにそれらの二乗差の平均の平方根を取ることによって計算されます。\n",
        " - 同じジェリービーンズの例で言うと、100個と予想したが実際には110個のジェリービーンズがあった場合、RMSEは3強となる。\n",
        "\n",
        "- 相関は、\n",
        " - 2つの変数間の関係を測定する方法である。\n",
        " - 相関が1であれば、その変数が完全な正の関係（一方の変数が増加すると、もう一方の変数も増加するという意味）、\n",
        " - 相関が-1であれば、その変数が完全な負の関係（一方の変数が増加すると、もう一方の変数は減少するという意味）、\n",
        " - 相関が0であれば、その変数に関係がないことを意味します。\n",
        " - 植物の背の高さとその植物が浴びる日照量を測定しているとします。\n",
        " - 植物の背が伸びれば、より多くの日光を浴びることができます。\n",
        " - したがって、この場合、身長と日照時間の相関は正となります。\n",
        "\n",
        "---\n",
        "\n",
        "- 平均絶対誤差、平均二乗誤差、二乗平均平方根誤差、相関はすべて、予測や予想が実際の観測とどの程度一致しているかを測定する方法です。\n",
        "\n",
        "- 平均絶対誤差（MAE）は、予測値と実際の値の間の平均的な差を測定します。\n",
        " - 予測がクッキーのレシピで、実際のオブザベーションはあなたが焼いたクッキーだと想像してください。\n",
        " - MAEは、あなたが焼いたクッキーとレシピの指示との間の大きさの平均的な差を測定するようなものです。\n",
        "\n",
        "- 平均二乗誤差（MSE）は、MAEと似ていますが、予測値と実測値の差を二乗したものです。\n",
        " - つまり、誤差が大きいと最終的な結果に大きな影響を与えることになります。\n",
        " - 焼いたクッキーとレシピの指示の大きさの平均差を測るようなものですが、大きなクッキーはより大きな影響を与えることになります。\n",
        "\n",
        "- 平均二乗誤差（RMSE）は、MSEと似ていますが、差の平方根をとります。\n",
        " - これは、焼いたクッキーとレシピの指示の間のサイズの平均差を測定するようなものですが、より大きなクッキーはより大きな影響を及ぼし、その差は元のデータと同じ単位で表されます。\n",
        "\n",
        "- 相関は、2つの変数がどの程度一緒に変化するかを測定します。\n",
        " - 予報が外の気温で、実際の観測が家の中の気温だとします。\n",
        " - 予報と観測の間に高い相関があれば、予報で外が暑くなると言っているときは、家の中の温度も暑くなることを意味します。\n",
        " - 相関が低ければ、予報と観測はあまり関係がないことになります。\n",
        "\n",
        "- これらの方法にはそれぞれ長所と短所があり、どの方法を使うのが最適かは、具体的な状況や扱うデータによって異なるかもしれません。\n",
        "\n"
      ],
      "metadata": {
        "id": "cQnZbBuS9Jxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **平均絶対誤差（MAE）とは、**\n",
        "- 予測がどの程度正確かを測定する方法です。\n",
        "- 予測と実際の値の差に注目し、それらの差の平均をとります。\n",
        "\n",
        "- 比喩：\n",
        " - リンゴの袋の重さを推測しようとしているところを想像してください。\n",
        " - MAEは、あなたが実際の重さからどれだけ離れているかを調べ、すべての推測の平均を取ります。\n",
        " - つまり、あなたが袋の重さを10ポンドと推測し、実際には8ポンドだった場合、あなたのMAEは1ポンドになります。\n",
        "\n",
        "- 箇条書きにします。\n",
        "\n",
        " - MAEは予測がどの程度正確かを測る尺度である\n",
        " - MAEは予測値と実際値との差に注目します。\n",
        " - MAEはそれらの差の平均をとる\n",
        " - 一言で言えば正確さ\n",
        "\n",
        "- わかりやすく、さまざまな予測手法のパフォーマンスを比較するのに便利です。\n",
        "- しかし、誤差の方向（予測が高すぎるか、低すぎるか）は考慮されません。\n",
        "- さらに、外れ値（他のデータとは大きく異なるデータポイント）に対して敏感であるため、\n",
        "- 場合によっては他の指標よりも有用性が低くなることがあります。\n",
        "\n"
      ],
      "metadata": {
        "id": "yvXSIivTAiFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **平均二乗誤差（MSE）は、**\n",
        "- 予測値と実際の値を比較することで、予測がどの程度正確かを測る方法です。\n",
        "- 予測値と実際の値の二乗差の平均を取ることで機能します。\n",
        "\n",
        "- MSEを説明するのに役立つ簡単なメタファーがあります：\n",
        " - あなたが友人とダーツゲームをしていると想像してください。\n",
        " - 友人がダーツを投げて、ブルズアイに近いところに落ちたが、中心には届かなかった。\n",
        " - あなたが投げたダーツは、友達のダーツよりもブルズアイに近いところに着弾しました。\n",
        " - あなたのダーツがブルズアイに近づいても、あなたのダーツとブルズアイの差は、友人のダーツとブルズアイの差より大きい。\n",
        " - MSEは、ダーツがブルズアイにどれだけ近いか、どれだけ離れているかの両方を考慮した点数のようなものである。\n",
        "\n",
        "- MSEの利点は以下の通りです。\n",
        "\n",
        " - 計算と解釈が簡単\n",
        " - 外れ値に敏感で、大きな誤差をより重視する。\n",
        " - MSEの欠点は以下の通りです。\n",
        "\n",
        "- データの規模に影響されるため、異なるデータセット間の予測を比較することが困難である。\n",
        "- 差分を二乗するので、小さい誤差より大きい誤差に重きを置くことができる。\n",
        "- 異なる予測を比較するとき、どの予測が最も正確かを特定しようとすると、MSEは有用な指標となりえます。\n",
        " - 平均誤差の全体的な尺度が得られるので、大きなデータセットがある場合に特に有用です。\n"
      ],
      "metadata": {
        "id": "JyIyrLk7BByM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrQMy03trc7e"
      },
      "source": [
        "#### Package imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTL1rdhnrc7f"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# hide warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、3つの異なるライブラリを使用しています。\n",
        "- これらは、異なるツールを内包する道具箱のようなものです。\n",
        "\n",
        "- 最初の行のimport warningsはwarningsというツールボックスを取得しており、これはコードの実行中に現れるかもしれない特定のメッセージを無視するために使うことができます。\n",
        "- 2行目のimport numpy as npはnumpyというツールボックスを取得していて、数字や数学演算を扱うためのツールを備えています。\n",
        " - また、略して「np」というニックネームもつけています。\n",
        "- 3行目のimport pandas as pdは、pandasというツールボックスを取得しています。\n",
        " - これは、スプレッドシートで見られるようなデータのテーブルを扱うためのツールです。\n",
        " - また、略して「pd」というニックネームもつけています。\n",
        "- 次の行 warnings.filterwarnings(\"ignore\") は、warnings ツールボックスを使用して、コード実行中に表示される可能性のある特定のメッセージを無視するようにコンピュータに指示しています。\n",
        "\n",
        "- 全体として、このコードはwarnings、numpy、pandasという3つの異なるツールボックスを取り込んでおり、これらはコードが後で使用する異なるツールを備えています。\n",
        "- また、コードの実行中に表示される可能性のある特定のメッセージを無視するようにコンピュータに指示しています。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UnTTGf_rN3py"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovZVEVS_rc7i"
      },
      "source": [
        "# **1.基本的な予測 工程**\n",
        "- ここでは、基本的な予測 工程と、それに対する主要なインターフェースについて説明します。\n",
        "\n",
        "- 以下の4つの工程をカバーしています。\n",
        "\n",
        " - 基本的な展開の工程：バッチフィッティング、フォーキャスト\n",
        "\n",
        " - 基本的な評価工程: グラウンドトゥルース観測に対する予測バッチの評価\n",
        "\n",
        " - 高度なデプロイメント工程：フィッティング、ローリングアップデート/フォーキャスト\n",
        "\n",
        " - 高度な評価工程：ローリング予測分割の使用、一般的なバックテスト・スキームを含む分割誤差と集計誤差の計算。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2q9vlqNrc7i"
      },
      "source": [
        "- すべての工程は、入力データの形式について共通の前提を置いている。\n",
        "\n",
        "- sktimeは時系列を表現するためにpandasを使用しています。\n",
        "\n",
        " - pd.DataFrame主に時系列やシーケンスのためのデータフレーム。行は時間インデックスを、列は変数を表す。\n",
        "\n",
        " - pd.Seriesは一変量時系列やシーケンスにも使用できます。\n",
        "\n",
        " - numpyの配列（1Dと2D）も渡すことができますが、pandasの使用が推奨されます。\n",
        "\n",
        "- Series.indexと DataFrame.indexは、時系列やシーケンスのインデックスを表すために使われます。\n",
        "- sktimeは、単純な時系列のためにpandasinteger, period, timestamp インデックスをサポートしています。\n",
        "\n",
        "- sktimeは、パネルおよび階層的な時系列のための、さらなる追加のコンテナ形式をサポートする。\n",
        " - これらはセクション1.6で説明されている。\n",
        "\n",
        "- 例題:このチュートリアルの実行例として、1949年から1960年までの国際航空旅客数の月別合計数からなる教科書的データセット、Box-Jenkins航空会社データセットを使用します。\n",
        "- 値は、千人単位です。Makridakis,Wheelwrightand Hyndman (1998)Forecasting: methods and applications\", exercises section 2 and 3を参照してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "- この文章は、sktimeというライブラリを使って未来予測をする方法について述べています。\n",
        "- ライブラリの様々な使い方と、予測をするためにどのようなデータが必要かを説明しています。\n",
        "\n",
        "- 基本的な予測の工程\n",
        " - このセクションでは、sktimeを使って予測を行うために必要な様々なステップについて説明します。\n",
        "\n",
        "- 高度な評価工程。これは、時間の経過とともに予測がどの程度正確であるかをチェックすることです。\n",
        " - 1.1 データコンテナ形式。\n",
        "\n",
        "- ライブラリは、データをどのように使用するかを知るために、データが特定の形式であることを期待します。\n",
        "- このライブラリは、データテーブルを扱うライブラリであるpandasと、数値や数学演算を扱うライブラリであるnumpyを使用しています。\n",
        "- このライブラリは、データがpandasのDataFrameまたはSeriesであることを想定しています。\n",
        " - Seriesは行と列を持つテーブルのような構造体です。\n",
        "- ライブラリは、DataFrameやSeriesのインデックス（目次のようなもの）を使って、時系列やシーケンスの読み方を知ることができます。\n",
        "- 例\n",
        " - このライブラリは、1949年から1960年までの国際航空旅客数の月別合計を持つデータセットを使用します。\n",
        " - 数値は千人単位である。\n",
        " - このデータセットは、sktimeの使い方のチュートリアルを通して、例として使用されます。\n",
        " - 全体として、このテキストはsktimeというライブラリを使って未来予測をする方法について書かれており、ライブラリのさまざまな使い方や、予測をするためにどのようなデータを与える必要があるのかが説明されています。\n",
        " - また、ライブラリの使い方の例として、1949年から1960年までの国際線の乗客のデータセットが使われています。\n",
        "\n"
      ],
      "metadata": {
        "id": "HI5xj-3tPQWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sktime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuiTYwlgJVxZ",
        "outputId": "b19906f7-379b-4ad2-bece-aa9b0ea8b644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sktime in /usr/local/lib/python3.8/dist-packages (0.15.1)\n",
            "Requirement already satisfied: pandas<1.6.0,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sktime) (1.3.5)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from sktime) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn<1.3.0,>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from sktime) (1.0.2)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.8/dist-packages (from sktime) (1.2.13)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.8/dist-packages (from sktime) (0.12.2)\n",
            "Requirement already satisfied: numpy<1.25,>=1.21.0 in /usr/local/lib/python3.8/dist-packages (from sktime) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.8/dist-packages (from sktime) (0.56.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from deprecated>=1.2.13->sktime) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.55->sktime) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.55->sktime) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.55->sktime) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0,>=1.1.0->sktime) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.6.0,>=1.1.0->sktime) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.12.1->sktime) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.55->sktime) (3.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQj1UBeVrc7j"
      },
      "outputs": [],
      "source": [
        "#特定の航空会社データのデータセットを読み込むために使用\n",
        "from sktime.datasets import load_airline\n",
        "#データの視覚的な表現に利用\n",
        "from sktime.utils.plotting import plot_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "80cGHH1Arc7k",
        "outputId": "5ddc4579-21fc-4d07-abd6-fe6eee0461c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Figure size 1152x288 with 1 Axes>,\n",
              " <matplotlib.axes._subplots.AxesSubplot at 0x7f3c85197d00>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# load_airlineツールを使って航空会社のデータを読み込み、\"y \"という変数に代入\n",
        "y = load_airline()\n",
        "print(y)\n",
        "# 前のステップで読み込まれて変数 \"y\" に格納されたデータを視覚的に表現\n",
        "plot_series(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードは2つの異なるライブラリを使っています。\n",
        " - 1つはsktimeと呼ばれ、もう1つはutilsと呼ばれるライブラリです。\n",
        " - sktime ライブラリには \"load_airline\" と呼ばれるツールがあり、utils ライブラリには \"plot_series\" と呼ばれるツールがある。\n",
        "\n",
        "- sktime.datasets import load_airlineの1行目は、sktimeライブラリからload_airlineというツールを取得しており、特定の航空会社データのデータセットを読み込むために使用できるようになっています。\n",
        "- 2行目のfrom sktime.utils.plotting import plot_seriesは、utilsライブラリから「plot_series」というツールを取得し、データの視覚的な表現に利用しています。\n",
        "- 次の行y = load_airline()は、load_airlineツールを使って航空会社のデータを読み込み、\"y \"という変数に代入しています。\n",
        "\n",
        "- 最後の行plot_series(y)は、plot_series ツールを使って、前のステップで読み込まれて変数 \"y\" に格納されたデータを視覚的に表現しているものです。\n",
        "\n",
        "- 全体として、このコードは、航空会社のデータの特定のデータセットをロードし、その視覚的な表現を作成するために、sktimeとutilsという2つの異なるライブラリを使っています。\n",
        "- load_airlineツールはデータをロードするために使用され、plot_seriesツールはその視覚的表現を作成するために使用されています。"
      ],
      "metadata": {
        "id": "NM893pLAP2Wx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-このコードでは、いくつかのツールを使って、未来についての予測やデータの可視化を行っています。\n",
        "\n",
        "- 最初の2行は from sktime.datasets import load_airline と from sktime.utils.plotting import plot_series で、sktime toolbox から load_airline と plot_series というツールを得ています。\n",
        "\n",
        "- 次に、y = load_airline() は load_airline ツールを使っていくつかのデータを取得し、それを y という変数に保存しています。\n",
        "\n",
        "- 次に、plot_series(y)はplot_seriesツールを使って変数yに格納されているデータを可視化します。\n",
        "\n",
        "- 次に、このコードでは、ツールボックスの中にあるような、プログラムの後半で使用されるいくつかのツールを取り込んでいます。\n",
        "\n",
        "- 最初の行のimport warningsは、コード実行中に表示される可能性のある特定のメッセージを無視するために使用できるツールを持つ「warnings」というツールボックスを取得しています。\n",
        "\n",
        "- 2行目のimport numpy as npは、数字や数学演算を扱うためのツールを持つ「numpy」と呼ばれるツールボックスを取得しています。\n",
        " - また、このツールボックスには、略して「np」というニックネームが付けられています。\n",
        "\n",
        "- 3行目のimport pandas as pdは、\"pandas \"というツールボックスを取得するもので、スプレッドシートで見られるようなデータのテーブルを扱うためのツールを備えています。\n",
        " - また、このツールボックスのニックネームは「pd」になっています。\n",
        "\n",
        "- 次の行 warnings.filterwarnings(\"ignore\") は、最初の行で導入された warnings ツールボックスを使って、コード実行中に表示される可能性のある特定のメッセージを無視するようにコンピュータに指示するものである。\n",
        " - これは、コンピュータに特定の事柄に注意を払わないように指示するようなものです。\n",
        "\n",
        "- 全体として、このコードは将来の予測をするためのツールを使い、load_airlineツールを使ってデータを取得し、plot_seriesツールを使ってそのデータを視覚化しています。 - また、プログラムの後半で使用するいくつかのツールを導入し、コードの実行中に表示される可能性のある特定のメッセージを無視するようにコンピュータに指示しています。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sxDiVurTRXrQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4mcZ2Qvrc7n",
        "outputId": "4e18c5fd-327c-45f3-d820-2350ab00cea9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeriodIndex(['1949-01', '1949-02', '1949-03', '1949-04', '1949-05', '1949-06',\n",
              "             '1949-07', '1949-08', '1949-09', '1949-10',\n",
              "             ...\n",
              "             '1960-03', '1960-04', '1960-05', '1960-06', '1960-07', '1960-08',\n",
              "             '1960-09', '1960-10', '1960-11', '1960-12'],\n",
              "            dtype='period[M]', length=144)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZy74NTVrc7o"
      },
      "source": [
        "- 一般的に、ユーザーは予測用のデータセットを読み込むために、pandasや pandas互換パッケージの内蔵の読み込み機能、\n",
        "- 例えばread_csvや、numpy.arrayなど他のインメモリ形式でデータが利用できる場合はSeriesや DataFrame コンストラクタを使うことが期待されています。\n",
        "\n",
        "- sktime forecastersは pandasに隣接するフォーマットで入力を受け付けますが、pandasのフォーマットで出力を生成し、入力を強制するように試みます。\n",
        "\n",
        "- 注：もしあなたの好きなフォーマットが適切に変換されない場合は、親切にもその機能をsktimeに提供することを検討してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzPJtGn5rc7o"
      },
      "source": [
        "\n",
        "### 1.2 基本的な展開の工程 - バッチ学習と予測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UEWeU3Prc7p"
      },
      "source": [
        "- 最もシンプルなユースケース工程は、バッチフィッティングおよび予測です。\n",
        "\n",
        "- つまり、過去のデータの1バッチに予測モデルをフィッティングし、将来のある時点における予測を求めるというものです。\n",
        "\n",
        "- この工程の手順は次のとおりです。\n",
        "\n",
        "- データの準備\n",
        "\n",
        " - 予測が要求される時点の指定。\n",
        "  - これはnumpy.arrayまたはForecastingHorizonオブジェクトを使用する。\n",
        "\n",
        "- forecaster の仕様と インスタンス化。\n",
        " - これはscikit-learn に似た構文に従います。\n",
        " - forecasterオブジェクトは、おなじみのscikit-learn BaseEstimatorインターフェイスに従います。\n",
        "\n",
        "- 予測器をデータに学習させる、予測器ズ学習法\n",
        " - 予測器・プレディクト方式で、予測を立てる\n",
        "\n",
        "- 以下では、まず、基本的なデプロイメントの工程のバニラバリアントの概要を順を追って説明します。\n",
        "\n",
        "- 最後に、1セルの工程を、パターンからの一般的な逸脱を含めて提供する（1.2.1項以下）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAasuJt7rc7p"
      },
      "source": [
        "### **ステップ1 - データ準備**\n",
        "1.1 節で述べたように、データはpd.Seriesまたはpd.DataFrame形式であることが前提である。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このテキストは、sktimeというライブラリを使って未来予測をする方法について述べています。\n",
        "- ライブラリの使い方と、予測をするためにどのようなデータを与える必要があるのか、その概要を説明しています。\n",
        "\n",
        "- 一般的に、ユーザーは予測用のデータセットを読み込むために、pandasやpandas互換パッケージの内蔵の読み込み機能、\n",
        " - 例えばread_csvや、データがnumpy.arrayなどの他のインメモリフォーマットで利用できる場合はSeriesやDataFrameコンストラクタを使うことが期待されます。\n",
        "- sktime forecastersは他のフォーマットで入力を受け取るかもしれませんが、pandasのフォーマットで出力を生成し、入力を変換しようとします。\n",
        " - もし、あなたの好きなフォーマットが適切に変換されなかったり、強制されない場合は、親切にもその機能をsktimeに貢献することを検討してください。\n",
        "- 1.2 基本的な展開の工程 - バッチ学習と予測。\n",
        "\n",
        "- つまり、過去のデータの1つのバッチに予測モデルを当てはめ、将来のある時点における予測を求めるということです。\n",
        "- この工程のステップは以下の通りです。\n",
        "- データの準備。データは、pd.Series または pd.DataFrame フォーマットであると仮定されます。\n",
        "- 予測が要求される時点を指定する。これはnumpy.arrayまたはForecastingHorizonオブジェクトを使用する。\n",
        "- 予測器の指定とインスタンス化。これはscikit-learnのような構文に従います;\n",
        " -  forecasterオブジェクトはおなじみのscikit-learn BaseEstimatorインターフェイスに従います。\n",
        "- 予測器の fit メソッドを用いて、予測器をデータに学習させる。\n",
        "- 予測器のpredictメソッドによる予測\n",
        " - 全体として、この文章はsktimeライブラリを使って未来予測をする方法について書かれており、\n",
        " - ライブラリを使う最もシンプルな方法である基本的なデプロイメントの工程のステップと、\n",
        " - 予測をするためにどのようなデータを与える必要があるかが説明されています。また、\n",
        " - このライブラリは、以下のような可能性があることにも言及している。\n",
        "\n"
      ],
      "metadata": {
        "id": "OCSBP1DZSYDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sktime.datasets import load_airline # load_airline 関数を sktime.datasets モジュールからインポートする。\n",
        "from sktime.utils.plotting import plot_series # sktime.utils.plotting モジュールから plot_series 関数をインポートする。\n",
        "\n",
        "# この例では、航空会社のデータセットを使用します。\n",
        "y = load_airline() # この行は、航空会社のデータセットをロードし、それを変数 'y' に代入します。\n",
        "plot_series(y) # この行は 'y' のデータをプロットするために plot_series 関数を使用します。"
      ],
      "metadata": {
        "id": "ipjv-VG0UMMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードでは、いくつかのツールを使って、未来についての予測やデータの可視化を行っています。\n",
        "\n",
        "- 最初の2行は from sktime.datasets import load_airline と from sktime.utils.plotting import plot_series で、sktime toolbox から load_airline と plot_series というツールを得ています。\n",
        "\n",
        "- 次に、y = load_airline() は load_airline ツールを使ってデータを取得し、それを y という変数に保存しています。\n",
        "\n",
        "- 次に、plot_series(y) は plot_series ツールを使って、変数 y に保存されたデータを可視化します。\n",
        " - これにより、より直感的にデータを可視化することができ、より簡単に未来についての予測を行うことができます。\n",
        "\n",
        "- 全体として、このコードは将来の予測をするためのツールを使っています。\n",
        "- load_airlineツールを使ってデータを取得し、plot_seriesツールを使ってそのデータを視覚化しています。\n",
        "- 読み込まれているデータは、プロットされる航空会社のデータセットです。\n"
      ],
      "metadata": {
        "id": "PuPoi5KbTM1y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGY0T25prc7r"
      },
      "source": [
        "# **ステップ2 -予測地平線の特定**\n",
        "- 次に、予測地平線を指定し、それを予測アルゴリズムに渡す必要があります。\n",
        "\n",
        "- 大きく分けて2つの方法があります。\n",
        "\n",
        "- 整数の numpy.arrayを使用します。\n",
        " - これは、時系列の整数インデックスまたは周期インデックス（PeriodIndex）を想定しています。\n",
        " - 整数は、予測を行いたい先の時間ポイントまたは期間の数を示します。\n",
        " - 例えば、1は次の期間を予測することを意味し、2は2つ目の次の期間を予測することを意味する、など。\n",
        "\n",
        "- ForecastingHorizonオブジェクトを使用します。\n",
        " - これは、引数としてサポートされている任意のインデックス・タイプを使用して、予測水平線を定義するために使用することができます。\n",
        " - 周期的なインデックスは想定されていません。\n",
        "\n",
        "- 予測水平線は、将来の特定の時点を参照する絶対的なものと、現在との時差を参照する相対的なものがある。\n",
        "- デフォルトでは、forecasterに渡されたyの中で最も新しい時点が現在となります。\n",
        "\n",
        "- numpy.arrayベースの予測水平線は常に相対的です。\n",
        "- ForecastingHorizonオブジェクトは相対的と絶対的の両方が可能です。\n",
        "- 特に、絶対的な予測水平線はForecastingHorizonを使用してのみ指定することができます。\n",
        "\n",
        "- numpyの 予測地平線を利用する"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- ステップ2：予測地平線の指定\n",
        "\n",
        "- さて、コンピュータ・プログラムにどのくらい先の予測をさせたいかを指示する必要があります。\n",
        "- これには2つの方法があります。\n",
        "- numpy.array \"と呼ばれる数値のリストを使用する。\n",
        " - これは、時系列が整数か時間の規則的なパターンをインデックスとして持っていると仮定しています。\n",
        " - リストの中の数字は、何個先の時点またはパターンについて予測を行いたいかをプログラムに伝える。\n",
        " - 例えば、1を入れると次に何が起こるかを予測し、2を入れるとその次に何が起こるかを予測する、といった具合です。\n",
        "- ForecastingHorizon \"という特殊なオブジェクトを使用します。\n",
        " - これは、サポートされているあらゆるタイプのインデックスを使って、予測水平線を定義するために使用することができます。\n",
        " - これは、インデックスにおける時間の規則的なパターンを想定しているわけではありません。\n",
        " - 予測水平線は、将来の特定の時点、または現在からの時間差のいずれかを指定することができます。\n",
        "- デフォルトでは、現在が、予測を行うためにプログラムに与えたデータの中で見られる最新の時点となります。\n",
        "- numpy.array \"ベースの予測水平線は常に相対的である。\n",
        "- ForecastingHorizon \"オブジェクトは相対的か絶対的かのどちらかを選ぶことができます。\n",
        "- 絶対的な予測水平線は、\"ForecastingHorizon \"を使ってのみ指定することができます。\n",
        "- 例\n",
        "\n",
        " - 明日の天気を予測したいと想像してください。そこで、1日先の予測地平線を指定する必要があります。\n",
        " - numpy.arrayを使うと、[1]と書き、翌日を予測することになります。\n",
        " - ForecastingHorizonを使うと、明日の日付を書きます。\n"
      ],
      "metadata": {
        "id": "YKcpMpMEVCIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr3DGT2irc7s",
        "outputId": "e3e1404b-ae37-40eb-9a13-f64d3f6dc6fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "fh = np.arange(1, 37) # この行では、1から36までの数値の配列を作成し、変数「fh」に代入しています。\n",
        "fh # この行は、fhに代入された配列を表示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-UsPfIHrc7s"
      },
      "source": [
        "これは、元のシリーズの期間が1ヶ月であるため、今後3年間の毎月の予測を要求します。別の例では、2ヶ月先と5ヶ月先だけを予測するために、次のように書きます。\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "fh = np.array([2, 5])  # 2nd and 5th step ahead\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードは、\n",
        "- sktime.datasetsモジュールからload_airline関数、sktime.utils.plottingモジュールからplot_series関数、nmpyをnpライブラリとしてインポートしています。\n",
        "- そして、航空会社のデータセットをロードし、それを変数 'y' に代入し、'y' にデータをプロットしています。\n",
        "- 次に、1から36までの数値の配列を作成し、変数'fh'に代入します。最後に、fhに代入された配列を表示します。"
      ],
      "metadata": {
        "id": "yVsBbq9PVpFS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrbM4xY5rc7s"
      },
      "source": [
        "### **ForecastingHorizonに基づく予測地平線の使用**\n",
        "- ForecastingHorizonオブジェクトは絶対インデックスを入力として受け取りますが、is_relativeフラグによって入力を絶対または相対とみなします。\n",
        "\n",
        "- ForecastingHorizonはpandasからの時間差型が渡された場合、自動的に相対的な水平線を仮定し、pandasからの値型が渡された場合、絶対的な水平線を仮定することになります。\n",
        "\n",
        "- この例で絶対的なForecastingHorizonを定義するには、以下のようにします。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 要約\n",
        "\n",
        "- ForecastingHorizon \"という特殊なオブジェクトを使用して、将来の予測を行います。\n",
        "\n",
        "- ForecastingHorizon \"オブジェクトは、将来の特定の時間点を入力として受け取るが、- 入力が特定の時間に関するものか、現在との時間差だけなのかを理解することも可能である。\n",
        "- 入力が特定の時間に関するものなのか、現在との時間差だけなのかは、与えた入力の種類によって自動的に理解することができる。\n",
        " - 例えば、現在からの時間差を与えると、相対的な水平線と判断します。\n",
        " - しかし、将来の具体的な時間を与えれば、それは絶対的な水平線と見なされる。\n",
        "- この例では、絶対的な \"ForecastingHorizon \"を定義しています。\n",
        "\n",
        "- この例では、将来のある特定の時点について何かを予測したいとします。\n",
        "- ForecastingHorizon \"オブジェクトに、予測したい将来の具体的な時間を指定する必要があります。\n",
        "- 例えば、次の月曜日の天気を予測したい場合、\"ForecastingHorizon \"オブジェクトに次の月曜日の日付を与えることになります。\n",
        "- 例\n",
        "\n",
        " - 例えば、来年の夏の気温を予測したいとします。\n",
        " - そこで、来年の夏の予測地平線を指定する必要があります。\n",
        " - ForecastingHorizonを使って、来年の夏の日付を書けば、\n",
        " - それが絶対的な水平線であると見なされます。\n",
        "\n"
      ],
      "metadata": {
        "id": "mVpNVJaGV47S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkePeZOBrc7t"
      },
      "outputs": [],
      "source": [
        "##forcastingHorizon クラスを sktime.forecasting.base からインポートする。\n",
        "from sktime.forecasting.base import ForecastingHorizon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-j_zFONrc7t",
        "outputId": "0cb53e23-6628-4a5f-d155-f789cd5628f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ForecastingHorizon(['1961-01', '1961-02', '1961-03', '1961-04', '1961-05', '1961-06',\n",
              "             '1961-07', '1961-08', '1961-09', '1961-10', '1961-11', '1961-12',\n",
              "             '1962-01', '1962-02', '1962-03', '1962-04', '1962-05', '1962-06',\n",
              "             '1962-07', '1962-08', '1962-09', '1962-10', '1962-11', '1962-12',\n",
              "             '1963-01', '1963-02', '1963-03', '1963-04', '1963-05', '1963-06',\n",
              "             '1963-07', '1963-08', '1963-09', '1963-10', '1963-11', '1963-12'],\n",
              "            dtype='period[M]', is_relative=False)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# ForecastingHorizonクラスのオブジェクトを作成、範囲は1961年1月から36ヶ月、is_relative=False、つまり絶対水平線であることを意味します。\n",
        "fh = ForecastingHorizon(\n",
        "    pd.PeriodIndex(pd.date_range(\"1961-01\", periods=36, freq=\"M\")), is_relative=False\n",
        ")\n",
        "fh# この行はForecastingHorizonオブジェクトを表示します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPZUsXIArc7u"
      },
      "source": [
        "- ForecastingHorizon-sはto_relativeとto_absoluteメソッドにより相対値から絶対値への変換を行うことができます。\n",
        "- これらの変換は両方とも互換性のあるカットオフが渡される必要があります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVTSQSs6rc7u"
      },
      "outputs": [],
      "source": [
        "cutoff = pd.Period(\"1960-12\", freq=\"M\")# 1960年12月という日付の変数'cutoff'の作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef1hjk6Erc7v",
        "outputId": "fe092da0-7b21-4f72-a3bf-e626015ae876"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ForecastingHorizon([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "            18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "            35, 36],\n",
              "           dtype='int64', is_relative=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "fh.to_relative(cutoff)# 変数 'cutoff' を参照して、絶対水平線から相対水平線に変換します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnZko55mrc7w",
        "outputId": "8217ed20-9911-430c-ebe1-f0f81ed917a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ForecastingHorizon(['1961-01', '1961-02', '1961-03', '1961-04', '1961-05', '1961-06',\n",
              "             '1961-07', '1961-08', '1961-09', '1961-10', '1961-11', '1961-12',\n",
              "             '1962-01', '1962-02', '1962-03', '1962-04', '1962-05', '1962-06',\n",
              "             '1962-07', '1962-08', '1962-09', '1962-10', '1962-11', '1962-12',\n",
              "             '1963-01', '1963-02', '1963-03', '1963-04', '1963-05', '1963-06',\n",
              "             '1963-07', '1963-08', '1963-09', '1963-10', '1963-11', '1963-12'],\n",
              "            dtype='period[M]', is_relative=False)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "fh.to_absolute(cutoff)# 変数 'cutoff' を基準にして、相対的な水平線を絶対的な水平線に変換します。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- forcastingHorizon クラスを sktime.forecasting.base からインポートする。\n",
        "- from sktime.forecasting.base import ForecastingHorizon\n",
        "- ForecastingHorizonクラスのオブジェクトを作成、範囲は1961年1月から36ヶ月、is_relative=False、つまり絶対水平線であることを意味します。\n",
        "- fh = ForecastingHorizon(\n",
        "-     pd.PeriodIndex(pd.date_range(\"1961-01\", periods=36, freq=\"M\")), \n",
        "- is_relative=False\n",
        ")\n",
        "- fh# この行はForecastingHorizonオブジェクトを表示します。\n",
        "- cutoff = pd.Period(\"1960-12\", freq=\"M\")# 1960年12月という日付の変数'cutoff'の作成\n",
        "-fh.to_relative(cutoff)# 変数 'cutoff' を参照して、絶対水平線から相対水平線に変換します。\n",
        "fh.to_absolute(cutoff)# 変数 'cutoff' を基準にして、相対的な水平線を絶対的な水平線に変換します。"
      ],
      "metadata": {
        "id": "YsUdnwoRjzKe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTOqwvl4rc7w"
      },
      "source": [
        "### **ステップ3 - 予測アルゴリズムを特定する**\n",
        "- 予測を行うには、予測アルゴリズムを指定する必要があります。\n",
        " - これはscikit-learnに似たインターフェースを使って行われます。\n",
        " - 最も重要なことは、すべてのsktime予測器は同じインターフェースに従っているので、\n",
        " - どの予測器が選ばれても、前と後のステップは同じだということです。\n",
        "\n",
        "- この例では、最後に見た値を予測するナイーブな予測方法を選択します。\n",
        " - パイプラインとリダクションの構文を使って、より複雑な仕様も可能である。\n",
        " - これについては、セクション2で後述する。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **概要**\n",
        "ステップ3\n",
        "-予測アルゴリズムの指定は、コンピュータ・プログラムに予測を行うためにどの方法を使うかを指示することです。\n",
        "\n",
        "- これはscikit-learnライブラリと同様のインターフェイスを使って行われます。\n",
        "- 最も重要なことは、すべてのsktime予測器は同じインターフェースに従うので、どの予測器を選んでも、前と後のステップは同じであるということです。\n",
        "- この例では、最後に見た値を予測するという最も単純な方法を選びます。\n",
        "- パイプラインやリダクションの構文を使って、より複雑な方法も使用できます。\n",
        " - これについては、セクション2で後述します。\n",
        "- まとめ：\n",
        " - このステップでは、どの予測方法を使うかをコンピュータ・プログラムに指示する\n",
        " - ここでは、最後に見た値を予測する最も単純な方法を使う。\n",
        " - より複雑な方法については後ほど説明します。\n",
        "\n"
      ],
      "metadata": {
        "id": "vbqCZOxlYc4l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNpeGTRcrc7x"
      },
      "outputs": [],
      "source": [
        "# sktime.forecasting.naive モジュールから NaiveForecaster クラスをインポートする。\n",
        "from sktime.forecasting.naive import NaiveForecaster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrOt-bIBrc7x"
      },
      "outputs": [],
      "source": [
        " # この行は、戦略 \"last\" を持つ NaiveForecaster クラスのオブジェクトを生成する。\n",
        "forecaster = NaiveForecaster(strategy=\"last\")\n",
        "# NaiveForecasterは、最後に観測された値を用いて予測を行う手法です。\n",
        "# strategy \"パラメータは、使用する予測戦略を指定するために使用されます。\n",
        "# この場合、\"last \"ストラテジーが使用されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードは sktime.forecasting.naive モジュールから NaiveForecaster クラスをインポートし、NaiveForecaster クラスのオブジェクトを戦略 \"last\" で生成しています。\n",
        "- NaiveForecasterは、最後に観測された値を用いて予測を行う手法です。\n",
        "- strategy \"パラメータは、使用する予測戦略を指定するために使用されます。\n",
        "- この場合、\"last \"ストラテジーが使用されます。"
      ],
      "metadata": {
        "id": "LrfcIVMUZHNs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr0Uyg7krc7x"
      },
      "source": [
        "### **ステップ4 - 見たデータに予測器を学習させる**\n",
        "ここで、予測器を見たデータに学習させる必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GkwNzBtrc7y",
        "outputId": "1b9d4677-3518-4381-f534-6a89977a1310"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NaiveForecaster()"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "forecaster.fit(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozeiEw7Irc7y"
      },
      "source": [
        "### **ステップ5 - 予測を依頼する**\n",
        "- 最後に、指定された予測地平線のための予測を要求します。\n",
        "- これは予測器をフィッティングした後に行う必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q64e-bc1rc7z"
      },
      "outputs": [],
      "source": [
        "y_pred = forecaster.predict(fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "WZv-GF5erc7z",
        "outputId": "68bfc6cf-43da-4a78-a326-f631159023a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Figure size 1152x288 with 1 Axes>,\n",
              " <matplotlib.axes._subplots.AxesSubplot at 0x7f3cf5e04fa0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAD4CAYAAAA+abFdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3icZ5X38e896pIlq1mWmyT3xAXbQbZj45A4JgmQEKcQmwApTlhYWBLYvCxkN0vZF1he2KU5kOwCwSkEkpBeIM2pjh23xHZsucRNripWr6Py3O8fmpFVRtJImmr/PtelS5qZZ+Y5Myr2mXPucxtrLSIiIiIiIiLRxBXuAEREREREREQGS8msiIiIiIiIRB0lsyIiIiIiIhJ1lMyKiIiIiIhI1FEyKyIiIiIiIlEnNtwBDEd2drYtKCgIdxgiIiIiIiISBFu3bj1lrR3l67aoTmYLCgrYsmVLuMMQERERERGRIDDGFPd1m9qMRUREREREJOoomRUREREREZGoo2RWREREREREok5Ur5kVERERERGJNq2trRw7dozm5uZwhxIxEhMTGT9+PHFxcX7fR8msiIiIiIhICB07dozU1FQKCgowxoQ7nLCz1lJRUcGxY8eYOHGi3/dTm7GIiIiIiIfjWErqmimuaqSkrhnHseEOSc5Azc3NZGVlKZH1MMaQlZU16Eq1KrMiIiIiInQksjtLalm+ZjPFVU3kZyTxzKr5zMpNw+VS0iGBpUS2u6G8HqrMioiIiIgAZQ3uzkQWoLiqieVrNlPW4A5zZCLii5JZERERERHA3eZ0JrJexVVNuNucMEUkIv1RMisiIiIiAiTEusjPSOp2XX5GEgmx+i+zhJfWcvum30wRERERESAnJYFnVs3vTGjzM5L448q5xGhpo4SRdy33otXrmPjjtSxavY6dJbXDTmi/973v8atf/arz8l133cWvf/3r4YYbUhoAJSIiIiICuFyGWblp/M9nP0JmUhxZKfGseuR9PjImjbs+MQ13u0NCrIuclAQNhJKA+eYzO9l+vLbP2//9kql86bHtvdZy/2HFHH70yoc+7zNnXBq/Wj6r3/PecsstXHPNNXzzm9/EcRweeeQRNm3aNPQnEgZKZkVEREREPIyBzz6whVsX5vGr5bO448LJjEiIZdHd6zThWMJiRHysz7XcI+KHl8oVFBSQlZXF+++/T2lpKfPmzSMrK2tYjxlqQU1mjTHpwB+AWYAFbgH2Ao8CBcBhYIW1tsp0zGL+NfBpoBG42Vr7XjDjExERERHpqqy+hYaWdiZnpQCwMC+jM5GF01WxDbcvITc1MZyhyhlioApqSV0z+RlJ3RLa/Iwk8jOTeP1ri4d17i996Uvcf//9lJSUcMsttwzrscIh2Gtmfw28aK09B5gD7AbuBNZaa6cCaz2XAT4FTPV8fBm4N8ixiYiIiIh0c6CiAYDJWckAuNs14VjCy9da7mdWzScnJWHYj3311Vfz4osvsnnzZi677LJhP16oBa0ya4wZCXwcuBnAWtsCtBhjlgMXeQ57AHgD+A6wHHjQWmuBd40x6caYMdbak8GKUURERESkK28yO8mTzHonHPesimnCsYSKdy33htuX4G4L7Lrt+Ph4li5dSnp6OjExMQGINrSC+Vs4ESgH1hhj3jfG/MEYkwKM7pKglgCjPV+PA452uf8xz3UiIiIiIiFx4FQjxsDEzI5kNphVMRF/uVyG3NRE8jOSyU1NDNh6bcdxePfdd7n11lsD8nihFsw1s7HAecBt1tqNxphfc7qlGABrrTXGDGqmtDHmy3S0IZOXlxeoWEVEREREOFjRwPiRiSTEdlSpvFWxJ24qpM7dzpTsZMYEMJkQCZeioiKuuOIKrr76aqZOnRrucIYkmJXZY8Axa+1Gz+XH6UhuS40xYwA8n8s8tx8HJnS5/3jPdd1Ya39nrS201haOGjUqaMGLiIiIyNnnQEVj5/AnL5fLcKCikaX3rudUQ4sSWTkjzJgxg4MHD/Lzn/883KEMWdCSWWttCXDUGDPdc9UyoAh4FrjJc91NwDOer58FbjQdzgdqtF5WRERERELpQEUDk3oks0Bnm3HPYVAiEj7B3mf2NuBhY0w8cBBYRUcC/Zgx5lagGFjhOfZvdGzLs5+OrXlWBTk2EREREZFOdc1tlNW3dE4y7io/o+M6JbMikSOoyay1dhtQ6OOmZT6OtcA/BTMeEREREZG+HKz0bsvTuzKbMyKexFgXxVWNoQ5LRPqgmeIiIiIiInSslwWYnN27MmuMIS8jiSOqzIpEDCWzIiIiIiLAgVN9V2aBXvvNikh4KZkVEREREaGjMpuZHEd6UpzP2/MyktVmLGFhrUNbQwmttUdoayjBWifcIQ3Z/fffz9e//vWAPFawB0CJiIiIiESFgxUNfVZloaMyW1bfQlNrO0lxMSGMTM5m1jq0nNpJ2XPX0lZbTGxaPjmfeYL47FkYEzm1yfb2dmJiQvt7oWRWRERERISOyuzCvPQ+b/duz3OkqonpOSNCFZac4Sre+D+0lG/v8/b0hf/GqVe/QlttMQBttcWUPXct2Z/4X6o3/qfP+8SPmkPWRf3vH/u9732PzMxMvvnNbwJw1113kZOTwze+8Y1ux73xxht873vfIzU1lf3797N06VLuueceXC4XI0aM4Ctf+Qqvvvoqv/3tbzl8+DCrV6+mpaWFhQsXcs899xATE8OaNWv4yU9+Qnp6OnPmzCEhIWEwL1GfIieVFxEREREJk9Z2hyPVTT73mPXKT/duz6NWYwkdEzeiM5H1aqstxsQN7w2VW265hQcffBAAx3F45JFH+OIXv+jz2E2bNnH33XdTVFTEgQMHePLJJwFoaGhg4cKFbN++naysLB599FHeeecdtm3bRkxMDA8//DAnT57k+9//Pu+88w7r1q2jqKhoWHF3pcqsiIiIiJz1iquaaHeszz1mvbyVWQ2BkkAaqILa1lBCbFp+t4Q2Ni2f2LQ8xlz36pDPW1BQQFZWFu+//z6lpaXMmzePrKwsn8cuWLCASZMmAXD99dezbt06PvvZzxITE8O1114LwNq1a9m6dSvz588HoKmpiZycHDZu3MhFF13EqFGjAFi5ciX79u0bctxdKZkVERERkYBwHEtZgxt3m0NCrIuclARcLhPusPxyoKL/ScYA40YmEuMySmYlpGKSc8j5zBO91szGJOcM+7G/9KUvcf/991NSUsItt9zS53HGGJ+XExMTO9fJWmu56aab+MlPftLt2KeffnrYcfZFbcYiIiIiMmyOY9lZUsui1euY+OO1LFq9jp0ltTiODXdofjlwqu89Zr1iY1yMS0vkiNqMJYSMcRGfPYsxK99mwi37GbPy7YANf7r66qt58cUX2bx5M5dddlmfx23atIlDhw7hOA6PPvooS5Ys6XXMsmXLePzxxykrKwOgsrKS4uJiFi5cyJtvvklFRQWtra389a9/HXbcXqrMioiIiMiwlTW4Wb5mc2fVsriqieVrNrPh9iXkpiaGObqBHahoIDHWxZgBYtVesxIOxriITckN+OPGx8ezdOlS0tPT+51EPH/+fL7+9a93DoC6+uqrex0zY8YMfvSjH3HppZfiOA5xcXH89re/5fzzz+cHP/gBixYtIj09nblz5wYsfiWzIiIiIjJsTS3tvZK84qom3G3RsR/mwYoGJmUlD9gWnZ+RxFsHK0MUlUhwOY7Du+++O2C1NC0tjeeff77X9fX19d0ur1y5kpUrV/Y6btWqVaxatWp4wfqgNmMRERERGTTHsZTUNVNc1ciRqkaO1TR3Dkjyys9IIiE2Ov67ebCysd/1sl55Gckcr22mrT06knSRvhQVFTFlyhSWLVvG1KlTwx3OkKgyKyIiIiKD4l0f620rzs9I4tEbzuPxmwr57ANbOq97ZtV8clICs59kMFlrOVjRyMVTsgc8Nj8jiXbHcrymmfzMvtfXikS6GTNmcPDgwc7LH3zwATfccEO3YxISEjqnEUeiQSWzpmOV8QhrbW2Q4hERERGRCOdrfezKh95j0zeXcO+1s8lOSWB8emLUTDMurXPT0NLuV2W26/Y8SmZlOKy1vaYEh9Ps2bPZtm1b2M5v7eCHxQ3Y92GM+bMxJs0YkwLsBIqMMf8yhPhERERE5AzgbnN8ro9tbHH45VsH+fqTH5CbmhgViSzAgQrPJON+9pj1ys/oOKa4WhONZegSExOpqKgYUgJ3JrLWUlFRQWLi4IbF+VOZnWGtrTXGfAH4O3AnsBX4r8GHKSIiIiLRLiHW1Wuqr3d9bH5GMs+eKAljdIPXucdstj9rZk9XZkWGavz48Rw7dozy8vJwhxIxEhMTGT9+/KDu408yG2eMiQOuAn5jrW01xugtBBEREZGzVE5KAk/ePJ9r7t/ca31sfkYSZfUtNLa0kRwf+eNZHMdybs4IXv/qYlITYnEc229FOSkuhpwR8UpmZVji4uKYOHFiuMOIev78hfkf4DCwHXjLGJMPaM2siIiIyFnK5TK0tjv84sqZzBidysik2M71sQWedaRHqps4Jyc1zJH2zzvIasVDW7sl5bNy0/pNaPMzkjlSpTZjkXDrd82sZ+BTqbV2nLX207ajqfsIsDQk0YmIiIhIRNpytIZrH9jCiISYbutjCzxrSg9XRn7l0tcgq+VrNlPW4O73fj1brEUkPPpNZq21DvDtHtdZa21bUKMSERERkYi2p7yeEQkxjE3rPrDFO+33cGXkVy77GmTlbut/D9m8jCSOVDVpeI9ImPmzi/WrxphvGWMmGGMyvR9Bj0xEREREItbesjrOGTWi19YiY9ISiYsxFFdHfuXSO8iqK+8gq/7kZyTT3OZQVt8SzPBEZAD+JLMrgX8C3qJjivFWYEswgxIRERGRyLanrJ5zckb0uj7GZchLT6I4CiqzOSkJPHZjYWdC23WQVX9O7zUb+c9R5Ew24AAoa63GbImIiIhIp3p3G0erm5nuI5kFKMhM5nAUrCl1uQzbT9TwiytnMm/cSBLjXJ2DrPqT32V7ngV5GaEIVUR8GLAya4xJNsb8uzHmd57LU40xVwQ/NBERERGJRPvK6wF8VmahY01ptFQtX9xTxp0v7KYgM7nbIKv+5HuGXGkIlEh4+dNmvAZoARZ7Lh8HfhS0iEREREQkou0p8yazvrfeKchI5mStm+bW9lCGNSTvH69l3riRg7pPelIcaYmxUZOwi5yp/ElmJ1trfwa0AlhrG4GB37ISERERkTPSnrJ6XAamZCf7vL0gs6MN90iED4GqbmrlUGUjc8amDfq+BRnJHFFlViSs/ElmW4wxSYAFMMZMBvrffEtEREREzlh7y+qZlJVCQmyMz9vz06OjDXfHiVoA5g4hmc3PSOKwKrMiYTXgACjg+8CLwARjzMPAx4CbgxmUiIiIiESuPeX1nDPK93pZOF2ZjfS9ZredqAEYdJux41juvHgKbY6lpK7Zr6FRIhJ4/kwzfsUY8x5wPh3txd+w1p4KemQiIiIiZyDHsZQ1uHG3OSTE+jc9N5K0O5Z95Q1cOi2nz2PGpiUS6zIRX7ncdryW0akJ5KYl+n0fx7HsLKnl8w+/R3FVU+d2PrNy06Lq+yhyJvBnmvF5QD5wEjgB5BljJhtj/KnqioiIiIiHNxFatHodE3+8lkWr17GzpBbHseEOzW/FVY2425w+JxkDxMa4GD8ykeLKyG4z3naiZtAtxmUNbpav2dzZQl1c1cTyNZspa9AqPJFQ82fN7D3Au8DvgN8DG4C/AnuNMZf2d0djzGFjzAfGmG3GmC2e6zKNMa8YYz70fM7wXG+MMauNMfuNMTs8SbSIiIjIGeNMSIROTzLuO5mFjr1mI3nab0ubw67SOuYOssXY3eb0WgtcXNWEu80JZHgi4gd/ktkTwDxrbaG19qPAPOAgcAnwMz/uv9RaO9daW+i5fCew1lo7FVjruQzwKWCq5+PLwL3+Pw0RERGRyHcmJEJ+J7MZyRyO4AFQRaV1tLbbQVdmE2Jd5GckdbsuPyOJhFh//lstIoHkz2/dNGvtLu8Fa20RcI619uAQz7kceMDz9QPAVV2uf9B2eBdIN8aMGeI5RERERCJOU6sT9YnQnrJ6slPiyUqJ7/e4vIwkTtQ20xKhifq2zknGg6vM5qQk8Myq+Z3fx/yMJJ5eNZ+clISAxygi/fNn3esuY8y9wCOeyyuBImNMAp69Z/thgZeNMRb4X2vt74DR1tqTnttLgNGer8cBR7vc95jnupNdrsMY82U6Krfk5eX5Eb6IiIhI+HgHPtW72yita+ahz8/jhj+/3214UDQlQnvL6gesykJHm7G1cLS6icnZKSGIbHC2naghOS6GKYOMzeUyzMpNY8PtS6hoaGFfeQNJsTEa/iQSBv4kszcDXwO+6bn8DvAtOhLZpQPcd4m19rgxJgd4xRizp+uN1lrrSXT95kmIfwdQWFgYPdMSRERE5KzjHfjkXSebn5HE3/9hIa/+4yKOVTczOjWBadkpUZUI7Smr58pZuQMeV+CpXB6uaozIZHb78VrmjE0jZgivvctlyE1NxN3qcO0DW/jV8plM8yPBF5HAGrCnxVrbZK39ubX2as/Hf1trG621jrW2foD7Hvd8LgOeAhYApd72Yc/nMs/hx4EJXe4+3nOdiIiISFTyNfDpU7/fSJzLsPTe9bx9sCKqEtmKhhbKG1r63WPWqyAzGYDDETjR2FrLthM1zBnketme8jOTmZiZzBsHKgIUmYgMhj9b83zMM3V4nzHmoPfDj/ulGGNSvV8DlwI7gWeBmzyH3QQ84/n6WeBGz1Tj84GaLu3IIiIiIlGnr4FPFnAZOFIdeYlef/wd/gQwbmQiLkNETjQ+XNlETXPboCcZ+3LRlCzePFARVdsriZwp/Gkzvg/4Z2Ar0D6Ixx4NPGWM8Z7nz9baF40xm4HHjDG3AsXACs/xfwM+DewHGoFVgziXiIiISMTxTr7tmtB6Bz6NG5nI0Qie9uvLYJLZuBgX40cm9UrmI8G2EzUAzBvk8Cdflk7OZs2mo2w/Wcu8ACTHIuI/f5LZGmvt3wf7wJ5px3N8XF8BLPNxvQX+abDnEREREYlUOSkJPHj9PG78S++BT3npSVFZmY2PcXW2EA+kIDOJw5WRV5nddqIWl4FZY1KH/VgXTc4C4I0Dp5TMioSYP8ns68aY/wKeBDp39LbWvhe0qERERETOAMbAT1/7kIeun8cET0U2JyUBl8uQl5HMxiNV4Q5xUPaW1TNtVIrfQ5PyM5J5MwLXk247XsM5OSNIiosZ9mONT09iSnYKb+yv4J8/PjkA0YmIv/xJZhd6Phd2uc4CFwc+HBEREZEzx/GaZv62p5zLzhnNkklZ3W7Ly0ji8R0ncBwb8UOgvNsL3blsCm3t1u+Y8zOSOFbTRGu7Q1xM+PfS9T6Pby+dgmP9fx4DuWhyFn/dfoJ2xw5pOrKIDM2Ayay1dqDtd0RERETEh01HqwFYmJfe67a89CRa2y0ldW7GjkwMdWh+87W90DOr5jMrN23ARLAgMxnHwrHqZiZm+deaHCzDeR4DuWhyFn/YeIT3j9dQOKH391pEgsOfacajjTH3GWP+7rk8wzO8SURERCRoHMdSUtdMcVUjJXXNUTktdmNxFXExxucWMHnpHfuwRvq6WV/bCy1fs5myBvcA9+yozHbcJ/zrZofzPAaydEo2gLboEQkxf/o97gdeAsZ6Lu8DvhmsgEREROTs0zNxbWtz2FlSy6LV65j447UsWr2OnSW1UZfQbj5azdyxI0mI7b02M8+T6B2JwGm/XfW1vZC7zRnwvgUZnr1mI+A5Dud5DGRMWiLTR6Xwxv5Tw34sEfGfP8lstrX2McABsNa2MbgtekRERET65G3/7Jq4Ftc0Ba2KFirtjmXLsWoW+GgxhuipzHq3F+rKu73QQMaPTOSJmwqZNy4t7NV1lzFDfh7+uHByNm8fqqStffjJsYj4x5/f3gZjTBYdQ58wxpwP1AQ1KhERETlr+Gr/LKl1B62KFiq7S+uod7f3mcyOTIojLTE24pPZnJQEnlk1vzMR7Lq9UH8cx7K3vJ47nt3FvF+8FZbqurfif+BUA0erGnng+nmDfh7+umZ2Lvd/bi4HK6O3LV4k2vgzzfgO4FlgsjHmHWAU8NmgRiUiIiJnDV/tn2X1bvIzkrpdH8gqWih4hz8tmJDR5zF56UkcjYD1pP1xuQyTM1P45fKZFGQkk5uW0Lm9UH/6WqO64fYl5KYGf+CVr4FPL9y6gA23LcHd7nTbJikQ58oZkcDV9wd+uJSI9G3AfxE8+8leCCwGvgLMtNbuCHZgIiIicnbw1cb64JajPHnz4KuBkWTTkWpGJsYyNTulz2Py0pMivjILsPlYNdfcv4XjNc3kpib6laAFc42qP3wl05fftwlMx/63/j4Pf8/lTWS954q2tniRaOTPNOPrgCRr7S7gKuBRY8x5QY9MREREzgo5KQn89cbCbonrf1w2ndmjU/nrjYW8/tXFrPv6x6KuyrXpSBUL8tL7jXlCRlLED4ACWF9cBcCigr6rzD0NZ61tIIQymQ534i5ytvLnr8l3rbV1xpglwDLgPuDe4IYlIiIiZwuXy7DuUAW/Wj6Lg/+2jA23L2FWbhqxsS5O1Daz9N71FFc1RVUi29jSxgcldczvp8UYOpK7isZWGtxtIYpsaNYfquTcnBFkJsf7fZ+hrrUNlFAm0+FO3EXOVv78hnknF18O/N5a+wLg/18yERERkQHct/Eov33nEAWZ3ds/53r2Z912vDac4Q3a+8draXdsn8OfvKJhorHjWDYUV7GoIHNQ93O5DLNy09hw2xLe+Npi/vzF80JaXc9JSeD+z80NSTId7sRd5GzlzwCo48aY/wUuAX5qjEnAvyRYREREZEDHqpvYVVrHTfMn9LptQnoSmclxbDsRXRspbDzS0Za7YMIAyWzG6WT23NGpQY9rKPaU1VPV1MrHBtFi7OVyGXLTEvncn7bibnPYcPsFQYjQt1MNLdz5wm7+emMho0bEB3TgU0/exP31ry6muKqJjKTYqGuLF4lG/iSlK4CXgMustdVAJvAvQY1KREREzhov7ysH4NJpo3rdZoxh7tiRbD8RXZXZzUeryUtPIjet/6m9nZXZCF43u764EoDFg6zMdrUgL4P3j9fSEsI1pC/vK2fjkWpMEAY++eJyGfLSk/j0H95lzeajSmRFQsCfZHYM8IK19kNjzEXAdcCmoEYlIiIiZ42X95YzJi2B2WN8VybnjE3jg5O1tLVHzzCdTUeqB2wxBhiblojLRHab8fpDVWQlxzFtVN9TmQeyYEI6Le1OSN+UeHFPGTkj4pk3dmTIzulyGc7NSaWotC5k5xQ5m/mTzD4BtBtjpgC/AyYAfw5qVCIiInJWaHcsr35YzqXTRmGM70rWvHEjaW5z2FveEOLohqa83s2hykbmD9BiDBAb42LcyESORnhldnFBZp/fH394E/tNR6sCFVa/2h3LS3vLuGx6TsgrpDNzUykqrQ/pOUXOVv4ks461tg24BrjbWvsvdFRrRURERIZl67FqKhtbuXR6Tp/HdA6BioJ1s45jOdXQwutfXczyWbk4jh3wPpG812x5vZt95Q3DajGGjrXPo1MT2HykOkCR9e+9YzVUNLZy2fTerevBNmN0Ksdrmqluag35uUXONv4MgGo1xlwP3Ah8xnNdXPBCEhERkbPFS3vLMQY+MTW7z2Om54wgIdbFtuO1fCGCd7p3HMvOklqWr9lMcVVT50TbgQYB5WUkdw6MijQbPPvLLh7C8KeujDEszEsP2fP8+54yjIFLw5LMjgCgqLSu15sAjmMpa3DjbnM6B1IZY2lvLMO2t2Bi4nElZeM0neq8HJPc8UZPtB8T7vNH2jHhPr+vY4yJvhm//iSzq4B/BH5srT1kjJkIPBTcsERERORs8PLeMs4bN5JRI/rewiQuxsXs3NSIr8yWNbg7E1mA4qomlq/ZzIbbl5Cb2vcgqAnpSTy+4wSOYyNuaNA7hyqJizEU+tEyPZD5E9J5dlcp1U2tpCcFty7y0t4y5o9PJzsMW+PMzO1Y+72rpHsy6+vNjlf+YQETzGHKnruWttpikiZdScb5/0bZ8ytpqy0mNi2fnKtegPbmqD4m3OePtGPCfX6fx3zmCeKzZ0VdQjtgtNbaImvt7dbav3guH7LW/jT4oYmIiMiZrKaplXePVPtVPZszbiTbjtdg7cBtu+HibnM6E1mv4qom3ANM8M3PSKK13VJS5w5meEOyobiK88aNJCkuZtiPtSCvo7q75WhwW40rG1vYeKSKy87pu3U9mAoykkmOi2FXjyFQvt7sqKw+2ZlgAKTOuKEzwQBoqy2mveZg1B8T7vNH2jHhPr+vY8qeu5b2xjKizYDJrDFmqjHmcWNMkTHmoPcjFMGJiIjImeu1/adodyyXTRs46Zg7No2KxlaO1zSHILKhSYh1ke/ZN9YrPyOJhNj+/7vVuT1PhK2bdbe1s/lo9bDXy3p5B2IFu9X4lX3lOBY+FaZk1uUynDt6BLt7JLO+3uzIiLedCQWAKzGj22UAE5cc9ceE+/yRdky4z+/rmLbaYmhvIdr4U0deA9wLtAFLgQeBPwUzKBERETmzOY5ldGoCb35tMVNHpQw4KGneuI7tVbZF8H6zOSkJPH5TYWdC610zmzNAq2teRuTtNes4lqPVTbz4D+dz64I8vwZZDSQ9KY7po1LYHOTK7Et7yslIivNrmnSwzBydyq6S7hONfb3ZUdViiE3L77zsNFd1uwxgWxuj/phwnz/Sjgn3+X0dE5uWDzHxRBt/ktkka+1awFhri621PwAuD25YIiIicqZyHMsHJbV84eH3uPCe9Sy+ex07S2r7TZhm56ZhDLx/PHLXzbpchhM1zfziypl8eOfFbLh9yYDDnyDyKrPetZ2X/O+7LL13PZfft3HA74+/FuRlsPFI9aDbxR3HUlLXTHFVIyV1zT5jcRxLSW0ztyycwNOr5hPO1cczclM5Udt9onFOSgJ//sJ53d7syEwfQ85nnuhMLOqKHiLnikc7L8em5RMzclLUHxPu80faMeE+v69jcj7zROegqGhiBvpjYoxZDywBHgdeA44D/89aOz344fWvsFuAw6QAACAASURBVLDQbtmyJdxhiIiIyCCU1DWzaPW6bi2X+RlJAw5Kmv7/XmP2mFQev2l+KMIckm8/X8Td6w5R9+NPERvj/yCV9H//OzcWTmD1VbOCGJ1/hvr98cdv3znEbU/t5PBdy8jLSPbrPv5MiR7qJOlgeaGolM/8cRNv/9PH+NjE023atz7yPtefN56po1J6TTOmvQW6TJn1Xu46iTaajwn3+SPtmHCf39cxkTr8yRiz1Vpb6Os2f6YZfwNIBm4HfghcDNwUuPBERETEX7629oi0CbgDGeqgpHnjRrLlWGj2KR2qopI6po8aMahEFjqqs0erGoMU1eAM9fvjjwUTOoZAbTpS7Xcy68+U6KFOkg6WGaM9E41L6zqT2VMNbu7feoz8zBQ+Ma3r0DNDbEput/u7elwGzohjwn3+SDsm3Of3dUy08Wea8WZrbT1QC9xurb3GWvtu8EMTERGRrrzVp0Wr1zHxx2tZtHrg9txINNRBSXPGpnGwopGaLq2bkaaotK5zn9HByEtPipg246F+f/zxkbGpxMe42DSIdbP+JNfBTMCHIj8jieS4GIq6DIF6eW851sInzwn93rciZyp/phkXGmM+AHYAHxhjthtjPhr80ERERKSrvqpPZQ2Rt6VLf3JSEnjo8/MGPShp7tg0ALZH6BCoBncbh6uaONdTlRuMCRlJETMAKinGxX0r5g76++OPhNgYvjBvLJdNH9Xv+teuYowZMLkOZgI+FC6XYcboERSVnE5mX9pbTnZKPIXjwzeYSuRM40+b8R+Br1lr3wYwxiyhY8LxR4IZmIiIiHTnq/qUm5rgub4xatqOXS7D3W8f5P7PzaMgM8nvuD86YSRP3FRIRnIcJXXNEfdc95R3TK+dmTv4ZHbBhHQunTaKw5WNJMYF9/s4UKv6L94+xMt7y1j7j4uIcZmA/lw5juXW8/P5wsPv9bu21RtjU0s7JXVuHrh+Hjf95f3O+zzdI7nOSUnodUygEvChmpmbysv7yoGO5/PinjIunTYqon5mRaKdP8lsuzeRBbDWrjPGtAUxJhEREfHBW33yJrQL89L5yafP5aJ71kfE0Bt/NbW288QHJZwzOo3/uMy/eZIdk2rd3PHsroh9rt6W0sG2GTuOZWZuKisf2hr05zbQoKTqplZWv32Qi6dkMykrJaDnho7uAm8iC77XtvqK8flbF7DhtiXUNLdRVFrHocpG5owd2fm4O0vq+M7zRTxxUyFZKfER8cbOjNGpPLDlGFWNLRysbKS8oYVPhmnvW5EzlT+9F28aY/7XGHORMeZCY8w9wBvGmPOMMecNdGdjTIwx5n1jzPOeyxONMRuNMfuNMY8aY+I91yd4Lu/33F4wnCcmIiJypslJSeD+z51u//zuJdNY9ei2qGs7Liqtw7EwexAVzGhosd5VUk9cjGHyIJPAsgZ3ZyILwX1uA72Oq98+RE1zG9+9ZFrAzw3+rW31FeMV920CA9NGpfDDV/bxry/s7tae/Nv1h9h+opaCzGTyM5LJTU0M+5sc3gr9rtI6/r6nDIBLp2m9rEgg+ZPMzgGmAd8HfgCcC8wDfg78tx/3/wawu8vlnwK/tNZOAaqAWz3X3wpUea7/pec4ERER8The28ydL+zmiZsKOXTXMs7JGRFRQ2/8tcOz5nX2mDS/7xNpA3582V1ax7TsEcQNcpJxKJ9bf63qhyobmTcujW9dOIm540b28QjD48/a1v5eD2MM37poMnvLG3h+dykAVY0tPLz1OJ8/bzyZyfFBiXsoZnrWTheV1vPSnjI+On4kOanha3sWORP5M814aT8fF/d3X2PMeOBy4A+ey4aOrX0e9xzyAHCV5+vlnst4bl/mOV5ERESA53aVsvFINSnxseRnJJMcHxNRQ2/89UFJHYmxLqZk+1/BjLQBP74UldYNab1sKJ9bz3N1bVWf/J9ruf3pnaycNy5oE7JzUhJ4ZtX8fodLDfR6XDdnLHnpSfz3GwcA+OOmozS2tnPbkoKgxDxUeRlJjEiIYf2hSjYUV6nFWCQIgv0vwK+AbwPetxazgGprrXfN7TFgnOfrccBRAM/tNZ7juzHGfNkYs8UYs6W8vDyYsYuIiESU54pKmDYqhek5HWsy/UkMItHOk7XMzE0lZhBtoJH+XJta2zlY2ci5Q9iWJ5TPLSclgb988aP9tqp/9oEtQWvfdrkMs3LTeO6WBbz+1cW8+pVFvdYG92yn7/l6xMW4+OcLJ9Ha7vBheT3n52fwylfOZ3au/5X+UDDGcG5OKo9sO4Fj4ZPTlcyKBJo/A6CGxBhzBVBmrd1qjLkoUI9rrf0d8DuAwsLC6NpYT0REZIhqm1t5bf8pbl8yqfM6b2Kw4fYlHKtupqzeHVEDkfqy42Qtnz539KDu0/lcb1vC/ooGgIh6rnvK6rG2Y+jPYHmf2/O3LuRUQwvjRiYwKTMlKM/N5TK8uLuU31w9m1ljUml3bMjbt10uQ3ZKPB/5+Zv85NPn8p2Lp3S7vbyhhTtf2M3jNxaSPcL3MKcvzc/jI7lpXPq7dyN2IBjAFefmcOfFU8hOiWdSVjKOYyMqPpFoF8zK7MeAK40xh4FH6Ggv/jWQbozxJtHjgeOer48DEwA8t48EKoIYn4iISNR4eW85re2WK2d2TwJdLkNuaiLrD1dyxX2bOF7bHKYI/VNW56asvoXZY4aW9OWmJfKz1w7wlb/uiKikwDvJeOYQklnoeG6jU+NZeu96Ht12IqjP7cmdJfzPhsNhbVXPTUtkVm4qaz/s3WX38r4yNh6pBkOfw5zqWtu45bHIHn7mOJZLpudwx7O7uPCe9Sy+ex07S2qD1sItcjYa8C+VMSbZGPNdY8zvPZeneqqu/bLW/qu1dry1tgD4HPCatfYLwOvAZz2H3QQ84/n6Wc9lPLe/Zq3Vb7uIiAjwXFEpWclxLMrP8Hn7xyd1rMx5+2Bkvw/8QYln+NMwWkLn56Wzp7yeuubI2SmwqLSOWJcZ1DrgnrJTEpg3Lo21H54KYGTdNbe2s6esno+M7Xj9w9m+ffHUbNYdqqS5tb3b9S/vLWdUSjzzxvY9hCoaBoKVNbi5/k+hmVItcrby5223NYAbWOS5fBz40TDO+R3gDmPMfjrWxN7nuf4+IMtz/R3AncM4h4iIyBmjrd3hhd2lXH7uaGL7mJQ7e0waaYmxvHWwMsTRDc6Okx3J7EcGMcm4p/kT0rEWth6rDlRYw7a7tJ6p2SnED7OiefGUUaw/XEVjS3AS9aLSOtocy1xPoti1Vf3QXcvYcPuSkLXqfmLqKJrbHNYfruq8znEsr+wr55Jpo/qNIRoGgkVDwi0S7fz5jZ9srf0Z0ApgrW0EBvUXzlr7hrX2Cs/XB621C6y1U6y111lr3Z7rmz2Xp3huPzjI5yIiInJGWn+4isrGVj4zs+91pjEuw5KCTNYdivDK7Mk6ckbED2uLksIJHYnYpqORk8zuKqkb0nrZnj4xLZuWdod1h4LzpsR2z7ZIc8aefjPB26oe6v1ZL5yURYzLsHb/6Vbj7SdrKatv4dLp/e/HGukDwSA6Em6RaOfPb1OLMSYJsADGmMl0VGpFREQkBJ4tKiE+xsWl0/qfhrpkUiZFpfWciuA2xg9O1g6rKgsd7biTspLZEiHJbHNrOwcqGpgxhG15elpSkEl8jItXg9RqvO1ELSnxMUzOGno7dKCkJsayMC+dtftOP9eX9pYBcMm0/pPZcFaU/RUNCbdItPNnmvH3gReBCcaYh+kY7HRzMIMSERGRjpbLsno318wew+XnjiYlPqbf473rZtcdquSqWWNCEeKgtDuWXSV1/OPigmE/1vwJ6bxbXDXwgSGwr7wBx8KMIWzL01NKQiyL8jN4LUjJ7I4THW8mDGZbpGBaNnUUP351H9VNraQnxfHy3nI+MiaNMWmJA97XW1GOVF0Tbneb43Mqs4gMz4CVWWvtK8A1dCSwfwEKrbVvBDcsERGRs5vjWHaW1LLo7nUs+c073PLotgEnoRaOTycx1hWx62YPVDTQ3OYwOwAVzMLx6RRXNVFWF/4qtHeScSDajAGWTcvm/RM1VDS0BOTxvKy1bDtR0zn8KRIsm5KNY+GNA6eod7fxzuHKAVuMo0m4WrhFzhb+Nu0nAlVALTDDGPPx4IUkIiIiZQ1ulq/ZPKhJqPGxLhbmZbAuQica7/Cs1wxEMrUgLx2AzRHQalxUWkeMyzBtVGBad5dNycZaeH1/YKuzR6qaqGluY24EJbPn52eQHBfDq/tO8caBClrbLZedQcmsiATXgG3GxpifAiuBXYB3/JoF3gpiXCIiIme1oU5CvWBSJv+59kPqmttITfRnNVHofFBSh8sEpoJ53riRuExHMnv5jL4HY4VCUWkdU7KSSYjtvw3cX/MnpJOaEMurH57is3PGBuQxoWO9LMCcfra8CbX4WBcXTs7itf2nMAaS4lwsmZgZ7rBEJEr486/cVcB079RhERGRSOc4lrIGd1SvU/NOQu2a0PozCfWCSVk4r37IhuJKLp3e/8CoUPvgZC1Ts1NIiht+0peSEMuM0alBq8z68zPkPeaOCyfT2m5xHBuQn7PYGBcXTc5i7YflAx88CNtO1GAMAWnzDqTr540lJT6WUSPiuWb2GOJcmvYrIv7x56/FQSAu2IGIiIgEQuda09XrmPjjtSxavW7AtaaRKCclgSdvHvwk1EX5GcS4DG8HaWuX4fjgZC2zhznJuKv5eelsPlqNtYH93vrzM9T1mCW/eYebH3k/oD9ny6Zmc6CikcOVjYOOvaSumeKqRkrqmrvFs+NEx5sJKQmRU7F3HMuM0anc8ewuPv7b9X6tDRcR8fInmW0Ethlj/tcYs9r7EezAREREhmIoa00jkctlqGhw84srZ7L3O0v93npkREIs540bydsRtm623t3GwcpGZuUGMJkdn86phhYOVzYNfPAg+PMzFOyfs8vPHc0TNxXS0NLWKynty0BJ+LYTtcyNoBZj6Hgdr31gS9T/vopIePjz1tyzng8REZGIN9S1ppHopb2nuHvdIWp//CniB2gv7urz542lICOFw5WNJMYFt83a33bckrpmXvvHxYwaER+wdtz5XYZATcxKHvbjefnzMxTMnzPHsdS3tHHHs7sormrqrMoP9GZGXwn2htuXkBQbw6HKRm5dmDfs+ALpTPp9FZHQGzCZtdY+EIpAREREAmGoa00j0eajVcwblzaoRNZxLIsLsljx4JZBJUJD4a0EehMoX+fy55ihmp2bRkKsi81Hq1kxN3CDkvz5GQrmz1lZg5ur+khK+9tXtb/E8MPyBoCImmQMZ9bvq4iEXp9/KYwxj3k+f2CM2dHzI3QhioiI+M/XWtM/rJhDWX10tS22tTtsOVrDgryMQd2vrMHdmchCcNs2w92OGx/rYu7YNDYfrRr2Y3WVk5LA06u6/wzdt2IO1U2tncdsPFLFH1bMGfSaZn8MtVrpTQy78iaG2zsnGUdWMpuTksAzqwa/NlxEBPqvzH7D8/mKUAQiIiISCC6X4URtE7+4ciazxqSSHBfD15/8gBgDv756Nm2OjYoJx0Wl9TS2tnfup+qvULZt9nUub1uxu82htd0GNZ5rZ49hWs4IiqsaA/Z9dbkMKXEx/OLKmUwblUJqQiy3PfUB1sJvrplNc5sD1vD+sWrW37aElvbATs0earXyaHUTf1gxhy89tr2zCv7ETYXkpCSw7UQt2SnxjE3ru7IbDi6XYVZuGhtuXxLV08dFJDz6TGattSc9n4tDF46IiMjwPb2zlCd2nOTUf1yGy2X47iemUdXcypLfvBP01ttA2eSpNi6YMLhkNpRtm77OtXzmaE7UurnOUx1+/tYFQYvHcSwfn5zFyoe2Bvz7+mxRKd96rojDdy0jLyOZn10xg+M1zVx4z/rOcz1183xGjwh84uWtVvZsze6vWmmt5Z+f2UVmUhzvfH0J7vZ2ikrq+OVbB7lvxVx2nKhhztg0jIm8n3eXy/TbPi0i0pf+2ozrjDG1XT7Xdr0cyiBFREQG4+2DFVwwMbMzyRibnthZrYLomJi66Ug1GUlxTMlOGdT9Qtm2mZOSwKM3fLTbuf7rMzM6E1mAH76yjzUr5wYlnrIGd2ciC4H9vr66r5zpo1LIy+gYLDUyKY5be/wMXX1/cH6GulYrN33jAn5z9Wxmjk7tN2l+cU8Z6w9XcfmM0YwdmcjEzBRaHcv+Uw1sP1HDf185kx998hxteSMiZ5T+KrORtaO2iIiIH0pqm9lX3sA/LMzvvC4aJ6ZuOlLNgrz0QVfSvInQm19bzKHKJtISY4NWgXa5DOsOVfDr5bOYM65jGFPP13rjkWr+9W+7eeNriwEC2kY61O/rQBOY3W3tvHmwglsW5HW5LrQ/Q95q5RM7TnLbUzs5+G/LKMj0PbHZWst3X9zLxMxkVs0/HfOVM3LJTolnRRAq1yIikaDfHh9jTIwxZk+oghERERmutw5WAvDxSVmd1/U3GCcSNbjb2FlSy/xBthh7uVyGvIxkbnl0Gz9+dV9QE5fHd5Tw8zcPkJ+RTG5qos/XuqTO7bm+45hAxePv99W7hre4qpHyhmY+6GcvVoD1h6toanW4ZNqoQZ8r0Lw/x2/52DfY+7z2lNVz1yem8uvlM7tNvi5rcHPDn9+Pqo4EEZHB6PcvsLW2HdhrjImsTclERET68NbBClLiY5g37vTU1mibmPre8RocCwsHOcm4pwsmZvL2wUqsDU5rqbutnfeOdZ+4HOo254HO5d0ayJu8bj5S43Pbm64J3iv7yolxGS6anDWocwXDzNGpZCTFdb5J4+t5zfyvN7jj2V1MyEjqlpRHY0eCiMhgDLjPLJAB7DLGbAIavFdaa68MWlQiIiJD9PahCj5WkElszOn3a7uuQTxU2UiDuz2iWy03HqkGGHJl1uuCSVk8uPUYe8vrOScn8KuHtp+opaXd4fz803GGcjqt91xvfW0xByubGBEf0+v72nNroJT42AETvFf3lXN+XjppiXFheV49n+MFkzJ5u0dl1teWR1f12ItWe7iKyJnOn79m36Vje57/C/y8y4eIiEhEqWxs4YOTdVwwKbPXbd41iG8dqOTS373LkeomH48QGTYfqaIgI4mc1OFV/byvw9s9qnqB4k26e1aQva91oNuKfXG5DBMykrnj2Z38n+d29TpXz+pkZWNLv+3CFQ0tbD1ewye6tBh3PVeonldXF0zM4sNTDZysbe68zp+qa7R1JIiIDNaAyay19k1fH6EITkREZDDWHeq9Xran6+aMAeCx7SdCEtNQbDpazcL84bUYA0zNTmF0akLn6xJoG4urGJuWyPj0pIEPDrLLpufwzuEqappau13fc63rz17f32u68p8+P68zwXtt/ymshUt9JLPh4mvdrD9reLt1JNy1jA23L4nojgQRkcHqb2uedZ7P2ppHRESiwlsHK0iIdfXbnjspK4X5E9J5bFtkJrOldW6Kq5qG3WIMYIzhgomZPocHBcLGI1XdWozD6VPn5NDuWNbuP9Xt+pyUBO7/3OnktaTOzdi0BDbc1pHgPXrDR/nWc0XsONnxX5tX9pUzMjE2IK9/oMwbl0ZKfEy3dbM5KQk8eP28Aauu4aomi4iEQn9b8yzxfNYWPSIiEhXePljJwrx0EuNi+j1uxZyx/MvzRew/1TDofVyDbdORKgAW5AUmmVoyMZPHd5zkSFVj556pgXCqwc2Bikb+4fz8gQ8OgfPzM0hLjOXve8q4ZvaYzut3ltRx5wu7eerm+WQkx/Va6zoyMY595Q38699287cvLeSVfeUsnZLdbc11uMXGuPhYQfd1s4cqG/n280U8esNHGZ2aELI1vCIikcTvv9TGmBxjTJ73I5hBiYiIDFZdcxvvHa/hgn5ajL1WzB0LwKPbjgc7rEFxHEtuagKvf3UxkzKTu02mHSpvi+rbAW413ljsXS8bGRXMuBgXl0wdxUt7yrpNb16z+QjvH69lQnqSz+pkelIc/7ZsKtVNrew4Wcv9n5vH9y6ZFpDXPpAumJTJzpI6KhpaAFi97hDvHa/p83mJiJwNBkxmjTFXGmM+BA4BbwKHgb8HOS4RERG/OY7leG0zr35lEV88b/yAiciE9CQWF2SEdN1s171OS+qae8Xo3WplxUNbWXrvej72m3d67X86FLPHpJGWGDukIVD9xbzxSBUuA4XjIyOZBbjsnFEcq2lmV0kdAC1tDn/aeozlM0eTlRLf5/3+aXE+P/n0uVy1ZjNL713P1fdvDshrH0jeNyXWHaqkpqmVNZuP8Lm54xiTlhjmyEREwsefyuwPgfOBfdbaicAy4N2gRiUiIuInbxL4qd+/y9J71/PJ37/rVyKyYs5YPjhZx+7SupDF6N3rdNHqdew/VU9J7elEsay+91YrPfc/HYoYl2FJQe+tXYYSc9fXddORamaPSSMlwZ9d/kLjk9NzAHhxbzkAzxWVUNHYyqoF/TeUVbvbWPXotoC/9oE0f0I6CbEu3jpYwX2bjlDvbucbF0wMd1giImHlTzLbaq2tAFzGGJe19nWgMMhxiYiI+MXXfpv+JCKfmzuWJ24qpKXd8VkpDWaMuakJnKh1s+ju04lijbttwK1WhmrJpEx2l9VTXu9/ctbf6+o4lo1HqgK2rjdQxqcnMSs3lZf2lgGwZtNRxo1M5JIBJhP7s81NuCXGxbCqcDyXTR/FwrwMXvnK+cwdOzLcYYmIhJU/yWy1MWYE8BbwsDHm10BDcMMSERHxz1ASkY72WTd3PLuLeb94q1fVMdgxfnvplF6VwAOnGgbcamWouraoDjVmb5zuNod9p+qpaW7j/Lzhbx8UaJdNz+Htg5XsLavnxb1l3FQ4gZgB1pL6s81NuDmO5YbCCXzl8R1c8Nt3+NJj2yOuFVpEJNT8+Su9HGgE/hl4ETgAfCaYQYmIiPhrKInIUKu5gYoxMzm+V6L4w1f28eTN8wfcamUoPjpuJE/dPJ+CzOQ+q9Bd18ceq26ipNbd5+t6evhT5CWz180Zw1++eB5VTa389cZCvnz+wDMrc1ISeGZVcF77QClrcPP5h9+L6FZoEZFQG3Chi7XWW4V1gAeCG46IiISS41jKGty425yo3dojJyWBP3/hvM7/6PuTiIS6rTQlLoY/rJjDlx7bTnFVEw0tbeRnJHWLoaTOzfj0BDbcviSg3w/Hsewtr+ebz+zs9vrMyk3rfGzv+lhvgp+fkcSjN5zHYzd8lBUPbe287sHr55GVFMe7R6pIS4zlnJwRw4ot0BzHkhDr4o5nd3V7ruNH2n5fR5fLMCs3LeCvfSBFQyu0iEioBW1qgzEmkY7W5ATPeR631n7fGDMReATIArYCN1hrW4wxCcCDwEeBCmCltfZwsOITETnb+UpgeiY50cDlMvzPhsP8YcUcpmSn+JWIeCulXZODYLaVvrS3nJ+/eYCXv3w+8bEukuNdPL1qPlf1eO2zkgKfQPVVhd5w+xJyUxP7PGblQ++x6ZtLOhO86qZWVr99kLgYw40fHc91c8YGNM5AKGtwd76m4Pu59sXlMgMeE06h/pkVEYkGwfwL6AYuttbOAeYCnzTGnA/8FPiltXYKUAXc6jn+VqDKc/0vPceJiEiQhLrVNlgqGlr403vHWX+4yu/9Nn21lT55c/DaSl/YXcq+8gYmZiaTn5HMqJREZnsqgYfuWsaG25cE7U0Efyp6fR3T2OKQm5pIfkYys3PTuHVhPtf/6T0+9pt3uPXRbRG3ZvNMrl5GQyu0iEio9VmZNcastdYuM8b81Fr7ncE+sO3YsbzeczHO82GBi4HPe65/APgBcC8da3N/4Ln+ceA3xhhju+58LiIiAXOm/Mf/9f2nsBY+MTXb7/t0bSttcLez42QtH5bXM29c4KfDtjuWv+0u49Pn5hAbc/o95FBVAv2p6PlzTFmDmy/4WLPpT9UzVM7k6mU0tEKLiIRaf3/dxxhjFgNXGmPmGWPO6/rhz4MbY2KMMduAMuAVOoZHVVtr2zyHHAPGeb4eBxwF8NxeQ0crcs/H/LIxZosxZkt5ebk/YYiIiA++BictnzkaA517n0ZS1a0vr354itSEWOZPGNw2Md5kcnJ2Cv/+9z38fuORoMS3+Wg15Q0tXH7u6KA8/kB8VfSe6lGFzklJ4K83FvZb9YuGNz/O9Oql92fW3w4EEZEzXX9rZr8HfBcYD/yix23eCmu/rLXtwFxjTDrwFHDOEOPs+pi/A34HUFhYGPn/yxIRiVA5KQk8/IXzOqtty2eO5q5PTOPCe9ZH1Rra1/af4qLJWd2qnoO1fFYu//XGAaoaW8hIjg9gdPB8USkxLsNl0/vf6zRYulb06prb2FlSR3F1I3O7VKFdLsPfikpYfdUsPjImjYS43lW/aKh6qnopInJ26fNfIGvt49baTwE/s9Yu7fExYCLb47GqgdeBRUC6McabRI8Hjnu+Pg5MAPDcPpKOQVAiIhIExsAv3zzAH1fO5dBdy1h99Syue3BLVK2hPVzZyP5TDVw8iBZjX66alUu7Y3lhd1mAIjvthd2lLCnIDHiSPBjeit6U7BT+5fki7n2nuNvtza3t/OLtQzz1QQn5mb6rftFS9VT1UkTk7DHg26nW2h8aY640xvy35+MKfx7YGDPKU5HFGJMEXALspiOp/aznsJuAZzxfP+u5jOf217ReVkQkeHaX1vPEByXsKasnPyMZxxLxbaQ9rf3wFACfmDq8qmfh+HTGpiXyzM6SId2/6x6tXduzj1Y3sf1ELZfPCE+LcU/GGK6bM5a1+09RXn/6TYqX9pZT29zGirl9TyjuWvUM9tAqERERfwyYzBpjfgJ8AyjyfHzDGPOffjz2GOB1Y8wOYDPwirX2eeA7wB3GmP10rIm9z3P8fUCW5/o7gDsH+2RERMR/T+/qSNyunNmRaPlaQxtpbaQ9vbb/FLmpCcwYPbz9Tl0uw5UzR/Pi3jKaWtsHdV/vFkeLVq9j4o/Xsmj1reE5SAAAIABJREFUus4pvy8UlQJwxYycYcUXSCvnjKXdsTzVJXH/6/YTZCXHsWyACreqniIiEkn8+R/K5cAl1to/Wmv/CHwSGLA6a63dYa2dZ639iLV2lrX2/3quP2itXWCtnWKtvc5a6/Zc3+y5PMVz+8HhPDEREenfMztLWDAhnXEjOxJYX22kT9xUGHFtpF7WWtZ+WM6yqdkYM/yk6qpZuTS0tHdWe/3V3xZHL+wuZXJWMtNHDS/ZDqQ5Y9OYNiqFx7adAKCptZ1ni0q4evYY4oax7lhERCTU+hsA1VU6UOn5OvD7FoiISEgdq25i89Fq/vPTp+fydW0jbWppZ/vJWtYdquS88YObEhwqO0vqKKtvYdkwW4y9LpqcTVpiLE/vLOGKftqCHcdS1uDG3eZggOqmtl7t2bmpCbhbHf5l6RTiYwzWdqxRjgTGGFbMGct/rv2Q0jo36w5VUO9uZ2U/LcYiIiKRyJ9k9ifA+8aY1wEDfBy1AIuIRLVnd3W0v141K7fb9V33Pv3G07vYdqKGr39sYkS2k776Ycf2bAO1xvorPtbF7UsmsiAvneKqRp+TcL0txd5KbH5GEi/+w/ndpvwuzEvnJ58+l4vujdyp0CvnjuNHr37I4ztO8NaBCnJGxHPhpF674YmIiEQ0fwZA/QU4H3gSeAJYZK19NNiBiYhEsr4G/kSLZ3adZPqoFM7JSe3zmOvPG8exmmbWHars85hwWrvvFNNGpTAhPWngg/3gOJbPzBjNbU/t7LX21ctXS/GdLxTx5M2n27O/e8k0Vj26LaKnQs/MTeVzc8YyLTuFf1oykSdvno8rUkrHIiIifvKrzdhae5KOacMiImc9X9W5SKu89aeqsYXX91dwx4WT+z3uyhmjSY6L4S/bjvPxyeGr2nVt602IdZGdFE95YwvfvngKsS6D49iAvO5lDW5WPLS1VxK64fYlndVqd5vTq6X4mV2l/Paa2Z17m7Y7NuKnQjuO5bYLJvH5h7dG5c+wiIgI+DcASkREuuhv4E80+NueMtoc26vFuKeUhFiWz8rl8e0naG0PTSLWs+Ld1uZ0mxT81cd3sKOklsV3r+Oie9bzhYff61U9HSpfiWrPJLSvic9dp/wmx8dE/FTosgZ3ZyIL0fczLCIiAkpmRUT80jXJqmvuPfAn0ipvvnifw/RRI3julvkUjht4nt/n5o6lorGVV/aVhyS+nlvcHK5u7PbGwY2FE7j2gS1BScL82ZooJyWBhz4/r9vE52dWze828dnXVOiex4SbP4m7iIhIpOu3zdgYEwPsstae099xIiJnsp5txc/fuqDbwB+IvMpbT0Ntjb5seg4ZSXH85f3jfPrcvif8BoKvindpXUu31zkzOT5oSZg3Ce35GnVNQi3ww5f38dDn5zEhPcnnkKiuU6G9rdE9jwk3b+IeTT/DIiIiPfX7r5a1th3Ya4zJC1E8IiIRp2eS9cNX9rFm5dyIrrz1NNTW6PhYF9+6cBLXzRnL4crgDrvyVS0sq3d3q5ZWNrYErYW3axK64fb/396dx0lV3Xkf/5ym6aYbGmj2fRFFEUiDtCyKC4OOE43iEhHcwHVm4hIfM2NMnEz0McmjTkwiMSZjcIHEDRWVKEYTAyqKCwLKJvsu0NA00BvVS53nj7rVVFff2rprbb7v16tedN+6t+6pU0X1/dX5nd+ZyB+u+FaTYP/THWX8beMBdh8+ysDCfHoVtHMNUgPTjkPtk0qZMHosIiISSTQFoAqBNcaYz4BK/0Zr7SUJa5WISBoJDrI+3XGIHy1cx+LvncGh6lq2lFbRqyC9Rt6CNTet1Ou1nH9yD66cuyzhhYLcRgvnLtvJ/Jmnc/mzvkB87rKdvDqjuCHVON5BmD8IffnLPXz/9dWsu2cSJ/fo0HD/wnUltMky/PPQ+KxtmyqZMHosIiISSTTB7E8S3goRkTRWXVPfJMjaW+4hNzuLnDZZXDFnGY9dOoI7Jg5OYSvDa25aaUmlpyGQBfcKv/HSo30uz119Gtc8v7whUH3ggpM5tUdBo6CrW15OwoOwy0b04vuvr2b+qj38aPJJDdvf/nofZwwspDA/J67nS4XANYVFREQyUTTrzL4PbAPaOj9/DixPcLtERNJCbb2X+99dzzPT3NOKh/UsYGTvAuat3J3ilobXo30uL1w7Jua00mQWCvJay4N/W8+caaPZet9klt45kRG9OpKdndUoZTf490SMJvbrnMe4AZ15bdWehm3fHD7Kit1H+PawHnE/n4iIiMQu4sisMeYW4FagCzAE6Av8AZic2KaJiKTek59sZ96Xe/i3CYNCjgZOLerDT/66np2HqunfOS/CI6bO/yzayOypRZzYrX3UI5rJLBT03qYDvLPhAP96xiDOLkzdurZ+l43szb1vrWNHWRUDCvN5++sSAC48JbGFsERERCQ60VyN3AacCRwBsNZuBPS1tIi0emVVNdz/znomDenKOUO6hhwNvGpUXwBe/vKbVDU1okWbD/Da6n3sK/fENKLpVijo9QQVCnpxxW46tcvm26ekx5+Yy5x1eF9bvRfwpRj369SOkb0LUtksERERcUQzZ9Zjra0xxnfRY4zJxrc6gYhIRF6vpaTSk1FFZvxt3nPEw5NXFjGsZwf8n4FuTuzWntP6dmLeym+4+5whSWxp9P74yQ665Lfl8pG9YzousFDQwapa1pdUUFVT36zXMNx7obq2nvmr9vLdot7kZreJ+bET4aTuHRjZu4D5X+3h3ycM4m8bDjBtdJ+w7wURERFJnmhGZt83xvwYyDPGnA+8DPwlsc0SkdbAv7bphFlLGPzz95gwawmr9x5J2NIu8RDY5jG//oC7F6yhps4bsc1TR/Xhs52H2FpalaSWRm9/hYfXVu/hujH9aNc29kDRXyhoSNd8bn35S379wZaYHyPSe2Hhun2Ue+qY7oxyp4vLR/ZmybaDzF+1h3JPnVKMRURE0kg0wey9wH5gFfCvwELgvxLZKBFpHZq7tmkqNbfNU4v6MG5AZw5W17C9LLHrscZq7rJd1NZbbhk3sEWPk5vdhuuL+/P66r3sK4/tNYzUry+u+IaeBblMOrFbi9oYb1eP7ssr1xfTr3Mer808nfPSrH0iIiLHs4hpxtZarzFmDvApvvTi9dba9LhCE5G05qlNXiVcN25prUDYtOfmVu8d0DmPhy4axnfnJH491lDPLfg8Xq+lpMLDhEGFvHvreE4JWC+1uW4eN4Bff7CFOct2cs+kE6M+Lly/Hq6u5c11+7h1/EDapFEKutdrqaqt5+4Fa5LymoqIiEhsIo7MGmMuAjYDs4DHgU3GmG8numEiktnq6r3sOFTdUDjIL1GVcIO5pbVuPFDBqghpz4eqa5vV5pJKDzNfXJmUUeho0rcb9vntEiY+/hG3vPxlXFK8h/Us4KzBXXjq0x3E9L2mxbVfswzsOFTNX28Zzx0TB6XNaDb4XtNLMyyzQERE5HgSzRXlo8Aka+251tpzgEnArxPbLBHJRF6vZW/5UbaXVbF0exnPfr6jWWubxoNbWuvm0qomwclP31nP7iPVbC+rYn1JBb9bsoW500en9Xqs0aRCJzLF++bxA+iS35aN+yvDplT73w9bSivZdbi6Sb/Ou34MWw9Wc8nTnzHp9x9z/v9+klZzqpP5moqIiEjsoqlmXG6t3RTw+xagPEHtEZEM5R8J9AdQAwvzeOHaMRT37cSS289kc2kV2U5l3GSkaLoFIu1zshttGzegM7dPHMzZv/u4oc3PThvF6D4dQ64pG0oy12N1e269CnKd7VXkZmdR4alLWCD23ZG96dsxjwv++EnI9Fu398NbN49l6R0T8dT7+rW23tvQ9/72TXnmc5beOZFeBe1a3M6WSuZrKiIiIrEL+RfZGHO5MeZyYJkxZqExZqYxZga+SsafJ62FIpIR3EYCp//5Cw5U19C3Ux5//GQ7Fz/1GbXe5Ixq+QORQJU1dY223TPpRG6e92WjNs98cSUVtfUh15QNxW091kSNQgc/t3EDOvP/LhzGuU983JB2XO91T+uNRyB22FPHTfPCp1S7vR8umv0ZGBr61WtJ65HPZL6mIiIiErtwVzUXO7d2wD7gHOBcfJWN80IfJiLHo0gpmdeO6UdZdS0L15UkpT092ufy8vXFjQKRE7vm83pAcNKjQ27cgqnA9Vg/uXMij182gqHd2ydkFLpH+1z+dPWxlN2fnD+UG15qHFze+9Za5s9MTCAWTfptNPu4feGQTiOfga/p1vsms/TOiSr+JCIikkZCphlba29IZkNEJPMEVtStqfOGTcmcfGI3ehbk8tzyXVw2snfC25aVZXhv434eu3QERb07ktv2WDVjfwpxliGuaaT+9VhX7Snn4qc/Z/bUIm4cOyAuzyeQMfDQexuZO300AwrzqPfaJoHjG2v28bvLR8acLh2NaNJvc9tE3sc/8hmYipxuI5/+11RERETSTzTVjAcbY35ljJlvjFngvyWjcSKSvoIr6t7z5lpemVEcciQwu00W00b14c21JZRV1SS8fdZafvfRNuZ8vpOBXY6lC/uDk4GF+fTtmJeQNNLzTurGqD4deXTx5oQUM9qwv5KFX+9nXUkFAwvzyc9p414pOOC5RpsuHY1o0m+3lFYxe2pR2H008ikiIiItEU0BqNeBp/DNlU2PiUwiknLBcyLfWLMPgA9uOwOvxXUk8Nox/Xjsw6288tUebhk/MKHt+2rPEXYdPsr9F/QMuU9gMBXP0UtjDD84dwjXPb+ChV+X8J1TQ7ehORZtOgDApCFdgeSPcDb02x0T2VpWxeHqWk7tUdCo3/77nfXkt83i4zsmUlMfum818ikiIiLNFU0we9RaOyvhLRGRjOI2J/KNNfv4zaUjGFiY73rMaX07cUqPDjy3fFfCg9k31/qC6wtP6RF2v0QFU1OL+jBv5W7y2mY1VBiOV5rv+1tK6dOxHSd2aw8kLigPJyvL0KtjOxZtLuWa55bz+g2nc8nwXgAs33WIf2w6wMMXDaN3RwWqIiIikhjRBLOPGWN+CrwLNJSqtNYuT1irRCTtNWfZEmMM/3nuEDrntWXzgUra57ZJWND11roSTu/fmV4pCqbaGMOPJg9l+p+/CLl8TXNYa1m8uZTzTuqGMcceJ1UjnFd+qzc/XpjHLxdvbghmf7l4MwW52dya4C8sRERE5PgWTZWTkcAtwEPAo87tl4lslIikvy55bXn6qlExzTf1ei2j+nbi7gVrOOmhfzBh1hJW7z0S93mlJeUePt1RxkXD4pveG1MbKj0NgSy4L1/THOv2VbCv3MO5Q7rFo5ktlt0mi7vOPoElWw/yyfYytpZW8fJXe7h1/EA65bVNdfNERESkFYtmZPZK4ARrbeIrtohIxvjHplIeeHc9b908jvY5baJKbS2p9HD5s583CfCW3jkxrqOKb39dgrXwnVPDpxgnUjRL04QSWCU6uF8XbfbNlz3XmS+bDm4aO4C31uyjps7LoaO1vHz9GMYPKEx1s0RERKSViyaYXQ10BmJaHNIY0x+YC/QELPCktfYxY0wX4CVgELANmGqtLTO+fLnHgAuBKmCmUplF0te8ld+wrqSCIV3zyc1uE9UxLQnwYvHWun306diO0X07xfVxYxFtGnZw4NotL4e1JeVNijn505Pf31xK/87tOKGr+7zkVMhv24YH/uVkrn5ueeMCVB0SO29XREREjm/RpBl3Br42xrwT49I8dcAPrLWnAuOB24wxpwL3Au9Za08C3nN+B/g2cJJzuxX4fYzPRSRjeL2WveVH2V5Wxd7yo9TVeRv9nojlXOLJU1fPa6v3cOnwXlEHsnAswAvUknVd3dTUeXln/X4uHNaj0ZzSZHNbvub1oDTs4OWNJsxawrZDVY2qRAemJ3u9vvmyk4Z0S+lzC1ZS6WkIZCF+KdUiIiIi4UQzMvvT5jywtXYPsMf5udwYsw7oC0wBznV2mwMsBn7obJ9rrbXAJ8aYzsaY3s7jiLQa/gDGH7BMGd6Tn5w/lCvmLItroaBEenf9fg4frWPqqD4xHee2hMyz00bRpRlzK91ScQG2HqxiwY1j6d4hB6/XpqwPAysMl1bWsGF/ZcN2v+DljbaXVbOvvCbk6PWafeUcqKzhnDRKMYbkjbiLiIiIBIoYzFpr32/pSYwxg4DRwKdAz4AAdS++NGTwBbo7Aw7b5WxrFMwaY27FN3LLgAEDWto0kaQLDmCuL+7fEMhC4uaRhhNujqabeV9+Q2FeW847qXtM5wleQqbSU89N81Zy8fBe/HjySVG3MT8ni28Oe7g0ICh+55ZxVNd5G21L9ZcC/grD7dtmM+6xJUw/rS9/vLKo4X63ILCkwhMyPblhfdkT06P4k19zKluLiIiItFTEKw1jTLkx5ohzO2qMqTfGHIn2BMaYDsCrwF3W2kbHOaOwMeVTWmuftNYWW2uLu3eP7UJaJB0EBzBd8nNSOqrlluoarsJwdW09b6zZy2Uje5PTjGDFH+ANLMzn1F4FDOicx9vr9rGltDJkmnVwGz/fcbghaAVff20qrWqyLV1SXQvaZTO1qA8vrdxNpaeuYbtb2vXcZTuZP7NxevLc6aPpnp/D+5tLGVSYx6Au6TNfFtxTqiNVthYRERFpqWhGZgv8PztFmqbgmwMbkTGmLb5A9jlr7Xxn8z5/+rAxpjfHCkvtBvoHHN7P2SbSqtTUeRuNYh2sqnEf1WqTnFEtt1TXcCPDb39dQoWnnqtiTDEO5YkrRvLVnnIm/2FpyBHV4Da2z8lu8gWA27Z0SnW9cVx/nl22k1e+2sOM030fdRVH65g9tYib533Z8NwfuOBkTu1R0DB6fbCqhseXbKVDbjZ3nX0CWcakNH3aTfCIezSj+yIiIiItFdPVsvV5Hbgg0r5O4PsUsM5a+6uAuxYAM5yfZwBvBGy/3viMBw5rvqy0Nl6v5aH3NjZan3Xusp28OqO40ajW7KlFrNpzJClFoWKd7zhv5Td0b5/DpDjN26z1Wm58aWXYEdXgNvq/AAhUWVOX8OJSLXHmoC6c1K09T3+2AwBrLbe/tpqH3tvEh7edydb7JrP0zomM6NWR7OyshtHrb/XqyMzTB3D5s59zzhMfc+3zyxOyNm9LBY649ypop0BWREREEi7iyKwx5vKAX7OAYuBoFI99JnAdsMoYs9LZ9mPgIWCeMeYmYDsw1blvIb5leTbhW5rnhmiegEgmeXHlbp5ZtotLR/ZuNIrVLS/n2O9tspi3cjfDe3dkwqwlCZ//eaAyupFhfwXm7505iDvPGkxWnKrpRhNMW0ujNj6yaBPPXDWKG5wgeGBhHid2zef1G05vMmc2XVJdjTHcMLY/P174NRv2V7D5QCXvbtjPo5ecSr/OeSGP219Vw/UvrEjpnGoRERGRdBRNNeOLA36uw7c27JRIB1lrlwChrnYnu+xvgduiaI9IRqqqqeNHC9dxWt9OXDSsZ5OgNDAwuaKoDxMf/yghAUxgIaXD1bU88dFW/nT1aK57fkVDEPjSdaext9yDpz66tU9bIpriQU8u3cZTU4u4yUnH3VvuoU/HXJbeMbGhjf6gNZ1TXa8f058Fq/dSVlVLp7y2LLx5LJOGhC/mpErBIiIiIu6imTOrEVIRR6xVfwOP2Vdew2+mjGBA58gpmHVem5AAJnhZIH9xoeK+nRqCwPy2WWwureayZ4/t8+6t42OaVxsLt+V65l03piE4/XR7GQ8t2swJXfOjClTTebSyV0EuD3/nVKb9+YuovxRQpWARERERdyGDWWPMf4c5zlprH0xAe0TSllsgGCkQCXVMpAI+iQpg3Io9Xf/CikZB6d7yo0x3gi3/PiUVodc+bang4kHrSyp44N31PHfNGDq2y+bet9bRo0MOV43qR0G7aJJJ0ldJpSfmlGG3YD+d0qdFREREUiXclWGly7b2wE1AV0DBrBxXoq36Gzh6mwXNGtF0C2Beb2YAE9ie+ihGfGNd+zQe/MWDAErKayitqmXtvnIK89py51mDqfV6Mz6QhealDKtSsIiIiIi7kFeH1tpH/T8bYwqA7+MryvQi8Gio40TixS2lF4g5zTdeoglEgkdiP7ztzGaNaAYGMAcqath4oJIKT13MzzW4PW/eNDZiUOo2Kuxf+/TyZxM/OjimXycevWQ4Vz+3vFEgn27L0TRHc0fcA4N9EREREfEJewVljOlijPkZ8BW+wPc0a+0PrbUl4Y4TaSl/EDZh1hIG//w9JsxawsYDFawK2pbMJUraGBNx6Zfg0Vv/iGa4Y0LxBzBDu3fgnjfX8r35q6iP8Fz9FYf9y/mUVDRuz4N/28AzAcsCuQWl/lHhwH0euOBkRvb0rX0auIRMIoLLkkoP1ziBLPiC/0uDlurJVG59q5RhERERkeYJN2f2f4DLgSeBkdbaiqS1So57bim9m0uruG3+qpQtUfL3jfuZPbWIm52KugML83h1RjHWwvayKnKzszhUVdto1O2RRZuaHBNr8JKTncXPvn0K0/+8nOeW7+L64v6u+7nNz33n1vGN2vPpjkP8aOE6Fn/vDADX0e1waa3J6OfWXL1XKcMiIiIi8RNuEtoPAA/wX8B95tiakgZfAaiOCW6bHMfcApr2OdkpC3Lq6r3c/84GLhrWvSEQ8dR52XPkKFf89thasH+9ZXyjNNJPdxzi8SVb+eC2M/Ba9+AxGld+qw9vj9lHt/Y5bDtYRbu2TR/H7QuATQcqm6S17i33kJudFTYwTWVaa2uv3quUYREREZH4CHl1aK3NstbmWWsLrLUdA24FCmQl0fwBTaDKmrom26YM70kWNKTVJirl+C9r97HjUDXnDe1Br4J2DCzMp2O7bGa+uLJR8HjvW2uZP7Npim7fjnkMLMynV0HkZXlCuX3iCdw2fxUn/MI9xdrtC4AH/7ahSXvSPa1VqbgiIiIiEg1jbXLmGyZCcXGxXbZsWaqbIQmwaX8F2w9VN0rPfeeWcVTXebnUGX2cMrwn9503lCvnLot6qZzmmvz7j9lcWsWmH/0T2W183wFtL6ti8M/fa7Lvrp+cR1aWiWsa6d7yo0yYtaTJaGXwkjpu+3x210TqvWRUWmtz1vMVERERkdbHGPOFtbbY7b7MX+tCWh1rLbe/thqv1/LhbWdSb22jasb+NN8s4OwnPk74HNo1e8tZtLmUX1x4SkMgC6HTYRORRhrNPNIueW15ZtoobnBGi/3Bfde8zAsElYorIiIiIpEomJW08/bXJby7YT+/umQ4/TrnNbnfH+RsL6tK6BzaY6OD9bw283TOGlzY6H63tWATlQ4bzTzSxz/axstffsPCm8eRn9NGI5oiIiIi0qopmG0FglMyu+XlcKC6JuNSNL1ey74KD53z2rLw5rFMGtIt7P6JLBTkVhn4jRtOp3NeTkNfJrMyrVvgPHtqETsPVdOroB17jhzlgXc3cNbgLpzSowMBBdtERERERFolzZnNcMFB15ThPfnJ+UO5Yk7i55HGU6jgMVy73Y55ZUYxo/t0ivm5Bn8hgIUJvw0/RzXZAtuYnWW4+43VVNbU8/vvFlFS4WHXoaOM6lPAwC7tU9I+EREREZF405zZVix4OZbri/s3BLKQ/LVYm8ttWZlI7Q4cGT1a62XVniO8tGI3Y/p1junc0azP6m9TKtc6DZ5H+uC/DGPX4WrO/t1Hjb4A8HptWn9xISIiIiISD61j4cbjWHBhoC75OSkPwrxey97yozEtlxNNgSM3/gBvUJd8vth1mF++v4XVe47E1MbdR6pDrs8aKN3WOu2Yl81NTrVnOPYFQEmlJ8UtExERERFJvPS5MpdmKauqbRR0HayqcQ3CspM0Uucf5ZwwawmDf+6+Hqqb7CzT4uDxjomDaZ/ThkcWbYqpjTvKjmbk+qzN/QJARERERKQ1UDCbYQJHFNfsLee3S7Ywd/rohqBr7rKdvDqjuFEQNntqEXM/38nuw9UxjZY2R6h04dJqT9jR2r9vOMDsqUUtCh67ts/hXycM5IWV37CltDLqNpZUeJoE0nvLPfTrnMvSOyey9b7JLL1zYtrNO/YXwAqUbqPHIiIiIiKJojmzKRRcdChSJVy3uZ1zpo+muG+nRhV1u+XlNPp9W2kVYwcWMvHxxnMrExGcuY0W9irIZWfZ0ZBFqSo9dfznm2u5ZnSfFlcGvvvsIXy6vYy95R7aZBnXxwlu4yOLNjF7ahE3Oym7mbI+azKXBhIRERERSTeqZpwirkWHbhlHx3Zt8dS7B3N7y48yYVbsFXabe1xzbDpQyfn/u7TRud68aSy3zV8V8vy/XLyZe95cy0e3n8mEQV1adH6v17J0exnXPr88ZODu1h9Thvdk1mUj8FoybjmjWL4QERERERHJJOGqGSsfMUWCU117FeTyzREPE34beq5pc+dIJmtu5f4KDz9YsJpnrhrVKF34pG7tQ56/qqaOXy7exPlDu7U4kAVfv/oDWf95gosidcrN5umgNj5wwcn07ZjHwMJ8ehW0y5iA0F8AK9PaLSIiIiLSUkozTpHgAPOeSSdyw0srwy5N4y+SFDzCGWmOpH9uZazHRcvrteyr8LDjUDU3jh3IgMJ2jdKFsTQ5/5ThPckCNpdW8fsrvsXgLvlxaUs0gfvcL3bx7Oc7eeeW8eS2zdKIpoiIiIhIBtLIbIqUe+oaFe8JtaROYMGnPUeOMmfaqJiLJPnnVgYe9+y0UXTJa9vi5+FPlz7jt0uYMGsJd72xmgpPPT3a5zaMFvbo0Pj8U4b35L7zhnL2Ex9T9Oj73L1gDVmGuBSlilQUqd5r+dX7W6j3Wk7q3l4jmiIiIiIiGUojsymwdNtBfvjWWuZMH82MF1awvayaypo619HLveWeRoWTFtx4OkvvmBhyXq2brCzDiF4dG0ZLKzz1/Or9TbTPaUP3DrktGpksqXCvXhw4ohx8/izg7Cc+DntMc7kVRXrx2jENAf+CNXvZeKCSF68dgzEKYEVEREREMpWC2STxF+qtqdE6AAAMSUlEQVSp9NRTWlVDj/Y5jOjZoSHAy8/J4vUbTufSgCDs4e+cygVPftIo6LvkaV/QN7AwtrRc/9xKf1tuHDuAK+d+EbG6cbgCQ16vZU+5J6r5uIHn315WlbA5vMGB8+bSKn68cB1/uvo0+nTyFZsa3CWfy0f2avG5REREREQkdRTMJoFb5eJXZ5xO57ycRsFj17zcRnNNPbWJKdzkK5K0IuLIaNiKy3Vedh6u5mitN+b5uImewxsYONfVW+q8XjYdqKSipo7/OHcItfVestsow15EREREJJPpij5BAue67jpc3SQV94o5jSvsQtPKtLltw8//bK5oqxuHrbj8i/e47vkVdO+Qw+tB83EjzeN1m8ObqPVRB3fJ5+HvDGfGiys45eFF3L1gDSd37xCX+bkiIiIiIpI6GplNgOARzQ9vO7NZI6xu8z/jEfRFOzJ6uLo2YsXlS5/5nM/umthoRDnS/NvgVOBEVhMuqfQw/c9fNG7zs/GZnysiIiIiIqmjYDYBgkc0Syo8zUqrTVTQ5xYkz55axPaDVQ0B3tcl5WzcX9mo3aEqLlfVeFs0hzeRkrXGroiIiIiIJJfSjBMgOIB6ZNEmZk8talZabXDqcTxGLwOD5K33TWbJ7Wcy+5Pt/Pdf17P9YBVbSyvZWlrFPzaWMH/msXRgf8XlQPGc65oIkZbqERERERGRzGSsTczcQWPM08B3gBJr7QhnWxfgJWAQsA2Yaq0tM741Uh4DLgSqgJnW2uWRzlFcXGyXLVuWkPa3xN7yo0yYtaTJMjuzLhuB15LQtNrm2nawki2l1dw0b2XDaO0rM4op6tWRA9U1DRWXvznsaVRxOVQV5HThVsQq3dssIiIiIiI+xpgvrLXFrvclMJg9G6gA5gYEs48AB621Dxlj7gUKrbU/NMZcCNyBL5gdBzxmrR0X6RzpGsxmYgDlFoAPLMxzrXAcaqmedJWJbRYRERERkfDBbMLmzFprPzDGDAraPAU41/l5DrAY+KGzfa71RdafGGM6G2N6W2v3JKp9iZTMAkfxEu3c0mTNdY2nTGyziIiIiIiEl+wCUD0DAtS9QE/n577AzoD9djnbmgSzxphbgVsBBgwYkLiWtlCmBVCJXvtVREREREQknlIWqTijsDHnOFtrn7TWFltri7t3756Alh2fkrn2q4iIiIiISEsle2R2nz992BjTGyhxtu8G+gfs18/ZJkmSianRIiIiIiJy/Er2yOwCYIbz8wzgjYDt1xuf8cDhTJ0vm8kSsQyQiIiIiIhIIiRsZNYY8wK+Yk/djDG7gJ8CDwHzjDE3AduBqc7uC/FVMt6Eb2meGxLVLhEREREREcl8iaxmPD3EXZNd9rXAbYlqi4iIiIiIiLQuKlUrIiIiIiIiGUfBrIiIiIiIiGQcBbMiIiIiIiKScYxvumpmMsbsx1dIKp11Aw6kuhHHAfVz8qivk0d9nRzq5+RRXyeP+jo51M/Jo75OnnTr64HW2u5ud2R0MJsJjDHLrLXFqW5Ha6d+Th71dfKor5ND/Zw86uvkUV8nh/o5edTXyZNJfa00YxEREREREck4CmZFREREREQk4yiYTbwnU92A44T6OXnU18mjvk4O9XPyqK+TR32dHOrn5FFfJ0/G9LXmzIqIiIiIiEjG0cisiIiIiIiIZBwFsyIiIiIiIpJxFMwGMcY8bYwpMcasDthWZIxZaoxZZYz5izGmY9AxA4wxFcaY/wjY9n1jzGpjzBpjzF1hzvcvxpj1xphNxph7A7bf7myzxphu8X6e6SCWvjbGDDLGVBtjVjq3PwQcM8bZf5MxZpYxxoQ4X6i+/idjzHLn9ZpjjMlO5PNOtnj0szEm3xjzljHma+c9/VCY87m+HsaY+40xuwMe+8JEP/dki9d7OuDYBYGP5XK/Pj9a/vmx2OlD/309Qpwv1Ps67N+HTBenz4+CgG0rjTEHjDG/CXE+fX60/D19lTHmK+ez+uEw5wvV11c6x3qNMRmxNEesYulr575vOfetce5v52zX9UcY8ehno+sPicRaq1vADTgbOA1YHbDtc+Ac5+cbgQeDjnkFeBn4D+f3EcBqIB/IBv4OnOhyrjbAZuAEIAf4EjjVuW80MAjYBnRLdb+kuq+dvlgd4nE+A8YDBngb+Ha0fY3vC52dwFBnv/8L3JTqvkm3fnbey5Ocn3OAD936OdzrAdzv/z/SWm/xek87918OPB/mfa/Pj/h8fiwGiqM4X6j3ddi/D5l+i+d7OuD4L4CzY+xnfX5E91ndFdgBdHd+nwNMjrGvhwEnR/t/IxNvMfZ1NvAVUBTQx23C9WHQuXT90YJ+RtcfukW4aWQ2iLX2A+Bg0OahwAfOz38DrvDfYYy5FNgKrAnYfxjwqbW2ylpbB7yP78I02Fhgk7V2i7W2BngRmOK0Y4W1dlvLn1H6irWv3RhjegMdrbWfWGstMBe41GXXUH3dFaix1m6I9pyZJh797LyXFzk/1wDLgX7B+8XwerRK8ehrAGNMB+Bu4GdhdtPnRxz6OhoR3tcJOWe6iHc/G2OGAj3wXZAG36fPj5b39QnARmvtfuf3v7sdE66vrbXrrLXrm/csMkOMff3PwFfW2i+dY0uttfW6/ogsHv2s6w+JRMFsdNbgXCQCVwL9oeGC84fAA0H7rwbOMsZ0NcbkAxf6jwnSF9+3cn67nG3HM9e+dgw2xqwwxrxvjDnL2dYXX7/5herDUH19AMgOSKX6Lu6vVWsTaz83MMZ0Bi4G3nN53Eivx+1O+tvTxpjCFj2DzNGcvn4QeBSoCvO4+vxoqrnv62ec1LOfhEgTDPe+DnfO1qrZnx/ANOAl52IzmD4/moq1rzcBJxtfGnI2vov5UNcf0fztPJ6E6uuhgDXGvOOkBN/jbNf1R/PE2s8NdP0hbhTMRudG4HvGmC+AAqDG2X4/8GtrbUXgztbadcDDwLvAX4GVQH3SWpvZQvX1HmCAtXY0vhGr500c5qY5F1TTgF8bYz4Dyjk+Xqtm9bNzcfQCMMtauyXGc/4eGAKMcs7zaMueQsaIqa+NMaOAIdba11LT3IzWnPf1NdbakcBZzu26OJ2zNWvJ5/Q0fJ8hsdLnRxR9ba0tA/4deAnf6Pc2jo+/afEQqq+zgYnANc6/lxljJrf0ZLr+iK2fdf0hobSqieaJYq39Gl/6gz9F6iLnrnHAd40xjwCdAa8x5qi19nFr7VPAU84xvwB2GWP6A39xjv0DvnkTgd/C9QN2J/r5pLNQfW2t9QAe5+cvjDGb8X2Lt5vG6Sb9gN2x9LW1dim+i1iMMf/sPG6r1ox+XuYc+iS+FLbfOMe2wTf/DWABvj8YTV4P5/H2+TcaY/4IvJmI55ZumtHXpwPFxpht+D6jexhjFuMLsvT5EUZz3tfWWv/7s9wY8zww1hjzHNG/r0P9fWi1mvv5YYwpArKttV84v+vzI4Jmvqf/gvNZYYy5FaiPpa+PV2H+L+8CPrDWHnDuW4hvHuif0fVHzJrRz/5RWF1/iLtYJtgeLzeCCisAPZx/s/Dl4N/ocsz9BEwuDzhmAPA10NnlmGxgCzCYY0UBhgfts41WWsAllr4GunOs4MIJ+D6guji/B0/4vzCWvg44Zy6+D81/SnW/pGk//wx4FciKcC7X1wPoHbDP/wFeTHW/pGtfh3qsoPv0+dHCvnb6sJuzvS2+Yn7/FuJcod7XEf8+ZPotXu9p4CHggQjn0udHyz+r/ccU4ssMGxpLXwfcv5hWWgAqxr4uxDdPM7Co50XR9KGzj64/Wt7Puv7QLfTrnuoGpNsNXwrDHqAW37dENwHfBzY4t4cA43Lc/TQOZj8E1jofWq6VBJ39LnQedzNwX8D2O53z1wHfALNT3Tep7Gt8BQLWOH+YlwMXBzxOMb55ypuBx91enwh9/T/AOmA9cFeq+yUd+xnfN5zW6aeVzu3mEOdzfT2APwGr8FUrXBD4x6W13OL1ng54vEGEr3isz4+Wva/b4/tm/yvn/sdwAoQY3tcR/z5k8i2e72l8F/SnRDifPj9a/jfxBXzXH2uBac3o68uc83uAfcA7qe6bVPa1s/+1Tn+vBh6J1Icu59P1RzP7GV1/6Bbh5n+RRURERERERDKGCkCJiIiIiIhIxlEwKyIiIiIiIhlHwayIiIiIiIhkHAWzIiIiIiIiknEUzIqIiIiIiEjGUTArIiIiIiIiGUfBrIiIiIiIiGSc/w/obHViF7nFUQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plotting predictions and past data\n",
        "plot_series(y, y_pred, labels=[\"y\", \"y_pred\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qcKoOh3rc70"
      },
      "source": [
        "### **1.2.1 基本的なデプロイメント工程の概要**\n",
        "- 便宜上、基本的な展開の工程を1つのセルにまとめて紹介する。\n",
        "- これは、同じデータを使用しているが、異なる予測器\n",
        "- ：同じ月に観測された最新の値を予測するものである。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1Puwbuyrc71"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sktime.datasets import load_airline \n",
        "# load_airline関数をsktime.datasetsモジュールからインポートする。\n",
        "from sktime.forecasting.base import ForecastingHorizon \n",
        "# sktime.forecasting.base モジュールからForecastingHorizon クラスをインポートする。\n",
        "from sktime.forecasting.naive import NaiveForecaster \n",
        "# sktime.forecasting.naive モジュールからNaiveForecaster クラスをインポートする。\n",
        "import numpy as np \n",
        "#numpyライブラリをインポートする。\n",
        "\n",
        "#ステップ1：データ指定\n",
        "y = load_airline() # この行は、航空会社のデータセットをロードし、変数 'y' に代入する。\n",
        "\n",
        "# step 2: 予測の地平線を指定する\n",
        "fh = np.arange(1, 37) # この行では、1から36までの数値の配列を作成し、変数'fh'に代入しています。\n",
        "\n",
        "# step 3: 予測アルゴリズムの指定\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12) # この行は、NaiveForecasterクラスのオブジェクトを、戦略「last」、季節期間「12」で作成します。\n",
        "\n",
        "# ステップ4: 予測器を学習させる\n",
        "forecaster.fit(y) # この行は、データ 'y' に対して予測器を学習させる。\n",
        "\n",
        "# step 5: 予測値のクエリ\n",
        "y_pred = forecaster.predict(fh) # この行は、データ 'fh' に対して、学習した予測器の predict メソッドを使用し、その結果を 'y_pred' に代入しています。\n",
        "\n",
        "# optional: 予測と過去のプロット\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "from sktime.datasets import load_airline \n",
        "##### load_airline関数をsktime.datasetsモジュールからインポートする。\n",
        "from sktime.forecasting.base import ForecastingHorizon \n",
        "##### sktime.forecasting.base モジュールからForecastingHorizon クラスをインポートする。\n",
        "from sktime.forecasting.naive import NaiveForecaster \n",
        "##### sktime.forecasting.naive モジュールからNaiveForecaster クラスをインポートする。\n",
        "import numpy as np \n",
        "##### numpyライブラリをインポートする。\n",
        "\n",
        "##### ステップ1：データ指定\n",
        "y = load_airline() # この行は、航空会社のデータセットをロードし、変数 'y' に代入する。\n",
        "\n",
        "##### step 2: 予測の地平線を指定する\n",
        "fh = np.arange(1, 37) # この行では、1から36までの数値の配列を作成し、変数'fh'に代入しています。\n",
        "\n",
        "##### step 3: 予測アルゴリズムの指定\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12) # この行は、NaiveForecasterクラスのオブジェクトを、戦略「last」、季節期間「12」で作成します。\n",
        "\n",
        "##### ステップ4: 予測器を学習させる\n",
        "forecaster.fit(y) # この行は、データ 'y' に対して予測器を学習させる。\n",
        "\n",
        "##### step 5: 予測値のクエリ\n",
        "y_pred = forecaster.predict(fh) # この行は、データ 'fh' に対して、学習した予測器の predict メソッドを使用し、その結果を 'y_pred' に代入しています。\n",
        "\n",
        "##### optional: 予測と過去のプロット\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WAWjZOH2bGqc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "mz-m_bktrc71",
        "outputId": "7a674014-975e-4634-ecab-50cf5ac00dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Figure size 1152x288 with 1 Axes>,\n",
              " <matplotlib.axes._subplots.AxesSubplot at 0x7f3cf5d95460>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# オプション：予測値と過去データのプロット\n",
        "plot_series(y, y_pred, labels=[\"y\", \"y_pred\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "以下のPythonコードは、航空会社のデータセットに対して時系列予測を行うために、sktimeライブラリの様々なモジュールとクラスを使用しています。\n",
        "- このコードの利点と特徴は以下の通りです。\n",
        "\n",
        "- データのロード。このコードでは、sktime.datasetsモジュールのload_airline()関数を使い、航空会社のデータセットを簡単に読み込んでいます。\n",
        "\n",
        "- 予測の水平軸。このコードでは、numpyライブラリのnp.arange(1, 37)関数を使用して、36の予測地平線の配列を作成します。\n",
        "\n",
        "- 予測アルゴリズム。このコードでは、sktime.forecasting.naiveモジュールのNaiveForecasterクラスを使用しています。\n",
        "- これは、最後に観測された値に基づいて将来の値を予測するシンプルで使い勝手の良い予測アルゴリズムです。\n",
        "\n",
        "- 予測器を学習させるこのコードでは、データ 'y' に対して予測器オブジェクトの fit メソッドを使い、予測器をデータに学習させています。\n",
        "\n",
        "- 予測値の問い合わせコードはデータ 'fh' に学習した予測器の predict メソッドを使い、その結果を 'y_pred' に代入します。\n",
        "\n",
        "- 精度は？\n",
        " - NaiveForecasterのアルゴリズムは必ずしも高精度ではありませんが、ベンチマークや\n",
        "\n"
      ],
      "metadata": {
        "id": "8OV-Mqvtbqf1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9v2VJKorc71"
      },
      "source": [
        "### **1.2.2 既に学習している水平線を必要とする予測者**\n",
        "- 予測地平線がすでに学習で提供されていることを必要とする予測器もあります。\n",
        "- そのような予測器は、水平線が学習で渡されないと、有益なエラーメッセージを出します。\n",
        "- すべての予測器は、すでに学習で渡された水平線を予測のために記憶します。\n",
        "- このようなforecasterを追加できるように修正した工程は以下の通りです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjj_dC2Arc72"
      },
      "outputs": [],
      "source": [
        "\n",
        "# step 1: データ指定\n",
        "y = load_airline() # 航空会社のデータセットをロードし、変数 'y' に格納する。\n",
        "\n",
        "# step 2: 予測の地平線を指定する\n",
        "import numpy as np # numpyライブラリのインポート\n",
        "fh = np.arange(1, 37) # 1から37までの整数の配列として、予測地平線を指定する\n",
        "\n",
        "# ステップ3: 予測アルゴリズムを指定する\n",
        "from sktime.forecasting.naive import NaiveForecaster # NaiveForecaster クラスをインポートする。\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12) # NaiveForecasterクラスのインスタンスを作成し、「last」戦略を使用し、季節期間を12に指定する。\n",
        "\n",
        "# ステップ4: 予測器の学習\n",
        "forecaster.fit(y, fh=fh) # 指定された予測地平線を持つデータに予測器を学習させる。\n",
        "\n",
        "# step 5: 予測を問い合わせる\n",
        "y_pred = forecaster.predict() # 学習した予測器を使って時系列の将来の値を予測し、変数 'y_pred' に格納する。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- step 1: データ指定\n",
        "- y = load_airline() # 航空会社のデータセットをロードし、変数 'y' に格納する。\n",
        "\n",
        "- step 2: 予測の地平線を指定する\n",
        "- import numpy as np # numpyライブラリのインポート\n",
        "- fh = np.arange(1, 37) # 1から37までの整数の配列として、予測地平線を指定する\n",
        "\n",
        "- ステップ3: 予測アルゴリズムを指定する\n",
        "- from sktime.forecasting.naive import NaiveForecaster # NaiveForecaster クラスをインポートする。\n",
        "- forecaster = NaiveForecaster(strategy=\"last\", sp=12) # NaiveForecasterクラスの- インスタンスを作成し、「last」戦略を使用し、季節期間を12に指定する。\n",
        "- ステップ4: 予測器の学習\n",
        "- forecaster.fit(y, fh=fh) # 指定された予測地平線を持つデータに予測器を学習させる。\n",
        "\n",
        "- step 5: 予測を問い合わせる\n",
        "- y_pred = forecaster.predict() # 学習した予測器を使って時系列の将来の値を予測し、変数 'y_pred' に格納する。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ojzDQCwJdh9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ここでは、最後に観測された値を将来の値の予測として使用する予測アルゴリズムであるNaiveForecasterクラスがsktimeパッケージで実装されています。\n",
        "- この戦略は \"last \"引数で指定され、季節期間は \"sp \"引数で指定される。\n",
        "- fh \"変数は予測の地平線を指定し、それは予測がなされる将来の時間ステップの数である。\n",
        "- 予測器は「fit」メソッドを使って「y」データセットに学習させ、「predict」メソッドを使って予測を生成する。"
      ],
      "metadata": {
        "id": "EGvKoMUmdO_k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-04-10T16:07:06.475031Z",
          "iopub.status.busy": "2021-04-10T16:07:06.473831Z",
          "iopub.status.idle": "2021-04-10T16:07:06.613175Z",
          "shell.execute_reply": "2021-04-10T16:07:06.613700Z"
        },
        "id": "49LXGUsGrc72"
      },
      "source": [
        "### **1.2.3 非同期データを利用できるフォーキャスター**\n",
        "- 多くのフォアキャスタは非同期時系列、つまり予測されないがyの予測に有用な他の時系列を利用できます。\n",
        "- 非同期時系列はfit、predict、その他のメソッドにおいて常にX引数として渡されます（以下を参照ください）。\n",
        "- 非同期時系列は常にpandas.DataFramesとして渡す必要があります。\n",
        "- 非一様時系列を扱えるほとんどの予測ツールは、\n",
        " - fitに渡されるXの時間インデックスはfitに渡されるyの時間インデックスのスーパーセットであり、\n",
        " - 予測に渡されるXの時間インデックスはfhの時間インデックスのスーパーセットであると仮定しますが、\n",
        " - これは一般のインターフェース制限事項ではありません。\n",
        "- 非同質時系列を使用しないフォアキャストは、まだこの引数を受け付けます(そして、内部では使用しません)。\n",
        "\n",
        "- 非同期データを渡すための一般的なワークフローは以下の通りです。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "概要：\n",
        "- フォアキャスターと呼ばれる特別なツールがあります。\n",
        " - それは、yと呼ばれる何かについて予測をするのを助けるために、非遺伝的データと呼ばれる余分な情報を使うことができます。\n",
        " - 余分な情報は常にpandas DataFrameと呼ばれる特別な形式で与えられ、フォアキャスターは余分な情報が彼らが予測しようとしているものよりも多くの情報を持っていると仮定しています。\n",
        " - 予測者の中にはこの余分な情報を使わない人もいますが、それでも受け入れるのです。\n",
        " - この余分な情報を利用するためのプロセスは、特定のステップの集合です。"
      ],
      "metadata": {
        "id": "hMsvjSVHtczZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK4PDYw8rc72"
      },
      "outputs": [],
      "source": [
        "\n",
        "# step 1: データ指定\n",
        "y = load_airline() # 航空会社データセットをロードし、変数 'y' に格納する。\n",
        "\n",
        "# step 2: エクゾジニアスデータの作成\n",
        "import pandas as pd # pandasライブラリのインポート\n",
        "X = pd.DataFrame(index=y.index) # 'y' データフレームと同じインデックスの空のDataFrameを作る\n",
        "\n",
        "# ステップ3: 水平線予測の指定\n",
        "import numpy as np # numpyライブラリのインポート\n",
        "fh = np.arange(1, 37) # 1から37までの整数の配列として、予測地平線を指定する。\n",
        "\n",
        "# ステップ4: 予測アルゴリズムを指定する\n",
        "from sktime.forecasting.naive import NaiveForecaster # NaiveForecaster クラスをインポートする。\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12) # NaiveForecasterクラスのインスタンスを作成し、「last」戦略を使用し、季節期間を12に指定する。\n",
        "\n",
        "# ステップ5: フォアキャスターをフィットさせる\n",
        "forecaster.fit(y, X=X, fh=fh) # 指定された予測期間と非均質データでフォーキャスターをフィットさせる。\n",
        "\n",
        "# ステップ6：予測値のクエリ\n",
        "y_pred = forecaster.predict(X=X) # フィットしたフォアキャスターと非同期データを使って時系列の将来値を予測し、変数 'y_pred' に格納する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードは、sktimeパッケージを使って、非均質データによる時系列予測を行うものです。\n",
        "- 航空会社のデータセットをロードし、'y'データフレームと同じインデックスを持つ空のDataFrameの形で、いくつかのダミー非同期データを作成します。\n",
        "- そして、numpyのarange関数を使って、予測したい将来の時間ステップの範囲である予測地平を指定します。\n",
        "- そして、予測アルゴリズムを指定します。この場合、\"last \"戦略と季節性周期12を持つナイーブ・フォーキャスターです。\n",
        "- そして、フォアキャスターをデータと非均質データに適合させ、最後に適合したフォアキャスターと非均質データを用いて予測を生成します。"
      ],
      "metadata": {
        "id": "LROh_ILPvt0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  step 1: データ指定\n",
        "- y = load_airline() # 航空会社データセットをロードし、変数 'y' に格納する。\n",
        "\n",
        "- step 2: エクゾジニアスデータの作成\n",
        "- import pandas as pd # pandasライブラリのインポート\n",
        "- X = pd.DataFrame(index=y.index) # 'y' データフレームと同じインデックスの空のDataFrameを作る\n",
        "\n",
        "- ステップ3: 水平線予測の指定\n",
        "- import numpy as np # numpyライブラリのインポート\n",
        "- fh = np.arange(1, 37) # 1から37までの整数の配列として、予測地平線を指定する。\n",
        "\n",
        "- ステップ4: 予測アルゴリズムを指定する\n",
        "- from sktime.forecasting.naive import NaiveForecaster # NaiveForecaster クラスをインポートする。\n",
        "- forecaster = NaiveForecaster(strategy=\"last\", sp=12) # NaiveForecasterクラスのインスタンスを作成し、「last」戦略を使用し、季節期間を12に指定する。\n",
        "\n",
        "- ステップ5: フォアキャスターをフィットさせる\n",
        "- forecaster.fit(y, X=X, fh=fh) # 指定された予測期間と非均質データでフォーキャスターをフィットさせる。\n",
        "\n",
        "- ステップ6：予測値のクエリ\n",
        "- y_pred = forecaster.predict(X=X) # フィットしたフォアキャスターと非同期データを使って時系列の将来値を予測し、変数 'y_pred' に格納する。\n"
      ],
      "metadata": {
        "id": "gJ9UTd_DvZoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 上記のコードは、sktimeライブラリを使用した時系列予測のワークフローを示すPythonスクリプトです。\n",
        "- このスクリプトは5つのステップに分かれており、それぞれが時系列予測に関連する特定のタスクを実行します。\n",
        "- このコードの主な利点と特徴は以下の通りです。\n",
        "\n",
        "- メリット\n",
        "\n",
        "- スクリプトは、時系列予測に役立つ一連のツールと関数を提供するsktimeライブラリを使用した時系列予測のための明確で理解しやすいワークフローを示しています。\n",
        "- このスクリプトでは、データに明確なトレンドやパターンがない場合に有効な、シンプルで理解しやすいアルゴリズムであるNaive Forecasterアルゴリズムを使用しています。\n",
        "特徴\n",
        "\n",
        "- スクリプトは、航空会社のデータセットをロードし、いくつかのダミー外生データを作成します。\n",
        "- スクリプトは、予測される将来のタイムポイントの範囲を持つnumpy配列を作成することによって、予測の地平を指定します。\n",
        "- スクリプトは、NaiveForecasterクラスのインスタンスを、戦略 \"last \"とsp=12で初期化することにより、予測アルゴリズムを指定します。\n",
        "- スクリプトは、fitメソッドの引数として、y、X、fhを渡すことで、データセットにフォーキャスターをフィットさせます。\n",
        "- スクリプトは、forecasterのpredictメソッドを呼び出し、Xを引数として渡すことで予測値を問い合わせ、その出力を変数y_predに保存します。\n",
        "- このスクリプトは、時系列の最後の値を使って次の値を予測する単純なアルゴリズムであるナイーブ・フォーキャスター・アルゴリズムを使っていることに注目すべきです。\n",
        " - これはデータに明確な傾向やパターンがない場合に有用ですが、多くの状況で他のより複雑なモデルよりも精度が劣る可能性があります。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vocAIjOsu5ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 上記のコードでは、時系列予測のためのライブラリであるsktimeライブラリからいくつかのクラスと関数をインポートしています。\n",
        "- このコードで使われている主なクラスと関数は以下の通りです。\n",
        "\n",
        "- load_airline。\n",
        " - この関数は、航空会社の乗客数に関する履歴データを含む航空会社データセットを読み込むために使用されます。\n",
        "\n",
        "- ForecastingHorizon。\n",
        " - このクラスは、予測がカバーすべき将来の時点の範囲を指定するために使用されます。\n",
        "\n",
        "- NaiveForecaster:\n",
        " - このクラスは、予測アルゴリズムを指定するために使用されます。\n",
        " - この場合、次の値を予測するために系列の最後の値を使用するナイーブ・フォーキャスターです。\n",
        "\n",
        "- numpy。\n",
        " - このライブラリは、その関数とメソッドのいくつかを使用するためにインポートされます。\n",
        "\n",
        "- このコードでは、これらのクラスと関数を使って時系列予測を行います。\n",
        " - 具体的には、次のようなことを行っています。\n",
        "\n",
        " - load_airline 関数を用いて航空会社のデータセットをロードし、変数 y に格納する。\n",
        " - 予測する将来の時点の範囲をnumpy配列で作成し、予測地平を指定する。\n",
        " - NaiveForecasterクラスのインスタンスを、戦略 \"last \"とsp=12で初期化します。\n",
        " - y, X, fh を引数として渡し、フォアキャスターをデータセットにフィットさせる。\n",
        " - 予測値の問い合わせは、forecasterのpredictメソッドを呼び出し、Xを引数として渡すことで行う。\n",
        "- このコードの利点は以下の通りです。\n",
        "\n",
        " - 時系列予測に役立つツールや関数のセットを提供するsktimeライブラリを使用する。\n",
        " - ナイーブフォーキャスターはシンプルで理解しやすいアルゴリズムであり、データ に明確なトレンドやパターンがない場合に有用です。\n",
        " - このコードは、時系列予測を実行するための明確で理解しやすいワークフローを提供します。\n",
        "- このコードの特徴は\n",
        "\n",
        " - 航空会社のデータセットをロードする\n",
        " - ナイーブ・フォーキャスター・アルゴリズムを使う\n",
        " - 予測地平線を指定する\n",
        " - フォーキャスターをデータセットに適合させる\n",
        " - 予測結果を問い合わせる\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fV_OIe5Ot_Js"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yreNQFaIrc72"
      },
      "source": [
        "- 注意：ワークフロー1.2.1と1.2.2のように、非同質変数を使用するいくつかのフォーキャストは、predictにおいてのみ予測地平線を必要とするかもしれません。\n",
        "- そのような予測器は、ステップ4と5で呼び出されるかもしれません。\n",
        "```python\n",
        "forecaster.fit(y, X=X)\n",
        "y_pred = forecaster.predict(fh=fh, X=X)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xxHHJlArc73"
      },
      "source": [
        "### **1.2.4.多変量予測**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GwOfd0krc73"
      },
      "source": [
        "- sktimeのすべてのフォーキャスターは多変量予測をサポートしています。\n",
        "- いくつかのフォーキャスターは「純正」多変量、その他は「列による適用」です。\n",
        "\n",
        "- 以下は、sktime.datasetsのLongleyデータセットでVAR（ベクトル自己回帰）フォーキャスターを使った一般的な多変量予測のワークフローの例です。\n",
        "- ワークフローは一変量フォアキャスターと同じですが、入力は複数の変数（列）を持っています。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **要約:**\n",
        "- 多変量予測は、一度に複数の事柄について予測を行う方法です。\n",
        "- sktimeパッケージはforecasterと呼ばれる様々なツールを使ってこれを行うことができます。\n",
        "- フォーキャスターの中には一度に多くのことを予測するのが得意なものもあれば、一度に一つのことしか予測できないものもありますが、\n",
        "- それらを何度も使って異なることを予測することができます。\n",
        "- 次の例は、VARと呼ばれるこれらのツールの1つを使用して、Longleyデータセットの異なる変数について予測する方法を示しています。\n",
        "- 手順は、1つの物事について予測をする方法と似ていますが、\n",
        "- より多くの情報を使用する必要があります。"
      ],
      "metadata": {
        "id": "LDmt7z3TxWhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLy_FYB5rc73"
      },
      "outputs": [],
      "source": [
        "from sktime.datasets import load_longley # sktime.datasetsモジュールからload_longley関数をインポートする。\n",
        "from sktime.forecasting.arima import ARIMA # ARIMA クラスをインポートする。\n",
        "\n",
        "_, y = load_longley() # longleyデータセットをロードし、変数'y'に格納する。\n",
        "\n",
        "y = y.drop(columns=[\"UNEMP\", \"ARMED\", \"POP\"]) # 'y' dataframe から列 \"UNEMP\", \"ARMED\", \"POP\" を削除する。\n",
        "\n",
        "forecaster = ARIMA() # ARIMAクラスのインスタンスを作る。\n",
        "forecaster.fit(y, fh=[1, 2, 3]) # 指定された予測地平線を持つデータにフォーキャスターをフィットさせる。\n",
        "\n",
        "forecaster.forecasters_ # フィットしたフォアキャスターの推定量にアクセスする。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RfkBlNwrc73"
      },
      "source": [
        "\n",
        "多変量予報士yの入力は、各列が変数であるpandas.DataFrameである。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "_5i_9saLrc74",
        "outputId": "ef302576-2220-4adb-ca38-773174eac9dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        GNPDEFL       GNP\n",
              "Period                   \n",
              "1947       83.0  234289.0\n",
              "1948       88.5  259426.0\n",
              "1949       88.2  258054.0\n",
              "1950       89.5  284599.0\n",
              "1951       96.2  328975.0\n",
              "1952       98.1  346999.0\n",
              "1953       99.0  365385.0\n",
              "1954      100.0  363112.0\n",
              "1955      101.2  397469.0\n",
              "1956      104.6  419180.0\n",
              "1957      108.4  442769.0\n",
              "1958      110.8  444546.0\n",
              "1959      112.6  482704.0\n",
              "1960      114.2  502601.0\n",
              "1961      115.7  518173.0\n",
              "1962      116.9  554894.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df5e92e5-c5ff-4660-8952-132f804223b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GNPDEFL</th>\n",
              "      <th>GNP</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Period</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1947</th>\n",
              "      <td>83.0</td>\n",
              "      <td>234289.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1948</th>\n",
              "      <td>88.5</td>\n",
              "      <td>259426.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949</th>\n",
              "      <td>88.2</td>\n",
              "      <td>258054.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1950</th>\n",
              "      <td>89.5</td>\n",
              "      <td>284599.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>96.2</td>\n",
              "      <td>328975.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>98.1</td>\n",
              "      <td>346999.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>99.0</td>\n",
              "      <td>365385.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1954</th>\n",
              "      <td>100.0</td>\n",
              "      <td>363112.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>101.2</td>\n",
              "      <td>397469.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1956</th>\n",
              "      <td>104.6</td>\n",
              "      <td>419180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1957</th>\n",
              "      <td>108.4</td>\n",
              "      <td>442769.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>110.8</td>\n",
              "      <td>444546.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>112.6</td>\n",
              "      <td>482704.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>114.2</td>\n",
              "      <td>502601.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961</th>\n",
              "      <td>115.7</td>\n",
              "      <td>518173.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>116.9</td>\n",
              "      <td>554894.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df5e92e5-c5ff-4660-8952-132f804223b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df5e92e5-c5ff-4660-8952-132f804223b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df5e92e5-c5ff-4660-8952-132f804223b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpUX7BcTrc74"
      },
      "source": [
        "多変量解析の結果 y_pred は pandas.DataFrame であり、列は各変数の予測値である。y_predの変数は、多変量解析の入力であるyと同じものである。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ji-sg61irc75",
        "outputId": "bf68819f-c47a-4227-9527-48364da55b0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         GNPDEFL            GNP\n",
              "1963  121.688295  578514.398653\n",
              "1964  124.353664  601873.015890\n",
              "1965  126.847886  625411.588754"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d61f37d-5c95-48a1-98f9-6431e3645609\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GNPDEFL</th>\n",
              "      <th>GNP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1963</th>\n",
              "      <td>121.688295</td>\n",
              "      <td>578514.398653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>124.353664</td>\n",
              "      <td>601873.015890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>126.847886</td>\n",
              "      <td>625411.588754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d61f37d-5c95-48a1-98f9-6431e3645609')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d61f37d-5c95-48a1-98f9-6431e3645609 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d61f37d-5c95-48a1-98f9-6431e3645609');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ex0__5wrc75"
      },
      "source": [
        "- 上記のように、すべてのフォアキャストは多変量の入力を受け入れ、多変量の予測を作成します。\n",
        "- 2つのカテゴリーがあります。\n",
        "\n",
        " - VARのような純粋に多変量であるフォーキャスター。\n",
        "     - ある内生（y）変数の予測は、他の変数の値に依存します。\n",
        " - ARIMAのような一変量であるフォーキャスター。\n",
        "     - 予測は、内因性（y）変数によって行われ、他の変数に影響されない。\n",
        "- 多変量フォーキャスターの完全なリストを表示するには、以下のようにタグ 'scitype:y' に 'multivariate' または 'both' タグ値を持つフォーキャスターを検索してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipF4AGLrrc75"
      },
      "outputs": [],
      "source": [
        "# all_estimators 関数をインポートする from sktime.registry module\n",
        "from sktime.registry import all_estimators \n",
        "\n",
        "# タグの値が 'multivariate' または 'both' である推定値に対してループ処理を行う for 'scitype:y'\n",
        "for forecaster in all_estimators(filter_tags={\"scitype:y\": [\"multivariate\", \"both\"]}):\n",
        "    \n",
        "print(forecaster[0]) # 推定値の名前を表示する。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Pythonのコードでは、\n",
        "- sktime.registryモジュールからall_estimators関数をインポートしています。\n",
        " - この関数は、sktimeパッケージに登録されているすべてのestimator（forecaster）を返します。\n",
        " - この関数はオプションのパラメータfilter_tagsを受け取り、タグに基づいて返されるestimatorsをフィルタリングするために使用することができる。\n",
        " - この例のコードでは、タグ「scitype:y」の値に基づいて推定量をフィルタリングし、このタグの値が「multivariate」または「both」であるすべての推定量の名前を出力している。\n",
        "\n",
        "- このコードの利点は以下の通りである。\n",
        "\n",
        " - sktimeパッケージで利用可能な、特に多変量予測のために設計されたすべての推定量のリストにアクセスすることができる。\n",
        " - また、このコードはタグのような様々な基準に基づいて推定量をフィルタリングするように変更することができ、ユーザーは自分の問題に最も適した推定量を迅速に見つけることができる。\n",
        "- このコードの特徴は以下の通りである。\n",
        "\n",
        " - タグに基づいて推定量をフィルタリングし、リストにアクセスする機能\n",
        " - 多変量予測に適した推定量の名前を見ることができる。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NtATnBmQyxvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードでは、sktime.registryモジュールからall_estimators関数をインポートしています。\n",
        "- この関数は、sktimeパッケージに登録されているすべての推定量（フォーキャスト）を返す。\n",
        "- このコードでは、この関数を使用して、返された推定量を「scitype:y」というタグの値に基づいてフィルタリングし、このタグの値が「multivariate」または「both」であるすべての推定量の名前を出力している。\n",
        "\n",
        "- メリット\n",
        "\n",
        " - sktimeパッケージで利用可能な、特に多変量予測のために設計されたすべての推定量のリストにアクセスできるようになる。\n",
        " - また、このコードはタグのような様々な基準に基づいて推定量をフィルタリングするように変更することができ、これによりユーザーは自分の問題に最も適した推定量を素早く見つけることができる。\n",
        "- 特徴\n",
        "\n",
        " - タグに基づいて推定量をフィルタリングし、リストにアクセスする機能\n",
        " - 多変量予測に適した推定量の名前を見ることができる。\n",
        "\n",
        "- 要約: \n",
        " - このコードはsktime.registryモジュールからall_estimators関数をインポートし、\n",
        " - それを使って多変量予測に適した全ての推定量の名前をフィルタリングして表示します。\n",
        " - これにより、ユーザーは自分の問題に最も適した推定量を素早く見つけることができ、\n",
        " - また、多変量予測に利用できる全ての推定量を確認することができます。"
      ],
      "metadata": {
        "id": "NKB2BdtTznTa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np7fkw0Drc76"
      },
      "source": [
        "- 一変量フォーキャスターは、タグ値「univariate」を持ち、列ごとに1つのモデルを適合させます。\n",
        "- 列ごとのモデルにアクセスするには、forecasters_パラメータにアクセスします。\n",
        "- これは、フィットしたフォーキャストをpandas.DataFrameに格納し、フィットしたフォーキャストは、予測が行われる変数がある列に格納されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "nL7f9iz0rc76",
        "outputId": "bf1aa8f6-d7b0-4c8c-bc33-28b61bffd384"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/utils/validation/_dependencies.py\u001b[0m in \u001b[0;36m_check_soft_dependencies\u001b[0;34m(package_import_alias, severity, obj, suppress_import_stdout, *packages)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mpkg_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_import_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# if package cannot be imported, make the user aware of installation requirement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pmdarima'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d0d536dba7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"UNEMP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ARMED\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"POP\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mforecaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mforecaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/forecasting/arima.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, order, seasonal_order, start_params, method, maxiter, suppress_warnings, out_of_sample_size, scoring, scoring_args, trend, with_intercept, time_varying_regression, enforce_stationarity, enforce_invertibility, simple_differencing, measurement_error, mle_regression, hamilton_representation, concentrate_scale)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARIMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_instantiate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/forecasting/base/adapters/_pmdarima.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forecaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_PmdArimaAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_instantiate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/forecasting/base/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseForecaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0m_check_estimator_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/utils/validation/_dependencies.py\u001b[0m in \u001b[0;36m_check_estimator_deps\u001b[0;34m(obj, msg, severity)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mpkg_deps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpkg_deps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpkg_deps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mpkg_deps_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_soft_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpkg_deps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseverity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseverity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mcompatible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompatible\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpkg_deps_ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sktime/utils/validation/_dependencies.py\u001b[0m in \u001b[0;36m_check_soft_dependencies\u001b[0;34m(package_import_alias, severity, obj, suppress_import_stdout, *packages)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 )\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mseverity\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mseverity\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"warning\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: ARIMA requires package 'pmdarima' to be present in the python environment, but 'pmdarima' was not found. 'pmdarima' is a soft dependency and not included in the base sktime installation. Please run: `pip install pmdarima` to install the pmdarima package. To install all soft dependencies, run: `pip install sktime[all_extras]`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\n",
        "from sktime.datasets import load_longley # sktime.datasetsモジュールからload_longley関数をインポートする。\n",
        "from sktime.forecasting.arima import ARIMA # ARIMA クラスをインポートする。\n",
        "\n",
        "_, y = load_longley() # longleyデータセットをロードし、変数'y'に格納する。\n",
        "\n",
        "y = y.drop(columns=[\"UNEMP\", \"ARMED\", \"POP\"]) # 'y' dataframe から列 \"UNEMP\", \"ARMED\", \"POP\" を削除する。\n",
        "\n",
        "forecaster = ARIMA() # ARIMAクラスのインスタンスを作る。\n",
        "forecaster.fit(y, fh=[1, 2, 3]) # 指定された予測地平線を持つデータにフォーキャスターをフィットさせる。\n",
        "\n",
        "forecaster.forecasters_ # フィットしたフォアキャスターの推定量にアクセスする。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードは、ARIMAモデルを使った時系列予測を行うためにsktimeパッケージを使用しています。\n",
        "- longleyデータセットをロードし、'y'データフレームから \"UNEMP\", \"ARMED\", \"POP \"の列を削除します。\n",
        "- そして、予測地平線を指定します。\n",
        " - これは、予測が必要な将来の時間ステップの範囲です。\n",
        " - そして、予測アルゴリズムを指定します、この場合はARIMAです。\n",
        " - そして、フォアキャスターをデータに適合させ、\n",
        " - 最後にforecasters_attributeを呼び出して適合させたフォアキャスターの推定量にアクセスします。"
      ],
      "metadata": {
        "id": "KHYTppDswiR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "要約：\n",
        "- 一変量予測ツールは、一度に一つのことしか予測できないツールである。\n",
        "- それらは「一変量」とラベル付けされ、一度に1つの列を見て予測を行う。\n",
        "- これらのツールを使用した後、forecasters_パラメータを見ることで、各カラムに対して行われた予測を見ることができます。\n",
        "- このパラメータは、DataFrameと呼ばれる特別なテーブルに予測を格納し、各列の予測はテーブルの異なる列に格納されます。"
      ],
      "metadata": {
        "id": "NCfBA1SX0M4a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOiPqA8Arc76"
      },
      "source": [
        "### **1.2.5 確率的予測：予測区間、分位数、分散、および分布の予測**\n",
        "- sktimeは、確率的予測を行うための統一されたインターフェイスを提供します。\n",
        "- 確率的予測では、以下のメソッドが利用できる可能性があります。\n",
        "\n",
        "- predict_interval は、区間予測を生成します。\n",
        "- predict_interval は区間予測を生成します。\n",
        "- predict の引数に加え、引数 coverage (名目区間範囲) が提供されなければなりません。\n",
        "- predict_quantiles は、分位数予測を生成します。\n",
        " - predict の引数に加え、引数 alpha (分位値)を提供しなければなりません。\n",
        "- predict_var は、分散予測を生成します。\n",
        " - これは、predictと同じ引数を持っています。\n",
        "- predict_proba は完全な分布の予測を生成します。\n",
        " - これはpredictと同じ引数を持っています。\n",
        "- すべての予測業者が確率的予測を返すことができるわけではありませんが、もしある予測業者が1種類の確率的予測を提供するならば、他の予測も返すことができます。\n",
        "- このような能力を持つ予測器のリストは、registry.all_estimatorsで照会することができ、 capability:pred_intタグがvalueTrueであるものを探します。\n",
        "\n",
        "- 確率的予測の基本的なワークフローは、基本的な予測ワークフローと似ていますが、予測の代わりに確率的予測手法の1つが使用されるという違いがあります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "要約: \n",
        "- 確率的予測は、いくつかの追加情報を使って予測を行う方法である。\n",
        "- sktime パッケージには 'predict_interval', 'predict_quantiles', 'predict_var', 'predict_proba' と呼ばれるツールがあり、これを利用することができます。\n",
        "- これらのツールは、可能な予測の範囲、最も可能性の高い予測、予測の広がりといった情報を与えてくれる。\n",
        "- sktimeパッケージのすべてのツールが確率的予測を行えるわけではないが、あるツールがある種の確率的予測を行えるのであれば、他のツールも行えるはずである。- all_estimators関数を使って、どのツールが確率的予測を行えるかを確認することができます。"
      ],
      "metadata": {
        "id": "CO8Qiu7Q0pjZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12eUn431rc77"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sktime.datasets import load_airline # sktime.datasetsモジュールからload_airline関数をインポートします。\n",
        "from sktime.forecasting.theta import ThetaForecaster # ThetaForecaster クラスをインポートする。\n",
        "\n",
        "y = load_airline() # 航空会社のデータセットをロードし、変数 'y' に格納する。\n",
        "\n",
        "fh = np.arange(1, 13) # 予測の地平線を指定する。\n",
        "\n",
        "forecaster = ThetaForecaster(sp=12) # ThetaForecasterのインスタンスをsp=12で作成する。\n",
        "forecaster.fit(y, fh=fh) # 指定された予測地平線を持つデータにフォアキャスターをフィットさせる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pINH0Mhrrc77"
      },
      "source": [
        "Now we present the different probabilistic forecasting methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLO-wNg_rc77"
      },
      "source": [
        "### **predict_interval - 区間予測**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNUwj2Otrc77"
      },
      "source": [
        "- predict_intervalは、float（またはfloatのリスト）である引数coverageを取り、照会された予測区間の公称coverageです。\n",
        "- predict_intervalは、対称的な予測区間を生成します、\n",
        " - 例えば、coverage 0.9 は、分位0.5 - coverage/2 = 0.05 で「低い」予測、分位0.5 + coverage/2 = 0.95 で「高い」予測が返ってきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlXgv5txrc78"
      },
      "outputs": [],
      "source": [
        "coverage = 0.9\n",
        "y_pred_ints = forecaster.predict_interval(coverage=coverage) # カバレッジ0.9で予測の区間を予測する。\n",
        "y_pred_ints # 予測された区間にアクセスする\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJYPxS0jrc78"
      },
      "source": [
        "- 戻り値の y_pred_ints は pandas.DataFrame であり、列のマルチインデックスを持ちます。\n",
        " - 第一階層は fit の y の変数名(変数名がない場合は Coverage)、\n",
        " - 第二階層は入力 coverage と同じ順序で区間が計算された coverage fraction、\n",
        " - 第三階層は lower と upper のカラム。\n",
        " - 行は、予測が行われたインデックス(y_pred または fh と同じ)。\n",
        " - 項目は、同じ行のインデックスに対する公称カバレッジ予測区間の下限/上限(列名として)である。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **要約:**\n",
        "- y_pred_intsは、ツールによって行われた予測を示す特別なテーブルです。\n",
        "- この表は、\n",
        " - 予測される変数の名前、\n",
        " - ある範囲に入る予測のパーセンテージ、\n",
        " - 予測の下限と上限のような、\n",
        " - 異なるレベルの情報を持つ列があります。\n",
        " - 表の行は、予測がなされた時間ステップを示します。\n",
        " - 表の各エントリーは、ある時間ステップの予測値の下限と上限、\n",
        " - およびその範囲に入る予測値の一定の割合を示しています。"
      ],
      "metadata": {
        "id": "zUo13-Iv2ZbD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUgQQPrErc78"
      },
      "source": [
        "Pretty-plotting the predictive interval forecasts:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、\n",
        "- ThetaForecasterを使って確率的な予測を行うためにsktimeパッケージを使っています。\n",
        "    - 航空会社のデータセットをロードし、そして、予測地平線を指定します。\n",
        "    - これは、予測が望まれる将来の時間ステップの範囲です。\n",
        "    - そして、予測アルゴリズムを指定します。\n",
        "    - この場合、季節期間sp=12を指定したThetaForecasterです。\n",
        "    - そして、そのフォアキャスターをデータにフィットさせ、\n",
        "    - 最後に、カバレージパラメータでpredict_intervalを呼び出して、\n",
        "    - カバレージ0.9の予測区間にアクセスします。\n",
        "\n",
        "- 利点\n",
        "\n",
        "    - これは、ユーザがThetaForecasterを使って確率的な予測を行うことを可能にします。\n",
        "    - それは区間予測を与え、ユーザーに可能な予測の範囲のアイデアを与える。\n",
        "- 特徴\n",
        "\n",
        "    - インターバル予測を行う機能\n",
        "    - 区間予報の適用範囲を指定する機能\n",
        "- 要約:\n",
        "    - コードは、航空会社のデータセットをロードし、ThetaForecasterをデータに適合させ、\n",
        "    - 指定された次の12時間ステップのインターバル予測を生成する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "owsPrCC719BC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hMFqdICrc79"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sktime.utils import plotting # plotting モジュールをインポートする from sktime.utils\n",
        "\n",
        "# 予測を行う\n",
        "y_pred = forecaster.predict()\n",
        "\n",
        "# figure と axis オブジェクトを作成し、系列をプロットします。\n",
        "fig, ax = plotting.plot_series(\n",
        "y, y_pred, labels=[\"y\", \"y_pred\"], pred_interval=y_pred_ints\n",
        ")\n",
        "\n",
        "# 予測の分位数を予測する\n",
        "y_pred_quantiles = forecaster.predict_quantiles(alpha=[0.275, 0.975])\n",
        "y_pred_quantiles #予測された分位数にアクセスする\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、\n",
        "- 予測された時系列のプロットを、予測区間と分位数とともに生成するためにsktimeパッケージを使用します。\n",
        "    - まず、適合したフォーキャスターを使って予測を行い、\n",
        "    - 次にsktime.utilsモジュールのplotting.plot_series関数を使って図と軸オブジェクトを作成し指定したラベルと予測区間で系列をプロットします。\n",
        "    - そして、predict_quantiles関数で別の予測を行い、予測された分位数にアクセスします。\n",
        "\n",
        "- 利点\n",
        "\n",
        "    - ユーザーは、予測された時系列と予測区間および分位数の視覚化を簡単に作成することができます。\n",
        "    - plot_series関数は自動的にデータのプロットを処理し、ユーザーは予測された時系列の明確で情報量の多い視覚化を容易に作成することができます。\n",
        "- 特徴\n",
        "\n",
        "    - 予測された時系列を予測区間と分位数とともに簡単に視覚化する機能。\n",
        "    - plot_series関数が自動的にデータのプロットを処理するので、\n",
        "    - ユーザーは予測された時系列の明確で情報量の多い視覚化を簡単に作成することができます。\n",
        "- 要約: \n",
        "    - このコードは、予測された時系列のプロットを、予測区間と分位数とともに生成します。\n",
        "    - これは、プロットを作成するためにsktime.utilsモジュールのplotting.plot_series関数を使用し、\n",
        "    - 量子化幅を予測するためにpredict_quantiles関数を使用します。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1SLMZDOh3ojT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QC1T_OCrc7-"
      },
      "source": [
        "##### `predict_quantiles` - quantile forecasts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcZvntSqrc7-"
      },
      "source": [
        "- sktimeは予測値の分位値を返す統一インターフェースとしてpredict_quantilesを提供しています。predict_intervalに似ています。\n",
        "\n",
        "- predict_quantiles は引数 alpha を持ち，照会される分位値を含む。\n",
        "- predict_interval の場合と同様に，alpha は float，または float のリストである。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5mAdQvyrc7_"
      },
      "outputs": [],
      "source": [
        "y_pred_quantiles = forecaster.predict_quantiles(alpha=[0.275, 0.975])\n",
        "y_pred_quantiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOCD-cU2rc8A"
      },
      "source": [
        "- predict_quantilesの出力であるy_pred_quantilesは、2レベルのカラムのマルチインデックスを持つpandas.DataFrameです。\n",
        "    - 第1レベルは、fitのyからの変数名（変数名がない場合はQuantiles）、\n",
        "    - 第2レベルは、分位値予測が照会された分位値（alphaから）で、\n",
        "    - 第3レベルは、分位値予測が照会された分位値です。\n",
        "    - 行は予測が行われたインデックス(y_predやfhと同じ)です。\n",
        "    - 項目は、その変数、その分位値、同じ行の時間インデックスに対する分位値予測です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSZ2TO0mrc8A"
      },
      "source": [
        "- 備考：\n",
        "    - わかりやすくするために：分位値と（対称）区間予測は以下のように相互に変換することができる。\n",
        "\n",
        "    - alpha < 0.5: α-分位予測は，coverage = (0.5 - alpha) * 2を持つ予測区間の下限と等しい．\n",
        "\n",
        "    - alpha > 0.5: アルファ分位値予測は、カバレッジ= (alpha - 0.5) * 2の予測区間の上界に等しい。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **要約:**\n",
        "- sktimeツールは、分位値予測と呼ばれる、予測が該当する可能性のあるさまざまなレベルまたは範囲を予測する方法を提供します。\n",
        "- predict_quantiles関数を使用して、予測値の下限や上限のような異なるレベルを予測することができます。\n",
        "- 出力は、異なるレベルの予測値を示す表で、行は予測が行われた時間ステップを示し、列は異なるレベルまたは範囲を示しています。\n",
        "- このツールには区間を予測する方法もあり、これらの区間と分位の予測値は特定の数式を使用して相互に変換することができます。\n"
      ],
      "metadata": {
        "id": "Tk6_EqWM5ULi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQdjskHBrc8A"
      },
      "source": [
        "\n",
        "### **predict_var - 分散予測値．**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQZEDV4crc8B"
      },
      "source": [
        "predict_var は分散予測値を生成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3g8DEvsrc8B"
      },
      "outputs": [],
      "source": [
        "from sktime.utils import plotting\n",
        "\n",
        "# 予測を行う\n",
        "y_pred = forecaster.predict()\n",
        "\n",
        "# figure と axis オブジェクトを作成し、系列をプロットします。\n",
        "fig, ax = plotting.plot_series(\n",
        "y, y_pred, labels=[\"y\", \"y_pred\"], pred_interval=y_pred_ints\n",
        ")\n",
        "\n",
        "# 予測の分散を予測する\n",
        "y_pred_var = forecaster.predict_var()\n",
        "y_pred_var # 予測された分散にアクセスする"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、\n",
        "- 予測された時系列のプロットを、予測間隔と分散とともに生成するためにsktimeパッケージを使用します。\n",
        "    - まず、適合したフォアキャスターを使って予測を行い、\n",
        "    - 次にsktime.utilsモジュールのplotting.plot_series関数を使って図と軸オブジェクトを作成し、指定したラベルと予測区間で系列をプロットします。\n",
        "    - そして、predict_var 関数で別の予測を行い、予測された分散にアクセスします。\n",
        "\n",
        "- 利点\n",
        "\n",
        "    - 予測された時系列と予測区間、分散を簡単に視覚化することができます。\n",
        "    - plot_series関数は自動的にデータのプロットを処理し、\n",
        "    - ユーザーは予測された時系列の明確で情報量の多い視覚化を簡単に作成することができます。\n",
        "- 特徴\n",
        "\n",
        "    - 予測された時系列を予測区間と分散とともに簡単に視覚化する機能。\n",
        "    - plot_series関数が自動的にデータのプロットを処理するので、ユーザーは予測された時系列の明確で情報量の多い可視化を簡単に作成することができます。\n",
        "- 要約: \n",
        "    - このコードは、予測された時系列のプロットを、予測区間と分散とともに生成します。- これは、プロットを作成するためにsktime.utilsモジュールのplotting.plot_series関数を使用し、予測の分散を予測するためにpredict_var関数を使用しています。\n",
        "\n"
      ],
      "metadata": {
        "id": "LDS-z-kx6Hbr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr0-Ews1rc8B"
      },
      "source": [
        "出力される y_pred_var のフォーマットは predict と同じですが，これは常に pandas.DataFrame に強制され，エントリーは点予測ではなく分散予測であることが異なります．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6bKgJMFrc8C"
      },
      "source": [
        "##### predict_proba - ディストリビューション予測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td1p5ezrrc8C"
      },
      "source": [
        "完全な予測分布を予測するには、predict_probaを使用することができます。これはtensorflow Distributionオブジェクトを返すので、sktimeの深層学習依存セットdl（tensorflowとtensorflow-probability依存を含む）がインストールされている必要がある。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zS5Q_SaLrc8C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "4fdda37d-2b0a-48d5-8219-ce65e54e7387"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-39ae7b56856a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 予測を行う\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sktime'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from sktime.utils import plotting\n",
        "\n",
        "# 予測を行う\n",
        "y_pred = forecaster.predict()\n",
        "\n",
        "# figure と axis オブジェクトを作成し、系列をプロットします。\n",
        "fig, ax = plotting.plot_series(\n",
        "y, y_pred, labels=[\"y\", \"y_pred\"], pred_interval=y_pred_ints\n",
        ")\n",
        "\n",
        "# 完全な分布予測を行う\n",
        "y_pred_proba = forecaster.predict_proba()\n",
        "y_pred_proba # 予測された分布にアクセスする\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、\n",
        "- 予測された時系列のプロットを、予測区間と完全な分布予測とともに生成するために、sktimeパッケージを使用します。\n",
        "    - まず、適合したフォアキャスターを使って予測を行い、\n",
        "    - 次にplotting.plot_series関数を使って図と軸オブジェクトを作成し、時系列データと予測をプロットします。\n",
        "    - そして、forecasterオブジェクトのpredict_probaメソッドを呼び出して完全な分布予測を生成し、それをy_pred_proba変数に代入しています。\n",
        "    - そして、この変数は予測された分布を見るためにアクセスすることができます。\n",
        "\n",
        "    - plotting.plot_series関数は、プロット上の陰影領域として予測区間をプロットするために使用されるpred_intervalなど、いくつかのオプション引数を取ることができます。- predict_proba メソッドは、予測値の完全な分布である確率的な予測を返します。\n",
        "    - これは、ユーザーが予測の不確実性をよりよく理解することを可能にします。\n",
        "    - 全てのフォーキャスターが確率的予測をサポートしているわけではなく、\n",
        "    - サポートしているフォーキャスターは予測水平線や他のパラメータを指定するための異なるオプションを持っている可能性があることに注意してください。\n",
        "\n",
        "- 要約:\n",
        "    -  このコードは、予測された時系列のプロットを、予測区間と完全な分布予測とともに生成するためにsktimeパッケージを使用します。\n",
        "    - それはまず、適合したフォーキャスターを使って予測を行い、\n",
        "    - 次にplotting.plot_series関数を使って図と軸オブジェクトを作り、\n",
        "    - 時系列データと予測値をプロットします。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dm4w9QEd7bMi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YiQZcdurc8D"
      },
      "source": [
        "\n",
        "\n",
        "- predict_probaによって返される分布は、デフォルトでは、時間点でのマージナルであり、時間点でのジョイントではありません。\n",
        "- より正確には、返された分布オブジェクトは以下のようにフォーマットされ、解釈されます。\n",
        "\n",
        "    - バッチの形状は1次元で、長さはfhと同じです。\n",
        "    - イベントの形状は1次元で、長さは予測される変数の数に等しい。\n",
        "    - i 番目の（バッチ）分布は，fh の i 番目のエントリに対して予測される．\n",
        "    - j 番目の（イベント）成分は j 番目の変数で、フィット/アップデートの y と同じ順番。\n",
        "    - ジョイント予測分布を返すために、marginalパラメータをFalseに設定することができます（現在作業中）。\n",
        "    - この場合、2次元イベント形状(len(fh), len(y))の分布が返される。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **概要：**\n",
        "- 「Predict_proba」は、ある事柄が将来どの程度の確率で起こるかを予測する。\n",
        "- 起こる可能性のある事柄のそれぞれについて、数字を与えてくれる。\n",
        "- デフォルトでは、一度に1つのことしか予測しませんが、\n",
        "- 一度に複数のことを予測するように変更することができます。\n",
        "- 現在、このオプションはまだ作業中です。"
      ],
      "metadata": {
        "id": "8Ook3_8Y8lRr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21bryEicrc8D"
      },
      "source": [
        "\n",
        "\n",
        "### **1.2.6 パネル予測および階層的予測**\n",
        "- sktime は、パネルおよび階層的な予測を行うための統一されたインターフェイスを提供します。\n",
        "\n",
        "- すべてのsktimeフォーキャスターは、特定の入力フォーマットで提示される必要があるパネルと階層データに適用することができます。\n",
        "- 純粋なパネル予測や階層予測でない予測器は、インスタンスによって適用されます。\n",
        "\n",
        "- パネルデータや階層データを渡すのに推奨される（唯一ではない）フォーマットは、MultiIndex行を持つpandas.DataFrameです。\n",
        "- このMultiIndexでは、最後のレベルはsktime互換の時間インデックス形式である必要があり、残りのレベルはパネルまたは階層ノードです。\n",
        "\n",
        "データ例です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **要約**\n",
        "- sktimeは、特に物事のグループや階層を持つ物事について、将来起こりうることを予測するのに役立つツールです。\n",
        "- このツールは様々な種類のデータで動作し、MultiIndexと呼ばれるpandasの特別な種類のテーブルを使用することが推奨されています。\n",
        "- このテーブルは、sktimeが理解できる特別な種類の日付フォーマットを持つ必要があり、またグループや階層に関する情報を持つ必要があります。\n",
        "- こうすることで、ツールはあなたに最適な予測を行うことができます。\n"
      ],
      "metadata": {
        "id": "Nh0uSG5O9Xod"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55SBT4RErc8E"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "from sktime.forecasting.arima import ARIMA # ARIMAは、時系列データを予測するための手法である。\n",
        "from sktime.utils._testing.hierarchical import _make_hierarchical # _make_hierarchical は、階層的な時系列を作成する関数である。\n",
        "\n",
        "# 2列の階層的な時系列を作成する\n",
        "y = _make_hierarchical(n_columns=2)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oAK6f3Rrc8E"
      },
      "source": [
        "As stated, all forecasters, genuinely hierarchical or not, can be applied, with all workflows described in this section, to produce hierarchical forecasts.\n",
        "\n",
        "The syntax is exactly the same as for plain time series, except for the hierarchy levels in input and output data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4wpGmH5rc8F"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "from sktime.forecasting.arima import ARIMA # ARIMAは、時系列データを予測するための手法である。\n",
        "\n",
        "\n",
        "# 予測の水平軸（予測する未来のタイムステップ数）を設定する\n",
        "fh = [1, 2, 3] \n",
        "\n",
        "# ARIMAモデルの作成\n",
        "forecaster = ARIMA()\n",
        "\n",
        "# データと予測地平線を用いてモデルをフィットさせる\n",
        "forecaster.fit(y, fh=fh)\n",
        "\n",
        "# 階層的な時系列のサブフォーキャスターにアクセスする\n",
        "forecaster.forecasters_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6hCTHd0rc8F"
      },
      "source": [
        "Similar to multivariate forecasting, forecasters that are not genuinely hierarchical fit by instance.\n",
        "The forecasters fitted by instance can be accessed in the `forecasters_` parameter, which is a `pandas.DataFrame` where forecasters for a given instance are placed in the row with the index of the instance for which they make forecasts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMGjza2Vrc8F"
      },
      "outputs": [],
      "source": [
        "# 階層的な時系列のサブフォーキャスターにアクセスする\n",
        "forecaster.forecasters_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClsEXdTPrc8G"
      },
      "source": [
        "If the data is both hierarchical and multivariate, and the forecaster cannot genuinely deal with either, the `forecasters_` attribute will have both column indices, for variables, and row indices, for instances, with forecasters fitted per instance and variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewoioYz8rc8G"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインポート\n",
        "from sktime.forecasting.arima import ARIMA # ARIMAは、時系列データを予測するための手法である。\n",
        "from sktime.utils._testing.hierarchical import _make_hierarchical # _make_hierarchical は、階層的な時系列を作成する関数である。\n",
        "\n",
        "# 2列の階層的な時系列を作成する\n",
        "y = _make_hierarchical(n_columns=2)\n",
        "\n",
        "# 予測の水平軸（予測する未来のタイムステップ数）を設定する\n",
        "fh = [1, 2, 3] \n",
        "\n",
        "# ARIMAモデルの作成\n",
        "forecaster = ARIMA()\n",
        "\n",
        "# データと予測地平線を用いてモデルをフィットさせる\n",
        "forecaster.fit(y, fh=fh)\n",
        "\n",
        "# 階層的な時系列のサブフォーキャスターにアクセスする\n",
        "forecaster.forecasters_\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  必要なライブラリのインポート\n",
        "- from sktime.forecasting.arima import ARIMA # ARIMAは、時系列データを予測するための手法である。\n",
        "- from sktime.utils._testing.hierarchical import _make_hierarchical \n",
        "-  _make_hierarchical は、階層的な時系列を作成する関数である。\n",
        "\n",
        "-  2列の階層的な時系列を作成する\n",
        "- y = _make_hierarchical(n_columns=2)\n",
        "\n",
        "-  予測の水平軸（予測する未来のタイムステップ数）を設定する\n",
        "- fh = [1, 2, 3] とする。\n",
        "\n",
        "-  ARIMAモデルの作成\n",
        "- forecaster = ARIMA()\n",
        "\n",
        "-  データと予測地平線を用いてモデルをフィットさせる\n",
        "- forecaster.fit(y, fh=fh)\n",
        "\n",
        "-  階層的な時系列のサブフォーキャスターにアクセスする\n",
        "- forecaster.forecasters_\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i21ZLaaNY__S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、まず必要なライブラリであるARIMAと_make_hierarchicalをインポートします。\n",
        "- ARIMAは時系列データを予測する手法であり、_make_hierarchicalは階層的な時系列を作成する関数である。\n",
        "- 次に_make_hierarchical関数を使って2列の階層型時系列を作成し、変数yに格納します。\n",
        "\n",
        "- そして、リストfh = [1, 2, 3]を作成して、予測地平（予測する未来の時間ステップの数）を設定します。\n",
        "- これは、1、2、3ステップ先の未来を予測するようにモデルに指示します。\n",
        "\n",
        "- 次に、ARIMAモデルを作成し、変数forecasterに格納します。\n",
        "- そして、.fit()メソッドを用いて、データと予測水平軸でモデルを適合させます。\n",
        "- データとして変数yを、予測水平線としてfhを渡します。\n",
        "\n",
        "- 最後に、forecaster.forecasters_を使って、階層化された時系列のサブフォーキャスターにアクセスします。\n",
        "\n",
        "- この種の予測は、株式市場予測、売上予測、天気予報など、多くの実世界のアプリケーションで有用です。\n",
        "- ARIMAモデルは、明確なトレンドがあるデータだけでなく、よりランダムなデータの予測にも使用できるため、時系列予測によく使われる手法です。\n",
        "- しかし、限界があり、すべてのタイプの時系列データに最適な手法とは限りません。\n"
      ],
      "metadata": {
        "id": "8eS5vZ1EZTy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- 次のコードは、ARIMA（自己回帰統合移動平均）と呼ばれる手法で、sktimeというPythonのライブラリを使って、将来の事象について予測を行うものです。\n",
        "\n",
        "- from sktime.forecasting.arima import ARIMA sktimeからARIMAライブラリをインポートしています。\n",
        "- from sktime.utils._testing.hierarchical import _make_hierarchical ARIMAモデルをテストするためのデータを生成するヘルパー関数をインポートしています。\n",
        "- y = _make_hierarchical(n_columns=2) 上のヘルパー関数で生成されたデータの値を2列で代入したyという変数を作成します。\n",
        "- fh = [1, 2, 3] fhという変数が作成され、[1, 2, 3]の数値のリストの値が代入されます。\n",
        "- forecaster = ARIMA() は forecaster という ARIMA クラスのオブジェクトを作成します。\n",
        "- forecaster.fit(y, fh=fh) は引数として y 変数と fh 変数を渡し、forecaster オブジェクトの fit メソッドを呼び出します。これは、データyと予測水平線fhでモデルを学習させます。\n",
        "- forecaster.forecasters_はforecasterオブジェクトの属性で、内部で使用されている個々のforecasterにアクセスするために使用されます。\n",
        "- 要約すると、このコードはARIMAモデルを使って、あるデータと予測地平についてモデルを学習させ、モデル内部のフォーキャスターにアクセスすることで、将来の出来事について予測を行っています。\n"
      ],
      "metadata": {
        "id": "7nsO8xJyY4Ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- Pythonのヘルパー関数は、他のタスクや関数を支援するために使用される関数の一種です。\n",
        "- この関数は単独で使用されることを意図しておらず、\n",
        " - 補助する主なタスクや関数をより簡単に、\n",
        " - またはより効率的にするために設計されています。\n",
        "\n",
        "- 例えば、あなたがサンドイッチを作っているとします。\n",
        "- メインタスクはサンドイッチを作ることですが、\"gather ingredients \"というヘルパー関数が用意されています。\n",
        "- このヘルパー関数の仕事は、パン、チーズ、肉など、サンドイッチを作るのに必要な材料をすべて集めることです。\n",
        "- これによって、サンドイッチを作ろうとしている最中に材料を探しに行く必要がなくなるので、サンドイッチを作るというメインの作業が楽になります。\n",
        "\n",
        "- ヘルパー関数の利点のひとつは、メインのタスクや関数をより整理して理解しやすくできることです。\n",
        "- また、ヘルパー関数は、メイン関数が動作するために必要な特定のタスクを処理することができるため、メインタスクをより効率的にすることができます。\n",
        "\n",
        "- ヘルパー関数のデメリットは、コードが複雑になることです。\n",
        "- 多くのヘルパー関数がある場合、すべてのヘルパー関数を追跡し、それらがどのように一緒に動作するかを理解するのは難しいかもしれません。\n",
        "\n",
        "- ヘルパー関数を使用しない場合でも、メインのタスクや関数は動作しますが、より難しくなったり非効率になったりする可能性があります。\n",
        "- たとえば、サンドイッチを作るときに「材料を集める」というヘルパー機能を使わなければ、サンドイッチを作ろうとしているときに立ち止まって材料を集めなければならず、作業が長引いたり、難しくなったりする可能性があります。\n",
        "\n",
        "- 要するに、ヘルパー関数とは、メイン関数がタスクを達成するのを助ける小さな関数です。\n",
        "- これによって、コードがより整理され、理解しやすくなり、効率的になります。\n",
        "- しかし、適切に使用しなければ、コードをより複雑にしてしまう可能性があります。\n"
      ],
      "metadata": {
        "id": "CIY6KAtobz6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- このコードでは、ARIMAと呼ばれる手法を使って、過去の値に基づいて将来の値を予測しようとしています。\n",
        "- このコードでは、_make_hierarchical というヘルパー関数を使って、階層型データと呼ばれる特定の種類のデータを作成しています。\n",
        "\n",
        "- このヘルパー関数は、ARIMA予測手法の入力として必要な、この特定のタイプのデータを作成するために使用されます。\n",
        "- n_columnsという1つの引数を取り、何列のデータを作成すべきかを指定するのに使用されます。\n",
        "- この場合、それは2に設定されている。\n",
        "\n",
        "- ヘルパー関数は階層的なデータを作成し、変数 'y' に格納する。次に、別の変数 'fh' が作成され、未来に予測する時間ステップ数を表す [1, 2, 3] に設定されます。\n",
        "\n",
        "- 次に、ARIMA法を初期化し、'fit'関数を使って、データ'y'と予測地平'fh'にモデルを当てはめます。\n",
        "- 最後の行の 'forecaster.forecasters_' は、適合したモデルから学習されたフォーキャストを取り出すために使用されます。\n",
        "\n",
        "- このヘルパー関数を使う利点は、ARIMA予測手法に必要な特定の種類のデータを簡単に作成できることと、テストや実験のために様々な種類のデータを迅速かつ簡単に作成できることです。\n",
        "\n",
        "- このヘルパー関数の欠点は、特定のタイプのデータしか作成できないため、別のタイプのデータが必要な他のケースでは役に立たない可能性があることです。\n",
        "\n",
        "- このヘルパー関数を使わない場合、データを手動で作成することになり、時間がかかる上にミスが発生しやすくなります。\n",
        "- また、さまざまな種類のデータを使ってのテストや実験も難しくなります。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yxt0heuNdQgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- ARIMAとは「AutoRegressive Integrated Moving Average」の略で、過去のデータから将来の値を予測するために用いられる予測手法である。\n",
        "- このコードでは、まず、ARIMA関数をsktimeライブラリからインポートする。\n",
        "\n",
        "- 次に_make_hierarchicalヘルパー関数を使って、2列のデータを持つ変数 \"y \"を作成する。\n",
        "- このデータはARIMA関数の入力として使用される。\n",
        "\n",
        "- 次に、予測したい将来のステップ数を表す変数 \"fh \"を作成します。\n",
        "- 今回は1,2,3ステップ先を予測するように設定されています。\n",
        "\n",
        "- 次に、「forecaster」変数を作成し、ARIMA関数と等しく設定します。\n",
        "- この変数に \"y \"データと \"fh \"ステップを入力として与え、\"fit \"メソッドを使用する。\n",
        "\n",
        "- 最後に、forecaster変数の \"forecasters_\"属性を使って、ARIMAモデルによる予測にアクセスします。\n",
        "\n",
        "- ARIMAを使用する利点は、過去のデータに基づいて将来の値を予測できること、\n",
        "- 一変量データで使用できること、\n",
        "- 実装が簡単であることです。\n",
        "- しかし、すべての種類のデータに適しているわけではなく、パラメータの選択に敏感な場合があります。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eQl9qC0AbIc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "日本語\n",
        "\n",
        "\n",
        "- ARIMAとは「AutoRegressive Integrated Moving Average」の略で、時系列予測に使われる手法の一つです。\n",
        "- 時系列予測とは、過去の気象データのパターンを見て、明日の天気を予測しようとするようなものです。\n",
        "\n",
        "- このコードでは、sktime.forecasting.arimaという特定のタイプのARIMAを使用しています。\n",
        "- これは、過去のデータに基づいて将来のイベントに関する予測を行うのに役立つPythonのパッケージです。\n",
        "\n",
        "- コードの最初の行は、sktimeパッケージからARIMAメソッドをインポートしています。\n",
        "- 2行目はsktime.utils._testing.hierarchicalから_make_hierarchicalヘルパー関数をインポートしています。\n",
        "\n",
        "- ヘルパー関数_make_hierarchicalはARIMAモデルが分析するための過去データのデータセットを作成するために使用されます。\n",
        "- このコードでは、データセットが2列のデータであることを指定しています。\n",
        "\n",
        "- 次のコードでは、「fh」という整数のリストを作成しています。\n",
        "- これは「forecasting horizon」の略で、モデルがどの程度先のことを予測すべきかを指定するために使われます。\n",
        "- この場合、リストには1、2、3という数字が含まれ、次の1、2、3の時間ステップを表すことができる。\n",
        "\n",
        "- 次の行では、\"forecaster \"というARIMAオブジェクトを作成して、データセットにフィットして予測を行うために使用します。\n",
        "\n",
        "- 次の行はforecasterオブジェクトのfitメソッドを呼び出し、入力としてデータセット \"y \"と予測水平線 \"fh \"を使っています。\n",
        "- この行は、過去のデータと指定された予測地平線を用いてモデルを学習させます。\n",
        "\n",
        "- 最後の行は、モデルによる予測を得るためにforecasterオブジェクトのforecasters_メソッドを呼び出しています。\n",
        "\n",
        "- ARIMAは一変量および多変量解析に使用でき、時系列予測に広く使用されている手法です。\n",
        "- しかし、ARIMAを使うことのデメリットは、次のようなことが起こりうることです。\n",
        "\n",
        "\n",
        "\n",
        "- また、時系列データが定常であると仮定していますが、必ずしもそうとは限りません。- さらに、複雑で非線形の時系列の予測には適さないかもしれません。\n",
        "\n",
        "- 要約すると、ARIMAは時系列分析において、過去のデータに基づいて将来の値を予測するために使用される手法です。\n",
        "- 差分、自己回帰、移動平均の各要素を組み合わせて時系列をモデル化するのです。\n",
        "- しかし、正しいパラメータを決定するのは困難であり、データが定常であることを前提としています。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QogyBvuXfYxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- ARIMA（AutoRegressive Integrated Moving Average）は、時系列データの分析および将来値の予測に使用される手法である。\n",
        "- 過去のデータのパターンを見て、将来の値を予測する。\n",
        "\n",
        "- 例えば、あるお店のオーナーが、過去に売れたリンゴの数から、来週は何個売れるかを予測したいとします。\n",
        "- 過去1ヶ月間、毎日何個のリンゴを売ったかというデータを収集し、ARIMAを使ってそのデータのパターンを分析する。\n",
        "- その分析を使って、店主は来週何個のリンゴが売れるか予測することができる。\n",
        "\n",
        "- また、ARIMAは、関連する複数の時系列データのパターンを見る多変量解析にも利用できる。\n",
        "- ただし、ARIMAは定常的な時系列データ、つまりデータにトレンドや季節変動がない場合にのみ適していることに注意する必要がある。\n",
        "- データが定常でない場合は、差分法を適用して定常化してからARIMAを使用することもある。\n",
        "\n",
        "- ARIMAを使用する利点としては、時系列予測に広く使用され、確立された方法であることが挙げられます。\n",
        "- 一方、デメリットとしては、使用する差分項や自己回帰項の適切な数を決定することが難しいことが挙げられます。\n",
        "\n",
        "- 時系列データの分析にARIMAや他の手法を用いないと、予測がうまくいかなかったり、データのパターンを理解できなかったりすることがあります。\n",
        "\n",
        "- 要約すると、ARIMAは過去のデータのパターンを見て、時系列データの将来の値を分析し、予測するために使用される方法である。\n",
        "- 一変量解析でも多変量解析でも使用でき、データが定常的である場合に使用するのが望ましい。\n",
        "- しかし、適切な項数を決めるのが難しい場合がある。\n",
        "- ARIMAを使用しないと、予測が甘くなり、データのパターンを理解できなくなる可能性があります。\n"
      ],
      "metadata": {
        "id": "bwj61yjzgMxM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob5fH2BXrc8H"
      },
      "source": [
        "削減、集約、調整など、階層的予測に関するさらなる詳細は、チュートリアルの「階層的予測」で紹介されています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHVKuRB7rc8H"
      },
      "source": [
        "\n",
        "### **1.3 基本的な評価ワークフロー**\n",
        " - グラウンドトゥルース観測に対する予測バッチの評価\n",
        "- フォーキャスターを展開する前にその統計的パフォーマンスを評価し、継続的に展開する場合は定期的にパフォーマンスを再評価することは良い習慣です。\n",
        "- 基本的なバッチ予測タスクの評価ワークフローは、セクション1.2のワークフローで解決されるように、バッチ予測と実際を比較することから構成されます。\n",
        "- これは（バッチ式）バックテストと呼ばれることもあります。\n",
        "\n",
        "- 基本的な評価ワークフローは以下の通りである。\n",
        "\n",
        "- 代表的に選ばれた歴史的な系列を時間的なトレーニングセットとテストセットに分割する。\n",
        "- テストセットはトレーニングセットの時間的な未来である必要があります。\n",
        "- トレーニングセットにフォアキャスターを適用することで、セクション 1.2 と同様にバッチ予測を取得し、テストセットの予測値を問い合わせる。\n",
        "- 実際のテストセットと予測値を比較するための定量的なパフォーマンス指標を指定する。\n",
        "- テストセットにおける定量的性能の計算\n",
        "- このパフォーマンスが、選択したベースライン・パフォーマンスよりも統計的に優れているかどうかをテストします。\n",
        "- 注：ステップ5（テスト）は、現在sktimeではサポートされていませんが、開発ロードマップにあります。\n",
        " - 当面は、適切な手法（例：Diebold-Mariano検定、定常信頼区間）のカスタム実装を使用することをお勧めします。\n",
        "\n",
        "- 注：この評価セットアップは、与えられたアルゴリズムが過去のデータでどの程度の性能を発揮したかを決定するものであることに注意してください。\n",
        " - 結果は、将来のパフォーマンスが過去のパフォーマンスを反映すると仮定できる限りにおいて、代表的なものであるに過ぎない。\n",
        " - これはある種の仮定（例：定常性）のもとで論じることができるが、一般的には誤りであるだろう。\n",
        " - したがって、アルゴリズムが複数回適用される場合には、予測性能のモニタリングが推奨されます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WcpZsvKrc8H"
      },
      "source": [
        "### **例題**\n",
        "- この例では、セクション 1.2 と同じ航空会社のデータを使用します。\n",
        "- しかし、次の3年間を予測する代わりに、航空会社のデータの最後の3年間（以下：y_test）を保持し、その前の年（以下：y_train）から最近の3年間（以下：y_pred）を予測するように求められたとき、予測者が3年前にどのように実行したであろうかを見ています。\n",
        "- \"どのように \"は、定量的なパフォーマンス指標（以下mean_absolute_percentage_error）によって測定されます。\n",
        "- そして、これはフォーキャスターが今後3年間にどの程度のパフォーマンスを発揮するかを示すものとして考えられています（1.2節で行われたこと）。\n",
        "- これは、統計的な仮定とデータの特性によって、伸びるかもしれないし、そうでないかもしれない（注意：しばしば伸びる - 過去のパフォーマンスは、一般的に将来のパフォーマンスを示すものではない）。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **概要**\n",
        "- この文章は、予測ツール（ARIMAなど）を使う前に、うまく機能しているかどうかをチェックする方法について話しています。\n",
        "- どの程度うまく機能しているかをチェックし、それを継続的に確認することは良いことです。\n",
        "- その方法は、過去のデータを2つに分けて、1つは予測ツールをトレーニングする部分、もう1つはそれをテストする部分とすることです。\n",
        "- そして、予測値と実際に起こったことを比較することで、そのツールがどれだけ未来を予測したかを確認することができます。\n",
        "- 注意しなければならないのは、過去にうまくいったからといって、将来もうまくいくとは限らないということです。\n",
        "\n",
        "- 詳細はこちら\n",
        "\n",
        "- 階層的予測には、縮小、集約、調整など、さまざまな予測方法があります。もっと詳しく説明したチュートリアルがあります。\n",
        "- 予測ツールを使う前にそのパフォーマンスを評価し、長く使うのであればチェックし続ける必要があります。\n",
        "- 予測ツールを評価する方法は、過去のデータをツールをトレーニングする部分とテストする部分に分けることです。\n",
        "- 学習した予測ツールを使って、テスト・データを使って未来を予測します。\n",
        "- そして、パフォーマンス・メトリックスを使って予測と実際のデータを比較します。\n",
        "- 注意すべきは、過去にうまくいったからと言って、将来もうまくいくとは限らないということです。\n",
        "- 現在、sktimeはステップ5をサポートしていません。これは、パフォーマンスが選択した基準値よりも優れているかどうかをテストすることです。\n",
        "- 航空会社のデータを使った例がある。過去3年分のデータをテストデータとして使用し、残りは予測ツールの学習に使用する。\n",
        "- その後、このツールを使って過去3年間の予測を行い、そのパフォーマンスを平均絶対誤差と呼ばれる指標で測定する。\n",
        "- これは、ツールが将来どの程度の成果を上げるかを示す指標として使われますが、注意すべきは、過去のパフォーマンスが必ずしも将来のパフォーマンスを予測するとは限らないということです。\n",
        "\n"
      ],
      "metadata": {
        "id": "ZJt1_OGSh24G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLoXHwUMrc8I"
      },
      "source": [
        "#### ステップ1 - 過去のデータセットを一時的な訓練バッチとテストバッチに分割する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uonPbMearc8I"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.model_selection import temporal_train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T2AYY26rc8J"
      },
      "outputs": [],
      "source": [
        "y = load_airline()\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
        "# we will try to forecast y_test from y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "043ujBm5rc8J"
      },
      "outputs": [],
      "source": [
        "# plotting for illustration\n",
        "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])\n",
        "print(y_train.shape[0], y_test.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch1dZn_Crc8K"
      },
      "source": [
        "### **ステップ 2 - y_train から y_test の予測を行う**\n",
        "これは1.2節のワークフローとほぼ同じで、y_trainを使ってy_testの指標を予測するものです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNGDltr9rc8K"
      },
      "outputs": [],
      "source": [
        "# we can simply take the indices from `y_test` where they already are stored\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
        "\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# y_pred will contain the predictions\n",
        "y_pred = forecaster.predict(fh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp5kNIbRrc8K"
      },
      "outputs": [],
      "source": [
        "# plotting for illustration\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spOG-Dhnrc8K"
      },
      "source": [
        "### **ステップ3、4 - 予測指標の指定、テストセットでの評価**\n",
        "- 次のステップは予測指標を指定することです。\n",
        "- これらは、予測系列と実系列を入力すると数値を返す関数です。\n",
        "- np.arrayではなく、indexで系列を受け付ける点がsklearnメトリクスと異なります。\n",
        "- 予測メトリクスは、2つの方法で呼び出すことができます。\n",
        "\n",
        "- 例えば、mean_absolute_percentage_error は python function (y_true : pd.Series, y_pred : pd.Series) -> float である。\n",
        "- コンポーザブルクラスインターフェースを使用する。\n",
        "- 例えば、MeanAbsolutePercentageErrorはpythonクラスであり、同じシグネチャで呼び出すことができる。\n",
        "- カジュアルなユーザーは、関数インターフェイスを使用することを選択することができます。\n",
        "- クラスインターフェイスは、パラメータの修正、カスタムメトリックの構成、メトリックパラメータのチューニングなどの高度なユースケースをサポートします（このチュートリアルでは扱いません）。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vT9T02qrc8L"
      },
      "source": [
        "このような数値を適切に解釈するためには、当該指標の特性を理解し（例：低い方が良い）、適切なベースラインや競合アルゴリズムと比較することが有用です（ステップ5参照）。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#sktime ライブラリから MeanAbsolutePercentageError クラスをインポート\n",
        "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
        "\n",
        "#対称パラメータを False に設定した MeanAbsolutePercentageError クラスのインスタンスを作成します。\n",
        "mape = MeanAbsolutePercentageError(symmetric=False)\n",
        "\n",
        "#このクラス・インタフェースは、MAPE (Mean Absolute Percentage Error) の変種を簡単に構築することができます。\n",
        "#例えば，非対称版\n",
        "#また、メトリックの特性、例えば、より高い値が良いのか、そうでないのかを調べることができる\n",
        "mape.get_tag(\"lower_is_better\")\n",
        "\n",
        "#評価は、真のテストセット値と予測値をmapeオブジェクトに渡すことで動作します。\n",
        "mape(y_test, y_pred)"
      ],
      "metadata": {
        "id": "tvuPz2nIkKPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "y = load_airline()\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
        "# y_train から y_test を予測しようとする\n",
        "# 説明のためのプロット\n",
        "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])\n",
        "print(y_train.shape[0], y_test.shape[0])\n",
        "\n",
        "# 既にインデックスが格納されている `y_test` から、単純にインデックスを取得することができます。\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
        "\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# y_pred には予測値が格納されます。\n",
        "y_pred = forecaster.predict(fh)\n",
        "# 説明のためのプロット\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
        "# オプション 1: リーン関数インターフェイスを使用する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # オプション1：リーン関数のインターフェイスを使用する。\n",
        "# note: 最初の引数は基底真理値、2番目の引数は予測値です。\n",
        "# 一般的にほとんどのメトリクスで順番は重要\n",
        "\n",
        "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
        "# オプション2: コンポーザブルクラスインターフェースの使用\n",
        "mape = MeanAbsolutePercentageError(symmetric=False) # オプション2: 構成可能なクラスインターフェースを使用する。\n",
        "# クラスインターフェースにより、MAPEの変種を簡単に構築することができます。\n",
        "# 例：非対称バージョン\n",
        "# メトリックの特性を検査することもできる\n",
        "# 例えば、より高い値が良いのか（答えはノー）？\n",
        "mape.get_tag(\"lower_is_better\")\n",
        "\n",
        "# 評価はオプション2と全く同じように動作しますが、インスタンス化されたオブジェクトを使用します。\n",
        "mape(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NXkLOJ_9l8em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "\n",
        "# 航空会社のデータをロードする\n",
        "y = load_airline()\n",
        "\n",
        "# データをトレーニングセットとテストセットに分割する\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=36) # データをトレーニングセットとテストセットに分割する。\n",
        "\n",
        "# 説明のため、トレーニングデータとテストデータをプロットする\n",
        "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])\n",
        "\n",
        "# トレーニングデータとテストデータの形状を表示する\n",
        "print(y_train.shape[0], y_test.shape[0])\n",
        "\n",
        "# 予測地平線を定義する\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False) # 予測地平線を定義する。\n",
        "\n",
        "# ナイーブフォーキャスターを定義する\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12) # ナイーブフォーキャスターを定義する。\n",
        "\n",
        "# 学習データに対してナイーブフォーキャスターをフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# テストデータに対して予測を行う\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 説明のために予測値をプロットする\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
        "# オプション 1: リーン関数インターフェイスを使用する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # オプション1：リーン関数のインターフェイスを使用する。\n",
        "# note: 最初の引数は基底真理値、2番目の引数は予測値です。\n",
        "# 一般的にほとんどのメトリクスで順番は重要\n",
        "\n",
        "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
        "# オプション2: コンポーザブルクラスインターフェースの使用\n",
        "mape = MeanAbsolutePercentageError(symmetric=False) # オプション2: 構成可能なクラスインターフェースを使用する。\n",
        "# クラスインターフェースにより、MAPEの変種を簡単に構築することができます。\n",
        "# 例：非対称バージョン\n",
        "# メトリックの特性を検査することもできる\n",
        "# 例えば、より高い値が良いのか（答えはノー）？\n",
        "mape.get_tag(\"lower_is_better\")\n",
        "\n",
        "# 評価はオプション2と全く同じように動作しますが、インスタンス化されたオブジェクトを使用します。\n",
        "mape(y_test, y_pred)"
      ],
      "metadata": {
        "id": "92z6wdRknadX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "、次のような動作が行われます。\n",
        "\n",
        "- sktime.performance_metrics.forecasting ライブラリから mean_absolute_percentage_error 関数をインポートして、平均絶対誤差 (MAPE) が計算されます。\n",
        "- そして、この関数は、対称引数をFalseに設定して、y_testとy_predの変数に適用されます。\n",
        "- MAPEは予測の精度を評価するためによく使われる指標で、予測値と実際の値との差をパーセンテージで表したものです。\n",
        "- Falseに設定された対称引数は、平均絶対誤差の計算において、負の誤差を正の誤差と区別して扱うべきではないことを示すために使用されます。\n",
        "- この例では、MAPE は y_train データで学習され、y_test データで予測を行うために使用されたフォーキャスターの性能を評価するために使用されています。\n",
        "\n"
      ],
      "metadata": {
        "id": "m_rF4Ei_ogbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sktime.forecasting.model_selection ライブラリは、temporal train test split に使用されます。\n",
        "- temporal_train_test_split(y, test_size=36) は、test_size を 36 として、データセットを訓練セットとテストセットに分割するために使用されます。\n",
        "- ForecastingHorizon(y_test.index, is_relative=False) は、バッチ予測の取得に使用されます。\n",
        "- NaiveForecaster(strategy=\"last\", sp=12) がフォアキャスターとして使われ、学習セットに適合されます。\n",
        "- mape = MeanAbsolutePercentageError(symmetric=False) は、非対称バージョンでMean Absolute Percentage Errorを計算するために使用されます。\n",
        "- mape.get_tag(\"lower_is_better\") は、高い値が良いのかどうかをチェックするために使用されます。\n",
        "- mape(y_test, y_pred) はフォアキャスターの性能を評価するために使用されます。\n",
        "\n",
        "- メリット\n",
        "\n",
        "    - 上記のコードにより、フォアキャスターを配備する前に、その性能を評価することができます。\n",
        "    - 継続的な展開の場合、定期的に性能を再評価することができます。\n",
        "    - 平均絶対誤差(MAPE)の変数を簡単に構築することができます。\n",
        "    - 検査が可能\n",
        "\n"
      ],
      "metadata": {
        "id": "zmrqdChumKu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 次のPythonコードは、Mean Absolute Percentage Error（MAPE）指標を使用してフォアキャストのパフォーマンスを評価するためにsktimeライブラリを使用する方法を示しています。\n",
        "\n",
        "- コードの特徴\n",
        "\n",
        "- このコードは、まず、sktimeライブラリからMeanAbsolutePercentageErrorクラスをインポートします。\n",
        "- 次に、このクラスを使用して、対称パラメータを False に設定した MAPE メトリクスのインスタンスを作成します。\n",
        "- temporal_train_test_split 関数を使用して、データをトレーニングセットとテストセットに分割しています。\n",
        "- NaiveForecasterクラスは、戦略「last」、季節期間12でナイーブフォーキャスターを作成するために使用されます。\n",
        "- そして、このフォアキャスターをトレーニングデータにフィットさせ、テストセットの予測値を生成するために使用します。\n",
        "- そして、mean_absolute_percentage_error関数が、テストセットと予測値の間のMAPEを計算するために使用されます。\n",
        "- 最後に、MeanAbsolutePercentageErrorクラスのインスタンスが、予測値とテストセットを評価するために使用されます。\n",
        "#### - コードの利点\n",
        "\n",
        "- sktimeライブラリは、時系列データの処理と予測モデルの評価のために、使いやすく一貫したインターフェイスを提供します。\n",
        "- temporal_train_test_split関数は、時系列データを簡単にトレーニングセットとテストセットに分割することができます。\n",
        "- NaiveForecasterクラスは、ベンチマークとして使用するためのシンプルで強力なフォーキャスターを提供します。\n",
        "- mean_absolute_percentage_error関数とMeanAbsolutePercentageErrorクラスは、MAPEメトリックを計算し、フォアキャストのパフォーマンスを評価する簡単な方法を提供します。\n",
        "- MAPEクラスのsymmetricパラメータは、メトリックが対称であるかどうかを制御することができます。\n",
        "#### コードの作用機序\n",
        "\n",
        "- このコードでは、まずload_airline()関数を使用して航空会社データセットをロードします。\n",
        " - これは、提供されたコードスニペットでは指定されていません。\n",
        "- temporal_train_test_split 関数でデータをトレーニングセットとテストセットに分割し、テストセットは 36 時間ステップの大きさにしています。\n",
        "- 次に、NaiveForecaster クラスは\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9-D3ha0xm5mY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "次のPythonコードは、予測モデルの性能を評価するためにMean Absolute Percentage Error (MAPE)を使用します。このコードは、sktime.performance_metrics.forecastingライブラリからMeanAbsolutePercentageError クラスをインポートしています。\n",
        "\n",
        "このコードでは、対称パラメータをfalseに設定してクラスのインスタンスを作成しています。これは、実際の値がゼロであれば、この関数はエラーを出さず、誤差を調整しないことを意味します。このメソッドは、低い値が良いかどうかを示すブール値を返します。\n",
        "\n",
        "そして、テストデータと予測データを引数としてmape関数を呼び出します。これは予測の正確さの指標であるMAPE値を提供します。\n",
        "\n",
        "MAPE（Mean Absolute Percentage Error）を使用する利点と特徴は以下の通りです。\n",
        "\n",
        "予測精度を評価するためによく使われる方法です。\n",
        "パーセンテージで表現されるので解釈しやすい\n",
        "ゼロやマイナスの値を扱う能力がある。\n",
        "平均絶対誤差(MAPE)を使用するデメリットは以下の通りです。\n",
        "\n",
        "外れ値に対して敏感である\n",
        "実績がゼロの場合、不定になる可能性がある。\n",
        "MAPEは、他の評価指標と同様に、独自の前提条件があり、すべての状況で使用することが適切とは限らないことに留意する必要があります。データにゼロやマイナスの値が多い場合は、平均絶対誤差（MAE）など別の評価指標を使用する方が適切でしょう。\n"
      ],
      "metadata": {
        "id": "yktG4NdhjBsA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uoV7AxSylrQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEAtpcIrc8N"
      },
      "source": [
        "- 注：mean_absolute_scaled_errorのようないくつかのメトリクスは、評価のためにトレーニングセットも必要とします。\n",
        " - この場合、トレーニング・セットは y_train 引数として渡す必要があります。\n",
        " - 個々のメトリクスについては、API リファレンスを参照してください。\n",
        "\n",
        "- 注：ワークフローは、非均質データを利用するフォーキャストでも同じです \n",
        " - X はメトリックに渡されません。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efa5h5DRrc8N"
      },
      "source": [
        "### **ステップ5 - ベンチマークに対するパフォーマンスのテスト**\n",
        "- 一般的に、予測性能はベンチマーク性能に対して定量的にテストされるべきです。\n",
        "\n",
        "- 現在（sktime v0.12.x）、これはロードマップの開発項目である。\n",
        "- ご協力をお願いします。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 要約：\n",
        "- この文章は、予測アルゴリズムの性能を、その予測と実際のデータを比較することによって評価するプロセスについて説明しています。\n",
        "\n",
        "- 基本的な評価のワークフローは以下のステップを含んでいます。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.    過去のデータ・セットをトレーニング・セットとテスト・セットに分割する。\n",
        " - テスト・セットはトレーニング・セットの未来であるべきです。\n",
        "2.    トレーニングセットにフォーキャスターを適用してバッチ予測を取得し、テストセットの予測値を問い合わせる。\n",
        "3.   実際のテストセットと予測値を比較するための定量的なパフォーマンス指標を指定します。\n",
        "4.   テストセットに対する定量的パフォーマンスを計算します。\n",
        "5.   このパフォーマンスが、選択したベースライン・パフォーマンスよりも統計的に優れているかどうかをテストします。\n",
        " - この評価プロセスは、アルゴリズムが過去のデータに対してどの程度のパフォーマンスを示したかを示すだけであり、必ずしも将来のパフォーマンスを代表するものではないことに注意が必要である。\n",
        " - また、アルゴリズムが複数回適用された場合の予測パフォーマンスをモニターすることも重要である。\n",
        "\n",
        "- 航空会社のデータを使った例として、過去3年間のデータを持ち出し、その前の年のデータを使って直近の3年間を予測するよう求められた場合に、予測者が3年前にどのようなパフォーマンスを示したかを確認することが挙げられます。\n",
        "- このパフォーマンスは定量的なパフォーマンス指標（mean_absolute_percentage_error）で測定され、フォアキャスターが今後3年間にどの程度のパフォーマンスを発揮するかを示す指標として検討されます。\n",
        "- 統計的な仮定やデータの特性によって、伸びしろがある場合とない場合があることを念頭に置いておく必要があります。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TZb9jDO4qFkh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOEyO4ycrc8O"
      },
      "source": [
        "### **1.3.1 基本的な一括予測評価ワークフローの概要 **\n",
        "- 関数メトリック・インターフェース\n",
        "- 便宜上、基本的なバッチ予測評価ワークフローを1つのセルにまとめて紹介します。\n",
        "このセルは無駄のないファンクション・メトリック・インターフェースを使用しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYfcyfZks0jh"
      },
      "outputs": [],
      "source": [
        "# このコードでは、時系列予測のためにsktimeライブラリを使用しています。\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "from sktime.datasets import load_airline # 航空会社データセットのロードに使用。\n",
        "from sktime.forecasting.base import ForecastingHorizon # 予測の水平軸を指定するため。\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split # 過去のデータをトレーニングセットとテストセットに分割する。\n",
        "from sktime.forecasting.naive import NaiveForecaster # ナイーブフォーキャスターを適用する。\n",
        "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error # 予測性能を評価するため。\n",
        "\n",
        "# ステップ1: ヒストリカルデータの分割\n",
        "# 航空会社のデータセットをロードする\n",
        "y = load_airline()\n",
        "\n",
        "# データセットを訓練セットとテストセットに分割する\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
        "\n",
        "# ステップ2：基本的な予測ワークフローの実行\n",
        "# 予測地平線を指定する\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False) # 予測地平線の指定\n",
        "\n",
        "# 最後のオブザベーションを予測戦略として、季節性を12としたナイーブフォーキャスターをフィッティングする。\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# テストセットに対する予測値の生成\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# step 3: 評価指標の指定と\n",
        "# step 4: 予測性能の計算\n",
        "# 平均絶対パーセンテージ誤差を用いて予測性能を評価する。\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) 平均絶対パーセンテージエラー(mean_absolute_percentage_error)。\n",
        "\n",
        "# step 5: ベースラインに対する予測性能のテスト\n",
        "# 開発中\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードでは、時系列予測のためにsktimeライブラリを使用しています。\n",
        "\n",
        "- 必要なライブラリのインポート\n",
        "- from sktime.datasets import load_airline # 航空会社データセットのロードに使用。\n",
        "- from sktime.forecasting.base import ForecastingHorizon # 予測の水平軸を指定するため。\n",
        "- from sktime.forecasting.model_selection import temporal_train_test_split # 過去のデータをトレーニングセットとテストセットに分割する。\n",
        "- from sktime.forecasting.naive import NaiveForecaster # ナイーブフォーキャスターを適用する。\n",
        "- from sktime.performance_metrics.forecasting import  mean_absolute_percentage_error # 予測性能を評価するため。\n",
        "\n",
        "-  ステップ1: ヒストリカルデータの分割\n",
        "-  航空会社のデータセットをロードする\n",
        "- y = load_airline()\n",
        "\n",
        " - データセットを訓練セットとテストセットに分割する\n",
        "- y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
        "\n",
        "-  ステップ2：基本的な予測ワークフローの実行\n",
        "-  予測地平線を指定する\n",
        "- fh = ForecastingHorizon(y_test.index, is_relative=False) # 予測地平線の指定\n",
        "\n",
        "- 最後のオブザベーションを予測戦略として、季節性を12としたナイーブフォーキャスターをフィッティングする。\n",
        "- forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
        "- forecaster.fit(y_train)\n",
        "\n",
        "- テストセットに対する予測値の生成\n",
        "- y_pred = forecaster.predict(fh)\n",
        "\n",
        "-  step 3: 評価指標の指定と\n",
        "-  step 4: 予測性能の計算\n",
        "-  平均絶対パーセンテージ誤差を用いて予測性能を評価する。\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) 平均絶対パーセンテージエラー(mean_absolute_percentage_error)。\n",
        "\n",
        "-  step 5: ベースラインに対する予測性能のテスト\n",
        "-  開発中\n",
        "\n"
      ],
      "metadata": {
        "id": "arsUH0XDrc8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このスクリプトはsktimeライブラリを使用して航空会社のデータセットをロードし、データを訓練セットとテストセットに分割します。\n",
        "- そして、予測地平線を指定し、予測戦略として最後の観測を使い、季節性を12としたナイーブ・フォーキャスターをあてはめ、テストセットの予測を生成し、平均絶対誤差率を使って予測性能を評価します。\n",
        "- 最後のステップであるベースラインに対する予測性能のテストは、現在開発中である。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fYgxYdI1swt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "以下のPythonコードは、統計的フォーキャスターの性能を評価するために使用されます。コードは5つのステップに分かれています。\n",
        "\n",
        "- sktime.forecasting.model_selectionモジュールのtemporal_train_test_split関数を用いて、履歴データセットを時間的学習セットとテストセットに分割する。\n",
        " - この場合、test_size パラメータは36に設定され、これは系列の最後の36個のオブザベーションがテストセットとして使用されることを意味します。\n",
        "\n",
        "- sktime.forecasting.naiveモジュールのNaiveForecasterクラスを使って基本的な予測ワークフローを実行します。\n",
        " - フォアキャスターはトレーニングセットに適合され、テストセットの予測は sktime.forecasting.base モジュールの ForecastingHorizon クラスを使用して行われます。\n",
        "\n",
        "- sktime.performance_metrics.forecasting モジュールの mean_absolute_percentage_error 関数を使用して評価メトリックを指定する。\n",
        " - この関数は、テストセットと予測値の間の平均絶対誤差（MAPE）を計算する。\n",
        " - symmetricパラメータはFalseに設定されており、これはMAPEが対称にならないことを意味します。\n",
        "\n",
        "- テストセットと予測値を入力として mean_absolute_percentage_error 関数を呼び出して、予測性能を計算する。\n",
        "\n",
        "- ベースラインに対して予測パフォーマンスをテストする。\n",
        " - このステップは現在開発中であり、sktimeライブラリではサポートされていません。 - このステップでは、適切なメソッドのカスタム実装を使用することが推奨されます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vDaIL9iTrjtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- 次のPythonコードは、平均絶対誤差（MAPE）メトリックを使用して予測モデルのパフォーマンスを評価するために使用されます。\n",
        " - このコードは、以下のステップに分かれています。\n",
        "\n",
        "- 履歴データを分割する。最初のステップは、sktime.datasetsライブラリのload_airline()関数を用いて過去のデータセットをロードすることである。\n",
        "- 次に、sktime.forecasting.model_selection ライブラリーの temporal_train_test_split() 関数を使用して、データセットをトレーニングセット (y_train) とテストセット (y_test) に分割する。test_size パラメータは 36 に設定されており、これはテストセットがデータセットの最後の 36 データポイントを含むことを意味します。\n",
        "\n",
        "- 基本的な予測ワークフローを実行する第二のステップは、sktime.forecasting.naiveライブラリのNaiveForecasterクラスを使って、簡単な予測モデルを作成することです。\n",
        "- このモデルはトレーニングセット（y_train）で学習され、テストセット（y_test）の予測を行うために使用されます。sktime.forecasting.base ライブラリの ForecastingHorizon クラスは、予測を行うべきテストセットのインデックスを指定するために使用されます。\n",
        "\n",
        "- 評価指標の指定と予測性能の計算。\n",
        " - 3番目のステップは、予測値と実際の値を比較するために使用する評価指標を指定することである。\n",
        " - MAPEの計算には、sktime.performance_metrics.forecastingライブラリのmean_absolute_percentage_error()関数が使用される。\n",
        " - symmetricパラメータはFalseに設定されており、これはMAPEが非対称式を使って計算されることを意味します。\n",
        "\n"
      ],
      "metadata": {
        "id": "L-GSkFDKr8MJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEllaP-Nrc8P"
      },
      "source": [
        "\n",
        "### **1.3.2 基本的な一括予測評価ワークフローの概要 **\n",
        "- メトリッククラスインターフェイス\n",
        "便宜上、基本的な一括予測評価ワークフローを1つのセルにまとめて表示します。このセルは、メトリックの高度なクラス指定インターフェイスを使用しています。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R7EQSWkrc8Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# このコードは、時系列予測のためにsktimeライブラリを使用しています。\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "from sktime.datasets import load_airline # 航空会社データセットのロードに使用。\n",
        "from sktime.forecasting.base import ForecastingHorizon # 予測の水平軸を指定する。\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split # 過去のデータをトレーニングセットとテストセットに分割する。\n",
        "from sktime.forecasting.naive import NaiveForecaster # ナイーブフォーキャスターを適用する。\n",
        "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError # 予測性能を評価するため。\n",
        "\n",
        "# step 1: ヒストリカルデータを分割する\n",
        "# 航空会社のデータセットをロードする\n",
        "y = load_airline()\n",
        "\n",
        "# データセットを訓練セットとテストセットに分割する\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
        "\n",
        "# ステップ2：基本的な予測ワークフローを実行する\n",
        "# 予測地平線を指定する\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False) # 予測地平線の指定\n",
        "\n",
        "# 最後のオブザベーションを予測戦略として、季節性を12としたナイーブフォーキャスターをフィッティングする。\n",
        "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# テストセットに対する予測値の生成\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# ステップ3：評価指標の指定\n",
        "#対称性=Falseで評価指標を初期化する。\n",
        "mape = MeanAbsolutePercentageError(symmetric=False)\n",
        "\n",
        "# step 4: 予測性能の計算\n",
        "# 平均絶対パーセンテージエラーを用いて予測パフォーマンスを評価する\n",
        "mape(y_test, y_pred)\n",
        "\n",
        "# step 5: ベースラインに対する予測性能のテスト\n",
        "# 開発中\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 最初の文では、このコードは特定のメソッド（この場合は関数メトリックインタフェース）を使って予測がどの程度うまく行われたかをチェックする方法を示している、と書かれています。\n",
        "- 2つ目の文では、このコードは予測がどの程度うまく行われたかをチェックする別の方法を示しているが、今回はメトリッククラスインターフェイスと呼ばれる別の方法を使用している、と書かれています。\n",
        "- 3つ目の文は、毎日や毎週など定期的に予測を行い、新しい情報が入手可能になったときに予測を更新したいと思うことがあると述べています。\n",
        " - このコードでは、updateメソッドとupdate_predictメソッドを使ってこれを行う方法を示しています。\n",
        "- 4文目は、updateメソッドを使って新しい情報を取り込み、新しい予測を行うことができることを説明しています。\n",
        "- 5つ目の文章では、updateメソッドを使用した後、「今」の状態（cutoff）をupdateで使用した最新の情報に設定することを説明しています。\n",
        "- 第6文は、このコードを用いて、1年先の予測を、1957年12月から毎月行う例を示している。\n",
        "- 第7文では、この例で、更新方式で最初の数ヶ月の予測をする方法を示すとある。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Eq_gWYd3u8QR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oZ56k45rc8Q"
      },
      "source": [
        "### 1.4 **高度な展開ワークフロー：ローリングアップデートと予測**\n",
        "- 一般的な使用例では、forecasterは定期的に新しいデータで更新し、ローリングベースで予測を行うことが必要です。\n",
        "- これは、同じ種類の予測を毎日または毎週などの定期的な時点で行う必要がある場合に特に便利です。\n",
        "- sktimeフォーキャスターは、更新とupdate_predictメソッドを介してこのタイプの展開ワークフローをサポートしています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9LMwKqlrc8R"
      },
      "source": [
        "\n",
        "### **1.4.1 update メソッドによるフォーキャスターの更新**\n",
        "- updateメソッドは、フォーキャスターがすでに適合しているときに呼び出され、新しいデータを取り込み、更新された予測を行うことができます。\n",
        "\n",
        "- 更新後、フォーキャスターの内部「現在」状態（カットオフ）は、更新バッチで見た最新のタイムスタンプ（以前に見たデータより遅いと仮定）に設定されます。\n",
        "\n",
        "- 一般的なパターンは以下の通りです。\n",
        "\n",
        "    - 予測ストラテジーを指定する\n",
        "    - 相対的な予測ホライズンを指定する\n",
        "    - fitを使って、フォーキャスターを最初のデータ・バッチに適合させる。\n",
        "    - predictを使って相対的な予測地平線の予測を行います。\n",
        "    - 新しいデータを取得する; updateを使って新しいデータを取り込む\n",
        "    - 更新されたデータに対してpredictを使って予測を行う\n",
        "    - 5と6を必要なだけ繰り返す\n",
        "- 例：\n",
        " - 航空会社の例で、1年先の予測を行いたいが、1957年12月から毎月行いたいとします。最初の数ヶ月は次のように予測します。\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# このコードは、時系列予測のためにsktimeライブラリを使用しています。\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "from sktime.datasets import load_airline # 航空会社データセットのロードに使用。\n",
        "from sktime.forecasting.ets import AutoETS # 自動ETSモデルフィッティング用\n",
        "from sktime.utils.plotting import plot_series # 予測を可視化する。\n",
        "import numpy as np\n",
        "# 航空会社のデータセットをロード\n",
        "y = load_airline()\n",
        "\n",
        "# これは 1957 年 12 月に知られているデータである\n",
        "y_1957Dec = y[:-36] とする。\n",
        "\n",
        "# ステップ1: 予測手法の指定\n",
        "# 利用可能な全てのCPUコアを使用して、季節性を12とした自動ETSモデルを適合させる。\n",
        "forecaster = AutoETS(auto=True, sp=12, n_jobs=-1)\n",
        "\n",
        "# step 2: 予測地平線の指定: 1年先、全月分\n",
        "fh = np.arange(1, 13)\n",
        "\n",
        "# step 3: このモデルを初めて使うので、フィットさせる\n",
        "forecaster.fit(y_1957Dec)\n",
        "\n",
        "# step 4: 1958年1月～1958年12月の最初の予測バッチを取得する。\n",
        "y_pred_1957Dec = forecaster.predict(fh)\n",
        "# 予測値と過去データのプロット\n",
        "plot_series(y_1957Dec, y_pred_1957Dec, labels=[\"y_1957Dec\", \"y_pred_1957Dec\"])\n",
        "\n",
        "# 1958 年 1 月\n",
        "\n",
        "# 新しいデータが観測される。\n",
        "y_1958Jan = y[[-36]].\n",
        "\n",
        "# step 5: 新しいデータでフォアキャスターを更新する\n",
        "forecaster.update(y_1958Jan)\n",
        "\n",
        "# step 6: 更新されたデータで予測を行う\n",
        "y_pred_1958Jan = forecaster.predict(fh)\n",
        "# fh は相対的なものなので、自動的に 1 ヶ月後の予測になることに注意。\n",
        "# すなわち、1958 年 2 月から 1959 年 1 月まで\n",
        "y_pred_1958Jan\n",
        "\n",
        "# 予測値と過去のデータをプロットする\n",
        "plot_series(\n",
        "y[:-35],\n",
        "y_pred_1957Dec,\n",
        "y_pred_1958Jan,\n",
        "labels=[\"y_1957Dec\", \"y_pred_1957Dec\", \"y_pred_1958Jan\"],\n",
        ")\n",
        "\n",
        "# 1958年2月\n",
        "\n",
        "# 新しいデータが観測される\n",
        "y_1958Feb = y[[-35]] とする。\n",
        "\n",
        "# step 5: 新しいデータでフォアキャスターを更新する\n",
        "forecaster.update(y_1958Feb)\n",
        "\n",
        "# step 6: 更新されたデータで予測を行う\n",
        "y_pred_1958Feb = forecaster.predict(fh)\n",
        "# 予測と過去のデータをプロットする\n",
        "plot_series(\n",
        "y[:-35],\n",
        "y_pred_1957Dec,\n",
        "y_pred_1958Jan,\n",
        "y_pred_1958Feb,\n",
        "labels=[\"y_1957Dec\", \"y_pred_1957Dec\", \"y_pred_1958Jan\", \"y_pred_1958Feb\"],\n",
        ")\n",
        "\n",
        "# 1958年3月\n",
        "\n",
        "# 新しいデータが観測される。\n",
        "y_1958Mar = y[[-34]].\n",
        "\n",
        "# ステップ 5&6: 1 ステップで更新/予測する\n",
        "forecaster.update_predict_single(y_1958Mar, fh=fh)\n",
        "\n"
      ],
      "metadata": {
        "id": "waFbXVMBw8QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、時系列予測のためにsktimeライブラリを使用しています。\n",
        "\n",
        "- 必要なライブラリのインポート\n",
        "- from sktime.datasets import load_airline # 航空会社データセットのロードに使用。\n",
        "- from sktime.forecasting.ets import AutoETS # 自動ETSモデルフィッティング用\n",
        "- from sktime.utils.plotting import plot_series # 予測を可視化する。\n",
        "- import numpy as np\n",
        "- 航空会社のデータセットをロード\n",
        "-y = load_airline()\n",
        "\n",
        "- これは 1957 年 12 月に知られているデータである\n",
        "- y_1957Dec = y[:-36] とする。\n",
        "- \n",
        "-  ステップ1: 予測手法の指定\n",
        "-  利用可能な全てのCPUコアを使用して、季節性を12とした自動ETSモデルを適合させる。\n",
        "- forecaster = AutoETS(auto=True, sp=12, n_jobs=-1)\n",
        "- \n",
        "-  step 2: 予測地平線の指定: 1年先、全月分\n",
        "- fh = np.arange(1, 13)\n",
        "- \n",
        "-  step 3: このモデルを初めて使うので、フィットさせる\n",
        "- forecaster.fit(y_1957Dec)\n",
        "- \n",
        "-  step 4: 1958年1月～1958年12月の最初の予測バッチを取得する。\n",
        "- y_pred_1957Dec = forecaster.predict(fh)\n",
        "- 予測値と過去データのプロット\n",
        "- plot_series(y_1957Dec, y_pred_1957Dec, labels=[\"y_1957Dec\", \"y_pred_1957Dec\"])\n",
        "- \n",
        "-  1958 年 1 月\n",
        "- \n",
        "-  新しいデータが観測される。\n",
        "- y_1958Jan = y[[-36]].\n",
        "- \n",
        "-  step 5: 新しいデータでフォアキャスターを更新する\n",
        "- forecaster.update(y_1958Jan)\n",
        "- \n",
        "-  step 6: 更新されたデータで予測を行う\n",
        "- y_pred_1958Jan = forecaster.predict(fh)\n",
        "-  fh は相対的なものなので、自動的に 1 ヶ月後の予測になることに注意。\n",
        "-  すなわち、1958 年 2 月から 1959 年 1 月まで\n",
        "- y_pred_1958Jan\n",
        "- \n",
        "-  予測値と過去のデータをプロットする\n",
        "- plot_series(\n",
        "- y[:-35],\n",
        "- y_pred_1957Dec,\n",
        "- y_pred_1958Jan,\n",
        "- labels=[\"y_1957Dec\", \"y_pred_1957Dec\", \"y_pred_1958Jan\"],\n",
        "- )\n",
        "- \n",
        "-  1958年2月\n",
        "- \n",
        "-  新しいデータが観測される\n",
        "- y_1958Feb = y[[-35]] とする。\n",
        "- \n",
        "-  step 5: 新しいデータでフォアキャスターを更新する\n",
        "- forecaster.update(y_1958Feb)\n",
        "- \n",
        "-  step 6: 更新されたデータで予測を行う\n",
        "- y_pred_1958Feb = forecaster.predict(fh)\n",
        "-  予測と過去のデータをプロットする\n",
        "- plot_series(\n",
        "- y[:-35],\n",
        "- y_pred_1957Dec,\n",
        "- y_pred_1958Jan,\n",
        "- y_pred_1958Feb,\n",
        "- labels=[\"y_1957Dec\", \"y_pred_1957Dec\", \"y_pred_1958Jan\", \"y_pred_1958Feb\"],\n",
        "- )\n",
        "- \n",
        "-  1958年3月\n",
        "- \n",
        "-  新しいデータが観測される。\n",
        "- y_1958Mar = y[[-34]].\n",
        "- \n",
        "-  ステップ 5&6: 1 ステップで更新/予測する\n",
        "- forecaster.update_predict_single(y_1958Mar, fh=fh)\n",
        "- \n",
        "- \n",
        "- "
      ],
      "metadata": {
        "id": "iiURN3kqxaTC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH2lVzKKrc8V"
      },
      "source": [
        "### **1.4.2 モデルを更新せずに \"現在 \"の状態を移動させる**\n",
        "- ローリングデプロイメントモードでは、例えば、新しいデータは観測されなかったが時間が経過した場合、あるいは計算に時間がかかりすぎて予測を問い合わせなければならない場合など、推定量の「現在」の状態（カットオフ）を後に移すことが有用な場合があります。\n",
        "\n",
        "- update インターフェースは、update およびその他の update 関数の update_params 引数を介して、このオプションを提供する。\n",
        "\n",
        "- update_params を False に設定すると、モデルの更新計算は行われず、データのみが保存され、内部の \"now\" 状態（カットオフ）が最新の日付に設定される。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 最初の文は、定期的に予測を行う場合、予測を行う時点である「今」の状態を後日移動させると便利な場合がある、というものです。\n",
        "- 2文目は、updateメソッドにupdate_paramsというオプションがあり、これを使うことでモデルを更新せずに「今」の状態を後に移動させることができる、と説明しています。\n",
        "- 3つ目の文章では、update_paramsがFalseに設定されている場合、コードはモデルを更新せず、データを保存して「now」状態を最新の日付に設定するだけであることが説明されています。"
      ],
      "metadata": {
        "id": "_eIyJTS2445t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD25Qlczrc8W"
      },
      "outputs": [],
      "source": [
        "\n",
        "# このスクリプトは、sktimeライブラリのload_airline関数、\n",
        "#sktime.forecasting.etsモジュールのAutoETSクラス、\n",
        "#sktime.utils.plottingモジュールのplot_seriesをインポートしています。\n",
        "from sktime.datasets import load_airline\n",
        "from sktime.forecasting.ets import AutoETS\n",
        "from sktime.utils.plotting import plot_series\n",
        "\n",
        "# 便宜上、完全なデータセットを用意する\n",
        "# シナリオでは、ある時点でこの一部だけを「知る」ことになることに注意\n",
        "y = load_airline()\n",
        "# 1957 年 12 月\n",
        "\n",
        "# これは 1957 年 12 月のデータです\n",
        "y_1957Dec = y[:-36] とする。\n",
        "\n",
        "# ステップ1: 予測手法の指定\n",
        "# auto=True、季節期間 sp=12、n_jobs=-1 で AutoETS クラスのオブジェクトを作成します。\n",
        "forecaster = AutoETS(auto=True, sp=12, n_jobs=-1)\n",
        "\n",
        "# ステップ2：予測地平線の指定：1年先、全月分\n",
        "# 予測の地平線を1年先、全月に指定する\n",
        "fh = np.arange(1, 13)\n",
        "\n",
        "# step 3: このモデルを初めて使うので、フィッティングを行う\n",
        "# 既知のデータでモデルをフィットさせる\n",
        "forecaster.fit(y_1957Dec)\n",
        "\n",
        "# step 4: 1958年1月～1958年12月の最初の予測バッチを取得する\n",
        "# 1958 年 1 月から 1958 年 12 月までの今後 12 ヶ月間の予測を作成する\n",
        "y_pred_1957Dec = forecaster.predict(fh)\n",
        "# 予測値と過去のデータをプロットする\n",
        "# 予測値と過去のデータをプロットする\n",
        "plot_series(y_1957Dec, y_pred_1957Dec, labels=[\"y_1957Dec\", \"y_pred_1957Dec\"])\n",
        "\n",
        "# 1958 年 1 月\n",
        "\n",
        "# 新しいデータが観測される。\n",
        "y_1958Jan = y[[-36]]\n",
        "\n",
        "# step 5: 新しいデータでフォーキャスターを更新する\n",
        "# 新しいデータでモデルを更新する\n",
        "forecaster.update(y_1958Jan)\n",
        "\n",
        "# step 6: 更新されたデータで予測を行う\n",
        "y_pred_1958Jan = forecaster.predict(fh)\n",
        "# fh は相対的なものなので、自動的に 1 ヶ月後の予測になることに注意。\n",
        "# すなわち、1958 年 2 月から 1959 年 1 月まで\n",
        "y_pred_1958Jan\n",
        "\n",
        "# 予測値と過去のデータをプロットする\n",
        "# 予測値と過去のデータをプロットする\n",
        "plot_series(\n",
        "y[:-35],\n",
        "y_pred_1957Dec,\n",
        "y_pred_1958Jan,\n",
        "labels=[\"y_1957Dec\", \"y_pred_1957Dec\", \"y_pred_1958Jan\"],\n",
        ")\n",
        "\n",
        "# 1958年2月\n",
        "\n",
        "# 新しいデータが観測される。\n",
        "y_1958Feb = y[[-35]] \n",
        "\n",
        "# step 5: 新しいデータでフォアキャスターを更新する\n",
        "# 新しいデータでモデルを更新する\n",
        "forecaster.update(y_1958Feb)\n",
        "\n",
        "# step 6: 更新されたデータで予測を行う\n",
        "y_pred_1958Feb = forecaster.predict(fh)\n",
        "# 予測と過去のデータをプロットする\n",
        "plot_series(\n",
        "y[:-35],\n",
        "y_pred_1957Dec,\n",
        "y_pred_1958Jan,\n",
        "y_pred_1958Feb,\n",
        "labels=[\"y_1957Dec\", \"y_pred_1957Dec\", \"y_pred_1958Jan\", \"y_pred_1958Feb\"],\n",
        ")\n",
        "\n",
        "# 1958年4月\n",
        "\n",
        "# 新しいデータが観測される。\n",
        "y_1958Apr = y[[-33]]\n",
        "\n",
        "# step 5: モデルのパラメータを再計算せずに更新を実行する\n",
        "# モデルのパラメータを再計算することなく、新しいデータでモデルを更新する\n",
        "forecaster.update(y_1958Apr, update_params=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- \n",
        "- \n",
        "-  このスクリプトは、sktimeライブラリのload_airline関数、sktime.forecasting.etsモジュールのAutoETSクラス、sktime.utils.plottingモジュールのplot_seriesをインポートしています。\n",
        "- from sktime.datasets import load_airline\n",
        "- from sktime.forecasting.ets import AutoETS\n",
        "- from sktime.utils.plotting import plot_series\n",
        "- \n",
        "-  便宜上、完全なデータセットを用意する\n",
        "-  シナリオでは、ある時点でこの一部だけを「知る」ことになることに注意\n",
        "- y = load_airline()\n",
        "-  1957 年 12 月\n",
        "- \n",
        "-  これは 1957 年 12 月のデータです\n",
        "- y_1957Dec = y[:-36] とする。\n",
        "- \n",
        "-  ステップ1: 予測手法の指定\n",
        "-  auto=True、季節期間 sp=12、n_jobs=-1 で AutoETS クラスのオブジェクトを作成します。\n",
        "- forecaster = AutoETS(auto=True, sp=12, n_jobs=-1)\n",
        "- \n",
        "-  ステップ2：予測地平線の指定：1年先、全月分\n",
        "-  予測の地平線を1年先、全月に指定する\n",
        "- fh = np.arange(1, 13)\n",
        "- \n",
        "-  step 3: このモデルを初めて使うので、フィッティングを行う\n",
        "-  既知のデータでモデルをフィットさせる\n",
        "- forecaster.fit(y_1957Dec)\n",
        "- \n",
        "-  step 4: 1958年1月～1958年12月の最初の予測バッチを取得する\n",
        "-  1958 年 1 月から 1958 年 12 月までの今後 12 ヶ月間の予測を作成する\n",
        "- y_pred_1957Dec = forecaster.predict(fh)\n",
        "-  予測値と過去のデータをプロットする\n",
        "-  予測値と過去のデータをプロットする\n",
        "- plot_series(y_1957Dec, y_pred_1957Dec, labels=[\"y_1957Dec\", \"y_pred_1957Dec\"])\n",
        "- \n",
        "-  1958 年 1 月\n",
        "- \n",
        "-  新しいデータが観測される。\n",
        "- y_1958Jan = y[[-36]].\n",
        "- \n",
        "-  step 5: 新しいデータでフォーキャスターを更新する\n",
        "-  新しいデータでモデルを更新する\n",
        "- forecaster.update(y_1958Jan)\n",
        "- \n",
        "-  step 6: 更新されたデータで予測を行う\n",
        "- y_pred_1958Jan = forecaster.predict(fh)\n",
        "-  fh は相対的なものなので、自動的に 1 ヶ月後の予測になることに注意。\n",
        "-  すなわち、1958 年 2 月から 1959 年 1 月まで\n",
        "- y_pred_1958Jan\n",
        "- \n",
        "-  予測値と過去のデータをプロットする\n",
        "-  予測値と過去のデータをプロットする\n",
        "- plot_series(\n",
        "- y[:-35],\n",
        "- y_pred_1957Dec,\n",
        "- y_pred_1958Jan,\n",
        "- labels=[\"y_1957Dec\", \"y_pred_1957Dec\", \"y_pred_1958Jan\"],\n",
        "- )\n",
        "- \n",
        "-  1958年2月\n",
        "- \n",
        "-  新しいデータが観測される。\n",
        "- y_1958Feb = y[[-35]] とする。\n",
        "- \n",
        "-  step 5: 新しいデータでフォアキャスターを更新する\n",
        "-  新しいデータでモデルを更新する\n",
        "- forecaster.update(y_1958Feb)\n",
        "- \n",
        "-  step 6: 更新されたデータで予測を行う\n",
        "- y_pred_1958Feb = forecaster.predict(fh)\n",
        "-  予測と過去のデータをプロットする\n",
        "- plot_series(\n",
        "- y[:-35],\n",
        "- y_pred_1957Dec,\n",
        "- y_pred_1958Jan,\n",
        "- y_pred_1958Feb,\n",
        "- labels=[\"y_1957Dec\", \"y_pred_1957Dec\", \"y_pred_1958Jan\", \"y_pred_1958Feb\"],\n",
        "- )\n",
        "- \n",
        "-  1958年4月\n",
        "- \n",
        "-  新しいデータが観測される。\n",
        "- y_1958Apr = y[[-33]].\n",
        "- \n",
        "-  step 5: モデルのパラメータを再計算せずに更新を実行する\n",
        "-  モデルのパラメータを再計算することなく、新しいデータでモデルを更新する\n",
        "- forecaster.update(y_1958Apr, update_params=False)\n",
        "- "
      ],
      "metadata": {
        "id": "2uwW64U43a4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このスクリプトは1958年4月の新しいデータでモデルを更新していますが、モデルのパラメータを再計算しているわけではありません。\n",
        "- これは、モデルを新しいデータに再適合させず、モデルの内部状態を更新するだけであることを意味します。\n",
        "- これは、モデルの再適合に多くの時間と資源がかかるようなシナリオで有用でしょう。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TnYdprIy4Egs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn1r9Ilfrc8W"
      },
      "source": [
        "### **1.4.3 バッチデータでのウォークフォワード予測**\n",
        "- sktimeは、データのフルバッチでupdate/predict展開モードをシミュレートすることもできます。\n",
        "\n",
        "- これは、すべてのデータが事前に利用可能である必要があるため、展開には有用ではありません。しかし、シミュレーションやモデル評価などの再生には有用です。\n",
        "\n",
        "- update/predict再生モードは、update_predictと、正確なウォークフォワード方式をコード化するre-samplingコンストラクタを使用して呼び出すことができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 最初の文章では、sktimeはupdate/predict展開モードをシミュレーションすることで、データのバッチに対して予測を行うことができると書かれています。\n",
        "- 2つ目の文章では、これは事前にすべてのデータが利用可能である必要があるため、実際にはあまり有用ではないが、シミュレーションやモデルの評価には有用であるとしている。\n",
        "- 3番目の文章では、update_predictメソッドを呼び出し、予測の方法を指定するre-samplingコンストラクタを使用することでこのモードを使用できることを説明しています。"
      ],
      "metadata": {
        "id": "5V5PBJho5Clt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFT4TkZPrc8W"
      },
      "outputs": [],
      "source": [
        "# from sktime.datasets import load_airline\n",
        "# from sktime.forecasting.ets import AutoETS\n",
        "# from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
        "# from sktime.utils.plotting import plot_series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdGkv43Orc8X"
      },
      "source": [
        "注：コメントアウトされています - インターフェイスのこの部分は、現在再作成中です。ご協力をお願いします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ7OEkEarc8X"
      },
      "outputs": [],
      "source": [
        "# for playback, the full data needs to be loaded in advance\n",
        "# y = load_airline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgmXMzQcrc8X"
      },
      "outputs": [],
      "source": [
        "# step 1: specifying the forecasting strategy\n",
        "# forecaster = AutoETS(auto=True, sp=12, n_jobs=-1)\n",
        "\n",
        "# step 2: specifying the forecasting horizon\n",
        "# fh - np.arange(1, 13)\n",
        "\n",
        "# step 3: specifying the cross-validation scheme\n",
        "# cv = ExpandingWindowSplitter()\n",
        "\n",
        "# step 4: fitting the forecaster - fh should be passed here\n",
        "# forecaster.fit(y[:-36], fh=fh)\n",
        "\n",
        "# step 5: rollback\n",
        "# y_preds = forecaster.update_predict(y, cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK0hSsH1rc8X"
      },
      "source": [
        "\n",
        "### 1.5 **高度な評価ワークフロー：**\n",
        "- ローリング再サンプリングと集計誤差、ローリングバックテスティング\n",
        "- ローリング予測におけるパフォーマンスに関してフォーキャスターを評価するために、フォーキャスターはローリング予測を模倣したセットアップで、通常は過去のデータでテストされる必要があります。\n",
        "- セクション1.3のようなバッチバックテストは、単一の予測バッチのみをテストするため、ローリング展開のための適切な評価セットアップではないことに注意してください。\n",
        "\n",
        " - 高度な評価ワークフローは、evaluateベンチマーク関数を用いて実施できます。\n",
        "\n",
        " - 評価されるフォーキャスター\n",
        " - 時間的分割のための scikit-learn 再サンプリング戦略 (cv below), \n",
        "- 例: ExpandingWindowSplitter や SlidingWindowSplitter。\n",
        " - 戦略 (string): フォーキャスタを常に再適合させるか、あるいは一度だけ適合させてから更新するか。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 最初の文は、ローリング予測を使用するフォーキャスターのパフォーマンスを評価するために、フォーキャスターを同様の方法、通常は過去のデータを使用してテストする必要があると述べています。\n",
        "- 2番目の文章は、1.3節で説明した方法を使うことは、単一の予測バッチをテストするだけなので、ローリング展開の評価には適切でないと説明しています。\n",
        "- 3文目は、高度な評価ワークフローは、evaluate関数を使用して実行することができると述べています。\n",
        "- 4文目では、evaluate関数は、評価するフォーキャスター、データを時間的に分割する方法、フォーキャスターを毎回再適合するか更新するかを示す文字列の3つの引数を取ると述べています。"
      ],
      "metadata": {
        "id": "847uZ-Kb55Us"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otkyklrvrc8Y"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.arima import AutoARIMA\n",
        "from sktime.forecasting.model_evaluation import evaluate\n",
        "from sktime.forecasting.model_selection import ExpandingWindowSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ua9FXGarc8Y"
      },
      "outputs": [],
      "source": [
        "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
        "\n",
        "cv = ExpandingWindowSplitter(\n",
        "    step_length=12, fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], initial_window=72\n",
        ")\n",
        "\n",
        "df = evaluate(forecaster=forecaster, y=y, cv=cv, strategy=\"refit\", return_data=True)\n",
        "\n",
        "df.iloc[:, :5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iROZ_Jmmrc8Z"
      },
      "outputs": [],
      "source": [
        "# visualization of a forecaster evaluation\n",
        "fig, ax = plot_series(\n",
        "    y,\n",
        "    df[\"y_pred\"].iloc[0],\n",
        "    df[\"y_pred\"].iloc[1],\n",
        "    df[\"y_pred\"].iloc[2],\n",
        "    df[\"y_pred\"].iloc[3],\n",
        "    df[\"y_pred\"].iloc[4],\n",
        "    df[\"y_pred\"].iloc[5],\n",
        "    markers=[\"o\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
        "    labels=[\"y_true\"] + [\"y_pred (Backtest \" + str(x) + \")\" for x in range(6)],\n",
        ")\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# このスクリプトは、sktime.forecasting.arimaモジュールからAutoARIMAクラス、sktime.forecasting.model_evaluationから評価関数、sktime.forecasting.model_selectionから拡張窓割り（ExpandingWindowSplitter）をインポートしている。\n",
        "from sktime.forecasting.arima import AutoARIMA\n",
        "from sktime.forecasting.model_evaluation import evaluate\n",
        "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
        "\n",
        "# 季節期間 sp=12, suppress_warnings=True で AutoARIMA クラスのオブジェクトを作成する。\n",
        "forecaster = AutoARIMA(sp=12, suppress_warnings=True) # 季節期間sp=12、suppress_warnings=TrueのAutoARIMAクラスのオブジェクトを作成する。\n",
        "\n",
        "# ExpandingWindowSplitter を用いて、データをトレーニングセットとテストセットに分割する。\n",
        "ステップ長 = 12, 水平線 fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], initial_window = 72 # 予測の水平線\n",
        "cv = ExpandingWindowSplitter(\n",
        "step_length=12,fh=[1,2,3,4,5,6,7,8,9,10,11,12],initial_window=72\n",
        ")\n",
        "\n",
        "# strategy refit と return_data=True を用いてトレーニングセットとテストセットを用いてモデルを評価する。\n",
        "# return_data=True は結果のデータフレームを返します。\n",
        "df = evaluate(forecaster=forecaster, y=y, cv=cv, strategy=\"refit\", return_data=True)\n",
        "\n",
        "# 結果のデータフレームの最初の5列を表示する\n",
        "df.iloc[:, :5]\n",
        "\n",
        "# フォーキャストの評価の可視化\n",
        "# 予測値と過去のデータをプロットする\n",
        "fig, ax = plot_series(\n",
        "y,\n",
        "df[\"y_pred\"].iloc[0],\n",
        "df[\"y_pred\"].iloc[1],\n",
        "df[\"y_pred\"].iloc[2],\n",
        "df[\"y_pred\"].iloc[3],\n",
        "df[\"y_pred\"].iloc[4],\n",
        "df[\"y_pred\"].iloc[5],\n",
        "markers=[\"o\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
        "labels=[\"y_true\"] + [\"y_pred (Backtest \" + str(x) + \")\" for x in range(6)\n",
        "\n"
      ],
      "metadata": {
        "id": "JlFdRiu2oDy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  このスクリプトは、sktime.forecasting.arimaモジュールからAutoARIMAクラス、sktime.forecasting.model_evaluationから評価関数、sktime.forecasting.model_selectionから拡張窓割り（ExpandingWindowSplitter）をインポートしている。\n",
        "- from sktime.forecasting.arima import AutoARIMA\n",
        "- from sktime.forecasting.model_evaluation import evaluate\n",
        "- from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
        "- \n",
        "-  季節期間 sp=12, suppress_warnings=True で AutoARIMA クラスのオブジェクトを作成する。\n",
        "- forecaster = AutoARIMA(sp=12, suppress_warnings=True) # 季節期間sp=12、suppress_warnings=TrueのAutoARIMAクラスのオブジェクトを作成する。\n",
        "- \n",
        "-  ExpandingWindowSplitter を用いて、データをトレーニングセットとテストセットに分割する。\n",
        "- ステップ長 = 12, 水平線 fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], initial_window = 72 # 予測の水平線\n",
        "- cv = ExpandingWindowSplitter(\n",
        "- step_length=12,fh=[1,2,3,4,5,6,7,8,9,10,11,12],initial_window=72\n",
        "- )\n",
        "- \n",
        "-  strategy refit と return_data=True を用いてトレーニングセットとテストセットを用いてモデルを評価する。\n",
        "-  return_data=True は結果のデータフレームを返します。\n",
        "- df = evaluate(forecaster=forecaster, y=y, cv=cv, strategy=\"refit\", return_data=True)\n",
        "- \n",
        "-  結果のデータフレームの最初の5列を表示する\n",
        "- df.iloc[:, :5]\n",
        "- \n",
        "-  フォーキャストの評価の可視化\n",
        "-  予測値と過去のデータをプロットする\n",
        "- fig, ax = plot_series(\n",
        "- y,\n",
        "- df[\"y_pred\"].iloc[0],\n",
        "- df[\"y_pred\"].iloc[1],\n",
        "- df[\"y_pred\"].iloc[2],\n",
        "- df[\"y_pred\"].iloc[3],\n",
        "- df[\"y_pred\"].iloc[4],\n",
        "- df[\"y_pred\"].iloc[5],\n",
        "- markers=[\"o\", \"\", \"\", \"\", \"\", \"\", \"\"],\n",
        "- labels=[\"y_true\"] + [\"y_pred (Backtest \" + str(x) + \")\" for x in range(6)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dcb73qSYoVLE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GxiSmIerc8Z"
      },
      "source": [
        "Todo: パフォーマンスメトリクス、平均値、テスト - sktimeとチュートリアルへの貢献は大歓迎です。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードはsktimeライブラリのAutoARIMAクラスを使ってAutoARIMAモデルのインスタンスを生成しています。\n",
        " - AutoARIMAクラスはpmdarimaライブラリのラッパーで、ARIMAモデルを異なるパラメータで複数回フィットさせることにより、自動的に最適なp、d、qパラメータを見つけます。\n",
        "\n",
        "- そして、sktime.forecasting.model_selectionモジュールのExpandingWindowSplitter関数を使って、データセットをトレーニングセットとテストセットに分割しています。   \n",
        " - ExpandingWindowSplitterはデータセットをウィンドウに分割し、最初のウィンドウはinitial_windowの長さで、それ以降のウィンドウは前のウィンドウよりstep_length長くなります。\n",
        "  - この場合、fhパラメータには各ウィンドウの予測地平線のリストが設定され、モデルはその地平線のために予測を行います。\n",
        "\n",
        "- 次に、sktime.forecasting.model_evaluationモジュールのevaluate関数がAutoARIMAモデルの性能を評価するために使われます。\n",
        " - この関数はいくつかのパラメータを取ります。\n",
        "\n",
        "- forecaster: 評価されるフォアキャスター・モデル\n",
        "- y: 予測を行うデータセット\n",
        "- cv: 使用するクロスバリデーション戦略\n",
        "- strategy: 毎回モデルを再フィットするか、新しいデータで更新するか。\n",
        "- return_data: 予測値と真の値をデータフレームで返すかどうか\n",
        "- evaluate関数は、各ウィンドウのモデルの予測値と真の値をdataframeで返し、その- dataframeの最初の5行を表示するようにインデックスを付けます。\n",
        "\n",
        "- 最後に、このコードでは plot_series 関数を用いて、最初の 6 つのウィンドウの真の値とモデルの予測値を可視化します。\n",
        "\n",
        "- evaluate関数を使う利点は、ローリングウィンドウ戦略を使ったローリング予測モデルのパフォーマンスを評価できることで、これは実運用で使うことを意図した予測モデルを評価するのにより現実的な方法と言えます。\n",
        "\n",
        " - また、予測値と真値をデータフレームで返すので、モデル性能の比較と可視化が容易にできます。\n",
        "\n",
        "- この例では、フォーキャスターは全データに対してではなく、データのローリングウィンドウに対してトレーニングされていることに注目することが重要です。\n",
        " - これは、実際のシナリオでは、モデルを訓練し予測を行うために利用可能な唯一のデータであるため、重要なことです。\n",
        "\n",
        "- ExpandingWindowSplitterは、データをトレーニングセットとテストセットに分割するために使用される戦略で、各ウィンドウはデータの拡張ウィンドウです。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3mMu7j5-mWVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、AutoARIMAモデルを使って将来の値を予測し、拡大窓交差検証戦略を使ってそのパフォーマンスを評価するためにsktimeライブラリを使用しています。\n",
        "\n",
        "- from sktime.forecasting.arima import AutoARIMA AutoARIMAモデルをインポートします。\n",
        " - このモデルは、ARIMAモデルの最適なパラメータセットを、様々なパラメータの組み合わせを試すことによって自動的に見つけます。\n",
        "\n",
        "- これは、クロスバリデーション戦略を用いて、フォーキャスターの性能を評価するために使用することができます。\n",
        "\n",
        "- このクラスは、時系列を訓練セットとテストセットに分割し、時系列が進むにつれてテストセットが大きくなるようにするために使用することができます。\n",
        "\n",
        "- forecaster = AutoARIMA(sp=12, suppress_warnings=True) AutoARIMAモデルのインスタンスを作成し、季節期間を12に、suppress_warnings=True（AutoARIMAモデルが生成する警告の一部を抑制する）を設定する。\n",
        "\n",
        "- cv = ExpandingWindowSplitter(step_length=12, fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], initial_window=72) ExpandingWindowSplitterクラスのインスタンスを作成し，時系列をトレーニングセットとテストセットに分割するのに使用されます．\n",
        "\n",
        "- df = evaluate(forecaster=forecaster, y=y, cv=cv, strategy=\"refit\", return_data=True) evaluate関数を呼び出し，拡大窓クロスバリデーション戦略を用いたフォーキャストの性能を評価します．\n",
        "\n",
        "- df.iloc[:, :5] は、evaluate関数によって返されたデータフレームの最初の5列を表示します。\n",
        "\n",
        "- fig, ax = plot_series(...) plot_series関数を用いて、時系列の真値と6種類のバックテストの予測値を表示するプロットを作成します。\n",
        "\n",
        "- ax.legend() は、プロットに凡例を追加します。\n",
        "\n",
        "- evaluate関数は、真の値、予測値、予測時刻、予測水平線の時刻、モデルのパラメータを列挙した、予測評価のDataFrameを返します。\n",
        "\n",
        "- ExpandingWindowSplitterクラスは、時系列を訓練セットとテストセットに分割し、時系列が進むにつれてテストセットが大きくなるようにします。step_lengthパラメータは、毎回テストセットに追加されるオブザベーションの数を制御し、fhパラメータは予測地平線を制御し、initial_windowパラメータは、最初の訓練セット内のオブザベーションの数を制御します。\n",
        "\n",
        "- AutoARIMAモデルは、パラメータの様々な組み合わせを試すことで、ARIMAモデルの最適なパラメータセットを見つけます。seasonal_periodパラメータ（sp）は、季節期間の時間単位の数、例えば1年のうち何ヶ月が12であるかを示すために使用されます。\n",
        "\n",
        "- plot_series関数は、異なるバックテストにおける時系列の真の値と予測値を示すプロットを作成するために使用されます。\n",
        "- markersパラメータはプロットされるポイントのマーカー形状を制御し、labelsパラメータはプロットされるポイントのラベルを制御します。\n",
        "\n"
      ],
      "metadata": {
        "id": "NPLe5-jAnDGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- sktimeは、過去のデータから未来の出来事を予測するためのライブラリです。\n",
        "- sktimeには様々なタイプの予測器（「フォアキャスター」と呼ばれる）があり、様々な方法でそれらを検索することができます。\n",
        "- ぞれのフォーキャスターには、一度に複数のことを予測できるか、可能性の幅を持た- 予測できるかなど、できることを説明する異なるプロパティやタグがあります。\n",
        "- l_estimatorsという関数を使って、すべてのフォアキャスターとそのタグのリストを見とができます。\n",
        "- また、filter_tags引数を使って、特定のタグに基づいてリストを ィリングすることができます\n",
        "- all_tags ユーティリティを使用すると、sktime に存在するすべての異なるタグのとその意味を見ることができ。"
      ],
      "metadata": {
        "id": "FmXNFOqAokLK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3OCSVdrrc8a"
      },
      "source": [
        "\n",
        "\n",
        "### **2.sktimeのフォーキャスター - ルックアップ、プロパティ、主なファミリー**\n",
        "- このセクションでは、その方法についてまとめています。\n",
        "\n",
        " - sktimeの中のフォーキャスターを検索する\n",
        " - フォーキャスターのプロパティ、対応する検索オプションとタグ\n",
        " - sktimeでよく使われるフォーキャスターの種類"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sktimeは、過去のデータに基づいて将来の出来事を予測するためのライブラリで、使用できる予測器（「フォーキャスター」と呼ばれます）の種類があります。\n",
        "- このセクションでは、sktimeで異なるタイプの予測器を探す方法、予測器の異なるプロパティまたはタグは何か、そしてsktimeで最もよく使われる予測器のタイプは何かについて説明します。"
      ],
      "metadata": {
        "id": "rmppPkKXpn1F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0sDsBy9rc8a"
      },
      "source": [
        "### **2.1 sktimeにある全てのforecasterをリストアップする**\n",
        "- 一般的に、sktimeで利用可能な全ての予測器はall_estimatorsコマンドでリストアップすることができます。\n",
        "\n",
        "- これは、ソフト依存がインストールされていないものも含めて、sktimeにある全てのフォーキャスターをリストアップします。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sktimeは、過去のデータに基づいて将来の事象を予測するために使用できる、多くの異なる予測器（「予測器」と呼ばれる）を持つライブラリです。\n",
        "- all_estimatorsコマンドはsktimeで利用可能なすべてのフォーキャスターをリストアップするために使用することができます。\n",
        "- このコマンドは、あなたが使用するのに必要なツールを持っていないかもしれないものまで、すべてのフォーキャスターを表示します。"
      ],
      "metadata": {
        "id": "WuFRZIjXp9T1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4XP2J62rc8a"
      },
      "outputs": [],
      "source": [
        "from sktime.registry import all_estimators\n",
        "\n",
        "all_estimators(\"forecaster\", as_dataframe=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq-9V8dCrc8b"
      },
      "source": [
        "- 結果のデータフレームの最後の列のエントリは、直接構築に使用することができるクラス、または単に正しいインポートパスのために検査されるクラスです。\n",
        "\n",
        "- フォーキャストをループするロジックでは、デフォルトの出力形式がより便利かもしれません。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- all_estimatorsコマンドを実行すると、すべてのフォーキャスターのリストが得られ、それはテーブルの形になります。\n",
        "- このテーブルの最後の列には、予測に使用できるフォーキャスターのクラスが含まれており、それらをインポートする正しい方法を確認することができます。\n",
        "- もしループを使ってリスト内のすべてのフォーキャスターを調べたいのであれば、リストのデフォルトのフォーマットの方が便利かもしれません。\n"
      ],
      "metadata": {
        "id": "xQxMaA7AqX9k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXRXcJzmrc8b"
      },
      "outputs": [],
      "source": [
        "forecaster_list = all_estimators(\"forecaster\", as_dataframe=False)\n",
        "\n",
        "# this returns a list of (name, estimator) tuples\n",
        "forecaster_list[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptsTNtZjrc8c"
      },
      "source": [
        "### **2.2 フォーキャスターのタグ**\n",
        "- すべてのフォアキャスターsktimeは、推定量の特性（例えば、多変量か、確率的か、そうでないかなど）を記述するいわゆるタグを持っている。\n",
        " - タグの使用、検査、検索についてはこのセクションで説明する。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sktimeのすべての予測器（フォアキャスター）には「タグ」というものがあり、複数の変数を扱えるか、確率の推定値が得られるかなど、予測器の特性に関する情報を知ることができます。\n",
        "- ここでは、これらのタグの使い方、タグの確認方法、タグに関する情報の入手方法について説明します。"
      ],
      "metadata": {
        "id": "JICHTqjTq8os"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkKBet4Src8c"
      },
      "source": [
        "2.2.1 能力タグ：多変量、確率的、階層的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYcBqCkMrc8c"
      },
      "source": [
        "\n",
        "- すべてのフォアキャスターはタグを持っており、これはキーと値のペアで、能力や内部実装の詳細を記述することができます。\n",
        "\n",
        "- 最も重要な \"ケイパビリティ \"スタイルのタグは以下の通りである。\n",
        "\n",
        "- requires-fh-in-fit - ブール値。フォアキャスターが、fitの中ですでに予測水平線fhを必要とするかどうか (True)、あるいは、predictの後半で渡すことができるかどうか (False)。\n",
        "\n",
        "- scitype:y - 文字列。\n",
        " - フォーキャスターが一変量（\"univariate\"）か、厳密に多変量（\"multivariate\"）か、あるいは任意の数の変数を扱える（\"both\"）かを示す。\n",
        "\n",
        "- capability:pred_int - ブール値。\n",
        " - predict_intervalなどを通じて、予報士が確率的な予測を返すことができるかどうか、セクション1.5を参照。\n",
        "\n",
        "- ignores-exogeneous-X - boolean（論理値）。\n",
        " - フォーキャスターが非遺伝変数Xを利用するかどうか (False) または利用しないかどうか (True).フォーキャスターが X を使用しない場合でも、インターフェースの統一性のために渡すことができ、無視される。\n",
        "\n",
        "- handles-missing-data - boolean。\n",
        " - フォーキャスターが、入力Xまたはyの欠損データを扱うことができるかどうか。\n",
        "\n",
        "- フォーキャスターのインスタンスのタグは、 get_tags (すべてのタグをリストアップ) と get_tag (1つのタグの値を取得) メソッドで検査することができます。\n",
        "\n",
        "- タグの値は、ハイパーパラメータの選択に依存することがある。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **要約：**\n",
        "- sktimeのすべての予測器（フォアキャスター）には、予測器の特性や構築方法に関する情報を与える「タグ」と呼ばれる特別なラベルがあります。\n",
        "\n",
        "\n",
        "- 各タグは、名前と値を持つラベルで、予測器について何かを教えてくれます。\n",
        "いくつかの重要なタグがあります。\n",
        "- 予測を開始する前に、予測すべき時間範囲を知る必要がある(requires-fh-in-fit)\n",
        "- 1つの変数または複数の変数を扱うことができる (scitype:y)\n",
        "- 予測が正しい確率の推定値を与えることができる (capability:pred_int)\n",
        "- 外部情報を利用する (ignores-exogeneous-X)\n",
        "- 欠損データを扱うことができる (handles-missing-data)\n",
        "- get_tags (すべてのタグを表示) と get_tag (特定のタグの値を表示) を使って予測変数のタグを確認することができます。\n",
        "- タグの値は、あなたがpredictorのパラメータをどのように設定したかに応じて変わるかもしれません。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hxt-DvWzrirE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPQMtNF1rc8d"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.arima import ARIMA\n",
        "\n",
        "ARIMA().get_tags()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sktime.forecasting.arimaモジュールからARIMAクラスをインポートする。\n",
        "from sktime.forecasting.arima import ARIMA\n",
        "\n",
        "# ARIMAクラスのインスタンスを作成する\n",
        "model = ARIMA()\n",
        "\n",
        "# モデルのタグを取得する\n",
        "tag = model.get_tags()\n",
        "\n",
        "# タグを表示する\n",
        "print(tag)"
      ],
      "metadata": {
        "id": "UcZfG1Pa3751"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードでは、まずsktime.forecasting.arimaモジュールからARIMAクラスをインポートします。\n",
        "- そして、コンストラクタを呼び出してARIMAクラスのインスタンスを生成します。このモデルのインスタンスを変数 \"model \"に格納します。\n",
        "- そして、モデルのインスタンスに対してget_tags()メソッドを呼び、モデルのタグを返します。\n",
        "- 最後に、print 関数でタグを表示します。\n",
        "- このコードでは、モデルのタグをチェックして、それをプリントしています。"
      ],
      "metadata": {
        "id": "za861vho4NS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードでは、sktime.forecasting.arimaモジュールからARIMAクラスをインポートしています。\n",
        "- そして、ARIMAクラスのインスタンスを作成し、その上でget_tags()メソッドを呼び出します。\n",
        "- get_tags()メソッドはモデルのタグを取得するために使用されます。\n"
      ],
      "metadata": {
        "id": "-8Gemq_V3sCo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUm8TmDtrc8d"
      },
      "source": [
        "\n",
        "- y_inner_mtypeとX_inner_mtypeは、フォアキャスターがパネルまたは階層的なデータをネイティブに扱えるかどうかを示します。\n",
        "\n",
        "- すべてのタグの説明は、all_tagsユーティリティを使用して得ることができます。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **概要**\n",
        "\n",
        "- y_inner_mtype と X_inner_mtype は、フォアキャスターが \"panel\" または \"hierarchical data\" と呼ばれる特殊なタイプのデータを扱うことができるかどうかを示すタグです。\n",
        "- もし、フォーキャスターがこのタイプのデータを扱うことができれば、それはタグで指定されることになります\n",
        "- すべてのタグとその意味について理解するために、セクション2.2.3のall_tagsユーティリティを使用することができます。\n",
        "\n",
        "- パネルデータや階層データは、通常のデータよりも情報の層が多い特別なタイプのデータです。\n",
        "- タマネギが何層にもなっているのと同じです。\n",
        "- このタイプのデータを扱える予報士もいれば、扱えない予報士もいます。\n",
        "- y_inner_mtypeとX_inner_mtypeタグは、使用しているフォーキャスターがパネルと階層化データを扱うことができるかどうかを示しています。\n",
        "- もし、タグが \"panel \"または \"hierarchical \"と言っていれば、そのフォーキャスターはそのタイプのデータを扱うことができます。\n",
        "- もし、すべてのタグとその意味についてもっと知りたい場合は、セクション2.2.3のall_tagsユーティリティを使用することができます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BR1pEsRussNF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB4nftTrc8d"
      },
      "source": [
        "### **2.2.2 タグによる予報士の検索とリストアップ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrDlhlEFrc8e"
      },
      "source": [
        "タグ付きのフォーキャストをリストアップするために、all_estimators ユーティリティは return_tags 引数で使用することができます。\n",
        "\n",
        "結果として得られるデータフレームは、テーブル・クエリーやサブセッテイングに使用することができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **要約**\n",
        "- 「all_estimators」というツールを使って、sktimeライブラリに存在する様々な予報士（天気予報士のようなもの）の一覧を表示することができます。\n",
        "\n",
        "### **説明**\n",
        "- このツールは、\"return_tags \"と呼ばれる特別なオプションと一緒に使うことで、各フォーキャスターの異なるプロパティを表示させることができます。\n",
        "- これらのプロパティはラベルのようなもので、それぞれのフォアキャスターが何ができるかを教えてくれるものです。\n",
        "- また、all_estimatorsツールによって生成されたリストは、特定のフォアキャスターを検索したり、より小さなグループに分割するなど、他のことに使用することができます。"
      ],
      "metadata": {
        "id": "qwvhOmz-th6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-25aFAmrc8e"
      },
      "outputs": [],
      "source": [
        "from sktime.registry import all_estimators\n",
        "\n",
        "all_estimators(\n",
        "    \"forecaster\", as_dataframe=True, return_tags=[\"scitype:y\", \"requires-fh-in-fit\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfLeseyzrc8f"
      },
      "source": [
        "特定のタグやタグ値をあらかじめフィルタリングするために、filter_tags 引数を使用することができる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNSLhRuUrc8f"
      },
      "outputs": [],
      "source": [
        "# this lists all forecasters that can deal with multivariate data\n",
        "all_estimators(\n",
        "    \"forecaster\", as_dataframe=True, filter_tags={\"scitype:y\": [\"multivariate\", \"both\"]}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sktime.registry から all_estimators をインポート\n",
        "from sktime.registry import all_estimators\n",
        "\n",
        "# scitype:y と requires-fh-in-fit タグを持つ全てのフォーキャストを取得する\n",
        "estimators_df = all_estimators(\n",
        "\"forecaster\", as_dataframe=True, return_tags=[\"scitype:y\", \"requires-fh-in-fit\"]\n",
        ")\n",
        "\n",
        "# 結果のデータフレームを表示する\n",
        "print(estimators_df)\n"
      ],
      "metadata": {
        "id": "rSJoyTlG4Xt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- このコードでは、all_estimators関数をsktime.registryモジュールからインポートしています。\n",
        "- この関数には、3つのパラメータを渡しています。\n",
        "\n",
        "- \"forecaster\" : すべてのフォーキャスターを取得します。\n",
        "- as_dataframe=True : 結果をdataframeフォーマットで返します。\n",
        "- return_tags=[\"scitype:y\", \"requires-fh-in-fit\"]:フォーキャストをフィルタリングしたいタグ。\n",
        "- この結果を変数estimators_dfに格納します。\n",
        "- 最後に、print関数を用いてデータフレームを出力しています。\n",
        "- このコードは、scitype:yとrequires-fh-in-fitタグを持つすべてのフォーキャスターを取得し、その結果をデータフレーム形式で返すために使用されています。"
      ],
      "metadata": {
        "id": "lk50KEb04h-n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAybveQtrc8f"
      },
      "source": [
        "\n",
        "### **重要：**\n",
        "- 上記で述べたように、タグの値はハイパーパラメータの設定に依存することがあります。\n",
        " - 例えば、ForecastingPipelineは、その中のフォーキャスターが多変量データを扱える場合にのみ、多変量データを扱うことができます。\n",
        "\n",
        "- 上記のような検索において、クラスのタグは通常、最も一般的な潜在値を示すように設定されます。\n",
        " - 例えば、あるパラメータの選択に対して、推定者が多変量を扱える場合、それはリストに表示されることになります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **概要**\n",
        "\n",
        "- 機械学習モデルがどのように設定されるかによって、タグの値が変わる可能性があることを覚えておくことが重要である。\n",
        "- クラス、つまり機械学習モデルの種類のタグは、通常、最も一般的な潜在的価値を示す。\n",
        " - 例えば、ある条件下で複数の変数を扱えるモデルであれば、複数変数を扱えるとして記載される。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tGCIJBv6uGUS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE0iSdJQrc8f"
      },
      "source": [
        "### **2.2.3 すべてのフォアキャスター・タグのリストアップ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyBNB2wZrc8g"
      },
      "source": [
        "すべてのフォアキャスター・タグをタグの説明とともに一覧表示するには、all_tags ユーティリティを使用することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeODyyvLrc8g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sktime.registry import all_tags\n",
        "\n",
        "# wrapping this in a pandas DataFrame for pretty display\n",
        "pd.DataFrame(all_tags(estimator_types=\"forecaster\"))[[0, 3]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pandas ライブラリをインポートする\n",
        "import pandas as pd\n",
        "\n",
        "# sktime.registry から all_tags をインポート\n",
        "from sktime.registry import all_tags\n",
        "\n",
        "# forecasterの全タグを取得する\n",
        "tags = all_tags(estimator_types=\"forecaster\")\n",
        "\n",
        "# タグからDataFrameを作成し、1列目と4列目のみを選択する\n",
        "tags_df = pd.DataFrame(tags)[[0, 3]]\n",
        "\n",
        "# 結果のデータフレームを表示する\n",
        "print(tags_df)\n"
      ],
      "metadata": {
        "id": "UwFE5D6242V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、まず、強力で使いやすいオープンソースのデータ分析・操作ツールであるpandasライブラリをインポートしています。\n",
        "- 次に、sktime.registryモジュールからall_tags関数をインポートしています。\n",
        "- この関数に1つのパラメータ 'estimator_types=\"forecaster\"' を渡して、forecasterのすべてのタグを取得します。\n",
        "- 次に、pandasのDataFrame関数を使ってタグのDataFrameを作成し、変数tags_dfに保存しています。\n",
        "- 最後に、DataFrameのインデックス演算子[[0, 3]]を使って1列目と4列目のみを選択し、print関数を使って結果のdataframeを出力しています。\n",
        "- このコードは、予報士のすべてのタグを取得し、すべての列のうち2列のみを含む結果をdataframe形式で返すために使用されています。\n"
      ],
      "metadata": {
        "id": "uEqgthov5DMh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMpdDVQ9rc8g"
      },
      "source": [
        "\n",
        "### **2.3 sktimeの一般的なフォーキャスター**\n",
        "- sktimeは、一般的に使用される多くのフォーキャストをサポートしており、その多くは最先端の予測パッケージからインターフェイスされています。\n",
        " - すべてのフォーキャスターは、統一されたsktimeインターフェースの下で利用可能です。\n",
        "\n",
        "- 現在安定的にサポートされているいくつかのクラスは以下の通りです。\n",
        "\n",
        " - ExponentialSmoothing, \n",
        " - ThetaForecaster, \n",
        " - そして statsmodels の autoETS。\n",
        " - pmdarima の ARIMA および AutoARIMA\n",
        " - statsforecastのAutoARIMA\n",
        " - tbatsのBATSとTBATS\n",
        " - 多項式トレンドの予測用PolynomialTrend\n",
        " - Facebook prophetのインターフェイスであるprophet\n",
        "- これは完全なリストではないので、セクション2.1と2.2で示したようにall_estimatorsを使用してください。\n",
        "\n",
        "- 説明のために、以下のすべての推定量は基本的な予測ワークフローで紹介されていますが、\n",
        "- これらは統一されたsktimeインターフェース（セクション1参照）のもと、高度な予測・評価ワークフローもサポートしています。\n",
        "\n",
        "- 他のワークフローで使用するには、以下に示す例の「フォーキャスター指定ブロック」（\"forecaster=\")をフォーキャスター指定ブロックに置き換えるだけでよい。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "概要\n",
        "\n",
        "- このセクションでは、パッケージによってサポートされているsktimeの一般的なフォーキャスターを説明します。\n",
        "- sktimeは多くの一般的に使われるフォーキャストをサポートしており、それらはすべて統一されたsktimeインターフェースの下で利用可能です。\n",
        "- サポートされているフォーキャスターの例としては、\n",
        " - ExponentialSmoothing, \n",
        " - ThetaForecaster, \n",
        " - AutoARIMA, \n",
        " - BATS, \n",
        " - TBATS, \n",
        " - PolynomialTrend, \n",
        " - Prophet.\n",
        "などがあります。\n",
        "- このリストは包括的なものではありませんので、all_estimatorsコマンドを使用してフォーキャスターの全リストをご覧ください。\n",
        "- これらのフォーキャスターは、基本的な予測、高度な予測、評価ワークフローなど、統一されたsktimeインターフェースの下で異なるワークフローで使用することができます。\n",
        "- これらのフォーキャスターを他のワークフローで使用するには、セクションで提供される例の中の「フォーキャスター仕様ブロック」を置き換えるだけです。\n",
        "\n"
      ],
      "metadata": {
        "id": "qmtxb8fwvXyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **概要**\n",
        "\n",
        "- 指数平滑化とは、過去のデータから将来の値を予測するために用いられる手法である。移動平均を使用して予測値を計算します。\n",
        "- Theta Forecasterは過去のデータに基づいて未来の価値を予測するのに使用される方法である。\n",
        " - Exponential Smoothing 法のバリエーションです。\n",
        "- AutoARIMA は、過去のデータに基づいて将来の値を予測するために使用される方法です。\n",
        " - ARIMAモデルの最適なパラメータを自動的に見つけます。\n",
        "- BATSとTBATSは、過去のデータに基づいて将来の値を予測するために使用される方法です。\n",
        " - これらは、データの季節性と傾向を考慮した指数平滑化法のバリエーションです。\n",
        "- 多項式トレンドは、過去のデータに基づいて将来の値を予測するために使用される方法です。\n",
        " - データのトレンドをモデル化するために多項式を使用します。\n",
        "- プロフェットは、過去のデータから将来の値を予測するために使用される方法です。\n",
        " - 線形モデルと非線形モデルを組み合わせて使用し、長期的なトレンドと季節性を扱うことができます。\n",
        "- 上記の手法はそれぞれ特有の長所と短所がありますが、いずれも過去のデータに基づいて将来の値を予測するために使用されます。\n",
        " - 例えば、指数平滑法はシンプルで分かりやすい手法ですが、複雑なデータを扱う場合には他の手法に比べ精度が落ちる可能性があります。\n",
        " - 一方、プロフェットはより高度な手法で、複雑なデータや長期的なトレンドを扱うことができますが、理解や利用が難しい場合があります。\n",
        "\n"
      ],
      "metadata": {
        "id": "Cj0oz5ETwdal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6xpY_itrc8g"
      },
      "outputs": [],
      "source": [
        "# imports necessary for this chapter\n",
        "from sktime.datasets import load_airline\n",
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
        "from sktime.utils.plotting import plot_series\n",
        "\n",
        "# data loading for illustration (see section 1 for explanation)\n",
        "y = load_airline()\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# この章に必要なモジュールをインポートする\n",
        "# load_airline モジュールは航空会社のデータセットをロードするために使われる\n",
        "from sktime.datasets import load_airline\n",
        "\n",
        "# ForecastingHorizonモジュールは予測の地平線を定義するために使われる\n",
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "\n",
        "# temporal_train_test_split モジュールは、データを訓練データとテストデータに分割するために使用される。\n",
        "# 時間に関して\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "\n",
        "# mean_absolute_percentage_errorモジュールは平均絶対誤差を計算するために利用されます。\n",
        "# 予測誤差を測定するために使用される\n",
        "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error #予測誤差を測定するために使用される平均絶対誤差を計算するモジュール。\n",
        "\n",
        "# plot_series モジュールは、時系列データをプロットするために使用されます。\n",
        "from sktime.utils.plotting import plot_series\n",
        "\n",
        "# 航空会社のデータセットをロードする\n",
        "y = load_airline()\n",
        "\n",
        "# テストデータセットに 36 個のオブザベーションがある状態で、データをトレーニングデータセットとテストデータセットに分割します。\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=36) # 訓練データとテストデータに分割し、テストデータセットに36個の観測値を入れる。\n",
        "\n",
        "# 予測地平線を定義する\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False) # 予測地平の定義\n",
        "\n"
      ],
      "metadata": {
        "id": "30hx-eDq5mfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  この章に必要なモジュールをインポートする\n",
        "-  load_airline モジュールは航空会社のデータセットをロードするために使われる\n",
        "- from sktime.datasets import load_airline\n",
        "- \n",
        "-  ForecastingHorizonモジュールは予測の地平線を定義するために使われる\n",
        "- from sktime.forecasting.base import ForecastingHorizon\n",
        "- \n",
        "-  temporal_train_test_split モジュールは、データを訓練データとテストデータに分割- するために使用される。\n",
        "-  時間に関して\n",
        "- from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "- \n",
        "-  mean_absolute_percentage_errorモジュールは平均絶対誤差を計算するために利用され- ます。\n",
        "-  予測誤差を測定するために使用される\n",
        "- from sktime.performance_metrics.forecasting import - mean_absolute_percentage_error 予測誤差を測定するために使用される平均絶対誤差を- 計算するモジュール。\n",
        "- \n",
        "-  plot_series モジュールは、時系列データをプロットするために使用されます。\n",
        "- from sktime.utils.plotting import plot_series\n",
        "- \n",
        "-  航空会社のデータセットをロードする\n",
        "- y = load_airline()\n",
        "- \n",
        "-  テストデータセットに 36 個のオブザベーションがある状態で、データをトレーニング- データセットとテストデータセットに分割します。\n",
        "- y_train, y_test = temporal_train_test_split(y, test_size=36) # 訓練データとテス- トデータに分割し、テストデータセットに36個の観測値を入れる。\n",
        "- \n",
        "-  予測地平線を定義する\n",
        "- fh = ForecastingHorizon(y_test.index, is_relative=False) # 予測地平の定義\n",
        "\n"
      ],
      "metadata": {
        "id": "B2F7c4Wm5uNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードスニペットでは、まずこの章に必要ないくつかのモジュールをsktimeライブラリからインポートしています。\n",
        "- load_airlineモジュールは航空会社のデータセットをロードするのに使われ、temporal_train_test_splitは時間に関してデータを訓練データとテストデータセットに分割するのに使われます。\n",
        "- ForecastingHorizonモジュールは、予測地平線を定義するのに使われ、mean_absolute_percentage_errorは、予測誤差を測るために使われる平均絶対誤差を計算するのに使われます。\n",
        "- plot_seriesモジュールは、時系列データをプロットするために使われます。\n",
        "- 次に、load_airline 関数を用いて航空会社データセットをロードし、変数 y に格納します。\n",
        "- そして、temporal_train_test_split 関数を用いて、テストデータセットに36個のオブザベーションを持つようにデータをトレーニングデータセットとテストデータセットに分割し、結果をそれぞれy_trainとy_testに格納します。\n",
        "- 最後に、ForecastingHorizon関数を用いて予測地平線を定義し、その結果を変数fhに格納します。\n",
        "- このコードでは、航空会社のデータセットを読み込み、それを訓練データとテストデータに分割し、テストデータセットに対して予測地平線を定義するために使用されます。\n"
      ],
      "metadata": {
        "id": "GSOuPRn25uXq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-RjQXD7rc8h"
      },
      "source": [
        "\n",
        "### **2.3.1 指数平滑化、シータフォーキャスター、statsmodels からの autoETS**\n",
        "- sktimeはstatsmodelsの統計的予測アルゴリズムである指数平滑化、シータ、自動ETSをインターフェイスにしています。\n",
        "\n",
        "- 例えば、加法的トレンド成分と乗法的季節性を持つ指数平滑化を航空会社のデータセットで使うには、次のように書きます。\n",
        " - なお、これは月次データなので、季節性周期性（sp）は12（＝1年の仮想周期性）を選択するのがよいでしょう。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **概要**\n",
        "\n",
        "- 指数平滑化、シータフォーキャスター、および自動ETSはすべて、sktimeライブラリで利用可能な統計的予測アルゴリズムである。\n",
        "- これらは、異なる数学的モデルを使用して、過去のデータポイントに基づく将来のデータポイントについて予測を行うために使用することができます。\n",
        "- 指数平滑化とは、移動平均法を用いてデータの変動を平滑化する方法です。\n",
        "- シータフォーキャスターは、シータ法を用いて将来のデータポイントを予測する手法です。\n",
        "- Auto-ETS は、与えられたデータセットに対して最適なETSモデルを自動的に選択する手法です。\n",
        "- これらの手法は、月次の航空旅客データなど、時系列データに関する予測を行うために使用することができます。\n",
        "- 統計的な予測手法であるという点では共通していますが、予測を行うために異なる数学的モデルを使用します。\n",
        "- これらの手法の長所は、過去のデータに基づいて正確な予測を行うことができ、実装が簡単であることです。\n",
        "- 一方、不規則性の高いデータの場合、正確な予測ができない可能性があることが欠点です。\n",
        "- これらの手法を使用することのインパクトは、将来のデータポイントについて正確な予測を行うことで、組織がより良い意思決定を行えるようになることである。\n",
        " - 注：ETSは、Error、Trend、Seasonalityの略。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qoGjdBV9xtRP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA52TlLprc8h"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
        "forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5f9uy_9rc8h"
      },
      "outputs": [],
      "source": [
        "# Import ExponentialSmoothing class from sktime.forecasting.exp_smoothing module\n",
        "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
        "\n",
        "# トレンドと季節成分の \"加算 \"でforecasterオブジェクトを初期化する。\n",
        "forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12) # トレンドを \"add\"、季節成分を \"additive \"としてフォアキャスターを初期化する。\n",
        "\n",
        "# 学習データに対してモデルをフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# テストセットの値を予測する\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# シリーズのプロット\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測の平均絶対誤差パーセンテージを計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測の平均絶対誤差を計算する。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-    Import ExponentialSmoothing class from sktime.forecasting.exp_smoothing module\n",
        "- from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
        "- \n",
        "-  トレンドと季節成分の \"加算 \"でforecasterオブジェクトを初期化する。\n",
        "- forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12) # ト- レンドを \"add\"、季節成分を \"additive \"としてフォアキャスターを初期化する。\n",
        "- \n",
        "-  学習データに対してモデルをフィットさせる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  テストセットの値を予測する\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  シリーズのプロット\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "-  予測の平均絶対誤差パーセンテージを計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測の平均絶対- 誤差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "9hJwSsdj6Z_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、まず、sktime.forecasting.exp_smoothingモジュールからExponentialSmoothingクラスをインポートしています。\n",
        "- そして、ExponentialSmoothingクラスのインスタンスを作成し、forecasterという変数に格納しています。\n",
        "- ExponentialSmoothingクラスは、3つのパラメータで初期化されます。\n",
        "\n",
        " - trend : モデル中のトレンド成分の種類、加法的トレンドには \"add \"を使用。\n",
        " - seasonal : モデル中の季節成分の種類、加法的季節性には \"additive \"を使用。\n",
        " - sp : 季節性期間の数。\n",
        "- 次に、forecasterオブジェクトのfitメソッドを使って、学習データにモデルを当てはめます。\n",
        "- forecaster オブジェクトの predict メソッドを使って、テストセットの値を予測し、変数 y_pred に格納します。\n",
        "- y_train, y_test, y_pred データとそれらのラベルを渡し、系列をプロットするために sktime.utils.plotting モジュールの plot_series 関数を使用します。\n",
        "- 最後に、sktime.performance_metrics.forecastingモジュールのmean_absolute_percentage_error関数を使って、予測の平均絶対誤差を計算します。\n",
        "- このコードスニペットは、\n",
        " - 訓練データセットに指数平滑化モデルを適合させ、\n",
        " - テストデータセットの値を予測し、\n",
        " - 訓練、テスト、予測の系列をプロットし、\n",
        " - 予測の平均絶対誤差を計算するために使用されます。\n"
      ],
      "metadata": {
        "id": "Y1q6EI-h6tBi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHJ4n72wrc8h"
      },
      "source": [
        "\n",
        "状態空間モデルの指数平滑化もRのets関数と同様に自動化することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEYFQCvrrc8i"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.ets import AutoETS\n",
        "forecaster = AutoETS(auto=True, sp=12, n_jobs=-1)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6_kyW2Vrc8h"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import AutoETS class from sktime.forecasting.ets module\n",
        "from sktime.forecasting.ets import AutoETS\n",
        "\n",
        "# forecasterオブジェクトをauto=True, sp=12, n_jobs=-1で初期化する。\n",
        "forecaster = AutoETS(auto=True, sp=12, n_jobs=-1) # フォアキャスター・オブジェクトを auto=True, sp=12, n_jobs=-1 で初期化します。\n",
        "\n",
        "# 学習データに対してモデルをフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# テストセットの値を予測する\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# シリーズのプロット\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測の平均絶対誤差パーセンテージを計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測の平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  Import AutoETS class from sktime.forecasting.ets module\n",
        "- from sktime.forecasting.ets import AutoETS\n",
        "- \n",
        "-  forecasterオブジェクトをauto=True, sp=12, n_jobs=-1で初期化する。\n",
        "- forecaster = AutoETS(auto=True, sp=12, n_jobs=-1) # フォアキャスター・オブジェク- トを auto=True, sp=12, n_jobs=-1 で初期化します。\n",
        "- \n",
        "-  学習データに対してモデルをフィットさせる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  テストセットの値を予測する\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  シリーズのプロット\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "-  予測の平均絶対誤差パーセンテージを計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測の平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jf0Vsp2U7Xfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、まず sktime.forecasting.ets モジュールから AutoETS クラスをインポートしています。\n",
        "- 次に、AutoETS クラスのインスタンスを作成し、変数 forecaster に格納します。\n",
        "AutoETS クラスは、3 つのパラメータで初期化されます。\n",
        "\n",
        " - auto : これを True にすると、ETS, ETSX, ETSM, ETSY の中から自動的に最適なモデルを選択します。\n",
        " - sp : 季節性期間の数\n",
        " - n_jobs : 実行する並列ジョブの数。-1 はすべてのプロセッサを使うことを意味する。\n",
        "- 次に、forecasterオブジェクトのfitメソッドを使って、学習データにモデルを当てはめます。\n",
        "- forecaster オブジェクトの predict メソッドを用いて、テストセットの値を予測し、変数 y_pred に格納します。\n",
        "- y_train, y_test, y_pred データとそれらのラベルを渡し、系列をプロットするために sktime.utils.plotting モジュールの plot_series 関数を使用します。\n",
        "- 最後に、sktime.performance_metrics.forecastingモジュールのmean_absolute_percentage_error関数を使って、予測の平均絶対誤差を計算します。\n",
        "- このコードスニペットは、トレーニングデータセットにAutoETSクラスを使用してETS、ETSX、ETSM、ETSYの中から最適なモデルをあてはめ、テストデータセットの値を予測し、トレーニング、テスト、予測した系列をプロットし、予測の平均絶対誤差を計算するために使用します。\n",
        "\n"
      ],
      "metadata": {
        "id": "3L38aAaV7ko8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fuu3K5Sirc8i"
      },
      "outputs": [],
      "source": [
        "# todo: explain Theta; explain how to get theta-lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "7i9sN-TNrc8i"
      },
      "source": [
        "### **2.3.2 ARIMAとautoARIMA**\n",
        "- sktimeはARIMAクラスのモデルに対してpmdarimaのインターフェイスを提供します。\n",
        "- パラメータを設定した古典的なARIMAモデルについては、ARIMAフォアキャストを使用してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JmI0aS9rc8i"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.arima import ARIMA\n",
        "forecaster = ARIMA(\n",
        "    order=(1, 1, 0), seasonal_order=(0, 1, 0, 12), suppress_warnings=True\n",
        ")\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS8WIqG6rc8i"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sktime.forecasting.arimaモジュールからARIMAクラスをインポートする。\n",
        "from sktime.forecasting.arima import ARIMA\n",
        "\n",
        "# 指定された順序と季節順序のパラメータでARIMAモデルのインスタンスを作成する。\n",
        "# suppress_warningsをTrueに設定し、モデルフィッティング中の警告メッセージを出さないようにする。\n",
        "forecaster = ARIMA(\n",
        "order=(1, 1, 0), seasonal_order=(0, 1, 0, 12), suppress_warnings=True\n",
        ")\n",
        "\n",
        "# 学習データにモデルを当てはめる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# フィットしたモデルを用いて、予測地平線の予測を行う\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 予測値をトレーニングデータとテストデータに並べてプロットします。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算する。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  sktime.forecasting.arimaモジュールからARIMAクラスをインポートする。\n",
        "- from sktime.forecasting.arima import ARIMA\n",
        "- \n",
        "-  指定された順序と季節順序のパラメータでARIMAモデルのインスタンスを作成する。\n",
        "-  suppress_warningsをTrueに設定し、モデルフィッティング中の警告メッセージを出さ- ないようにする。\n",
        "- forecaster = ARIMA(\n",
        "- order=(1, 1, 0), seasonal_order=(0, 1, 0, 12), suppress_warnings=True\n",
        "- )\n",
        "- \n",
        "-  学習データにモデルを当てはめる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  フィットしたモデルを用いて、予測地平線の予測を行う\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  予測値をトレーニングデータとテストデータに並べてプロットします。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "-  予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "0KfqOpEHB1xf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 上記のコードはsktime.forecasting.arimaモジュールのARIMAクラスを使って、指定された次数パラメータと季節次数パラメータでARIMAモデルのインスタンスを生成しています。\n",
        "- そして、このモデルを学習データ(y_train)にフィットさせ、それを使って予測地平(fh)の予測を行っています。\n",
        "- 予測値はplot_series関数で学習データとテストデータとともにプロットされ、予測値の平均絶対誤差はmean_absolute_percentage_error関数で計算されます。- suppress_warningsパラメータをTrueに設定することで、モデルフィッティング中に警告メッセージが表示されないようにします。\n",
        "- また、コードには各ステップを説明するためのコメントも含まれています。\n",
        "\n"
      ],
      "metadata": {
        "id": "IvEkgMNsCDRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードはsktime.forecasting.arimaモジュールのARIMAクラスを使って、指定された順序パラメータと季節順序パラメータを持つARIMAモデルのインスタンスを作成します。\n",
        "- そして、このモデルを学習データ(y_train)にフィットさせ、それを使って予測地平(fh)の予測を行います。\n",
        "- 予測値はplot_series関数で学習データとテストデータとともにプロットされ、予測値の平均絶対誤差はmean_absolute_percentage_error関数で計算されます。- suppress_warnings パラメータを True に設定すると、モデルフィッティング中に警告メッセージが表示されなくなります。\n",
        "\n"
      ],
      "metadata": {
        "id": "oSCkhWbsBhJg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me35-vnArc8j"
      },
      "source": [
        "AutoARIMAは、最適なpdqパラメータを自動的に取得する自動調整型ARIMAバリアントです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXoLawnTrc8j"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.arima import AutoARIMA\n",
        "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIkCq01vrc8j"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sktime.forecasting.arima モジュールからAutoARIMA クラスをインポートする。\n",
        "from sktime.forecasting.arima import AutoARIMA\n",
        "\n",
        "# 指定した季節周期で AutoARIMA モデルのインスタンスを作成する。\n",
        "# suppress_warnings を True に設定し、モデルフィッティングの際に警告メッセージが出ないようにする。\n",
        "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
        "\n",
        "# 学習データに対してモデルをフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# フィットしたモデルを用いて、予測地平線の予測を行う\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 予測値をトレーニングデータとテストデータに並べてプロットします。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算する。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  sktime.forecasting.arima モジュールからAutoARIMA クラスをインポートする。\n",
        "- from sktime.forecasting.arima import AutoARIMA\n",
        "- \n",
        "-  指定した季節周期で AutoARIMA モデルのインスタンスを作成する。\n",
        "-  suppress_warnings を True に設定し、モデルフィッティングの際に警告メッセージが- 出ないようにする。\n",
        "- forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
        "- \n",
        "-  学習データに対してモデルをフィットさせる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  フィットしたモデルを用いて、予測地平線の予測を行う\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  予測値をトレーニングデータとテストデータに並べてプロットします。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "-  予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "0spIukcNChoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 上記のコードは、sktime.forecasting.arimaモジュールのAutoARIMAクラスを使用して、指定された季節期間とsuppress_warningsパラメータでAutoARIMAモデルのインスタンスを生成しています。\n",
        "- そして、このモデルを学習データ(y_train)に適合させ、それを使って予測地平(fh)の予測を行います。\n",
        "- 予測値はplot_series関数で学習データとテストデータと共にプロットされ、予測値の平均絶対誤差はmean_absolute_percentage_error関数で計算されます。\n",
        "- suppress_warningsパラメータをTrueに設定することで、モデルフィッティング中に警告メッセージが表示されないようにします。\n",
        "- また、コードには各ステップを説明するためのコメントが含まれています。\n",
        "- AutoARIMAモデルはARIMAモデルの自動化バージョンで、グリッドサーチとステップワイズセレクションを組み合わせて最適なp、q、dのパラメータを自動で見つけます。\n",
        "\n"
      ],
      "metadata": {
        "id": "hmyfUYihCr0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "要約：\n",
        "- AutoARIMAモデルは、物事の予測をするのに最適な方法を見つけ出してくれる魔法のロボットのようなものです。\n",
        "- それは、我々が自分でやらなくても、ケーキを作るのに最適な材料を見つけ出すことができるロボットのようなものである。\n",
        "- ARIMAモデルは、物事の予測をするためのレシピのようなものです。\n",
        "- p、q、dの3つの材料があり、それぞれの材料の適切な量を把握して、できるだけ正確な予測をする必要があります。\n",
        "- AutoARIMAモデルは、私たちが自分で計算しなくても、各材料の適切な分量を計算してくれるロボットシェフのようなものです。\n",
        "- それは、私たちが自分でやらなくても、ケーキを作るのに最適な材料を考えてくれるロボットのようなものです。\n",
        "- AutoARIMAモデルの利点は、時間と労力を節約できることです。私たちが自分で材料を考える代わりに、ロボットシェフがケーキを作ってくれるようなものです。\n",
        "- 一方、AutoARIMAモデルの欠点は、常に最適な材料が見つかるとは限らないことです。\n",
        "- 時には、ロボットシェフが間違えて、ケーキに砂糖を入れすぎてしまうこともあるかもしれません。\n",
        "- AutoARIMAモデルのインパクトは、より正確かつ簡単に予測を行うことができることです。\n",
        "- 私たちが自分でやらなくても、おいしいケーキを作ってくれるロボットシェフがいるようなものです。\n",
        "\n"
      ],
      "metadata": {
        "id": "Ep6BWH69DX60"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qwFn1Ubrc8j"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.arima import AutoARIMA\n",
        "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_pred, y_test)\n",
        "# to obtain the fitted parameters, run\n",
        "forecaster.get_fitted_params()\n",
        "# should these not include pdq?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RyG3LAIrc8k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3Z8cdx7rc8k"
      },
      "source": [
        "### **2.3.3 BATSとTBATS**\n",
        "sktimeはtbatsパッケージのBATSとTBATSのインターフェイスを提供します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYS8LZkqrc8k"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.bats import BATS\n",
        "forecaster = BATS(sp=12, use_trend=True, use_box_cox=False)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gB9EmggBrc8k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sktime.forecasting.arima モジュールからAutoARIMA クラスをインポートする。\n",
        "from sktime.forecasting.arima import AutoARIMA\n",
        "\n",
        "# 指定した季節周期で AutoARIMA モデルのインスタンスを作成する。\n",
        "# suppress_warnings を True に設定し、モデルフィッティングの際に警告メッセージが出ないようにする。\n",
        "forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
        "\n",
        "# 学習データに対してモデルをフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# フィットしたモデルを使用して、予測地平線の予測を行う\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 予測値をトレーニングデータとテストデータに並べてプロットします。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_pred, y_test)\n",
        "\n",
        "# フィットしたパラメータを取得\n",
        "params = forecaster.get_fitted_params()\n",
        "print(params) # p,d,q と seasonal_p, seasonal_d, seasonal_q の値を表示する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  sktime.forecasting.arima モジュールからAutoARIMA クラスをインポートする。\n",
        "- from sktime.forecasting.arima import AutoARIMA\n",
        "- \n",
        "- 指定した季節周期で AutoARIMA モデルのインスタンスを作成する。\n",
        "-  suppress_warnings を True に設定し、モデルフィッティングの際に警告メッセージが 出ないようにする。\n",
        "- forecaster = AutoARIMA(sp=12, suppress_warnings=True)\n",
        "- \n",
        "-  学習データに対してモデルをフィットさせる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  フィットしたモデルを使用して、予測地平線の予測を行う\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  予測値をトレーニングデータとテストデータに並べてプロットします。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "-  予測値の平均絶対誤差を計算する\n",
        "- mean_absolute_percentage_error(y_pred, y_test)\n",
        "- \n",
        "-  フィットしたパラメータを取得\n",
        "- params = forecaster.get_fitted_params()\n",
        "- print(params) # p,d,q と seasonal_p, seasonal_d, seasonal_q の値を表示する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RhGXZlzGD4Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 上記のコードは、sktime.forecasting.arimaモジュールのAutoARIMAクラスを使用して、指定された季節期間とsuppress_warningsパラメータでAutoARIMAモデルのインスタンスを生成しています。\n",
        "- そして、このモデルを学習データ(y_train)に適合させ、それを使って予測地平(fh)の予測を行います。\n",
        "- 予測値は plot_series 関数を用いて訓練データとテストデータと共にプロットされ、予測値の平均絶対誤差は y_pred と y_test を正しい順番にして mean_absolute_percentage_error 関数を用いて算出されます。suppress_warningsパラメータをTrueに設定することで、モデルフィッティング中に警告メッセージが表示されないようにします。\n",
        "- このコードには、フィットしたパラメータを得るためのget_fitted_params()関数も含まれています。\n",
        "- これはフィットしたモデルのp、d、qとseasonal_p、seasonal_d、seasonal_qの値を表示します。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "要約：\n",
        "- コードは、物事の予測をするのに最適な方法を見つけ出し、それが何をしたかを教えてくれる魔法のロボットのようなものです。\n",
        "- それは、ケーキを作るのに最適な材料を見つけ出し、ケーキの中に何を入れたかを教えてくれるロボットのようなものだ。\n",
        "- AutoARIMAモデルは、物事について予測をするのに最適な方法を見つけ出すことができる魔法のロボットのようなものです。\n",
        "- 私たちが自分でやらなくても、ケーキを作るのに最適な材料を導き出してくれるロボットのようなものです。\n",
        "- コードはモデルを学習データに適合させます。\n",
        " - これは、ロボットシェフにケーキを作るために必要な材料を与えるようなものです。\n",
        "- このコードは、適合したモデルを用いて、予測期間の予測を行います。\n",
        " - これは、ロボットシェフにケーキを作るように依頼するようなものです。\n",
        "- このコードは、予測値を学習データとテストデータとともにプロットします。\n",
        " - これは、ロボットシェフが作ったケーキと本物のケーキを並べて見せるようなものです。\n",
        "- 予測値の平均絶対誤差を計算する。\n",
        " - これは、ロボットシェフのケーキが本物のケーキと同じくらいおいしいかどうかを確認するようなものである。\n",
        " - これは、ロボットシェフにケーキに入れる材料を聞くようなものです。\n",
        "- suppress_warningsパラメータは、\n",
        " - ロボットシェフがケーキを作るときに鳴るうるさいビープ音を消すスイッチのようなものである。\n",
        "- AutoARIMAモデルのインパクトは、より正確に、より簡単に予測を行うことができることです。\n",
        "- 私たちが自分でやらなくても、おいしいケーキを作ってくれるロボットシェフがいて、その成果を教えてくれるようなものです。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YtrSYzgID1dz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ISw92aJrc8k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sktimeライブラリからTBATSモデルをインポートする\n",
        "from sktime.forecasting.tbats import TBATS\n",
        "\n",
        "# 特定のパラメータを持つTBATSモデルのインスタンスを作成する。\n",
        "# spは季節期間を表し、この場合は12に設定されている。\n",
        "# use_trend=Trueはモデルが予測においてトレンド成分を考慮することを示します。\n",
        "# use_box_cox=False は、モデルがBox-Cox変換を使用しないことを示す。\n",
        "forecaster = TBATS(sp=12, use_trend=True, use_box_cox=False)\n",
        "\n",
        "# モデルを学習データにフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# 与えられた予測地平について予測するためにモデルを使用します。\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 学習データ、テストデータ、そして予測値をプロットする\n",
        "# それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"というラベルでプロット。\n",
        "\n",
        "# テストデータと予測値の間の平均絶対誤差を計算する\n",
        "# symmetric=False は誤差が対称的でないことを示す\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと予測値の間の平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- sktimeライブラリからTBATSモデルをインポートする\n",
        "- from sktime.forecasting.tbats import TBATS\n",
        "- \n",
        "-  特定のパラメータを持つTBATSモデルのインスタンスを作成する。\n",
        "-  spは季節期間を表し、この場合は12に設定されている。\n",
        "-  use_trend=Trueはモデルが予測においてトレンド成分を考慮することを示します。\n",
        "-  use_box_cox=False は、モデルがBox-Cox変換を使用しないことを示す。\n",
        "- forecaster = TBATS(sp=12, use_trend=True, use_box_cox=False)\n",
        "- \n",
        "-  モデルを学習データにフィットさせる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  与えられた予測地平について予測するためにモデルを使用します。\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  学習データ、テストデータ、そして予測値をプロットする\n",
        "-  それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"というラベルでプロット。\n",
        "\n",
        "# テストデータと予測値の間の平均絶対誤差を計算する\n",
        "# symmetric=False は誤差が対称的でないことを示す\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと予測値の間の平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2TVkJgAtN8Ez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnJP4X1Urc8l"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.tbats import TBATS\n",
        "forecaster = TBATS(sp=12, use_trend=True, use_box_cox=False)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- 実際のデータセット y_train, y_test, y_pred, fh と関数 plot_series と mean_absolute_percentage_error は、このコードを実行する前に定義しインポートする必要があることに注意しましょう。\n",
        "- また、季節性期間の値 'sp' は慎重に選択する必要があり、それはデータと問題のコンテキストに基づいている必要があります、\n",
        "- それはまた、結果をプロットし、エラーメトリックスを計算することによって、モデルのパフォーマンスをチェックすることが重要です。\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- このコードは時系列を予測するためにsktimeライブラリのTBATS (Tripple Exponential Smoothing with Additive Trend and Seasonality) メソッドを使用します。\n",
        "- TBATSモデルは季節性周期12（sp=12）で初期化され、トレンド成分（use_trend=True）を使用しますが、Box-Cox変換は使用しません（use_box_cox=False）。\n",
        "\n",
        "- このモデルは、fit()メソッドを用いて学習データ(y_train)にフィットされます。- predict() メソッドは、与えられた予測水平線 (fh) に対する予測を生成するために使用され、これらの予測は変数 y_pred に格納されます。\n",
        "\n",
        "- plot_series() 関数は、\n",
        " - 学習データ (y_train)、\n",
        " - テストデータ (y_test)、\n",
        " - 予測値 (y_pred) を、\n",
        "- それぞれ \"y_train\", \"y_test\", \"y_pred\" というラベルをつけてプロットするために使用される。\n",
        "\n",
        "- 最後に mean_absolute_percentage_error() 関数を使用して、テストデータと予測値の間の平均絶対誤差を計算する。\n",
        " - symmetric=False 引数は誤差が対称的であってはならないことを示します。\n",
        "\n",
        "- 実際のデータセット y_train, y_test, y_pred, fh と関数 plot_series と mean_absolute_percentage_error は、\n",
        " - このコードを実行する前に定義しインポートする必要があることに注意してください。\n",
        "- また、季節性期間の値 'sp' は慎重に選択する必要があり、それはデータと問題のコンテキストに基づいている必要があります、\n",
        "- それはまた、結果をプロットし、エラーメトリックスを計算することによって、モデルのパフォーマンスを確認することが重要です。\n",
        "\n"
      ],
      "metadata": {
        "id": "W49JKGmXNPWg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgma81X_rc8l"
      },
      "source": [
        "### **2.3.4 フェイスブックプロフェット**\n",
        "sktimeは、Facebookによるfbprophetへのインタフェースを提供します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oInFO8Orc8l"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.fbprophet import Prophet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivFygTPNrc8l"
      },
      "source": [
        "現在のインターフェースでは、期間インデックスをサポートしておらず、pd.DatetimeIndexのみです。sktime.DatetimeIndexを寄贈することで、これを改善することを検討してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoCSjVjhrc8l"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.fbprophet import Prophet\n",
        "# Convert index to pd.DatetimeIndex\n",
        "z = y.copy()\n",
        "z = z.to_timestamp(freq=\"M\")\n",
        "z_train, z_test = temporal_train_test_split(z, test_size=36)\n",
        "\n",
        "forecaster = Prophet(\n",
        "    seasonality_mode=\"multiplicative\",\n",
        "    n_changepoints=int(len(y_train) / 12),\n",
        "    add_country_holidays={\"country_name\": \"Germany\"},\n",
        "    yearly_seasonality=True,\n",
        "    weekly_seasonality=False,\n",
        "    daily_seasonality=False,\n",
        ")\n",
        "\n",
        "forecaster.fit(z_train)\n",
        "y_pred = forecaster.predict(fh.to_relative(cutoff=y_train.index[-1]))\n",
        "y_pred.index = y_test.index\n",
        "\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ut-zbYcrc8m"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sktimeライブラリからProphetモデルをインポートします。\n",
        "from sktime.forecasting.fbprophet import Prophet\n",
        "\n",
        "# yのインデックスを月次頻度でpandasのdatetimeインデックスに変換します。\n",
        "z = y.copy()\n",
        "z = z.to_timestamp(freq=\"M\")\n",
        "\n",
        "# データをトレーニングセットとテストセットに分割する\n",
        "z_train, z_test = temporal_train_test_split(z, test_size=36)\n",
        "\n",
        "# 特定のパラメータでProphetモデルのインスタンスを作成する\n",
        "# seasonality_mode=\"multiplicative\" は、モデルが乗法的な季節性を用いることを示します。\n",
        "# n_changepoints=int(len(y_train) / 12) は，y_train の長さを 12 で割った値を変化点の数として設定することを示します．\n",
        "# add_country_holidays={\"country_name\":「ドイツ\"} は，ドイツの祝日を考慮することを意味します．\n",
        "# yearly_seasonality=True は，1年ごとの季節性を考慮することを示す．\n",
        "# weekly_seasonality=False は、モデルが週ごとの季節性を考慮しないことを示します。\n",
        "# daily_seasonality=Falseは、日ごとの季節性を考慮しないことを示す。\n",
        "forecaster = Prophet(\n",
        "seasonality_mode=\"multiplicative\",\n",
        "n_changepoints=int(len(y_train) / 12),\n",
        "add_country_holidays={\"country_name\":\"Germany\"},\n",
        "yearly_seasonality=True,\n",
        "weekly_seasonality=False,\n",
        "daily_seasonality=False\n",
        ")\n",
        "\n",
        "# 学習データにモデルを当てはめる\n",
        "forecaster.fit(z_train)\n",
        "\n",
        "# 与えられた予測地平について予測するためにモデルを使用します。\n",
        "y_pred = forecaster.predict(fh.to_relative(cutoff=y_train.index[-1]))\n",
        "\n",
        "# 予測値のインデックスをテストインデックスに設定する\n",
        "y_pred.index = y_test.index\n",
        "\n",
        "# 学習データ、テストデータ、予測値のプロット\n",
        "# それぞれ \"y_train\", \"y_test\", \"y_pred\" というラベルを付けてプロットする。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# テストデータと予測値の間の平均絶対誤差を計算する\n",
        "# symmetric=False は誤差が対称的でないことを示す\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと予測値の間の平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  sktimeライブラリからProphetモデルをインポートします。\n",
        "- from sktime.forecasting.fbprophet import Prophet\n",
        "- \n",
        "-  yのインデックスを月次頻度でpandasのdatetimeインデックスに変換します。\n",
        "- z = y.copy()\n",
        "- z = z.to_timestamp(freq=\"M\")\n",
        "- \n",
        "-  データをトレーニングセットとテストセットに分割する\n",
        "- z_train, z_test = temporal_train_test_split(z, test_size=36)\n",
        "- \n",
        "-  特定のパラメータでProphetモデルのインスタンスを作成する\n",
        "-  seasonality_mode=\"multiplicative\" は、モデルが乗法的な季節性を用いることを示し- ます。\n",
        "-  n_changepoints=int(len(y_train) / 12) は，y_train の長さを 12 で割った値を変化- 点の数として設定することを示します．\n",
        "-  add_country_holidays={\"country_name\":「ドイツ\"} は，ドイツの祝日を考慮すること- を意味します．\n",
        "-  yearly_seasonality=True は，1年ごとの季節性を考慮することを示す．\n",
        "-  weekly_seasonality=False は、モデルが週ごとの季節性を考慮しないことを示しま- す。\n",
        "-  daily_seasonality=Falseは、日ごとの季節性を考慮しないことを示す。\n",
        "- forecaster = Prophet(\n",
        "- seasonality_mode=\"multiplicative\",\n",
        "- n_changepoints=int(len(y_train) / 12),\n",
        "- add_country_holidays={\"country_name\":\"Germany\"},\n",
        "- yearly_seasonality=True,\n",
        "- weekly_seasonality=False,\n",
        "- daily_seasonality=False\n",
        "- )\n",
        "- \n",
        "-  学習データにモデルを当てはめる\n",
        "- forecaster.fit(z_train)\n",
        "- \n",
        "-  与えられた予測地平について予測するためにモデルを使用します。\n",
        "- y_pred = forecaster.predict(fh.to_relative(cutoff=y_train.index[-1]))\n",
        "- \n",
        "-  予測値のインデックスをテストインデックスに設定する\n",
        "- y_pred.index = y_test.index\n",
        "- \n",
        "-  学習データ、テストデータ、予測値のプロット\n",
        "-  それぞれ \"y_train\", \"y_test\", \"y_pred\" というラベルを付けてプロットする。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "-  テストデータと予測値の間の平均絶対誤差を計算する\n",
        "-  symmetric=False は誤差が対称的でないことを示す\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと\n",
        "- 予測値の間の平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ISARpiC5PI2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、sktimeライブラリのProphetモデルを使って時系列を予測します。\n",
        "- Prophetモデルは、Facebookが開発したProphetライブラリのラッパーで、加法的あるいは乗法的な季節性、トレンド、休日を含む時系列予測に最適化されています。\n",
        "- Prophetモデルは、季節性モード、変化点数、休日、季節性などの特定のパラメータで初期化されます。\n",
        "\n",
        "- このコードでは、データセット'y'を月別頻度のpandas datetimeインデックスに変換し、トレーニングセットとテストセットに分割しています。\n",
        "- 次に、モデルを学習データに適合させ、与えられた予測地平について予測するために使用します。\n",
        "- 予測値は、訓練データとテストデータとともにプロットされます。また、テストデータと予測値の間の平均絶対誤差率も計算されます。\n",
        "\n",
        "- Prophetモデルは、強い季節パターンや休日を持つ時系列データを予測したい場合に有効です。\n",
        "- また、欠損データ、大きな外れ値、複数のチェンジポイントを扱いたい場合にもProphetモデルは有効です。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TnzhuWnXPcPL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZGXv7S8rc8m"
      },
      "source": [
        "2.3.5 状態空間モデル(構造的時系列)\n",
        "statsmodelsのUnobservedComponentsクラスを使って、状態空間モデルによる予測値を生成することもできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx3JEem0rc8m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MYUm6JZrc8m"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.structural import UnobservedComponents\n",
        "# We can model seasonality using Fourier modes as in the Prophet model.\n",
        "forecaster = UnobservedComponents(\n",
        "    level=\"local linear trend\", freq_seasonal=[{\"period\": 12, \"harmonics\": 10}]\n",
        ")\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "nB87Onzprc8m"
      },
      "source": [
        "### **2.3.6 StatsForecastからのAutoARIMA**\n",
        "- sktimeはStatsForecastのAutoARIMAクラスモデルとのインターフェイスを提供します。 \n",
        "- AutoARIMAは、最適なpdqパラメータを自動的に得る、自動チューニングされたARIMA変種です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5yQKUnqrc8n"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.statsforecast import StatsForecastAutoARIMA\n",
        "forecaster = StatsForecastAutoARIMA(sp=12)\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_pred, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sktimeライブラリからUnobservedComponentsモデルをインポートする。\n",
        "from sktime.forecasting.structural import UnobservedComponents\n",
        "\n",
        "# 特定のパラメータを持つUnobservedComponentsモデルのインスタンスを作成する。\n",
        "# level=\"local linear trend\" は、モデルが局所的な線形トレンドを考慮することを示す。\n",
        "# freq_seasonal=[{\"period\": 12, \"harmonics\": 10}] は、モデルがフーリエモードを使用して、12周期と10ハーモニックの季節性をモデル化することを示す。\n",
        "forecaster = UnobservedComponents(\n",
        "level=\"local linear trend\", freq_seasonal=[{\"period\": 12, \"harmonics\": 10}]\n",
        ")\n",
        "\n",
        "# 学習データにモデルを当てはめる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# 与えられた予測地平について予測するためにモデルを使用します。\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 学習データ、テストデータ、そして予測値をプロットする\n",
        "# それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"というラベルでプロットする。\n",
        "\n",
        "# テストデータと予測値の間の平均絶対誤差を計算する\n",
        "# symmetric=False は誤差が対称的でないことを示す\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと予測値の間の平均絶対誤差を計算する。\n"
      ],
      "metadata": {
        "id": "KiZy_ofZQQPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "-  sktimeライブラリからUnobservedComponentsモデルをインポートする。\n",
        "- from sktime.forecasting.structural import UnobservedComponents\n",
        "- \n",
        "-  特定のパラメータを持つUnobservedComponentsモデルのインスタンスを作成する。\n",
        "-  level=\"local linear trend\" は、モデルが局所的な線形トレンドを考慮することを示- す。\n",
        "-  freq_seasonal=[{\"period\": 12, \"harmonics\": 10}] は、モデルがフーリエモードを使- 用して、12周期と10ハーモニックの季節性をモデル化することを示す。\n",
        "- forecaster = UnobservedComponents(\n",
        "- level=\"local linear trend\", freq_seasonal=[{\"period\": 12, \"harmonics\": 10}].\n",
        "- )\n",
        "- \n",
        "-  学習データにモデルを当てはめる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  与えられた予測地平について予測するためにモデルを使用します。\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  学習データ、テストデータ、そして予測値をプロットする\n",
        "-  それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # - 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"という- ラベルでプロットする。\n",
        "- \n",
        "-  テストデータと予測値の間の平均絶対誤差を計算する\n",
        "-  symmetric=False は誤差が対称的でないことを示す\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと- 予測値の間の平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AtaxxWotrc8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、時系列を予測するためにsktimeライブラリのUnobservedComponentsモデルを使用します。\n",
        "- UnobservedComponentsモデルは状態空間モデルであり、時系列をトレンド、季節、不規則成分に分解することができます。\n",
        "\n",
        "- このコードでは、UnobservedComponentsモデルは、レベルや頻度季節などの特定のパラメータで初期化されます。\n",
        "- そして、このモデルを学習データに適合させ、与えられた予測地平について予測するために使用します。\n",
        "- そして、予測値は訓練データとテストデータとともにプロットされます。また、テストデータと予測値の間の平均絶対誤差率も計算されます。\n",
        "\n",
        "- UnobservedComponentsモデルは、時系列をトレンド、季節性、不規則性などの基礎的な構成要素に分解したい場合に便利です。\n",
        "- UnobservedComponents モデルは、時系列中の欠損データや複数の季節性を処理したい場合にも有用である。\n",
        "- UnobservedComponentsモデルは，加法的，乗法的，あるいは皆無といった異なるタイプのトレンドと季節性を持つ時系列も扱うことができる．\n",
        "\n"
      ],
      "metadata": {
        "id": "E7NPquj9Qi32"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq1p25kUrc8n"
      },
      "source": [
        "\n",
        "\n",
        "### **3.高度な構成パターン - パイプライン、リダクション、autoML、その他**\n",
        "- sktimeは、より単純なコンポーネントからフォーキャストを作成するために、多くの高度な構成パターンをサポートしています。\n",
        "\n",
        "- Reduction \n",
        " - scikit-learnのリグレッサーのような「より単純な」科学的タイプの推定量からフォーキャスターを構築する。\n",
        " - 一般的な例としては、ローリングウィンドウによる特徴量/ラベルの集計、別名「直接削減戦略」です。\n",
        "- チューニング \n",
        " - データドリブンな方法でフォーキャスターのハイパーパラメータの値を決定します。  \n",
        " - 一般的な例としては、訓練/テスト分割の時間的にローリングした再サンプリングでのグリッド検索があります。\n",
        "- パイプライン化 \n",
        " - 1つのフォアキャスターを得るために、フォアキャスターとトランスフォーマーを連結すること。\n",
        "  - 一般的な例としては、トレンド除去や季節性除去を行った後に予測を行うもので、\n",
        "  - この例として一般的な「STLフォーキャスター」があります。\n",
        "- 自動化されたモデル選択として知られるAutoML \n",
        " - ハイパーパラメーターだけでなく、予測戦略全体を選択するための自動チューニング戦略を使用します。\n",
        " - 一般的な例としては、オンライン・マルチプレクサーのチューニングが挙げられます。\n",
        "- 説明のために、以下のすべての推定器は基本的な予測ワークフローで紹介されますが、統一されたsktimeインターフェース（セクション1参照）のもと、高度な予測および評価ワークフローもサポートしています。\n",
        "\n",
        "- 他のワークフローで使用する場合は、以下に示す例の「フォーキャスター仕様ブロック」（\"forecaster=\"）をフォーキャスター仕様ブロックに置き換えるだけでよい。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "概要\n",
        "\n",
        "- テキストでは、フォアキャスター（将来の出来事や価値を予測するための道具）を作るための様々な方法について話しています。\n",
        "- 最初の方法は「リダクション」と呼ばれ、より単純なピースでパズルを組み立てるようなものである。\n",
        "- 2つ目は「チューニング」と呼ばれる方法で、機械をより良く動かすための微調整のようなものです。\n",
        "- 3つ目の方法は「パイプライン」と呼ばれ、異なるツールをつなげて1つの大きなツールにするようなものです。\n",
        "- 4つ目は「AutoML」と呼ばれる手法で、ロボットが最適なツールや設定を選んでくれるようなものです。\n",
        "- また、本文中では、これらの方法はさまざまな方法で使用できること、そして、提供された例はその方法のひとつに過ぎないことを述べています。\n",
        "\n"
      ],
      "metadata": {
        "id": "lIi1J0k8zTzY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qzMj_7qrc8n"
      },
      "outputs": [],
      "source": [
        "# imports necessary for this chapter\n",
        "from sktime.datasets import load_airline\n",
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
        "from sktime.utils.plotting import plot_series\n",
        "\n",
        "# data loading for illustration (see section 1 for explanation)\n",
        "y = load_airline()\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=36)\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sktimeライブラリからStatsForecastAutoARIMAモデルをインポートします。\n",
        "from sktime.forecasting.statsforecast import StatsForecastAutoARIMA\n",
        "\n",
        "# 特定のパラメータを持つ StatsForecastAutoARIMA モデルのインスタンスを作成する。\n",
        "# sp は季節期間を表し、この場合12に設定される。\n",
        "forecaster = StatsForecastAutoARIMA(sp=12)\n",
        "\n",
        "# 学習データに対してモデルをフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# 与えられた予測地平について予測するためにモデルを使用する\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 学習データ、テストデータ、そして予測値をプロットする\n",
        "# それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"というラベルでプロットする。\n",
        "\n",
        "# 予測値とテストデータ間の平均絶対誤差を計算する。\n",
        "mean_absolute_percentage_error(y_pred, y_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NQU0j0BTRClM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  sktimeライブラリからStatsForecastAutoARIMAモデルをインポートします。\n",
        "- from sktime.forecasting.statsforecast import StatsForecastAutoARIMA\n",
        "- \n",
        "-  特定のパラメータを持つ StatsForecastAutoARIMA モデルのインスタンスを作成する。\n",
        "-  sp は季節期間を表し、この場合12に設定される。\n",
        "- forecaster = StatsForecastAutoARIMA(sp=12)\n",
        "- \n",
        "-  学習データに対してモデルをフィットさせる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  与えられた予測地平について予測するためにモデルを使用する\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  学習データ、テストデータ、そして予測値をプロットする\n",
        "-  それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # - 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"という- ラベルでプロットする。\n",
        "- \n",
        "-  予測値とテストデータ間の平均絶対誤差を計算する。\n",
        "mean_absolute_percentage_error(y_pred, y_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n5svnrQORIQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、時系列を予測するためにsktimeライブラリのStatsForecastAutoARIMAモデルを使っています。\n",
        "- StatsForecastAutoARIMAモデルはstatsmodelsライブラリのラッパーで、auto_arima関数を使ってARIMAモデルのパラメータを最適化し、時系列を予測するものです。\n",
        "\n",
        "- このコードでは、StatsForecastAutoARIMAモデルは特定の季節期間12で初期化されます。\n",
        "- そして、このモデルを学習データに適合させ、与えられた予測地平について予測するために使用します。\n",
        "- そして、予測値がトレーニングデータとテストデータとともにプロットされます。\n",
        "- 予測値とテストデータの間の平均絶対誤差率も計算されます。\n",
        "\n",
        "- StatsForecastAutoARIMAモデルは、ARIMAモデルを使用して時系列データを予測し、モデルのパラメータを自動的に最適化したい場合に便利です。\n",
        "- StatsForecastAutoARIMAモデルは、時系列の欠損データや複数の季節性を処理したい場合にも有効です。\n",
        "- StatsForecastAutoARIMAモデルは、加法性や季節性など、異なるタイプのトレンドや季節性を持つ時系列も扱うことができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "PCmgOYZkRTf9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgCS0qbtrc8o"
      },
      "source": [
        "\n",
        "### **3.1 削減：予測から回帰へ**\n",
        "- sktimeはメタ推定を提供し、任意のscikit-learn推定量を予測に使用することができる。\n",
        "\n",
        "- モジュール式でscikit-learnと互換性があり、予測問題を解決するためにscikit-learnのリグレッサーを簡単に適用することができます。\n",
        "- パラメトリックで調整可能。窓の長さや予測を生成する戦略などのハイパーパラメータを調整することができる。\n",
        "- 適応型：scikit-learnの推定インターフェースを予測者のインターフェースに適応させ、モデルを調整し適切に評価できるようにする。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **概要**\n",
        "\n",
        "- sktimeは、任意のscikit-learnの推定量を予測に使う方法を提供し、予測問題を解決するために、任意のscikit-learnリグレッサを簡単に適用できるようにする。\n",
        "- この方法はモジュール化されており、scikit-learnと互換性があるため、使いやすく理解しやすい。\n",
        "- この方法はパラメトリックです。つまり、窓の長さや予測を生成するストラテジーなどのハイパーパラメータを調整することが可能です。\n",
        "- この手法はアダプティブ（適応的）であり、scikit-learnの推定器インターフェースを予測者のインターフェースに適応させ、モデルを調整し適切に評価できるようにすることを意味します。\n",
        "- このメソッドは、より単純なコンポーネントからフォーキャストを作成するための高度な構成パターンに使用することができます。\n",
        "- このメソッドは、scikit-learnのリグレッサーのような「より単純な」科学的タイプの推定量からフォーキャスターを構築する、リダクションにも使用することができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "aaKaMo6S0Dpg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUO1DsZIrc8o"
      },
      "source": [
        "\n",
        "\n",
        "### **例：**\n",
        "- k-nearest neighbors regressor (sklearn KNeighborsRegressor)をforecasterに変換するための集計削減戦略を定義する予定です。\n",
        " - 合成アルゴリズムは、sktime forecasterインターフェースに準拠したオブジェクト（図：大きなロボット）であり、パラメータアクセス可能なコンポーネント（図：小さなロボット）としてリグレッサを含んでいます。\n",
        " - fitでは、複合アルゴリズムはスライディングウィンドウ戦略を用いてデータを集計し、集計されたデータにリグレッサをフィットさせます（図：左半分）。\n",
        " - 予測では、複合アルゴリズムは、予測値を得るために、最後に観測された窓とリグレッサを提示する（写真：右半分）。\n",
        "\n",
        "<img src=\"https://github.com/arumajirou/sktime/blob/main/examples/img/forecasting-to-regression-reduction.png?raw=1\" width=\"500\"/>\n",
        "\n",
        "- 以下では、forecaster scitypeのsktime estimatorを生成するショートハンド関数make_reductionを用いてコンポジットを構築しています。\n",
        "- これは、構築された scikit-learn のリグレッサ、リグレッサ、および後でハイパーパラメータとして調整可能な追加パラメータで呼び出されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **概要**\n",
        "\n",
        "- 本文は、任意のscikit-learnの推定量を予測に使えるようにする「reduction」というメソッドについて述べています。\n",
        " - これは、scikit-learnのリグレッサーをフォアキャスターに変換するために使える手法です。\n",
        " - このメソッドはモジュール式で scikit-learn と互換性があるため、予測問題を解決するために任意の scikit-learn リグレッサを簡単に適用することができます。\n",
        " - パラメトリックで調整可能なので、窓の長さやストラテジーなどの特定の設定を調整して予測を生成することができます。\n",
        " - このメソッドは適応的で、scikit-learnの推定器インターフェースを予測者のインターフェースに適応させ、モデルを適切に調整・評価できるようにすることを意味しています。\n",
        "- 本文では、このメソッドの使用方法を例として示している。\n",
        " -  この例では、k-nearest neighbors regressorとsliding window戦略を用いてデータを集計し、集計したデータにregressorを当てはめます。\n",
        "  - 予測値は、最後に観測された窓でリグレッサを提示することによって得られる。\n",
        " - このメソッドは、構築された scikit-learn のリグレッサと、後でハイパーパラメータとして調整可能な追加パラメータで呼び出されます。\n"
      ],
      "metadata": {
        "id": "1LRUUh9S0upw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfciDj-crc8o"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "regressor = KNeighborsRegressor(n_neighbors=1)\n",
        "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROLXiWy6rc8o"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sklearn ライブラリから KNeighborsRegressor モデルをインポートする。\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# make_reduction 関数を sktime ライブラリからインポートする。\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "\n",
        "# KNeighborsRegressor モデルのインスタンスを作成する。\n",
        "# n_neighbors=1 は、モデルが 1 つの最近傍を考慮することを示す。\n",
        "regressor = KNeighborsRegressor(n_neighbors=1)\n",
        "\n",
        "# KNeighborsRegressor モデルを時系列予測モデルに変換するために make_reduction 関数を使用します。\n",
        "# window_length=15 は、モデルが長さ15のウィンドウを使用して予測することを示します。\n",
        "# strategy=\"recursive\" は、モデルが再帰的な戦略を用いて予測することを示します。\n",
        "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")\n",
        "\n",
        "#モデルを学習データにフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# 与えられた予測地平について予測するためにモデルを使用します。\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 学習データ、テストデータ、そして予測値をプロットする\n",
        "# それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"というラベルでプロット。\n",
        "\n",
        "# テストデータと予測値の間の平均絶対誤差を計算する\n",
        "# symmetric=False は誤差が対称的でないことを示す\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと予測値の間の平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "-  sklearn ライブラリから KNeighborsRegressor モデルをインポートする。\n",
        "- from sklearn.neighbors import KNeighborsRegressor\n",
        "-  make_reduction 関数を sktime ライブラリからインポートする。\n",
        "- from sktime.forecasting.compose import make_reduction\n",
        "- \n",
        "-  KNeighborsRegressor モデルのインスタンスを作成する。\n",
        "-  n_neighbors=1 は、モデルが 1 つの最近傍を考慮することを示す。\n",
        "- regressor = KNeighborsRegressor(n_neighbors=1)\n",
        "- \n",
        "-  KNeighborsRegressor モデルを時系列予測モデルに変換するために make_reduction 関- 数を使用します。\n",
        "-  window_length=15 は、モデルが長さ15のウィンドウを使用して予測することを示しま- す。\n",
        "-  strategy=\"recursive\" は、モデルが再帰的な戦略を用いて予測することを示します。\n",
        "- forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")\n",
        "- \n",
        "- モデルを学習データにフィットさせる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  与えられた予測地平について予測するためにモデルを使用します。\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  学習データ、テストデータ、そして予測値をプロットする\n",
        "-  それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # - 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"という- ラベルでプロット。\n",
        "- \n",
        "-  テストデータと予測値の間の平均絶対誤差を計算する\n",
        "-  symmetric=False は誤差が対称的でないことを示す\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと予測値の間の平均絶対誤差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "IOR-mI33rc8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは sklearn ライブラリの KNeighborsRegressor モデルと sktime ライブラリの make_reduction 関数を使用して時系列を予測するものです。\n",
        "- KNeighborsRegressor モデルはノンパラメトリックモデルで、回帰問題に使用することができます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c_R0XmLBSAbc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sthJhstnrc8p"
      },
      "source": [
        "上記の例では、「再帰的」削減戦略を使用しています。他に実装されている戦略としては\n",
        "\n",
        " - \"direct\",\n",
        " - \"dirrec\"（ディレック）\n",
        " - \"multioutput \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vry5nC0urc8p"
      },
      "source": [
        "- パラメータは scikit-learn 互換の get_params 機能を使用して検査することができます（および set_params を使用して設定することができます）。\n",
        " - これにより、KNeighborsRegressor のパラメータ（estimator_etc）と、削減戦略の window_length に、調整可能かつネストされたアクセスが可能です。\n",
        "  - ユーティリティ関数の下で、これは別のアルゴリズムクラスにマッピングされているので、ストラテジーはアクセスできないことに注意してください。\n",
        "  - アルゴリズムに関するチューニングは、後述の「autoML」の項を参照。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **概要**\n",
        "\n",
        "- 上記の例では、scikit-learn のリグレッサー（KNeighborsRegressor）をフォーキャスターに変換するために「再帰的削減戦略」という方法を使用しています。\n",
        "- 他にもストラテジーがあります。\"direct\"、\"dirrec\"、\"multioutput\"。\n",
        "- 削減戦略と scikit-learn regressor のパラメータは get_params と set_params を使ってアクセス、変更することができる\n",
        "- strategy\" パラメータは、異なるアルゴリズムクラスに対応するため、直接アクセスできません。\n",
        "- アルゴリズムに関するチューニングは、\"autoML \"のセクションを参照してください。\n",
        "\n"
      ],
      "metadata": {
        "id": "HbTOAcdj1t16"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0yj-k6erc8p"
      },
      "outputs": [],
      "source": [
        "forecaster.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsNjQMtjrc8p"
      },
      "source": [
        "### **3.2 パイプライン、デトレンド、デシーズナリゼーション**\n",
        "- よくある構成モチーフはパイプライン化です\n",
        " - ：例えば、まずデータを脱季節化または脱トレンド化し、次に脱トレンド化/脱季節化した系列を予測する。\n",
        " - 予測する際には、トレンドと季節成分をデータに戻す必要があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlTyJk2Krc8s"
      },
      "source": [
        "### **3.2.1 基本的な予測パイプライン**\n",
        "- sktimeは、この種の複合モデリングのための汎用パイプラインオブジェクト、TransforemdTargetForecasterを提供します。\n",
        " - これは、任意の数の変換をフォアキャスターと連鎖させます。\n",
        " - 変換は、前処理の変換と後処理の変換のいずれかになります。\n",
        " - 以下に、前処理変換を持つフォアキャスターの例を示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **概要**\n",
        "\n",
        "- 3.2節では、パイプラインと呼ばれる、まずデータからパターン（季節性やトレンドなど）を取り除き、その後クリーンなデータを予測する一般的な予測方法について説明しました。\n",
        " - TransforemdTargetForecasterはsktimeが提供するツールで、複数の変換とフォアキャスターを連鎖させることができます。\n",
        "- 本文中にある例は、前処理変換を持つフォアキャスターのもので、これは予測の前に変換が適用されることを意味します。\n",
        "- TransforemdTargetForecaster は任意の数の変換をフォアキャスターと連結することができ、変換は前処理または後処理のいずれでも可能です。\n",
        "\n"
      ],
      "metadata": {
        "id": "Ne5nsope2R0J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQGjP-Ksrc8s"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sktimeライブラリからARIMAモデルをインポートする\n",
        "from sktime.forecasting.arima import ARIMA\n",
        "# sktimeライブラリからTransformedTargetForecasterクラスをインポートする。\n",
        "from sktime.forecasting.compose import TransformedTargetForecaster # sktimeライブラリからTransformedTargetForecasterクラスをインポートする。\n",
        "# import the Deseasonalizer class from the sktime library\n",
        "from sktime.transformations.series.detrend import Deseasonalizer\n",
        "\n",
        "# TransformedTargetForecaster クラスのインスタンスを作成する。\n",
        "# このクラスは、複数のトランスフォーマーとエスティメーターをスタックすることができる。\n",
        "# リストの最初の要素は，トランスフォーマーの名前とトランスフォーマーのインスタンスを含むタプルである．\n",
        "# この場合、Deseasonalizerクラスで、モデルは \"乗法\"、季節期間は12に設定されています。\n",
        "# リストの2番目の要素は，推定量の名前と推定量のインスタンスを含むタプルである．\n",
        "# この場合、ARIMAモデルである\n",
        "forecaster = TransformedTargetForecaster(\n",
        "[\n",
        "(\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "(\"forecast\", ARIMA()),\n",
        "]\n",
        ")\n",
        "\n",
        "# 学習データにモデルを当てはめる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# 与えられた予測地平について予測するためにモデルを使用します。\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 学習データ、テストデータ、そして予測値をプロットする\n",
        "# それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"というラベルでプロット。\n",
        "\n",
        "# テストデータと予測値の間の平均絶対誤差を計算する\n",
        "# symmetric=False は誤差が対称的でないことを示す\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと予測値の間の平均絶対誤差を計算する。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  sktimeライブラリからARIMAモデルをインポートする\n",
        "- from sktime.forecasting.arima import ARIMA\n",
        "-  sktimeライブラリからTransformedTargetForecasterクラスをインポートする。\n",
        "- from sktime.forecasting.compose import TransformedTargetForecaster # sktimeライ- ブラリからTransformedTargetForecasterクラスをインポートする。\n",
        "-  import the Deseasonalizer class from the sktime library\n",
        "- from sktime.transformations.series.detrend import Deseasonalizer\n",
        "- \n",
        "-  TransformedTargetForecaster クラスのインスタンスを作成する。\n",
        "-  このクラスは、複数のトランスフォーマーとエスティメーターをスタックすることがで- きる。\n",
        "-  リストの最初の要素は，トランスフォーマーの名前とトランスフォーマーのインスタン- スを含むタプルである．\n",
        "-  この場合、Deseasonalizerクラスで、モデルは \"乗法\"、季節期間は12に設定されてい- ます。\n",
        "-  リストの2番目の要素は，推定量の名前と推定量のインスタンスを含むタプルである．\n",
        "-  この場合、ARIMAモデルである\n",
        "- forecaster = TransformedTargetForecaster(\n",
        "- [\n",
        "- (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "- (\"forecast\", ARIMA()),\n",
        "- ]\n",
        "- )\n",
        "- \n",
        "-  学習データにモデルを当てはめる\n",
        "- forecaster.fit(y_train)\n",
        "- \n",
        "-  与えられた予測地平について予測するためにモデルを使用します。\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  学習データ、テストデータ、そして予測値をプロットする\n",
        "-  それぞれ \"y_train\", \"y_test\", \"y_pred\" とラベルを付けて表示する。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # - 学習データ、テストデータ、予測値をそれぞれ \"y_train\", \"y_test\", \"y_pred \"という- ラベルでプロット。\n",
        "- \n",
        "-  テストデータと予測値の間の平均絶対誤差を計算する\n",
        "-  symmetric=False は誤差が対称的でないことを示す\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # テストデータと予測値の間の平均絶対誤差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "KKk5YlZMSrMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、sktimeライブラリのTransformedTargetForecasterクラスを使って、時系列を予測します。\n",
        "- TransformedTargetForecaster クラスは、複数の変換器と推定器を積み重ねることができます。\n",
        "- このコードでは、Deseasonalizer変換器を使用して、ARIMA推定器に渡す前に時系列から季節性を除去しています。\n",
        "\n",
        "- Deseasonalizer変換器は、model=\"multiplicative \"とsp=12で初期化され、周期12で季節性を除去するために乗法モデルを使用することを示している。\n",
        "- そして、時系列を予測するために、ARIMA推定器が使用されます。そして、TransformedTargetForecasterが学習データに適合され、与えられた予測地平について予測するために使用されます。\n",
        "- そして、予測値は訓練データとテストデータとともにプロットされます。また、テストデータと予測値の間の平均絶対誤差率も計算されます。\n",
        "\n",
        "- TransformedTargetForecaster クラスは、時系列を予測するために複数の変換器と推定器を使用したい場合に便利です。\n",
        "- このクラスは，複数の変換器と推定器を連結し，ある変換器の出力を別の変換器の入力として使用することができます．\n",
        "- これにより、1つのパイプラインで複数のモデルの力を利用することができ、予測結果を向上させることができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "w7JgWhqYS4Dd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-V8YSRlrc8t"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.arima import ARIMA\n",
        "from sktime.forecasting.compose import TransformedTargetForecaster\n",
        "from sktime.transformations.series.detrend import Deseasonalizer\n",
        "forecaster = TransformedTargetForecaster(\n",
        "    [\n",
        "        (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "        (\"forecast\", ARIMA()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYX7tYRkrc8t"
      },
      "source": [
        "\n",
        "\n",
        "- 上記の例では，TransformedTargetForecaster は，ステップのリストで構成され，それぞれが名前と推定値の組で，最後の推定値はforecaster scitype である．\n",
        "- 前処理の変換子は，transform と inverse_transform メソッドを持つ系列間変換子であるべきである．\n",
        "- 結果として得られる推定量は forecaster scitype であり、すべてのインターフェース定義メソッドを持つ。\n",
        "- fit では、すべての変換器がデータに fit_transform を適用し、次に forecaster の fit を適用する。\n",
        "- predict では、まず forecaster の predict を適用し、次に変換器の inverse_transform を逆の順序で適用する。\n",
        "\n",
        "- 上記と同じパイプラインは、乗算ダンダー法*で構築することもできます。\n",
        "\n",
        "- これは、上記のようにTransformedTargetForecasterを作成し、構成要素にはデフォルトの名前が与えられます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **概要：**\n",
        "- TransformedTargetForecasterは、ステップのリストを用いて予測を行う方法であり、各ステップは名前とエスティメータと呼ばれる特別なツールの組である。\n",
        "- 最後のステップは、最終的な予測を行うフォアキャスターと呼ばれるツールである。\n",
        "- 最後のステップの前にある他のステップはトランスフォーマーと呼ばれ、フォアキャスターが予測をしやすいようにデータを変更するものです。\n",
        "\n",
        "- TransformedTargetForecasterを使用すると、まずトランスフォーマーを使ってデータを変更します。\n",
        "- そして、フォアキャスターは変更されたデータに基づいて予測を行います。\n",
        "- 最後に、トランスフォーマーが予測を元の形に変えます。\n",
        "\n",
        "### **まとめ：**\n",
        "- 上記と同じパイプラインを乗算ダンダメソッド*で構築することも可能ですが、\n",
        "- 構成要素にデフォルトの名前をつけてしまうことになります。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6vyA5h-t3Fgw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfiK6HHwrc8t"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sktime.forecasting.arima import ARIMA\n",
        "from sktime.forecasting.compose import TransformedTargetForecaster\n",
        "from sktime.transformations.series.detrend import Deseasonalizer\n",
        "\n",
        "# Deseasonalizer トランスフォーマーのインスタンスを、モデルを \"multiplicative\" に設定し、季節期間を12に設定して作成する。\n",
        "# 演算子は、DeseasonalizerとARIMAモデルを連結するために使用される。\n",
        "forecaster = Deseasonalizer(model=\"multiplicative\", sp=12) * ARIMA()\n",
        "forecaster\n",
        "\n",
        "# 複数の Deseasonalizer トランスフォーマーのインスタンスを作成し、1 つは季節周期を 12 に設定し、もう 1 つは季節周期を 3 に設定する。\n",
        "# これらのトランスフォーマーを ARIMA モデルと連鎖させる。\n",
        "forecaster = (\n",
        "Deseasonalizer(model=\"multiplicative\", sp=12) * Deseasonalizer(model=\"multiplicative\", sp=12)\n",
        "* Deseasonalizer(model=\"multiplicative\", sp=3)\n",
        "* ARIMA()\n",
        ")\n",
        "\n",
        "# モデルのパラメータを取得する\n",
        "forecaster.get_params()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、Deseasonalizer変換器とsktimeライブラリのARIMA推定器を使用して、時系列を予測します。\n",
        "- Deseasonalizer変換器は、ARIMA推定器に渡す前に時系列から季節性を除去するために使用されます。\n",
        "\n",
        "- 最初のケースでは、Deseasonalizer変換器はmodel=\"multiplicative\" and sp=12で初期化され、これは周期12の季節性を除去するために乗法モデルを使用することを示します。 \n",
        "- そして、DeseasonalizerとARIMAモデルを連結するために*演算子が使用されます。\n",
        "\n",
        "- 2番目のケースでは、複数のDeseasonalizer変換器が使用され、1つは季節期間が12に設定され、もう1つは季節期間が3に設定されています。\n",
        "- 両方のDeseasonalizerは、*演算子を使用してARIMAモデルに連結されています。\n",
        "- そして、モデルのパラメータを取得するために get_params() メソッドが使用されます。\n",
        "\n",
        "- この場合、TransformedTargetForecasterクラスは使用されません。その代わり、*演算子を用いて複数のモデルを連結しています。\n",
        "- これは、複数のモデルを連鎖させるより簡潔で読みやすい方法で、1つのパイプラインで複数のモデルの力を利用できるため、予測結果を向上させることができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "fi1fBidOTi2_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cc0tqNqrc8u"
      },
      "source": [
        "- ダンダーの構築されたパイプラインの名前は、例えば2つのデサイスを使用する場合に備えて、ユニークな名前にします。\n",
        "\n",
        "- 多重季節性モデルの例。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDpp7OQdrc8u"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.arima import ARIMA\n",
        "from sktime.forecasting.compose import TransformedTargetForecaster\n",
        "from sktime.transformations.series.detrend import Deseasonalizer\n",
        "forecaster = Deseasonalizer(model=\"multiplicative\", sp=12) * ARIMA()\n",
        "forecaster\n",
        "forecaster = (\n",
        "    Deseasonalizer(model=\"multiplicative\", sp=12)\n",
        "    * Deseasonalizer(model=\"multiplicative\", sp=3)\n",
        "    * ARIMA()\n",
        ")\n",
        "\n",
        "forecaster.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r_X37YXrc8u"
      },
      "source": [
        "- また、後処理の変換を伴うパイプラインを作成することもできます。\n",
        "- これらはフォアキャスターの後の変換で、ダンダーパイプラインまたはTransformedTargetForecasterに含まれます。\n",
        "\n",
        " - 以下は、予測値の後処理に整数丸めを使用した、複数の季節性モデルの例です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxHfFedLrc8u"
      },
      "source": [
        "- 処理前変換と処理後変換の両方を存在させることができ、\n",
        " - この場合、処理前変換の逆変換の後に処理後変換が適用される。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tsd1OHKprc8v"
      },
      "outputs": [],
      "source": [
        "from sktime.transformations.series.func_transform import FunctionTransformer\n",
        "\n",
        "forecaster = ARIMA() * FunctionTransformer(lambda y: y.round())\n",
        "forecaster.fit_predict(y, fh=fh).head(3)\n",
        "forecaster = (\n",
        "    Deseasonalizer(model=\"multiplicative\", sp=12)\n",
        "    * Deseasonalizer(model=\"multiplicative\", sp=3)\n",
        "    * ARIMA()\n",
        "    * FunctionTransformer(lambda y: y.round())\n",
        ")\n",
        "\n",
        "forecaster.fit_predict(y_train, fh=fh).head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz4JyHn1rc8u"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sktime.transformations.series.func_transform import FunctionTransformer\n",
        "\n",
        "# ARIMA モデルのインスタンスを作成する\n",
        "# 演算子は ARIMA モデルと FunctionTransformer を連結するために使用される。\n",
        "forecaster = ARIMA() * FunctionTransformer(lambda y: y.round())\n",
        "\n",
        "# データにモデルをフィットさせ、与えられた予測地平について予測する\n",
        "# head(3) 関数は、最初の3つの予測を表示するために使用されます。\n",
        "forecaster.fit_predict(y, fh=fh).head(3)\n",
        "\n",
        "#季節周期を12に設定したものと、季節周期を3に設定したものがある \n",
        "# 複数のDeseasonalizer変換器のインスタンスを作成。\n",
        "# これらのトランスフォーマーを ARIMA モデルと FunctionTransformer で連結する。\n",
        "forecaster = (\n",
        "Deseasonalizer(model=\"multiplicative\", sp=12) * Deseasonalizer(model=\"multiplicative\", sp=12)\n",
        "* Deseasonalizer(model=\"multiplicative\", sp=3)\n",
        "* ARIMA()\n",
        "* FunctionTransformer(lambda y: y.round())\n",
        ")\n",
        "\n",
        "# モデルを学習データにフィットさせ、与えられた予測地平について予測する。\n",
        "# head(3) 関数は、最初の3つの予測を表示するために使用されます。\n",
        "forecaster.fit_predict(y_train, fh=fh).head(3)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- from sktime.transformations.series.func_transform import FunctionTransformer\n",
        "- \n",
        "-  ARIMA モデルのインスタンスを作成する\n",
        "-  演算子は ARIMA モデルと FunctionTransformer を連結するために使用される。\n",
        "- forecaster = ARIMA() * FunctionTransformer(lambda y: y.round())\n",
        "- \n",
        "-  データにモデルをフィットさせ、与えられた予測地平について予測する\n",
        "-  head(3) 関数は、最初の3つの予測を表示するために使用されます。\n",
        "- forecaster.fit_predict(y, fh=fh).head(3)\n",
        "- \n",
        "- 季節周期を12に設定したものと、季節周期を3に設定したものがある \n",
        "-  複数のDeseasonalizer変換器のインスタンスを作成。\n",
        "-  これらのトランスフォーマーを ARIMA モデルと FunctionTransformer で連結する。\n",
        "- forecaster = (\n",
        "- Deseasonalizer(model=\"multiplicative\", sp=12) * Deseasonalizer- (model=\"multiplicative\", sp=12)\n",
        "- * Deseasonalizer(model=\"multiplicative\", sp=3)\n",
        "- * ARIMA()\n",
        "- * FunctionTransformer(lambda y: y.round())\n",
        "- )\n",
        "- \n",
        "-  モデルを学習データにフィットさせ、与えられた予測地平について予測する。\n",
        "-  head(3) 関数は、最初の3つの予測を表示するために使用されます。\n",
        "- forecaster.fit_predict(y_train, fh=fh).head(3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tQsWRLm6UbNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、sktimeライブラリのFunctionTransformerクラスを使用して、ARIMA推定量に渡す前に時系列にカスタム関数を適用しています。\n",
        "- FunctionTransformerは、時系列を丸めるラムダ関数で初期化されます。\n",
        "- 最初のケースでは、ARIMAモデルは`FunctionTrans'で連結されます。\n",
        "\n"
      ],
      "metadata": {
        "id": "IAE52tjWUVS-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL9U32rhrc8v"
      },
      "source": [
        "\n",
        "### **3.2.2 パイプラインコンポーネントとしてのDetrender**\n",
        "- トレンド除去には、Detrender を使用します。\n",
        " - これは，任意のフォアキャスターを包んだ series-to-transformer scitype の推定値です．\n",
        " - 例えば，線形トレンド除去の場合，PolynomialTrendForecaster を使って線形トレンドをフィットし，TransformedTargetForecaster 内の Detrender トランスフォーマーを使ってそれを減算/加算することが可能です．\n",
        "\n",
        "- 何が起こるかをよりよく理解するために、まず、デトレンダーを個別に調べます。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **概要**\n",
        "- Detrenderは、時間とともに変化するデータのパターンを除去するのに役立つ特別なツールです。\n",
        " - これは、これらのパターンを識別するのに役立つフォーキャスターと呼ばれるツールを使用することによって行われます。\n",
        "\n",
        "- Detrenderの使い方の一例として、データから線形トレンドを取り除くことが挙げられます。\n",
        " - これは、PolynomialTrendForecasterと呼ばれるツールを使用することで可能です。\n",
        " - これは、PolynomialTrendForecasterというツールを使って行うことができます。- Detrenderは、データからこのトレンドを減算または加算することで、分析を容易にします。\n",
        "- DetrenderはTransformedTargetForecasterと呼ばれる別のツールの内部で使用することができ、一連のステップを使用することで予測を行うことができます。\n",
        "\n",
        "### **まとめ：**\n",
        "- Detrenderが何をするのか理解するために、個別に調べるのが有効です。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vhOjA7zn35E5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
        "from sktime.transformations.series.detrend import Detrender\n",
        "\n",
        "# 線形デトレンドのために次数1のPolynomialTrendForecasterのインスタンスを作成します。\n",
        "forecaster = PolynomialTrendForecaster(degree=1)\n",
        "\n",
        "# 上記のフォアキャスターで Detrender のインスタンスを作成します。\n",
        "transformer = Detrender(forecaster=forecaster)\n",
        "\n",
        "# 変換器を使ってデータをフィットさせ、変換します。\n",
        "yt = transformer.fit_transform(y_train)\n",
        "\n",
        "# 内部的には、Detrender はサンプル内の予測値を使用します。\n",
        "#PolynomialTrendForecaster の # サンプルの予測値を使用します。\n",
        "forecaster = PolynomialTrendForecaster(degree=1)\n",
        "fh_ins = -np.arange(len(y_train)) # サンプル内予測の水平軸\n",
        "y_pred = forecaster.fit(y_train).predict(fh=fh_ins)\n",
        "\n",
        "# 元の時系列、フィットした線形トレンド、残差のプロット\n",
        "plot_series(y_train, y_pred, yt, labels=[\"y_train\", \"fitted linear trend\", \"residuals\"]);\n",
        "\n",
        "# TransformedTargetForecaster のインスタンスを作成します。\n",
        "forecaster = TransformedTargetForecaster(\n",
        "[\n",
        "(\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "(\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
        "(\"forecast\", ARIMA()),\n",
        "]\n",
        ")\n",
        "\n",
        "# データにモデルをフィットさせ、与えられた予測地平について予測する\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 元の時系列、テストセット、予測値をプロットします。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 絶対誤差の平均値を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) #平均絶対誤差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "1bmlve3jUyrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- from sktime.forecasting.trend import PolynomialTrendForecaster\n",
        "- from sktime.transformations.series.detrend import Detrender\n",
        "- \n",
        "-  線形デトレンドのために次数1のPolynomialTrendForecasterのインスタンスを作成しま- す。\n",
        "- forecaster = PolynomialTrendForecaster(degree=1)\n",
        "- \n",
        "-  上記のフォアキャスターで Detrender のインスタンスを作成します。\n",
        "- transformer = Detrender(forecaster=forecaster)\n",
        "- \n",
        "-  変換器を使ってデータをフィットさせ、変換します。\n",
        "- yt = transformer.fit_transform(y_train)\n",
        "- \n",
        "-  内部的には、Detrender はサンプル内の予測値を使用します。\n",
        "- PolynomialTrendForecaster の # サンプルの予測値を使用します。\n",
        "- forecaster = PolynomialTrendForecaster(degree=1)\n",
        "- fh_ins = -np.arange(len(y_train)) # サンプル内予測の水平軸\n",
        "- y_pred = forecaster.fit(y_train).predict(fh=fh_ins)\n",
        "- \n",
        "-  元の時系列、フィットした線形トレンド、残差のプロット\n",
        "- plot_series(y_train, y_pred, yt, labels=[\"y_train\", \"fitted linear trend\", - \"residuals\"]);\n",
        "- \n",
        "-  TransformedTargetForecaster のインスタンスを作成します。\n",
        "- forecaster = TransformedTargetForecaster(\n",
        "- [\n",
        "- (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "- (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
        "- (\"forecast\", ARIMA()),\n",
        "- ]\n",
        "- )\n",
        "- \n",
        "-  データにモデルをフィットさせ、与えられた予測地平について予測する\n",
        "- forecaster.fit(y_train)\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- \n",
        "-  元の時系列、テストセット、予測値をプロットします。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "-  絶対誤差の平均値を計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) #平均絶対誤差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "Z3yIR5d_VGbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、ARIMA推定器に渡す前に時系列からトレンドを除去するために、sktimeライブラリのPolynomialTrendForecasterクラスとDetrenderクラスを使用しています。\n",
        "- PolynomialTrendForecasterは、時系列に多項式トレンドをフィットさせるために使用され、Detrenderはこのトレンドを除去するために使用されます。\n",
        "\n",
        "- Detrender変換器は、PolynomialTrendForecasterインスタンスで作成され、データのフィットと変換に使用されます。\n",
        "- 結果として変換された時系列は残差のみを含み、トレンドは除去されています。\n",
        "\n",
        "- そして、TransformedTargetForecasterはDeseasonalizer、Detrender、ARIMAモデルを一緒に連結するために使用されます。\n",
        "- TransformedTargetForecaster は、与えられた順序で変換を適用します。\n",
        "- この場合、まず時系列を脱季節化し、次にデトレンドを行い、最後にARIMAモデルを用いてデータを予測します。\n",
        "\n",
        "- 結果として得られる予測値は、元の時系列とテストセットとともにプロットされ、平均絶対誤差率が計算される。\n",
        "\n",
        "- この方法は、時系列に次のような特徴がある場合に有効である。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CacRmDP6VR1g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xfatzrFrc8v"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
        "from sktime.transformations.series.detrend import Detrender\n",
        "# linear detrending\n",
        "forecaster = PolynomialTrendForecaster(degree=1)\n",
        "transformer = Detrender(forecaster=forecaster)\n",
        "yt = transformer.fit_transform(y_train)\n",
        "\n",
        "# internally, the Detrender uses the in-sample predictions\n",
        "# of the PolynomialTrendForecaster\n",
        "forecaster = PolynomialTrendForecaster(degree=1)\n",
        "fh_ins = -np.arange(len(y_train))  # in-sample forecasting horizon\n",
        "y_pred = forecaster.fit(y_train).predict(fh=fh_ins)\n",
        "\n",
        "plot_series(y_train, y_pred, yt, labels=[\"y_train\", \"fitted linear trend\", \"residuals\"]);\n",
        "\n",
        "forecaster = TransformedTargetForecaster(\n",
        "    [\n",
        "        (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "        (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
        "        (\"forecast\", ARIMA()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZEZIdY5rc8v"
      },
      "source": [
        "Detrenderはscitype series-to-series-transformer であるため、TransformedTargetForecasterで任意のフォアキャスターのトレンド除去に使用することができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAsdfgp5rc8w"
      },
      "source": [
        "\n",
        "### **3.2.3 複雑なパイプラインのコンポジットとパラメータインスペクション**\n",
        "- sktimeは、scikit-learnの哲学であるコンポーザビリティとネストされたパラメータインスペクションに則っている。\n",
        " - ある推定値が正しいscitypeを持っている限り、そのscitypeを必要とするあらゆる合成原理の一部として使用することができる。\n",
        " - 上では、Detrender 内の forecaster の例を見てきましたが、これは scitype series-to-series-transformer の estimator であり、forecaster scitype の 1 つのコンポーネントを持つものです。\n",
        " - 同様に，TransformedTargetForecaster において，パイプラインの最後の forecaster 要素として，セクション 3.1 の削減合成を使用することができます．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **概要：**\n",
        "- sktimeツールは、異なるツールを組み合わせて連携させるという哲学を貫いており、それぞれのツールが何をするのかが分かりやすくなっています。\n",
        "\n",
        "- たとえば、TransformedTargetForecaster では、パイプラインの最後の段階として、3.1 節のツールを使うことができる。\n",
        "- このツールはリダクションコンポジットと呼ばれ、KNeighborsRegressorという別のツールで構成されており、テーブル内のデータを基に予測を行うために使用されます。\n",
        "\n",
        "### **まとめ：**\n",
        "- このコンポーザビリティとネストされたパラメータ検査はsktimeの大きな特徴の一つであり、\n",
        "- 正しいscitypeを持つ限り、異なる推定量を一緒に組み合わせることができ、\n",
        "- パイプラインの各推定量のパラメータを簡単に検査することが可能である。\n",
        "\n"
      ],
      "metadata": {
        "id": "cuNkg4Ch4bPG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaqH9B_Arc8w"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 必要なライブラリのインポート\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "\n",
        "# TransformedTargetForecasterクラスのインスタンスを生成する\n",
        "forecaster = TransformedTargetForecaster(\n",
        "# トランスフォーマーのリスト\n",
        "[\n",
        "# 季節周期を12とした乗法モデルを使って、データを季節外しする。\n",
        "(\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "# 1次多項式トレンドを用いたデトレンド処理\n",
        "(\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
        "# KNeighborsRegressor を用いた予測\n",
        "(\n",
        "\"forecast\",\n",
        "make_reduction(\n",
        "KNeighborsRegressor(),\n",
        "scitype=\"tabular-regressor\",\n",
        "window_length=15,\n",
        "strategy=\"recursive\",\n",
        "),\n",
        "),\n",
        "]\n",
        ")\n",
        "\n",
        "# 学習データにモデルを当てはめる\n",
        "forecaster.fit(y_train)\n",
        "# テストデータに対して予測を行う\n",
        "y_pred = forecaster.predict(fh)\n",
        "# 訓練データ、テストデータ、予測データをプロットする\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # 訓練データ、テストデータ、予測データをプロットする。\n",
        "# テストデータと予測値の間の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)\n",
        "\n",
        "# モデルのパラメータを表示する\n",
        "forecaster.get_params()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "-  必要なライブラリのインポート\n",
        "- from sklearn.neighbors import KNeighborsRegressor\n",
        "- from sktime.forecasting.compose import make_reduction\n",
        "- \n",
        "-  TransformedTargetForecasterクラスのインスタンスを生成する\n",
        "- forecaster = TransformedTargetForecaster(\n",
        "-  トランスフォーマーのリスト\n",
        "- [\n",
        "-  季節周期を12とした乗法モデルを使って、データを季節外しする。\n",
        "- (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "-  1次多項式トレンドを用いたデトレンド処理\n",
        "- (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
        "-  KNeighborsRegressor を用いた予測\n",
        "- (\n",
        "- \"forecast\",\n",
        "- make_reduction(\n",
        "- KNeighborsRegressor(),\n",
        "- scitype=\"tabular-regressor\",\n",
        "- window_length=15,\n",
        "- strategy=\"recursive\",\n",
        "- ),\n",
        "- ),\n",
        "- ]\n",
        "- )\n",
        "- \n",
        "-  学習データにモデルを当てはめる\n",
        "- forecaster.fit(y_train)\n",
        "-  テストデータに対して予測を行う\n",
        "- y_pred = forecaster.predict(fh)\n",
        "-  訓練データ、テストデータ、予測データをプロットする\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # - 訓練データ、テストデータ、予測データをプロットする。\n",
        "-  テストデータと予測値の間の平均絶対誤差を計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False)\n",
        "- \n",
        "-  モデルのパラメータを表示する\n",
        "- forecaster.get_params()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f2h0Ll2HXHUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、sklearnとsktimeというライブラリを使って、時系列予測を行っています。\n",
        "- ここで使われている主なクラスは、TransformedTargetForecasterクラスで、ターゲット変数を前処理するトランスフォーマーのセットと、変換されたターゲット変数を予測する最終フォアキャスターをラップしたクラスです。\n",
        "- このコードでは、3つのトランスフォーマーを使用しています。Deseasonalizer、Detrender、make_reduction です。\n",
        "\n",
        "- Deseasonalizerクラスは、時系列データから季節成分を除去するために使用されます。\n",
        "- これは、モデルタイプと季節期間を入力として受け取ります。\n",
        "- この例では、季節性周期が12の乗法モデルを使用しています。\n",
        "\n",
        "- Detrender クラスは、時系列データからトレンドを除去するために使用されます。\n",
        "- 入力としてフォアキャスターを受け付けますが、この場合は1次多項式トレンドフォアキャスターを使用します。\n",
        "\n",
        "- make_reduction() 関数は、時系列の削減を行うために使用されます。\n",
        " - この場合、KNeighborsRegressor を使用して変換されたターゲット変数を予測します。\n",
        "- また、入力としてstrategy、scitype、window_lengthを受け取ります。\n",
        "  - この場合、'recursive' strategy、'tabular-regressor' scitype、window_lengthは15を使用しています。\n",
        "\n",
        "- 学習データにモデルを当てはめた後、このコードはテストデータに対して予測を行い、学習データ、テストデータ、予測データをプロットしています。\n",
        "- また、テストデータと予測値の間の平均絶対誤差（mean absolute percentage error）を計算しています。\n",
        "\n",
        "- このコードの利点は、複数の変換器を組み合わせてターゲット変数を前処理しているため、予測がより正確になることです。\n",
        "- また、ノンパラメトリックアルゴリズムであるKNeighborsRegressorを使用しており、データ内の非線形関係を処理することができます。\n",
        "- さらに、モデルのパラメータを出力することで、デバッグに役立てることもできます。\n",
        "\n"
      ],
      "metadata": {
        "id": "39-3s5WyXVae"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKU0_-pCrc8w"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "forecaster = TransformedTargetForecaster(\n",
        "    [\n",
        "        (\"deseasonalize\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
        "        (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
        "        (\n",
        "            \"forecast\",\n",
        "            make_reduction(\n",
        "                KNeighborsRegressor(),\n",
        "                scitype=\"tabular-regressor\",\n",
        "                window_length=15,\n",
        "                strategy=\"recursive\",\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)\n",
        "\n",
        "forecaster.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUSVYVtkrc8w"
      },
      "source": [
        "scikit-learnのモデルと同様に、get_paramsとset_paramsによって、任意のコンポーネントのパラメータを検査し、アクセスすることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDgOH-tLrc8x"
      },
      "outputs": [],
      "source": [
        "forecaster.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFpSEbCjrc8x"
      },
      "source": [
        "### **3.3 パラメータチューニング**\n",
        "- sktimeは、scikit-learnのGridSearchCVと同様に、forecaster scitypeのコンポジターとしてパラメータチューニングストラテジーを提供する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8DsI7J7rc8x"
      },
      "source": [
        "\n",
        "### **3.3.1 ForecastingGridSearchCVを用いた基本的なチューニング**\n",
        "- コンポジター ForecastingGridSearchCV（および他のチューナー）は、\n",
        " - チューニングするフォアキャスター、\n",
        " - クロスバリデーションコンストラクター、 \n",
        " - scikit-learn パラメータグリッド、\n",
        " - およびチューニング戦略に特有のパラメータで構成されています。\n",
        "- クロスバリデーションコンストラクタは、サンプラー用の scikit-learn インターフェースに準拠しており、交換可能にスロットインすることができます。\n",
        "\n",
        " - 例として、3.1 節の Reduction Compositor において、時間的スライディングウィンドウを用いたウィンドウ長のチューニングを示す。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **要約：**\n",
        "\n",
        "- sktimeはForecastingGridSearchCVというツールを使ってフォアキャスターに最適な設定を見つける方法を提供しています。\n",
        "\n",
        "- このツールは scikit-learn の GridSearchCV と呼ばれるツールに類似している。\n",
        "- これは、フォアキャスターの異なる設定を試し、そして、どの設定が最もよく機能するかを見るために交差検証という方法を使うことで機能します。\n",
        "\n",
        "### **まとめ：**\n",
        "\n",
        "- ForecastingGridSearchCV を使うには、\n",
        " - チューニングするフォアキャスター、\n",
        " - クロスバリデーション法、\n",
        " - 可能な設定のセット、\n",
        " - そしてチューニング戦略に特有の他のパラメータを与える必要があります。\n",
        "\n",
        "- 例として、\n",
        " - 3.1節の縮小合成において、\n",
        " - ForecastingGridSearchCVを使って、\n",
        " - 時間的スライディングウィンドウ調整という方法で、\n",
        " - ウィンドウ長を調整することができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "_qkX9S-t5Xry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QXvMAOsqX8DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "from sktime.forecasting.model_selection import (\n",
        "    ForecastingGridSearchCV,\n",
        "    SlidingWindowSplitter,\n",
        ")\n",
        "regressor = KNeighborsRegressor()\n",
        "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\")\n",
        "param_grid = {\"window_length\": [7, 12, 15]}\n",
        "\n",
        "# We fit the forecaster on an initial window which is 80% of the historical data\n",
        "# then use temporal sliding window cross-validation to find the optimal hyper-parameters\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=20)\n",
        "gscv = ForecastingGridSearchCV(\n",
        "    forecaster, strategy=\"refit\", cv=cv, param_grid=param_grid\n",
        ")\n",
        "gscv.fit(y_train)\n",
        "y_pred = gscv.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)\n",
        "\n",
        "gscv.best_params_\n",
        "\n",
        "gscv.best_forecaster_"
      ],
      "metadata": {
        "id": "m9WeQhm_X8iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sklearn.neighbors モジュールから KNeighborsRegressor クラスをインポートする。\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# make_reduction 関数を sktime.forecasting.compose モジュールからインポートする。\n",
        "# そして、ForecastingGridSearchCV、SlidingWindowSplitterクラスをsktime.forecasting.model_selectionモジュールからインポートする。\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "from sktime.forecasting.model_selection import ForecastingGridSearchCV, SlidingWindowSplitter\n",
        "\n",
        "# KNeighborsRegressor モデルのインスタンスを作成する。\n",
        "regressor = KNeighborsRegressor()\n",
        "\n",
        "# 時系列予測モデルを作成するために make_reduction 関数のインスタンスを作成する。\n",
        "# 最後の window_length のオブザベーションで再帰的にリグレッサを適用することによって\n",
        "forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\") # 時系列予測モデルを作成するためにmake_reduction関数のインスタンスを作成します。\n",
        "\n",
        "# グリッドサーチのためのパラメータグリッドを指定\n",
        "param_grid = {\"window_length\":[7, 12, 15]}\n",
        "\n",
        "\n",
        "# 相互検証ストラテジーを作成するために SlidingWindowSplitter のインスタンスを作成する。\n",
        "# 学習データに対してスライディングウィンドウを用いた反復処理を行う．\n",
        "# initial_window パラメータには y_train の長さの 80% が設定される．\n",
        "# window_length パラメータは 20 に設定されます．\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=20).\n",
        "\n",
        "グリッド検索とクロスバリデーションを行うために， # ForecastingGridSearchCV のインスタンスを作成する．\n",
        "# 予測モデルの最適なハイパーパラメータを見つけるために，ForecastingGridSearchCVのインスタンスを作成します．\n",
        "# forecasterパラメータには，以前に作成されたforecasterが設定される．\n",
        "# 戦略パラメータは \"refit \"に設定され，全データセットに対して最適な推定値の再適合を行う．\n",
        "# cvパラメータには，以前に作成されたクロスバリデーション手法が設定される．\n",
        "# param_gridパラメータには，以前に指定されたパラメータグリッドが設定される．\n",
        "gscv = ForecastingGridSearchCV(forecaster, strategy=\"refit\", cv=cv, param_grid=param_grid)\n",
        "\n",
        "# グリッドサーチとクロスバリデーションのオブジェクトを学習データにフィットさせる\n",
        "gscv.fit(y_train)\n",
        "\n",
        "# 最適な推定量を用いて，水平方向の予測を行います．\n",
        "y_pred = gscv.predict(fh)\n",
        "\n",
        "# 学習データ、テストデータ、予測データをプロットします。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算する。\n",
        "\n",
        "# モデルの最適なパラメータを取得する\n",
        "gscv.best_params_\n",
        "\n",
        "# モデルの最適なフォアキャスターを取得する\n",
        "gscv.best_forecaster_ # モデルの最適なフォアキャスターを取得する\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-JpslXuFUlLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- #### sklearn.neighbors モジュールから KNeighborsRegressor クラスをインポートする。\n",
        "- from sklearn.neighbors import KNeighborsRegressor\n",
        "- \n",
        "- #### make_reduction 関数を sktime.forecasting.compose モジュールからインポートす- る。\n",
        "- #### そして、ForecastingGridSearchCV、SlidingWindowSplitterクラスをsktime.- forecasting.model_selectionモジュールからインポートする。\n",
        "- from sktime.forecasting.compose import make_reduction\n",
        "- from sktime.forecasting.model_selection import ForecastingGridSearchCV, - SlidingWindowSplitter\n",
        "- \n",
        "- #### KNeighborsRegressor モデルのインスタンスを作成する。\n",
        "- regressor = KNeighborsRegressor()\n",
        "- \n",
        "- #### 時系列予測モデルを作成するために make_reduction 関数のインスタンスを作成する。\n",
        "- #### 最後の window_length のオブザベーションで再帰的にリグレッサを適用することによ- って\n",
        "- forecaster = make_reduction(regressor, window_length=15, strategy=\"recursive\") - #### 時系列予測モデルを作成するためにmake_reduction関数のインスタンスを作成します。\n",
        "- \n",
        "- #### グリッドサーチのためのパラメータグリッドを指定\n",
        "- param_grid = {\"window_length\":[7, 12, 15]}\n",
        "- \n",
        "- \n",
        "- #### 相互検証ストラテジーを作成するために SlidingWindowSplitter のインスタンスを作- 成する。\n",
        "- #### 学習データに対してスライディングウィンドウを用いた反復処理を行う．\n",
        "- #### initial_window パラメータには y_train の長さの 80% が設定される．\n",
        "- #### window_length パラメータは 20 に設定されます．\n",
        "- cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), - window_length=20).\n",
        "- \n",
        "- グリッド検索とクロスバリデーションを行うために， #### ForecastingGridSearchCV のイ- ンスタンスを作成する．\n",
        "- #### 予測モデルの最適なハイパーパラメータを見つけるために，ForecastingGridSearchCV- のインスタンスを作成します．\n",
        "- #### forecasterパラメータには，以前に作成されたforecasterが設定される．\n",
        "- #### 戦略パラメータは \"refit \"に設定され，全データセットに対して最適な推定値の再適- 合を行う．\n",
        "- #### cvパラメータには，以前に作成されたクロスバリデーション手法が設定される．\n",
        "- #### param_gridパラメータには，以前に指定されたパラメータグリッドが設定される．\n",
        "- gscv = ForecastingGridSearchCV(forecaster, strategy=\"refit\", cv=cv, - param_grid=param_grid)\n",
        "- \n",
        "- #### グリッドサーチとクロスバリデーションのオブジェクトを学習データにフィットさせる\n",
        "- gscv.fit(y_train)\n",
        "- \n",
        "- #### 最適な推定量を用いて，水平方向の予測を行います．\n",
        "- y_pred = gscv.predict(fh)\n",
        "- \n",
        "- #### 学習データ、テストデータ、予測データをプロットします。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "- #### 予測値の平均絶対誤差を計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) #### 予測値の平均絶- 対誤差を計算する。\n",
        "- \n",
        "- #### モデルの最適なパラメータを取得する\n",
        "- gscv.best_params_\n",
        "- \n",
        "- #### モデルの最適なフォアキャスターを取得する\n",
        "- gscv.best_forecaster_ #### モデルの最適なフォアキャスターを取得する\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1gF5UhtOWJ97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- このコードでは、分類や回帰に使われるノンパラメトリックな手法であるk-nearest neighborsアルゴリズムを使って予測を行っています。\n",
        "- また、このコードはsktimeライブラリ、特にmake_reduction、ForecastingGridSearchCV、およびSlidingWindowSplitterクラスを利用しています。\n",
        "- また、予測モデルの最適なハイパーパラメータを見つけるために、グリッドサーチとクロスバリデーションを使用しています。\n",
        "- データセットの最初のウィンドウをトレーニングセットとして使用し、残りのデータをテストセットとして使用し、ウィンドウを前進させてデータの異なるサブセットをテストする。\n",
        "- そして、テストセットでの性能に基づいて最適なパラメータが選択される。\n",
        "- 最終的なモデルはデータセット全体に再適合され、予測対象期間の予測が行われる。\n",
        "- また、最良のフォーキャスターは更なる分析のために保存される。\n",
        "- この方法は、データの異なるサブセットでモデルをテストし、最もパフォーマンスの高いパラメータを選択することで、オーバーフィッティングを防ぐのに役立ちます。\n",
        "- また、テストセットでの性能に応じて最適なモデルを選択することで、より正確な予測を行うことができるようになります。"
      ],
      "metadata": {
        "id": "J-r0t3S7VRZq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RoCoaTJrc8y"
      },
      "source": [
        "\n",
        "- 他のコンポジットと同様、生成されたフォーキャスターはsktimeフォーキャスターの統一インターフェースを提供し、ウィンドウの分割、チューニングなどは手動で行う必要がなく、統一インターフェースの後ろで行われます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLYJH5Zlrc8y"
      },
      "outputs": [],
      "source": [
        "gscv.fit(y_train)\n",
        "y_pred = gscv.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBSri13Erc8y"
      },
      "source": [
        "チューニングされたパラメータは、best_params_属性でアクセスすることができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDHR242lrc8y"
      },
      "outputs": [],
      "source": [
        "gscv.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm97AXVbrc8y"
      },
      "source": [
        "\n",
        "- best_forecaster_ 属性にアクセスすることで、ハイパーパラメータが設定されたベストフォーキャスターのインスタンスを取得することができる。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXaqO3cbrc8z"
      },
      "outputs": [],
      "source": [
        "gscv.best_forecaster_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYEGmDqHrc8z"
      },
      "source": [
        "\n",
        "### **3.3.2 複雑なコンポジットのチューニング**\n",
        "- scikit-learnと同様に、ネストしたコンポーネントのパラメータは、そのget_paramsキーにアクセスすることでチューニングすることができます。\n",
        " - デフォルトでは、[estimatorname]がコンポーネント名、[parametername]が推定量[estimatorname]のパラメータ名であれば、\n",
        " - [estimatorname]__[parametername]がチューニングに使用されます。\n",
        "\n",
        "- 例えば、以下では、KNeighborsRegressorコンポーネントのn_neighborsを調整し、window_lengthを調整します。\n",
        "- 調整可能なパラメータはforecaster.get_params()で簡単に取得することができます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **要約：**\n",
        "- sktimeでは、複雑なツールの中で、異なるツールの設定を、それらのget_paramsキーにアクセスすることで調整することができます。\n",
        "\n",
        " - 例えば、以下では、window_lengthの調整に加え、KNeighborsRegressorコンポーネントのn_neighborsを調整することができます。\n",
        " - 調整可能なパラメータはforecaster.get_params()を使って簡単に問い合わせることができます。\n",
        "\n",
        "### **まとめ：**\n",
        "- ネストされたコンポーネントのパラメータを調整する別の方法は、scikit-learnのGridSearchCVと個別のパラメータグリッドを使って、リグレッサを個別に調整することです。\n",
        "\n",
        "- しかし、この方法は、内部のリグレッサを調整するために「全体的な」パフォーマンスメトリックを使用しないので、複合フォアキャスターのパフォーマンスが変化する可能性があります。\n",
        "- また、これのスマートな実装は、キャッシュを使用して、内部のチューニングから部分的な結果を保存し、実行時間を大幅に削減しますが、現在sktimeはこれをサポートしないことに注意してください。\n",
        "- もし、あなたがsktimeの改良を手伝いたいのであれば、貢献を検討することができます。\n",
        "\n"
      ],
      "metadata": {
        "id": "tGn5ujCM670q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hry5nl8_rc80"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "from sktime.forecasting.model_selection import (\n",
        "    ForecastingGridSearchCV,\n",
        "    SlidingWindowSplitter,\n",
        ")\n",
        "param_grid = {\"window_length\": [7, 12, 15], \"estimator__n_neighbors\": np.arange(1, 10)}\n",
        "\n",
        "regressor = KNeighborsRegressor()\n",
        "forecaster = make_reduction(\n",
        "    regressor, scitype=\"tabular-regressor\", strategy=\"recursive\"\n",
        ")\n",
        "\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30)\n",
        "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=param_grid)\n",
        "gscv.fit(y_train)\n",
        "y_pred = gscv.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)\n",
        "gscv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sklearn.neighbors モジュールから KNeighborsRegressor クラスをインポートする。\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# make_reduction と ForecastingGridSearchCV クラスを sktime.forecasting.compose と sktime.forecasting.model_selection モジュールからインポートする。\n",
        "from sktime.forecasting.compose import make_reduction\n",
        "from sktime.forecasting.model_selection import ForecastingGridSearchCV, SlidingWindowSplitter\n",
        "\n",
        "# window_length と n_neighbors パラメータを含むグリッドサーチのパラメータグリッドを指定する。\n",
        "param_grid = {\"window_length\":[7, 12, 15], \"estimator__n_neighbors\": np.arange(1, 10)}\n",
        "\n",
        "# KNeighborsRegressor クラスのインスタンスを作成する。\n",
        "regressor = KNeighborsRegressor()\n",
        "\n",
        "# make_reduction クラスのインスタンスを作成し、strategy を \"recursive\" に、scitype を \"tabular-regressor\" にセットする。\n",
        "forecaster = make_reduction(regressor, scitype=\"tabular-regressor\", strategy=\"recursive\")\n",
        "\n",
        "# SlidingWindowSplitterクラスのインスタンスを作成し、学習データに対してスライディングウィンドウを用いたクロスバリデーション戦略を作成する。\n",
        "# initial_window パラメータには y_train の長さの 80% が設定される．\n",
        "# window_length パラメータは 30 にセットされます．\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30).\n",
        "\n",
        "#グリッド検索とクロスバリデーションを行うために， # ForecastingGridSearchCV クラスのインスタンスを作成します．\n",
        "# 予測モデルの最適なハイパーパラメータを見つけるために，ForecastingGridSearchCVクラスのインスタンスを作成します．\n",
        "# forecasterパラメータには、以前に作成されたforecasterが設定される。\n",
        "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=param_grid)\n",
        "\n",
        "# 学習データにモデルを当てはめる\n",
        "gscv.fit(y_train)\n",
        "\n",
        "#グリッドサーチによって得られた最適なパラメータを用いて， # 予測水平軸に対する予測を行います．\n",
        "y_pred = gscv.predict(fh)\n",
        "\n",
        "# 学習データ、テストデータ、予測データをプロットします。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測値の平均絶対誤差を計算し、表示します。\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算し、表示する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rNJZONqwXA-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- #### sklearn.neighbors モジュールから KNeighborsRegressor クラスをインポートす- る。\n",
        "- from sklearn.neighbors import KNeighborsRegressor\n",
        "- \n",
        "- #### make_reduction と ForecastingGridSearchCV クラスを sktime.forecasting.- compose と sktime.forecasting.model_selection モジュールからインポートする。\n",
        "- from sktime.forecasting.compose import make_reduction\n",
        "- from sktime.forecasting.model_selection import ForecastingGridSearchCV, - SlidingWindowSplitter\n",
        "- \n",
        "- #### window_length と n_neighbors パラメータを含むグリッドサーチのパラメータグリ- ッドを指定する。\n",
        "- param_grid = {\"window_length\":[7, 12, 15], \"estimator__n_neighbors\": np.arange- (1, 10)}\n",
        "- \n",
        "- #### KNeighborsRegressor クラスのインスタンスを作成する。\n",
        "- regressor = KNeighborsRegressor()\n",
        "- \n",
        "- #### make_reduction クラスのインスタンスを作成し、strategy を \"recursive\" に、- scitype を \"tabular-regressor\" にセットする。\n",
        "- forecaster = make_reduction(regressor, scitype=\"tabular-regressor\", - strategy=\"recursive\")\n",
        "- \n",
        "- #### SlidingWindowSplitterクラスのインスタンスを作成し、学習データに対してスライ- ディングウィンドウを用いたクロスバリデーション戦略を作成する。\n",
        "- #### initial_window パラメータには y_train の長さの 80% が設定される．\n",
        "- #### window_length パラメータは 30 にセットされます．\n",
        "- cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), - window_length=30).\n",
        "- \n",
        "- ####グリッド検索とクロスバリデーションを行うために， #### - ForecastingGridSearchCV クラスのインスタンスを作成します．\n",
        "- #### 予測モデルの最適なハイパーパラメータを見つけるために，- ForecastingGridSearchCVクラスのインスタンスを作成します．\n",
        "- #### forecasterパラメータには、以前に作成されたforecasterが設定される。\n",
        "- gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=param_grid)\n",
        "- \n",
        "- #### 学習データにモデルを当てはめる\n",
        "- gscv.fit(y_train)\n",
        "- \n",
        "- ####グリッドサーチによって得られた最適なパラメータを用いて， #### 予測水平軸に対- する予測を行います．\n",
        "- y_pred = gscv.predict(fh)\n",
        "- \n",
        "- #### 学習データ、テストデータ、予測データをプロットします。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "- #### 予測値の平均絶対誤差を計算し、表示します。\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) #### 予測値の平- 均絶対誤差を計算し、表示する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nXyzqAhHXul_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 概要\n",
        "- このコードは、k-nearest neighborsと呼ばれる機械学習手法を用いて、将来のデータに関する予測を行うものである。\n",
        "- また、予測を行うプロセスを支援するsktimeというライブラリも使用している。\n",
        "- グリッドサーチとクロスバリデーションという方法を用いて、予測を行うための最適なルールセットを見つける。\n",
        "- データの初期部分はトレーニングセットとして使用され、残りは予測のテストに使用されます。\n",
        "- 最後に、トレーニングデータ、テストデータ、予測値をプロットし、平均絶対誤差を計算して、予測値を評価し、その精度をチェックします。\n",
        "\n",
        "---\n",
        "\n",
        "- 上記のコードは、kneighborsRegressor モデルのインスタンスを作成するために sklearn.neighbors モジュールから KNeighborsRegressor クラスを使用しています。\n",
        "- また、sktimeライブラリ、特にmake_reduction、ForecastingGridSearchCV、SlidingWindowSplitterの各クラスを利用しています。\n",
        "- このコードはまた、予測モデルの最適なハイパーパラメータを見つけるために、グリッドサーチとクロスバリデーションを使用しています。\n",
        "- データセットの最初のウィンドウはトレーニングセットとして使用され、残りのデータはパラメータの異なる組み合わせでモデルの性能を評価するために使用されます。\n",
        "- また、このコードでは、make_reductionクラスに対して、scitypeを \"tabular-regressor \"に、strategyを \"recursive \"に設定します。\n",
        "- また、このコードでは、window_lengthとn_neighborsパラメータを含むグリッドサーチのためのパラメータグリッドを指定している。\n",
        "- また、このコードでは、モデルのフィッティング後にgscv.best_params_を呼び出して、モデルの最適なパラメータを求めます。\n",
        "- また，このコードではSlidingWindowSplitterクラスを使用して，学習データに対してスライディングウィンドウを用いたクロスバリデーション手法を作成しています．\n",
        "- また、予測精度を計算するために、mean_absolute_percentage_error関数を使用しています。\n",
        "- また、plot_series 関数を使用して、学習データ、テストデータ、予測データをプロットしています。\n",
        "- また、fit メソッドを使用してトレーニングデータでモデルを学習し、predict メソッドを使用してテストデータで予測を行っています。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jO08n7vOYiXq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcEfEM28rc80"
      },
      "source": [
        "- 上記の代替案は、scikit-learnのGridSearchCVと個別のパラメータグリッドを使用して、リグレッサを個別にチューニングするものです。\n",
        "- これは内部リグレッサーのチューニングに「全体的な」性能指標を使用しないので、複合フォアキャスターの性能は異なるかもしれません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlS2X35Orc80"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# tuning the 'n_estimator' hyperparameter of RandomForestRegressor from scikit-learn\n",
        "regressor_param_grid = {\"n_neighbors\": np.arange(1, 10)}\n",
        "forecaster_param_grid = {\"window_length\": [7, 12, 15]}\n",
        "\n",
        "# create a tunnable regressor with GridSearchCV\n",
        "regressor = GridSearchCV(KNeighborsRegressor(), param_grid=regressor_param_grid)\n",
        "forecaster = make_reduction(\n",
        "    regressor, scitype=\"tabular-regressor\", strategy=\"recursive\"\n",
        ")\n",
        "\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30)\n",
        "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid)\n",
        "gscv.fit(y_train)\n",
        "y_pred = gscv.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvQWebzIrc81"
      },
      "source": [
        "### **注意:**\n",
        "- これを賢く実装すれば、内部チューニングの結果を部分的に保存するためにキャッシュを使い、実行時間を大幅に短縮することができます。\n",
        "- sktimeの改善に貢献することを検討してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clFt1-98rc81"
      },
      "source": [
        "\n",
        "### 3.3.3 **メトリクスの選択とスコアの取得**\n",
        "- sktime のすべてのチューニングアルゴリズムでは、ユーザーがスコアを設定することができます。\n",
        "- 予測では、デフォルトは平均絶対誤差率（mean absolute percentage error）です。\n",
        "- スコアは、セクション 1.3 と同様に、任意の scorer 関数またはクラスに対して score 引数を使用して設定することができる。\n",
        "\n",
        "- 再サンプリングチューナーは、個々の予測の再サンプル倍に関する性能を保持し、これは fit の呼び出しによって forecaster が適合された後に cv_results_ 引数から取得することができます。\n",
        "\n",
        "- 上記の例では、チューニングのために平均絶対誤差率ではなく、平均二乗誤差を使用することは、forecasterを以下のように定義することによって行われます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **概要**\n",
        "\n",
        "- このコードでは、予測アルゴリズムがどの程度うまく機能しているかを測定するために、スコアを設定しています。デフォルトのスコアは平均絶対誤差率です。\n",
        " - このスコアは他の関数やクラスに変更することができます。\n",
        "- また、データの異なる部分に対するアルゴリズムのパフォーマンス結果を得ることができます。\n",
        " - これは、モデルの適合後、'cv_results_'引数を見ることによって行われます。\n",
        "- この例では、スコアをデフォルトの平均絶対誤差の代わりに平均二乗誤差に変更しています。\n",
        " - これは、forecasterを特定の方法で定義することによって行われます。"
      ],
      "metadata": {
        "id": "wDnXPD-RuIuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsCiuwx8rc82"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sktime.performance_metrics.forecasting モジュールから MeanSquaredError クラスをインポートする。\n",
        "from sktime.performance_metrics.forecasting import MeanSquaredError\n",
        "\n",
        "# MeanSquaredError クラスのインスタンスを作成する。\n",
        "mse = MeanSquaredError()\n",
        "\n",
        "# window_length パラメータを含む、グリッド検索のパラメータグリッドを指定する\n",
        "param_grid = {\"window_length\":[7, 12, 15]}\n",
        "\n",
        "# KNeighborsRegressor クラスのインスタンスを作成する。\n",
        "regressor = KNeighborsRegressor()\n",
        "\n",
        "# SlidingWindowSplitter クラスのインスタンスを作成し、学習データに対してスライディングウィンドウを用いたクロスバリデーション手法を作成する。\n",
        "# initial_window パラメータは y_train の長さの 80% に設定される．\n",
        "# window_length パラメータは 30 にセットされます．\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30)\n",
        "グリッド検索とクロスバリデーションを行うために， # ForecastingGridSearchCV クラスのインスタンスを作成します．\n",
        "# 予測モデルの最適なハイパーパラメータを見つけるために，ForecastingGridSearchCVクラスのインスタンスを作成します．\n",
        "# forecasterパラメータには，以前に作成されたforecasterが設定される．\n",
        "# スコアリング・パラメータは以前に作成されたmse (Mean Squared Error)に設定される。\n",
        "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=param_grid, scoring=mse)\n",
        "\n",
        "# 学習データにモデルを当てはめる\n",
        "gscv.fit(y_train)\n",
        "\n",
        "# クロスバリデーションの結果を表示します\n",
        "gscv.cv_results_ja\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- ##### # sktime.performance_metrics.forecasting モジュールから MeanSquaredError クラ- スをインポートする。\n",
        "- from sktime.performance_metrics.forecasting import MeanSquaredError\n",
        "- \n",
        "- ##### # MeanSquaredError クラスのインスタンスを作成する。\n",
        "- mse = MeanSquaredError()\n",
        "- \n",
        "- ##### # window_length パラメータを含む、グリッド検索のパラメータグリッドを指定する\n",
        "- param_grid = {\"window_length\":[7, 12, 15]}\n",
        "- \n",
        "- ##### # KNeighborsRegressor クラスのインスタンスを作成する。\n",
        "- regressor = KNeighborsRegressor()\n",
        "- \n",
        "- ##### # SlidingWindowSplitter クラスのインスタンスを作成し、学習データに対してスライ- ディングウィンドウを用いたクロスバリデーション手法を作成する。\n",
        "- ##### # initial_window パラメータは y_train の長さの 80% に設定される．\n",
        "- ##### # window_length パラメータは 30 にセットされます．\n",
        "- cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), - window_length=30)\n",
        "- グリッド検索とクロスバリデーションを行うために， ##### # ForecastingGridSearchCV ク- ラスのインスタンスを作成します．\n",
        "- ##### # 予測モデルの最適なハイパーパラメータを見つけるために，- ForecastingGridSearchCVクラスのインスタンスを作成します．\n",
        "- ##### # forecasterパラメータには，以前に作成されたforecasterが設定される．\n",
        "- ##### # スコアリング・パラメータは以前に作成されたmse (Mean Squared Error)に設定され- る。\n",
        "- gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=param_grid, - scoring=mse)\n",
        "- \n",
        "- ##### # 学習データにモデルを当てはめる\n",
        "- gscv.fit(y_train)\n",
        "- \n",
        "- ##### # クロスバリデーションの結果を表示します\n",
        "- gscv.cv_results_ja\n"
      ],
      "metadata": {
        "id": "x3zpJCJ4Z9-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuTgobxCrc82"
      },
      "outputs": [],
      "source": [
        "from sktime.performance_metrics.forecasting import MeanSquaredError\n",
        "mse = MeanSquaredError()\n",
        "\n",
        "param_grid = {\"window_length\": [7, 12, 15]}\n",
        "\n",
        "regressor = KNeighborsRegressor()\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30)\n",
        "\n",
        "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=param_grid, scoring=mse)\n",
        "\n",
        "gscv.fit(y_train)\n",
        "gscv.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import the mean squared error metric from sktime\n",
        "from sktime.performance_metrics.forecasting import MeanSquaredError\n",
        "\n",
        "# 平均二乗誤差メトリックを初期化する\n",
        "mse = MeanSquaredError()\n",
        "\n",
        "# 検索するパラメータグリッドを定義する\n",
        "param_grid = {\"window_length\":[7, 12, 15]}\n",
        "\n",
        "# k-neighborsリグレッサーの初期化\n",
        "regressor = KNeighborsRegressor()\n",
        "\n",
        "# スライディングウィンドースプリッタを初期化します．\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), window_length=30) # スライディングウィンドウを初期化します．\n",
        "\n",
        "# 予測格子点探索クロスバリデータをリグレッサ、cv、パラメータグリッドで初期化する\n",
        "gscv = ForecastingGridSearchCV(regressor, cv=cv, param_grid=param_grid, scoring=mse) # 予測グリッド探索クロスバリデータをリグレッサ，cv，パラメータグリッドで初期化します．\n",
        "\n",
        "# グリッドサーチを学習データにフィットさせる\n",
        "gscv.fit(y_train)\n",
        "\n",
        "# グリッドサーチの結果を表示します\n",
        "gscv.cv_results_ #- グリッドサーチの結果を表示します．\n"
      ],
      "metadata": {
        "id": "MWcmzJT0cNic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- ##### # import the mean squared error metric from sktime\n",
        "- from sktime.performance_metrics.forecasting import MeanSquaredError\n",
        "- \n",
        "- ##### # 平均二乗誤差メトリックを初期化する\n",
        "- mse = MeanSquaredError()\n",
        "- \n",
        "- ##### # 検索するパラメータグリッドを定義する\n",
        "- param_grid = {\"window_length\":[7, 12, 15]}\n",
        "- \n",
        "- ##### # k-neighborsリグレッサーの初期化\n",
        "- regressor = KNeighborsRegressor()\n",
        "- \n",
        "- ##### # スライディングウィンドースプリッタを初期化します．\n",
        "- cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.8), - window_length=30) ##### # スライディングウィンドウを初期化します．\n",
        "- \n",
        "- ##### # 予測格子点探索クロスバリデータをリグレッサ、cv、パラメータグリッドで初期- 化する\n",
        "- gscv = ForecastingGridSearchCV(regressor, cv=cv, param_grid=param_grid, - scoring=mse) ##### # 予測グリッド探索クロスバリデータをリグレッサ，cv，パラメー- タグリッドで初期化します．\n",
        "- \n",
        "- ##### # グリッドサーチを学習データにフィットさせる\n",
        "- gscv.fit(y_train)\n",
        "- \n",
        "- ##### # グリッドサーチの結果を表示します\n",
        "- gscv.cv_results_ ##### #- グリッドサーチの結果を表示します．\n"
      ],
      "metadata": {
        "id": "5GShuko3cSxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 要約\n",
        "\n",
        "このコードはKNeighborsRegressorモデルを使って将来の値を予測しようとしている。\n",
        "- これは分類と回帰に使われるノンパラメトリックな方法である。\n",
        "- このコードでは、sktimeライブラリ、特に性能評価のためのMeanSquaredErrorクラスを使用しています。\n",
        "- また、予測モデルの最適なハイパーパラメータを見つけるために、グリッドサーチとクロスバリデーションを使用しています。\n",
        "- データセットの最初のウィンドウはトレーニングセットとして使用され、残りのデータはモデルの検証と性能の確認に使用されます。\n",
        "- また、このコードでは、予測値と実際の値の間の平均二乗誤差を計算し、モデルの性能を評価します。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "- 以下のコードでは、k-nearest neighbors アルゴリズム（KNeighborsRegressor）を使って予測を行います。\n",
        "- また、sktimeライブラリ、特にmake_reduction、ForecastingGridSearchCV、SlidingWindowSplitterの各クラスを利用しています。\n",
        "- また、予測モデルの最適なハイパーパラメータを見つけるために、グリッドサーチとクロスバリデーションを使用しています。\n",
        "- また、このコードでは、モデルの性能を評価するために、sktimeのperformance_metricsモジュールのMeanSquaredErrorクラスを使っています。\n",
        "\n",
        "\n",
        "- まず、このコードはsktimeのperformance_metricsモジュールからMeanSquaredErrorクラスをインポートし、そのクラスのインスタンスを作成します。\n",
        "\n",
        "- 次に、グリッド検索用のパラメータであるグリッドを指定します。\n",
        "- この場合、「window_length」パラメータだけです。\n",
        "\n",
        "- 次に、KNeighborsRegressor クラスのインスタンスを作成し、forecaster のベースリグレッサーとして使用します。\n",
        "\n",
        "- 次に、SlidingWindowSplitterクラスのインスタンスを作成します。\n",
        "- これは、学習データに対してスライディングウィンドウを使用して反復するクロスバリデーション戦略を作成するために使用されます。\n",
        "- initial_windowパラメータはy_trainの長さの80%に設定され、window_lengthパラメータは30に設定されています。\n",
        "\n",
        "- そして、このコードでは ForecastingGridSearchCV クラスのインスタンスを作成しています。\n",
        "- このクラスは、予測モデルの最適なハイパーパラメータを見つけるために、グリッドサーチとクロスバリデーションを実行するのに使われます。\n",
        " - forecaster \"パラメータは以前に作成したforecasterに、\n",
        " - \"cv \"パラメータは以前に作成したクロスバリデーション戦略に、\n",
        " - \"param_grid \"パラメータは以前に定義したパラメータグリッドに、\n",
        " - \"score \"パラメータは以前に定義した平均2乗誤差インスタンスにセットされます。\n",
        "\n",
        "- そして、fitメソッドを用いてモデルを学習データにフィットさせます。\n",
        "\n",
        "- 最後に，このコードは，cv_results_属性を用いて，クロスバリデーションの結果を取得します．\n",
        "\n",
        "- このコードの利点は、k-nearest neighbors アルゴリズムのハイパーパラメータを調整し、平均二乗誤差を用いてモデルの性能を評価することができることです。\n",
        "- さらに、sktimeライブラリを使用することで、時系列データの取り扱いが容易になり、時系列予測に特に有効なスライディングウィンドウによるクロスバリデーションを使用することができます。\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "このコードでは、y_train データセットに対して KNeighborsRegressor モデルにグリッドサーチによるクロスバリデーションを適用しています。グリッドサーチは、sktime の ForecastingGridSearchCV クラスを使用して実行されます。このクラスは、リグレッサー、cv、そしてパラメータグリッドを入力として受け取ります。cv は SlidingWindowSplitter として初期化され、スコアリングメトリックスは平均二乗誤差である。スライディングウィンドウスプリッタの initial_window パラメータは学習データの長さの80%に設定され、window_length は30に設定される。グリッドサーチオブジェクトの fit メソッドを用いて，訓練データセットに対してモデルのフィッティングを行います．グリッドサーチオブジェクトの cv_results_ 属性は、グリッドサーチの結果を表示するために使用されます。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m5btCGGBbGNc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJPB6iTXrc82"
      },
      "source": [
        "個々のヒダの性能は、フィッティング後、以下のようにアクセスできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTuIlKO1rc82"
      },
      "outputs": [],
      "source": [
        "gscv.fit(y_train)\n",
        "gscv.cv_results_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCbZn6uKrc82"
      },
      "source": [
        "\n",
        "### 3.4 **autoML（自動モデル選択、アンサンブル、ヘッジング**\n",
        "- sktimeは、アンサンブルと自動化されたモデル選択のためのコンポジット を多数提供しています。\n",
        "- 固定されたフォーキャスターに対して最適なハイパーパラメーターを見つけるためにデータ駆動型の戦略を使用するチューニングとは対照的に、このセクションの戦略は、組み合わせたり選択したりするフォーキャスターのコレクションを使用して、推定量のレベルで組み合わせたり選択したりしています。\n",
        "\n",
        "- このセクションで取り上げる戦略は以下の通りである。\n",
        "\n",
        " - autoML（自動モデル選択\n",
        " - 単純なアンサンブル\n",
        " - 重み更新を伴う予測重み付きアンサンブル、およびヘッジ戦略\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukug-8Eirc83"
      },
      "source": [
        "# 3.4.1 **チューニングとマルチプレクサを用いたautoML、別名自動モデル選択**\n",
        "- これは、リストからのフォアキャスターの選択を、セクション3.3のような一般的なハイパーパラメーターチューニング戦略によって調整可能なハイパーパラメーターとして公開するものです。\n",
        "\n",
        "- 単独では、MultiplexForecasterはforecastersの名前付きリストで構成されます。\n",
        " - これはforecastersの中の任意のforecasterの名前に設定することができ、forecastersの中でselected_forecasterによって指定されたforecasterと全く同じように動作します。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **概要**\n",
        "\n",
        "- このセクションでは、sktimeの自動モデル選択機能（autoMLとしても知られる）を使って、予測に最適なモデルを自動的に選択することについて説明しています。\n",
        "- このコードでは、予測を行うために複数のモデルを組み合わせたり、選択したりする方法であるアンサンブルとヘッジのためのいくつかの戦略について議論しています。\n",
        "- モデル選択を行う最も柔軟な方法は、MultiplexForecasterを使用することで、ユーザーは異なるフォアキャスターの中から選択することができます。\n",
        " - そして、選択されたフォアキャスターが予測を行うために使用されます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PHz886jhu2Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sktime.forecasting.model_selection モジュールから ForecastingGridSearchCV と SlidingWindowSplitter クラスをインポートする。\n",
        "from sktime.forecasting.model_selection import (\n",
        "ForecastingGridSearchCV,\n",
        "SlidingWindowSplitter,\n",
        ")\n",
        "\n",
        "# MultiplexForecasterのインスタンスを作成し、複数の予測モデルを一度に使用できるようにする。\n",
        "forecaster = MultiplexForecaster(\n",
        "forecasters=[\n",
        "(\"naive\", NaiveForecaster(strategy=\"last\")), # NaiveForecasterを \"last \"戦略で利用する。\n",
        "(\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)), # ExponentialSmoothingモデルを使用し、トレンドは「add」、季節周期は「12」とする。\n",
        "]\n",
        ")\n",
        "\n",
        "# 使用するクロスバリデーション用スプリッタを定義する\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.5), window_length=30) # クロスバリデーションで使用するスプリッタを定義します．\n",
        "\n",
        "# 検索対象となるパラメータグリッドを定義\n",
        "forecaster_param_grid = {\"selected_forecaster\":[\"ets\", \"naive\"]}.\n",
        "\n",
        "# グリッド検索オブジェクトのインスタンス化\n",
        "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid) # グリッド検索オブジェクトのインスタンスを作成します．\n",
        "\n",
        "# グリッドサーチを学習データにフィットさせる\n",
        "gscv.fit(y_train)\n",
        "\n",
        "# グリッドサーチで見つかった最適なモデルを用いて予測を行う\n",
        "y_pred = gscv.predict(fh)\n",
        "\n",
        "# 予測結果を訓練データ、テストデータと共にプロットします。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算する。\n",
        "\n",
        "# 最適なモデルのパラメータにアクセスする\n",
        "gscv.best_params_\n",
        "\n",
        "# グリッドサーチによって見つかった最良のフォアキャスターにアクセスする\n",
        "gscv.best_forecaster_\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Epz_VcSfiB6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- ##### # sktime.forecasting.model_selection モジュールから - ForecastingGridSearchCV と SlidingWindowSplitter クラスをインポートする。\n",
        "- from sktime.forecasting.model_selection import (\n",
        "- ForecastingGridSearchCV,\n",
        "- SlidingWindowSplitter,\n",
        "- )\n",
        "- \n",
        "- ##### # MultiplexForecasterのインスタンスを作成し、複数の予測モデルを一度に使用- できるようにする。\n",
        "- forecaster = MultiplexForecaster(\n",
        "- forecasters=[\n",
        "- (\"naive\", NaiveForecaster(strategy=\"last\")), ##### # NaiveForecasterを \"last \"戦- 略で利用する。\n",
        "- (\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)), ##### # ExponentialSmoothing- モデルを使用し、トレンドは「add」、季節周期は「12」とする。\n",
        "- ]\n",
        "- )\n",
        "- \n",
        "- ##### # 使用するクロスバリデーション用スプリッタを定義する\n",
        "- cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.5), - window_length=30) ##### # クロスバリデーションで使用するスプリッタを定義します．\n",
        "- \n",
        "- ##### # 検索対象となるパラメータグリッドを定義\n",
        "- forecaster_param_grid = {\"selected_forecaster\":[\"ets\", \"naive\"]}.\n",
        "- \n",
        "- ##### # グリッド検索オブジェクトのインスタンス化\n",
        "- gscv = ForecastingGridSearchCV(forecaster, cv=cv, - param_grid=forecaster_param_grid) ##### # グリッド検索オブジェクトのインスタンス- を作成します．\n",
        "- \n",
        "- ##### # グリッドサーチを学習データにフィットさせる\n",
        "- gscv.fit(y_train)\n",
        "- \n",
        "- ##### # グリッドサーチで見つかった最適なモデルを用いて予測を行う\n",
        "- y_pred = gscv.predict(fh)\n",
        "- \n",
        "- ##### # 予測結果を訓練データ、テストデータと共にプロットします。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "- ##### # 予測値の平均絶対誤差を計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) ##### # 予測値の- 平均絶対誤差を計算する。\n",
        "- \n",
        "- ##### # 最適なモデルのパラメータにアクセスする\n",
        "- gscv.best_params_\n",
        "- \n",
        "- ##### # グリッドサーチによって見つかった最良のフォアキャスターにアクセスする\n",
        "- gscv.best_forecaster_\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NClrEsRViHHT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnwXpNLprc84"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.compose import MultiplexForecaster\n",
        "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
        "from sktime.forecasting.naive import NaiveForecaster\n",
        "forecaster = MultiplexForecaster(\n",
        "    forecasters=[\n",
        "        (\"naive\", NaiveForecaster(strategy=\"last\")),\n",
        "        (\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)),\n",
        "    ],\n",
        ")\n",
        "forecaster.set_params(**{\"selected_forecaster\": \"naive\"})\n",
        "# now forecaster behaves like NaiveForecaster(strategy=\"last\")\n",
        "forecaster.set_params(**{\"selected_forecaster\": \"ets\"})\n",
        "# now forecaster behaves like ExponentialSmoothing(trend=\"add\", sp=12))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、Pythonで時系列を使った機械学習のためのライブラリであるsktimeライブラリを使用した時系列予測パイプラインです。\n",
        "- このパイプラインは複数のフォアキャスターから構成されており、与えられたタスクに対して最適なものを比較・選択するために使用することができます。\n",
        "- パイプラインはライブラリの'MultiplexForecaster'クラスを使用し、ユーザーが複数のフォアキャストを渡すことができるようにします。\n",
        "- ここでは、'NaiveForecaster' クラスと 'ExponentialSmoothing' クラスのインスタンスである 'naive' と 'ets' の2つのフォアキャスターを使用しています。\n",
        "\n",
        "- NaiveForecaster' クラスは、最後に観測された値を用いて将来の値を予測するために用いられ、単純に最後の値を予測値として用います（ここではストラテジーを \"last\" に設定しています）。\n",
        "- ExponentialSmoothing' クラスは、指数平滑法を用いて将来の値を予測するために使用されます。\n",
        "- これは、過去の観測値の加重平均を用いる時系列予測手法で、より最近の観測値に重みが加えられています。\n",
        "- トレンド期間と季節期間はそれぞれ「追加」と「12」に設定されています。\n",
        "- 次に、パイプラインは、y_train データを使用して学習される \n",
        "- 'ForecastingGridSearchCV' を使用してグリッド検索でまとめられ、将来の値を予測する \n",
        "- 'predict' メソッドを使用し、平均絶対誤差率を計算してそのパフォーマンスを評価します。\n",
        "- また、予測値を訓練データとテストデータと共にプロットし、その性能を可視化します。\n",
        "\n"
      ],
      "metadata": {
        "id": "Rd0cf0AyhkI8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNXrSd4Krc84"
      },
      "source": [
        "\n",
        "- MultiplexForecasterは単独ではあまり有用ではないが，チューニングラッパーと組み 合わせることで柔軟なAutoMLを可能にする．\n",
        " - 以下は，3.3節と同様に，スライディングウィンドウによるチューニングで NaiveForecaster と ExponentialSmoothing のいずれかを選択するフォアキャスターを定義したものである．\n",
        "\n",
        "- アップデート機能（セクション1.4参照）によるフォーキャスターのローリング使用と組み合わせることで、チューニングされたマルチプレクサは、時間の進行に応じて、性能に応じてNaiveForecasterとExponentialSmoothingの間を行き来することができます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **概要**\n",
        "\n",
        "- このコードでは、MultiplexForecasterという特別な関数を使って、あるデータセットに対するパフォーマンスに基づいて複数の予測モデル（NaiveForecasterとExponentialSmoothing）のうちの1つを選択することができる。\n",
        "- この関数は、時間の経過とともにモデルの選択を調整するためにスライディングウィンドウ手法を用いたチューニングラッパーと組み合わされています。\n",
        "- これにより、新しいデータが更新されるたびに、2つのモデル（NaiveForecasterとExponentialSmoothing）の間で、その性能に応じてモデルが切り替わるようになります。\n",
        "- これは「autoML」、つまり自動化されたモデル選択の方法であり、どのモデルを使用するかを人間に頼るのではなく、コードが決定することができるのです。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Glmx8IpuvNfP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPxP8HNgrc84"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import ForecastingGridSearchCV and SlidingWindowSplitter from sktime.forecasting.model_selection\n",
        "from sktime.forecasting.model_selection import (\n",
        "    ForecastingGridSearchCV,\n",
        "    SlidingWindowSplitter,\n",
        ")\n",
        "\n",
        "\n",
        "# 異なるフォアキャスターを持つMultiplexForecasterオブジェクトを作成する\n",
        "forecaster = MultiplexForecaster(\n",
        "forecasters=[\n",
        "(\"naive\", NaiveForecaster(strategy=\"last\")), # 予測値として最後の値を使用します。\n",
        "(\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)), # 加算トレンドと季節期間12で指数平滑化を行います。\n",
        "]\n",
        ")\n",
        "\n",
        "# データを訓練集合とテスト集合に分割するために，SlidingWindowSplitter オブジェクトを作成します．\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.5), window_length=30) # データを訓練セットとテストセットに分割するために，SlidingWindowSplitter オブジェクトを作成します．\n",
        "\n",
        "# グリッド探索のためのパラメータグリッドを作成\n",
        "forecaster_param_grid = {\"selected_forecaster\":[\"ets\", \"naive\"]}.\n",
        "\n",
        "# フォアキャスター、クロスバリデーションオブジェクト、パラメータグリッドを用いてForecastingGridSearchCVオブジェクトを作成する。\n",
        "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid) # フォーキャスター、クロスバリデーションオブジェクト、パラメータグリッドからForecastingGridSearchCVオブジェクトを生成する。\n",
        "\n",
        "# グリッド探索オブジェクトを学習データにフィットさせる\n",
        "gscv.fit(y_train)\n",
        "\n",
        "# フィットしたグリッドサーチオブジェクトを用いて予測を行う\n",
        "y_pred = gscv.predict(fh)\n",
        "\n",
        "# 予測結果を訓練データとテストデータと共にプロットします。\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算する。\n",
        "\n",
        "# グリッドサーチで得られた最適なパラメータと最適なフォーキャスターを表示します。\n",
        "print(gscv.best_params_)\n",
        "print(gscv.best_forecaster_)を実行します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- #### # import ForecastingGridSearchCV and SlidingWindowSplitter from sktime.- forecasting.model_selection\n",
        "- from sktime.forecasting.model_selection import (\n",
        "-     ForecastingGridSearchCV,\n",
        "-     SlidingWindowSplitter,\n",
        "- )\n",
        "- \n",
        "- \n",
        "- #### # 異なるフォアキャスターを持つMultiplexForecasterオブジェクトを作成する\n",
        "- forecaster = MultiplexForecaster(\n",
        "- forecasters=[\n",
        "- (\"naive\", NaiveForecaster(strategy=\"last\")), #### # 予測値として最後の値を使用し- ます。\n",
        "- (\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)), #### # 加算トレンドと季節期間- 12で指数平滑化を行います。\n",
        "- ]\n",
        "- )\n",
        "- \n",
        "- #### # データを訓練集合とテスト集合に分割するために，SlidingWindowSplitter オブ- ジェクトを作成します．\n",
        "- cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.5), - window_length=30) #### # データを訓練セットとテストセットに分割するために，- SlidingWindowSplitter オブジェクトを作成します．\n",
        "- \n",
        "- #### # グリッド探索のためのパラメータグリッドを作成\n",
        "- forecaster_param_grid = {\"selected_forecaster\":[\"ets\", \"naive\"]}.\n",
        "- \n",
        "- #### # フォアキャスター、クロスバリデーションオブジェクト、パラメータグリッドを- 用いてForecastingGridSearchCVオブジェクトを作成する。\n",
        "- gscv = ForecastingGridSearchCV(forecaster, cv=cv, - param_grid=forecaster_param_grid) #### # フォーキャスター、クロスバリデーション- オブジェクト、パラメータグリッドからForecastingGridSearchCVオブジェクトを生成す- る。\n",
        "- \n",
        "- #### # グリッド探索オブジェクトを学習データにフィットさせる\n",
        "- gscv.fit(y_train)\n",
        "- \n",
        "- #### # フィットしたグリッドサーチオブジェクトを用いて予測を行う\n",
        "- y_pred = gscv.predict(fh)\n",
        "- \n",
        "- #### # 予測結果を訓練データとテストデータと共にプロットします。\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "- #### # 予測値の平均絶対誤差を計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) #### # 予測値の- 平均絶対誤差を計算する。\n",
        "- \n",
        "- #### # グリッドサーチで得られた最適なパラメータと最適なフォーキャスターを表示し- ます。\n",
        "- print(gscv.best_params_)\n",
        "- print(gscv.best_forecaster_)を実行します。\n",
        "\n"
      ],
      "metadata": {
        "id": "Ld3vbgTQk5HV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqIIvonPrc85"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.model_selection import (\n",
        "    ForecastingGridSearchCV,\n",
        "    SlidingWindowSplitter,\n",
        ")\n",
        "forecaster = MultiplexForecaster(\n",
        "    forecasters=[\n",
        "        (\"naive\", NaiveForecaster(strategy=\"last\")),\n",
        "        (\"ets\", ExponentialSmoothing(trend=\"add\", sp=12)),\n",
        "    ]\n",
        ")\n",
        "cv = SlidingWindowSplitter(initial_window=int(len(y_train) * 0.5), window_length=30)\n",
        "forecaster_param_grid = {\"selected_forecaster\": [\"ets\", \"naive\"]}\n",
        "gscv = ForecastingGridSearchCV(forecaster, cv=cv, param_grid=forecaster_param_grid)\n",
        "gscv.fit(y_train)\n",
        "y_pred = gscv.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)\n",
        "\n",
        "gscv.best_params_\n",
        "\n",
        "gscv.best_forecaster_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードでは、異なるフォアキャスターを組み合わせるためにMultiplexForecasterオブジェクトを、グリッドサーチを使ってフォアキャスターの最適な組み合わせを見つけるためにForecastingGridSearchCVオブジェクトを使用しています。\n",
        "- MultiplexForecasterは2つのフォーキャスターで初期化されます\n",
        "- ：最後の値を予測値として使うナイーブフォーキャスターと、加法トレンドと季節期間12を持つ指数平滑化フォーキャスターです。\n",
        "- データはSlidingWindowSplitterオブジェクトを使って訓練セットとテストセットに分割されます。\n",
        "- ForecastingGridSearchCVオブジェクトはMultiplexForecasterオブジェクト、クロスバリデーションオブジェクト、グリッドサーチのためのパラメータグリッドで初期化されます。\n",
        "- そして、グリッドサーチはトレーニングデータに適合され、適合されたグリッドサーチオブジェクトを使用して予測が行われます。\n",
        "- 予測値は訓練データとテストデータとともにプロットされ、平均絶対誤差が計算される。\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "概要\n",
        "\n",
        "- このコードは、過去のデータに基づいて将来の値を予測するために使用される方法である時系列予測のためのものです。\n",
        "- このコードでは、\n",
        " - モデル選択、\n",
        " - 複数のフォアキャスターの構成、\n",
        " - フォアキャスターの特定のタイプ（ナイーブと指数平滑化）\n",
        "- のためのライブラリをインポートしています。\n",
        "- このコードでは、異なるフォアキャスター（この場合はナイーブ予測と指数平滑化予測）を含むMultiplexForecasterオブジェクトを生成しています。\n",
        "- SlidingWindowSplitterオブジェクトが、データを訓練セットとテストセットに分割するために作成されます。\n",
        "- グリッド検索が試行するために、可能なパラメータ設定のグリッドが作成されます。\n",
        "- ForecastingGridSearchCV オブジェクトが多重フォーキャスター、クロスバリデーション・オブジェクト、パラメータ・グリッドとともに作成されます。\n",
        "- グリッド検索オブジェクトはトレーニングデータに適合され、そして予測を行うために使用されます。\n",
        "- 予測値、トレーニングデータ、テストデータがプロットされ、予測値の平均絶対誤差が計算されます。\n",
        "- グリッドサーチで得られた最適なパラメータと最適なフォーキャスターが印刷されます。\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "954n_uCLj9GF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIXE8-oXrc86"
      },
      "source": [
        "他の調整済みフォアキャスターと同様に、最適なパラメータと調整済みフォアキャスターのインスタンスは best_params_ と best_forecaster_ を使って取得することができる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoHvZfZ2rc86"
      },
      "outputs": [],
      "source": [
        "gscv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE4SxQwLrc86"
      },
      "outputs": [],
      "source": [
        "gscv.best_forecaster_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL3x-pj8rc87"
      },
      "source": [
        "\n",
        "\n",
        "### **3.4.2 autoML: OptimalPassthroughによるトランスフォーマーの組み合わせの選択**\n",
        "- sktimeは、パイプライン内部のパイプラインコンポーネントを自動的に選択する機能、すなわち、パイプライン構造も提供します。\n",
        " - これは、OptionalPassthroughトランスフォーマーによって実現される。\n",
        "\n",
        "- OptionalPassthroughトランスフォーマーでは、パイプライン内部のトランスフォーマーがデータに適用されるかどうかをチューニングすることができる。\n",
        " - 例えば、sklearn.StandardScalerが予測に有利に働くかどうかを調整したい場合、OptionalPassthroughで包み込みます。\n",
        " - 内部的には、OptionalPassthroughはハイパーパラメータpassthrough: boolを持ち、これは調整可能です。\n",
        " - Falseの場合、コンポジットはラップしたトランスフォーマーのように振る舞い、Trueの場合、内部のトランスフォーマーは無視されます。\n",
        "\n",
        "- OptionalPasstrhoughを有効に使うには、scikit-learnでおなじみの__（ダブルアンダースコア）記法で適切なパラメータセットを定義します。\n",
        " - これにより、TabularToSeriesAdaptor(StandardScaler())のようなネストしたオブジェクトの属性にアクセスし、調整することができます。\n",
        " - ネストが2段階以上ある場合は、__を複数回使用することができます。\n",
        "\n",
        "- 次の例では、deseasonalize/scaleパイプラインを取り上げ、deseasonalizerとscalerがパイプラインに含まれる4つの可能な組み合わせについてyes/no (2 times 2 = 4); forecasterとscalerのパラメータについてチューニングしています。\n",
        "\n",
        "- 注: これは、セクション 3.4.1 のように MultiplexForecaster と任意に組み合わせて、パイプラインアーキテクチャとパイプライン構造を選択することができる。\n",
        "\n",
        "- 注意：scikit-learn と sktime は現在のところ、条件付きパラメータセットをサポートしていません（mlr3 パッケージなどとは異なります）。\n",
        " - これは、スケーラのパラメータがスキップされた場合でも、グリッドサーチはスケーラのパラメータに対して最適化されることを意味する。\n",
        "  - この機能を設計・実装することは、貢献や研究のための興味深い分野であろう。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **概要**\n",
        "\n",
        "- sktimeは、時系列予測のための様々なツールを提供するライブラリである。\n",
        "- 時系列の将来の値を予測するために、さまざまな手法を使用することができます。\n",
        "- また、このライブラリは、データに最適な予測手法を選択するための自動モデル選択ツールも提供しています。\n",
        "- このライブラリで提供されるツールには、MultiplexForecasterがあり、リストから予測手法を選択する際に、汎用的なハイパーパラメータチューニング戦略によって調整可能なハイパーパラメータとして公開されます。\n",
        "- これは、チューニングラッパーと組み合わせることで、柔軟なモデル選択の自動化を可能にします。\n",
        "- このライブラリで提供されるもう一つのツールは、OptionalPassthroughトランスフォーマーで、パイプライン内のトランスフォーマーがデータに適用されるかどうかをチューニングすることが可能です。\n",
        "- これは、パイプライン内部のパイプラインコンポーネントの最適な組み合わせを選択するために使用することができます。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0EnxE1lgv6Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import StandardScaler from sklearn.preprocessing\n",
        "from sklearn.preprocessing import StandardScaler.\n",
        "\n",
        "# import load_airline, TransformedTargetForecaster, ForecastingGridSearchCV and SlidingWindowSplitter from sktime.datasets, sktime.forecasting.compose and sktime.forecasting.model_selection それぞれから。\n",
        "from sktime.datasets import load_airline\n",
        "from sktime.forecasting.compose import TransformedTargetForecaster\n",
        "from sktime.forecasting.model_selection import (\n",
        "ForecastingGridSearchCV,\n",
        "SlidingWindowSplitter,\n",
        ")\n",
        "\n",
        "# import NaiveForecaster from sktime.forecasting.naive\n",
        "from sktime.forecasting.naive import NaiveForecaster\n",
        "\n",
        "# import OptionalPassthrough from sktime.transformations.compose\n",
        "from sktime.transformations.compose import OptionalPassthrough\n",
        "\n",
        "# import TabularToSeriesAdaptor, Deseasonalizer from sktime.transformations.series.adapt and sktime.transformations.series.detrend.\n",
        "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
        "from sktime.transformations.series.detrend import Deseasonalizer\n",
        "\n",
        "# パイプラインの作成\n",
        "pipe = TransformedTargetForecaster(\n",
        "steps=[\n",
        "(\"deseasonalizer\", OptionalPassthrough(Deseasonalizer())), # step 1: Deseasonalizer\n",
        "(\"scaler\", OptionalPassthrough(TabularToSeriesAdaptor(StandardScaler())), # step 2: StandardScaler\n",
        "(\"forecaster\", NaiveForecaster()), # step 3: NaiveForecaster\n",
        "]\n",
        ")\n",
        "\n",
        "# グリッド検索にまとめる\n",
        "cv = SlidingWindowSplitter(\n",
        "initial_window=60, window_length=24, start_with_window=True, step_length=24\n",
        ")\n",
        "param_grid = {\n",
        "\"deseasonalizer__passthrough\":[True, False], # Deseasonalizerを使用するか否かを設定するためのパラメータ\n",
        "\"scaler__transformer__with_mean\":[True, False], # 平均値スケーリングを使用するかどうかを設定するパラメータ\n",
        "\"scaler__passthrough\":[True, False], # StandardScalerを使うかどうか設定するパラメーター\n",
        "\"forecaster__strategy\":[\"drift\", \"mean\", \"last\"], # 予測ストラテジーを設定するパラメーター\n",
        "}\n",
        "gscv = ForecastingGridSearchCV(forecaster=pipe, param_grid=param_grid, cv=cv, n_jobs=-1)\n",
        "\n",
        "# 学習データへのパイプラインのフィット\n",
        "gscv.fit(y_train)\n",
        "\n",
        "# フィットしたパイプラインを用いて予測を行う\n",
        "y_pred = gscv.predict(fh)\n",
        "\n",
        "# 予測結果を訓練データとテストデータと共にプロットする\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 予測値の平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 予測値の平均絶対誤差を計算する。\n"
      ],
      "metadata": {
        "id": "dLYRNVEGfdRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ##### # import StandardScaler from sklearn.preprocessing\n",
        "- from sklearn.preprocessing import StandardScaler.\n",
        "- \n",
        "- ##### # import load_airline, TransformedTargetForecaster, - ForecastingGridSearchCV and SlidingWindowSplitter from sktime.datasets, sktime.- forecasting.compose and sktime.forecasting.model_selection respectively.\n",
        "- from sktime.datasets import load_airline\n",
        "- from sktime.forecasting.compose import TransformedTargetForecaster\n",
        "- from sktime.forecasting.model_selection import (\n",
        "- ForecastingGridSearchCV,\n",
        "- SlidingWindowSplitter,\n",
        "- )\n",
        "- \n",
        "- ##### # import NaiveForecaster from sktime.forecasting.naive\n",
        "- from sktime.forecasting.naive import NaiveForecaster\n",
        "- \n",
        "- ##### # import OptionalPassthrough from sktime.transformations.compose\n",
        "- from sktime.transformations.compose import OptionalPassthrough\n",
        "- \n",
        "- ##### # import TabularToSeriesAdaptor, Deseasonalizer from sktime.- transformations.series.adapt and sktime.transformations.series.detrend.\n",
        "- from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
        "- from sktime.transformations.series.detrend import Deseasonalizer\n",
        "- \n",
        "- ##### # パイプラインの作成\n",
        "- pipe = TransformedTargetForecaster(\n",
        "- steps=[\n",
        "- (\"deseasonalizer\", OptionalPassthrough(Deseasonalizer())), ##### # step 1: - Deseasonalizer\n",
        "- (\"scaler\", OptionalPassthrough(TabularToSeriesAdaptor(StandardScaler())), ##### - # step 2: StandardScaler\n",
        "- (\"forecaster\", NaiveForecaster()), ##### # step 3: NaiveForecaster\n",
        "- ]\n",
        "- )\n",
        "- \n",
        "- ##### # グリッド検索にまとめる\n",
        "- cv = SlidingWindowSplitter(\n",
        "- initial_window=60, window_length=24, start_with_window=True, step_length=24\n",
        "- )\n",
        "- パラメータグリッド\n",
        "- \"deseasonalizer__passthrough\":[True, False], ##### # Deseasonalizerを使用するか- 否かを設定するためのパラメータ\n",
        "- \"scaler__transformer__with_mean\":[True, False], ##### # 平均値スケーリングを使用- するかどうかを設定するパラメータ\n",
        "- \"scaler__passthrough\":[True, False], ##### # StandardScalerを使うかどうか設定す- るパラメーター\n",
        "- \"forecaster__strategy\":[\"drift\", \"mean\", \"last\"], ##### # 予測ストラテジーを設定- するパラメーター\n",
        "- }\n",
        "- gscv = ForecastingGridSearchCV(forecaster=pipe, param_grid=param_grid, cv=cv, - n_jobs=-1)\n",
        "- \n",
        "- ##### # 学習データにパイプラインをフィットさせる\n",
        "- gscv.fit(y_train)\n",
        "- \n",
        "- ##### # フィットしたパイプラインを用いて予測を行う\n",
        "- y_pred = gscv.predict(fh)\n",
        "- \n",
        "- ##### # 予測結果を訓練データとテストデータと共にプロットする\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "- ##### # 予測値の平均絶対誤差を計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) ##### # 予測値の- 平均絶対誤差を計算する。"
      ],
      "metadata": {
        "id": "mA130XUYe4Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "概要\n",
        "\n",
        "- 本コードは、Pythonの時系列機械学習用ライブラリであるsktimeライブラリを用いた時系列予測パイプラインである。\n",
        "- パイプラインは3つのステップで構成されています。Deseasonalizer, StandardScaler, NaiveForecasterの3つのステップで構成されています。\n",
        "- Deseasonalizerは時系列から季節成分を除去するために使用される。\n",
        "- StandardScalerは時系列の特徴をスケーリングするために使用される。\n",
        "- NaiveForecasterは、最後に観測された値を用いて将来の値を予測するために使用される。\n",
        "- 次に、ForecastingGridSearchCV を用いて、パイプラインをグリッド検索でまとめ、y_train データを用いてパイプラインを学習させ、predict メソッドを用いて将来の値を予測し、平均絶対誤差率を計算してそのパフォーマンスを評価します。\n",
        "- また、訓練データとテストデータと共に予測値をプロットし、その性能を可視化します。\n",
        "- このパイプラインは、過去の観測結果に基づいて将来の値を予測しなければならない時系列予測タスクに有用です。\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "概要\n",
        "\n",
        "- 本コードは、Pythonの時系列機械学習用ライブラリsktimeを用いた時系列予測パイプラインである。\n",
        "- パイプラインは3つのステップで構成されています。Deseasonalizer, StandardScaler, NaiveForecasterの3つのステップで構成されています。\n",
        "- Deseasonalizerは時系列から季節成分を取り除くために使用されます。\n",
        " - 例えば、毎年特定の月の売上に上昇トレンドがある場合、そのトレンドを取り除きます。\n",
        "- StandardScalerは時系列の特徴をスケーリングするために使用され、時系列の平均が0、標準偏差が1になるようにし、より良い予測に役立てる。\n",
        "- NaiveForecasterは、最後に観測された値を使用して将来の値を予測するために使用され、単に最後の値を予測値として使用します。\n",
        "- 次に、ForecastingGridSearchCV を用いて、\n",
        " - パイプラインをグリッド検索でまとめ、\n",
        " - y_train データを用いてパイプラインを学習させ、\n",
        " - predict メソッドを用いて将来の値を予測し、\n",
        " - 平均絶対誤差率を計算することでそのパフォーマンスを評価します。\n",
        "- また、予測値を訓練データとテストデータと共にプロットし、その性能を可視化します。\n",
        "- グリッドサーチは、パイプラインの最適なパラメータを見つけるために使用され、パラメータのすべての可能な組み合わせを試すことができます。\n",
        "- このパイプラインは、過去の観測値に基づいて将来の値を予測する必要がある時系列予測タスクに有用です。\n",
        "- 予測性能の評価には、平均絶対誤差（mean absolute percentage error）を使用し、予測精度の指標とします。\n",
        "- このパイプラインは、n_jobs=-1の並列処理により、利用可能なすべてのコアで実行され、学習プロセスを高速化することができます。\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tnUNu8W5gCUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iv-_J8Rrc87"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sktime.datasets import load_airline\n",
        "from sktime.forecasting.compose import TransformedTargetForecaster\n",
        "from sktime.forecasting.model_selection import (\n",
        "    ForecastingGridSearchCV,\n",
        "    SlidingWindowSplitter,\n",
        ")\n",
        "from sktime.forecasting.naive import NaiveForecaster\n",
        "from sktime.transformations.compose import OptionalPassthrough\n",
        "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
        "from sktime.transformations.series.detrend import Deseasonalizer\n",
        "# create pipeline\n",
        "pipe = TransformedTargetForecaster(\n",
        "    steps=[\n",
        "        (\"deseasonalizer\", OptionalPassthrough(Deseasonalizer())),\n",
        "        (\"scaler\", OptionalPassthrough(TabularToSeriesAdaptor(StandardScaler()))),\n",
        "        (\"forecaster\", NaiveForecaster()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# putting it all together in a grid search\n",
        "cv = SlidingWindowSplitter(\n",
        "    initial_window=60, window_length=24, start_with_window=True, step_length=24\n",
        ")\n",
        "param_grid = {\n",
        "    \"deseasonalizer__passthrough\": [True, False],\n",
        "    \"scaler__transformer__transformer__with_mean\": [True, False],\n",
        "    \"scaler__passthrough\": [True, False],\n",
        "    \"forecaster__strategy\": [\"drift\", \"mean\", \"last\"],\n",
        "}\n",
        "gscv = ForecastingGridSearchCV(forecaster=pipe, param_grid=param_grid, cv=cv, n_jobs=-1)\n",
        "\n",
        "gscv.fit(y_train)\n",
        "y_pred = gscv.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler # import StandardScaler from sklearn.preprocessing\n",
        "from sktime.datasets import load_airline # import load_airline from sktime.datasets\n",
        "from sktime.forecasting.compose import TransformedTargetForecaster # import TransformedTargetForecaster from sktime.forecasting.compose\n",
        "from sktime.forecasting.model_selection import (ForecastingGridSearchCV,SlidingWindowSplitter) # インポート ForecastingGridSearchCVとSlidingWindowSplitter from sktime.forecasting.model_selection\n",
        "from sktime.forecasting.naive import NaiveForecaster # import NaiveForecaster from sktime.forecasting.naive\n",
        "from sktime.transformations.compose import OptionalPassthrough # import OptionalPassthrough from sktime.transformations.compose\n",
        "from sktime.transformations.series.adapt import TabularToSeriesAdaptor # import TabularToSeriesAdaptor from sktime.transformations.series.adapt\n",
        "from sktime.transformations.series.detrend import Deseasonalizer # import Deseasonalizer from sktime.transformations.series.detrend\n",
        "\n",
        "# TransformedTargetForecaster 用のパイプラインを作成する\n",
        "pipe = TransformedTargetForecaster(\n",
        "steps=[\n",
        "(\"deseasonalizer\", OptionalPassthrough(Deseasonalizer())), # DeseasonalizerのOptionalPassthrough\n",
        "(\"scaler\", OptionalPassthrough(TabularToSeriesAdaptor(StandardScaler())), # TabularToSeriesAdaptorのOptionalPassthrough\n",
        "(\"forecaster\", NaiveForecaster()), # NaiveForecaster\n",
        "]\n",
        ")\n",
        "\n",
        "# グリッド検索にまとめる\n",
        "cv = SlidingWindowSplitter(\n",
        "initial_window=60, window_length=24, start_with_window=True, step_length=24\n",
        ")# SlidingWindowSplitter の使用法\n",
        "param_grid = {\n",
        "\"deseasonalizer__passthrough\":[True, False],\n",
        "\"scaler__transformer__with_mean\":[True, False],\n",
        "\"scaler__passthrough\":[True、False] ,\n",
        "\"forecaster__strategy\": [\"drift\", \"mean\", \"last\"],\n",
        "}\n",
        "gscv = ForecastingGridSearchCV(forecaster=pipe, param_grid=param_grid, cv=cv, n_jobs=-1)\n",
        "\n",
        "gscv.fit(y_train) # モデルのあてはめ\n",
        "y_pred = gscv.predict(fh) # 予測\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]) # 系列をプロットする。\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) # 平均絶対誤差を計算する。\n"
      ],
      "metadata": {
        "id": "n409eep6mPyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、過去の値に基づいて将来の値を予測するコンピュータ・プログラムのためのものである。\n",
        "- データを理解するためにsklearnと呼ばれるライブラリを使用します。\n",
        "- 予測を行う前にデータを処理するために、いくつかのステップからなる「パイプライン」を作成する。\n",
        "- パイプラインには、デシーズナライザー、スケーラー、フォーキャスターが含まれる。\n",
        "- デシーズナライザーは、毎日や毎月といった一定間隔で発生するパターンをデータから取り除く。\n",
        "- スケーラは、すべての値が0から1のような同じ範囲になるようにデータを変更します。\n",
        "- フォーキャスターは、未来を予測しようとする魔法の水晶玉のようなものです。\n",
        "- 次にパイプラインは、SlidingWindowSplitterという特殊なツールを使って、データをチャンクに分割し、パイプラインの性能を評価します。\n",
        "- また、ForecastingGridSearchCVというツールを使って、パイプラインの様々な設定を比較し、最適なものを探します。\n",
        "- このコードでは、パイプラインをトレーニングデータに適合させ、それを使って未知のデータに対して予測を行います。\n",
        "- また、学習データ、テストデータ、予測データをグラフにプロットし、予測値の誤差を計算します。\n",
        "\n",
        "#### まとめ\n",
        "\n",
        "- このコードは、過去の値を用いて将来の値を予測し、いくつかのツールを用いて予測結果を処理し評価する。\n",
        "- そして、予測値と実際の値を視覚的に比較するために結果をプロットし、予測値の誤差を計算する。\n"
      ],
      "metadata": {
        "id": "PTkAdyeToIRl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86TRZl_prc88"
      },
      "source": [
        "\n",
        "### **3.4.3 シンプルなアンサンブル戦略**\n",
        "TODO - このセクションへの貢献が望まれる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQVkQ7Bjrc88"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sktime.forecasting.compose import EnsembleForecaster # import EnsembleForecaster from sktime.forecasting.compose\n",
        "from sktime.forecasting.exp_smoothing import ExponentialSmoothing # import ExponentialSmoothing from sktime.forecasting.exp_smoothing\n",
        "\n",
        "# single, holt, dampedの指数平滑化モデルを作成します。\n",
        "ses = ExponentialSmoothing(sp=12) # シングル指数平滑化\n",
        "holt = ExponentialSmoothing(trend=\"add\", damped_trend=False, sp=12) # ホルトのリニアトレンドモデル\n",
        "damped = ExponentialSmoothing(trend=\"add\", damped_trend=True, sp=12) # Holt's Damped Trend Model (ホルトの減衰トレンドモデル)\n",
        "\n",
        "# アンサンブルフォーキャスターを作成\n",
        "Forecaster = EnsembleForecaster(\n",
        "[\n",
        "(\"ses\", ses), # 単一指数平滑化\n",
        "(\"holt\", holt), # ホルトの線形トレンドモデル\n",
        "(\"damped\", damped), # Holt's Damped Trend Model（ホルトの減衰トレンドモデル\n",
        "]\n",
        ")\n",
        "\n",
        "# 学習データに対してモデルをフィットさせる\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "# 未経験のデータで予測\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "# 学習データ、テストデータ、予測データをグラフにプロットする\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) #平均絶対誤差を計算する。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- from sktime.forecasting.compose import EnsembleForecaster#### # import - EnsembleForecaster from sktime.forecasting.compose\n",
        "- from sktime.forecasting.exp_smoothing import ExponentialSmoothing#### # import - ExponentialSmoothing from sktime.forecasting.exp_smoothing\n",
        "- #### # single, holt, dampedの指数平滑化モデルを作成します。\n",
        "- ses = ExponentialSmoothing(sp=12)#### # シングル指数平滑化\n",
        "- holt = ExponentialSmoothing(trend=\"add\", damped_trend=False, sp=12)#### # ホルト- のリニアトレンドモデル\n",
        "- damped = ExponentialSmoothing(trend=\"add\", damped_trend=True, sp=12)#### # - Holt's Damped Trend Model (ホルトの減衰トレンドモデル)\n",
        "- #### # アンサンブルフォーキャスターを作成\n",
        "- Forecaster = EnsembleForecaster(\n",
        "- [\n",
        "- (\"ses\", ses),#### # 単一指数平滑化\n",
        "- (\"holt\", holt),#### # ホルトの線形トレンドモデル\n",
        "- (\"damped\", damped),#### # Holt's Damped Trend Model（ホルトの減衰トレンドモデル\n",
        "- ]\n",
        "- )\n",
        "- #### # 学習データに対してモデルをフィットさせる\n",
        "- forecaster.fit(y_train)\n",
        "- #### # 未経験のデータで予測\n",
        "- y_pred = forecaster.predict(fh)\n",
        "- #### # 学習データ、テストデータ、予測データをグラフにプロットする\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- #### # 平均絶対誤差を計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False)#### #平均絶対誤- 差を計算する。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PqBtXm99qLGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- このコードは、過去の値から将来の値を予測するコンピュータ・プログラムのためのものである。\n",
        "- データを理解するためにsktimeと呼ばれるライブラリを使用します。\n",
        "- これは3つの異なるタイプの予測モデルを作成する。\n",
        "- 単一指数平滑化、ホルトの線形トレンドモデル、ホルトの減衰トレンドモデルである。\n",
        "- そして、これらの3つのモデルを組み合わせて、より正確な予測を行います。\n",
        "- そして、このコードは、学習データにアンサンブルモデルを当てはめ、それを使って未知のデータを予測します。\n",
        "- このコードはまた、学習データ、テストデータ、予測データをグラフにプロットし、予測値の誤差を計算します。\n",
        "\n",
        "### まとめ。\n",
        "\n",
        "- このコードは、\n",
        " - 3つの異なるタイプの予測モデルを作成し、\n",
        " - それらを組み合わせてより正確な予測を行い、\n",
        " - 訓練データにアンサンブルモデルを当てはめ、\n",
        " - 未知のデータで予測し、\n",
        " - 結果をプロットして予測値と実際の値を視覚的に比較し、\n",
        " - 予測値の誤差を計算します。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3LWJ7h-SpNxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 単一指数平滑化は、最後に見たものしか覚えていない人のようなものです。\n",
        " - それは予測をするために最も最近のデータだけを見ます。\n",
        "\n",
        "- Holtの線形傾向モデルは、彼らが見た最後のものを覚えているが、物事が良くなっているか悪くなっている場合にも気づいている人のようなものです。\n",
        " - それは予測をするためにデータの傾向を考慮に入れる。\n",
        "\n",
        "- ホルトの減衰トレンドモデルは、最後に見たものを覚えている人のように、物事が良くなっているか悪くなっているかだけでなく、トレンドが減速しているか早くなっているかにも気づくことができます。\n",
        " - これは、データのトレンドとトレンドの変化率を考慮して予測を行う。\n",
        "\n",
        "- Single Exponential Smoothingは最もシンプルなモデルで、使いやすく理解しやすいのですが、直近のデータしか考慮しないため、Holtのモデルほど正確ではありません。\n",
        "\n",
        "- HoltのLinear Trend Modelは、データの傾向を考慮するため、Single Exponential Smoothingよりも正確ですが、トレンドが急激に変化している場合には、HoltのDamped Trend Modelほど正確でない場合があります。\n",
        "\n",
        "- Holt's Damped Trend Modelは、データのトレンドとトレンドの変化率を考慮するため、最も正確なモデルですが、使い方や理解が難しい場合があります。\n",
        "\n",
        "### まとめ\n",
        "\n",
        "- 単一指数平滑化は、最後に見たものしか覚えていない人のようなものです。\n",
        "- HoltのLinear Trend Modelは、最後に見たものを覚えていて、さらに物事が良くなっているか悪くなっているかに気がつく人のようなものです。\n",
        "- Holtの弱められた傾向モデルは彼らが見た最後の事を覚えている、事がよりよくまたはより悪く、また傾向が減速しているかどうか気づく人のようであるまたはスピードをあげなさい。\n",
        "- Single Exponential Smoothingはシンプルですが、あまり正確ではありません。\n",
        "- HoltのLinear Trend Modelはより正確ですが、HoltのDamped Trend Modelは最も正確ですが、より複雑でもあります。\n",
        "\n"
      ],
      "metadata": {
        "id": "AKkqjCuhqbl6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "P_dnl6dIrc89"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.compose import EnsembleForecaster\n",
        "ses = ExponentialSmoothing(sp=12)\n",
        "holt = ExponentialSmoothing(trend=\"add\", damped_trend=False, sp=12)\n",
        "damped = ExponentialSmoothing(trend=\"add\", damped_trend=True, sp=12)\n",
        "\n",
        "forecaster = EnsembleForecaster(\n",
        "    [\n",
        "        (\"ses\", ses),\n",
        "        (\"holt\", holt),\n",
        "        (\"damped\", damped),\n",
        "    ]\n",
        ")\n",
        "forecaster.fit(y_train)\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TYgDrjPrc89"
      },
      "source": [
        "\n",
        "## **3.4.4 予測重み付きアンサンブルとヘッジアンサンブル**\n",
        "- モデル評価のために、テストデータ上のスライディングウィンドウで時間的クロスバリデーションを使用して、複数の予測を評価したい場合があります。\n",
        "- この目的のために、我々は、複合フォーキャスター、PredictionWeightedEnsemble を使用する online_forecasting モジュールのフォーキャスターを活用し、各フォーキャスターが蓄積した損失を追跡し、最も「正確な」フォーキャスターの予測によって加重した予測を作成することができます。\n",
        "\n",
        "- 予測タスクが変更されていることに注意してください：\n",
        " - 重みの更新を助けるために最初の予測が必要なので、我々は35の予測をします、我々は36ステップ先を予測しません。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**概要**\n",
        "\n",
        "- このセクションでは、予測のために異なるモデルを自動的に選択し組み合わせる様々な方法について説明しています。\n",
        "- 1つの方法は、MultiplexForecasterと呼ばれるツールを使うことです。\n",
        " - これは、ユーザーが異なるフォーキャスターのリストから選び、そのパフォーマンスによって切り替えることができるようにします。\n",
        "- もう一つの方法は、OptionalPassthroughと呼ばれるツールを使用することです。\n",
        "- また、PredictionWeightedEnsembleというツールを使う方法もあります。\n",
        " - これは、異なるフォアキャストのパフォーマンスを記録し、最も正確なフォアキャストの予測に重み付けをして、最終的な予測を作成するものです。\n",
        "- このツールを使用する場合、最初の予測が重みの更新に使用されるため、作成される予測の数は1つ減ることに注意してください。\n",
        "\n"
      ],
      "metadata": {
        "id": "r4vEIkQzwg8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sktime.forecasting.all import mean_squared_error # インポートmean_squared_error from sktime.forecasting.all\n",
        "from sktime.forecasting.online_learning import (NormalHedgeEnsemble, OnlineEnsembleForecaster)\n",
        "# import NormalHedgeEnsemble, OnlineEnsembleForecaster from sktime.forecasting.online_learning\n",
        "\n",
        "# NormalHedgeEnsembleでアンサンブルモデルを作成する\n",
        "hedge_expert = NormalHedgeEnsemble(n_estimators=3, loss_func=mean_squared_error)#を使用したアンサンブルモデルを作成する。\n",
        "\n",
        "# オンラインアンサンブルフォーキャスターを作成\n",
        "forecaster = OnlineEnsembleForecaster(\n",
        "[\n",
        "(\"ses\", ses), # 単一指数平滑化\n",
        "(\"holt\", holt), # ホルトのリニアトレンドモデル\n",
        "(\"damped\", damped), # ホルトの減衰トレンドモデル\n",
        "],\n",
        "ensemble_algorithm=hedge_expert,\n",
        ")\n",
        "\n",
        "# 学習データに対してモデルをフィットさせる\n",
        "forecaster.fit(y=y_train, fh=fh)\n",
        "\n",
        "# update_predict_single メソッドを使って未経験のデータで予測します。\n",
        "y_pred = forecaster.update_predict_single(y_test)\n",
        "\n",
        "# 学習、テスト、予測されたデータをグラフにプロットする\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "\n",
        "# 平均絶対誤差を計算する\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False) #平均絶対誤差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "BxofsK0QrrC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- from sktime.forecasting.all import mean_squared_error #### # インポート- mean_squared_error from sktime.forecasting.all\n",
        "- from sktime.forecasting.online_learning import (NormalHedgeEnsemble, - OnlineEnsembleForecaster)\n",
        "- #### # import NormalHedgeEnsemble, OnlineEnsembleForecaster from sktime.- forecasting.online_learning\n",
        "- \n",
        "- #### # NormalHedgeEnsembleでアンサンブルモデルを作成する\n",
        "- hedge_expert = NormalHedgeEnsemble(n_estimators=3, loss_func=mean_squared_error)- #### #を使用したアンサンブルモデルを作成する。\n",
        "- \n",
        "- #### # オンラインアンサンブルフォーキャスターを作成\n",
        "- forecaster = OnlineEnsembleForecaster(\n",
        "- [\n",
        "- (\"ses\", ses), #### # 単一指数平滑化\n",
        "- (\"holt\", holt), #### # ホルトのリニアトレンドモデル\n",
        "- (\"damped\", damped), #### # ホルトの減衰トレンドモデル\n",
        "- ],\n",
        "- ensemble_algorithm=hedge_expert,\n",
        "- )\n",
        "- \n",
        "- #### # 学習データに対してモデルをフィットさせる\n",
        "- forecaster.fit(y=y_train, fh=fh)\n",
        "- \n",
        "- #### # update_predict_single メソッドを使って未経験のデータで予測します。\n",
        "- y_pred = forecaster.update_predict_single(y_test)\n",
        "- \n",
        "- #### # 学習、テスト、予測されたデータをグラフにプロットする\n",
        "- plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "- \n",
        "- #### # 平均絶対誤差を計算する\n",
        "- mean_absolute_percentage_error(y_test, y_pred, symmetric=False) #### #平均絶対誤- 差を計算する。\n",
        "\n"
      ],
      "metadata": {
        "id": "aY3Fkn5krqcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 概要\n",
        "\n",
        "- このコードは、過去のデータから将来の値を予測する時系列予測に使用されるものである。\n",
        "- コードの最初の2行は、異なるライブラリから特定のツールをインポートしており、それらはコードの後半で使用されます。\n",
        "- このコードは、次にNormalHedgeEnsembleツールを使って「hedge_expert」というアンサンブルモデルを作成し、複数のモデルを一緒に組み合わせて予測を向上させます。\n",
        " - このプロセスでは、mean_squared_error ツールも使用します。\n",
        "- 次に、このコードは、hege_expertアンサンブルモデルと3つの異なる予測モデルを使用する「オンライン・アンサンブル・フォーキャスター」を作成します。\n",
        " - このコードは、ヘッジエキスパート・アンサンブルモデルと3つの異なる予測モデル（単一指数平滑化、ホルトの線形トレンドモデル、ホルトの減衰トレンドモデル）を使用する「オンライン・アンサンブル・フォーキャスター」を作成します。\n",
        "- フォーキャスターは学習データにフィットし、「update_predict_single」メソッドを用いて未経験のデータに対して予測が行われます。\n",
        "- そして、このコードでは、学習データ、テストデータ、予測データを可視化するためにグラフを描画します。\n",
        "- 最後に、予測精度の指標となる平均絶対誤差（Mean Absolute Percent Error）を計算します。\n",
        "\n"
      ],
      "metadata": {
        "id": "Dfmgx7wAsqBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCDfcHbGrc89"
      },
      "outputs": [],
      "source": [
        "from sktime.forecasting.all import mean_squared_error\n",
        "from sktime.forecasting.online_learning import (\n",
        "    NormalHedgeEnsemble,\n",
        "    OnlineEnsembleForecaster,\n",
        ")\n",
        "\n",
        "hedge_expert = NormalHedgeEnsemble(n_estimators=3, loss_func=mean_squared_error)\n",
        "\n",
        "forecaster = OnlineEnsembleForecaster(\n",
        "    [\n",
        "        (\"ses\", ses),\n",
        "        (\"holt\", holt),\n",
        "        (\"damped\", damped),\n",
        "    ],\n",
        "    ensemble_algorithm=hedge_expert,\n",
        ")\n",
        "\n",
        "forecaster.fit(y=y_train, fh=fh)\n",
        "y_pred = forecaster.update_predict_single(y_test)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDpWy1xJrc8-"
      },
      "source": [
        "\n",
        "まず、PredictionWeightedEnsemblerを初期化し、各予測者が蓄積した損失を追跡し、どの損失関数を使用するかを定義する必要があります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PdjmuD6mrc8-"
      },
      "outputs": [],
      "source": [
        "hedge_expert = NormalHedgeEnsemble(n_estimators=3, loss_func=mean_squared_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hW-NGpW8rc8-"
      },
      "source": [
        "\n",
        "- 次に、個々のフォーキャスターを定義し、使用するPredictionWeightedEnsemblerを指定することで、フォーキャスターを作成することができます。\n",
        "- そして、フォーキャスターをフィッティングし、update_predict関数で更新と予測を行うことで、次のようになります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bhVmLz6rc8_"
      },
      "outputs": [],
      "source": [
        "forecaster = OnlineEnsembleForecaster(\n",
        "    [\n",
        "        (\"ses\", ses),\n",
        "        (\"holt\", holt),\n",
        "        (\"damped\", damped),\n",
        "    ],\n",
        "    ensemble_algorithm=hedge_expert,\n",
        ")\n",
        "\n",
        "forecaster.fit(y=y_train, fh=fh)\n",
        "y_pred = forecaster.update_predict_single(y_test)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "mean_absolute_percentage_error(y_test, y_pred, symmetric=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **4.拡張ガイド - あなた自身のフォーキャスターを実装する**\n",
        "- sktimeは簡単に拡張できるように意図されており、sktimeへの直接の貢献と同様に、カスタムメソッドによるローカル/プライベートな拡張も可能である。\n",
        "\n",
        "- 始めるには\n",
        "\n",
        "- 推定器の実装\" 開発者ガイドに従ってください。\n",
        "- ストリーム、確率的、階層的な機能を持たない予測器にはシンプルな予測拡張テンプレートを使用する。\n",
        "- ストリーム、確率的、階層的な機能を持つ予測ツールには、高度な予測拡張テンプレートを使用します。\n",
        "- 確率的、階層的なフォアキャスターについては、チュートリアルでインターフェースに慣れることが推奨されます。\n",
        "- 予測拡張テンプレートに目を通す - これは、変更を加える必要がある場所をマークするTodoブロックを持つpythonファイルです。\n",
        "- オプションとして、もしインターフェイスの大きな変更を計画しているのであれば、ベースクラスアーキテクチャを見ましょう。\n",
        "- 予測拡張のテンプレートを、あなた自身のリポジトリ（ローカル/プライベート拡張）のローカルフォルダー、もしくはsktimeや提携リポジトリのクローン（貢献拡張の場合）の適当な場所、sktime.forecastingの中にコピーして、ファイル名を変え、ファイルのdocstringを適切に更新します。\n",
        "- todo \"部分に対処します。通常これは、クラス名の変更、タグの値の設定、ハイパーパラメータの指定、__init__、_fit、_predict、および_updateなどのオプションのメソッド（詳細は拡張機能テンプレートを参照）を記入することを意味します。\n",
        " - デフォルトの public インターフェースをオーバーライドしない限り、private メソッドを追加することができます。詳細については，拡張機能テンプレートを参照してください．\n",
        "- 作成した推定器を手動でテストする場合: 作成した推定器をインポートし，セクション 1 のワークフローで実行し，セクション 3 のコンポジターでそれを使用する．\n",
        "- 自動でテストする場合: 作成した estimator で sktime.utils.estimator_checks.check_estimator を呼び出す。\n",
        " - これは、クラスまたはオブジェクトのインスタンスに対して呼び出すことができます。\n",
        " - 拡張テンプレートに従って、get_test_params メソッドでテストパラメータを指定していることを確認する。\n",
        "- sktime またはその関連パッケージに直接コントリビュートする場合、さらに。\n",
        "\n",
        "- コードの作者として、また新しいestimatorファイルのCODEOWNERSに自分を追加する。\n",
        "- 新しいestimatorファイル（1つのクラスでない場合はその継承ツリー）と、上記の自動テストのみを含むpull requestを作成する。\n",
        "- プルリクエストでは、エスティメーターを説明し、最適にはエスティメーターが実装する戦略に関する出版物やその他の技術的なリファレンスを提供する。\n",
        "- プルリクエストを行う前に、寛容なライセンス (BSD-3) のオープンソースプロジェクトにコードを提供するために必要なすべての権限を持っていることを確認してください。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "juzjEas2xGLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**概要**\n",
        "\n",
        "- sktimeは、新しい予測手法で簡単に拡張できるように設計されたライブラリです。\n",
        "- 独自の予測手法を作るには、開発者ガイドに従い、提供されているシンプルな予測手法や高度な予測手法のテンプレートを使う必要があります。\n",
        "- テンプレートをコピーして、クラス名の変更、ハイパーパラメータの指定、必要なメソッドの実装など、必要な変更を行う必要があります。\n",
        "- 新しいメソッドは、ライブラリで提供されるワークフローやコンポジターで実行したり、check_estimator関数を使用してテストすることができます。\n",
        "- もし、新しいメソッドをsktimeライブラリに提供したい場合は、プルリクエストを作成し、あなた自身を著者として追加し、メソッドの説明と参照を提供する必要があります。\n",
        "- プルリクエストを作成する前に、オープンソースライセンスの下でコードを貢献するために必要な権限を持っていることを確認してください。\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QNh7nc5pxf-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5.概要\n",
        "sktimeにはいくつかの予測アルゴリズム（またはフォーキャスター）が付属しており、これらは全て共通のインターフェースを共有しています。\n",
        "- このインターフェースはscikit-learnインターフェースと完全に相互運用可能で、バッチとローリングモードでの予測に専用のインターフェースポイントを提供します。\n",
        "\n",
        "- sktimeは、複雑なパイプラインを容易に構築し、scikit-learnや個々のアルゴリズムライブラリなど、オープンソースエコシステムの他の部分と容易に接続することができる、豊富な合成機能を提供します。\n",
        "\n",
        "- sktimeは拡張が容易で、独自のフォーキャスターや合成原理の実装とテストを容易にするユーザーフレンドリーなツールが付属しています。\n",
        "\n",
        "### 有用なリソース\n",
        "- 詳細については、sktimeを使った予測に関する論文をご覧ください。\n",
        " - この論文では、予測APIについてより詳しく説明し、M4の研究を再現・拡張するためにそれを使っています。\n",
        "- 予測の良い入門書として、Hyndman, Rob J., and George Athanasopoulosを参照してください。\n",
        " - Forecasting: Principles and Practice.OTexts, 2018を参照。\n",
        "- 比較ベンチマーク研究/フォーキャスティングコンペティションについては、M4コンペティションおよびM5コンペティションを参照。\n",
        "\n"
      ],
      "metadata": {
        "id": "mwjyy9uRyBkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**概要**\n",
        "- sktimeは、様々な予測アルゴリズムを使って、将来の出来事について予測をすることを支援するライブラリである。\n",
        "- 使いやすく、scikit-learnのような他のライブラリと組み合わせることができる。\n",
        "- また、新しい予測方法を簡単に作成し、それをテストするツールもある。\n",
        "- 予測についてもっと学びたいなら、本やコンテストなどのリソースが利用できます。\n",
        "\n"
      ],
      "metadata": {
        "id": "Sjh67zdQx4c4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK5gMMhmrc9A"
      },
      "source": [
        "---\n",
        "\n",
        "### Credits:\n",
        "\n",
        "sktime: https://github.com/sktime/sktime/blob/main/CONTRIBUTORS.md"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3.7.11 ('sktime37')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "cb6287e4e3b26a4dcfcac85940452e8817d1be7d6015acaeb8af47f9065ee767"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}