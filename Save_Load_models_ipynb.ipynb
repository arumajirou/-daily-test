{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumajirou/-daily-test/blob/main/Save_Load_models_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOQMmWF2Qzw7"
      },
      "source": [
        "# Save and Load Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wdZTcUEIRCv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2140ebfe-a2d9-4f31-be73-272ef5c018ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mZTQtP6QzxB"
      },
      "source": [
        "Saving and loading trained Deep Learning models has multiple valuable uses. These models are often costly to train; storing a pre-trained model can help reduce costs as it can be loaded and reused to forecast multiple times. Moreover, it enables Transfer learning capabilities, consisting of pre-training a flexible model on a large dataset and using it later on other data with little to no training. It is one of the most outstanding 🚀 achievements in Machine Learning 🧠 and has many practical applications.\n",
        "\n",
        "In this notebook we show an example on how to save and load `NeuralForecast` models.\n",
        "\n",
        "The two methods to consider are:<br>\n",
        "1. `NeuralForecast.save`: Saves models into disk, allows save dataset and config.<br>\n",
        "2. `NeuralForecast.load`: Loads models from a given path.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJNXQMtYQzxD"
      },
      "source": [
        ":::{.callout-important}\n",
        "This Guide assumes basic knowledge on the NeuralForecast library. For a minimal example visit the [Getting Started](./Getting_Started.ipynb) guide.\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fQbZZtxQzxD"
      },
      "source": [
        "You can run these experiments using GPU with Google Colab.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Nixtla/neuralforecast/blob/main/nbs/examples/Save_Load_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6uza8zeQzxE"
      },
      "source": [
        "## 1. Installing NeuralForecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0wJtAtxPQzxE"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install neuralforecast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F82N6lqqQzxG"
      },
      "source": [
        "## 2. Loading AirPassengers Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d2o0lYXfQzxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "da243412-f1bd-4938-ac6b-c8366cbcb1dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unique_id         ds      y\n",
              "0        1.0 1949-01-31  112.0\n",
              "1        1.0 1949-02-28  118.0\n",
              "2        1.0 1949-03-31  132.0\n",
              "3        1.0 1949-04-30  129.0\n",
              "4        1.0 1949-05-31  121.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f438e410-7fc8-4075-bd89-e272c208bfb3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>ds</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1949-01-31</td>\n",
              "      <td>112.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1949-02-28</td>\n",
              "      <td>118.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1949-03-31</td>\n",
              "      <td>132.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1949-04-30</td>\n",
              "      <td>129.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1949-05-31</td>\n",
              "      <td>121.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f438e410-7fc8-4075-bd89-e272c208bfb3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f438e410-7fc8-4075-bd89-e272c208bfb3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f438e410-7fc8-4075-bd89-e272c208bfb3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a80656ea-06cc-48cb-9a8f-06700d56e0dd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a80656ea-06cc-48cb-9a8f-06700d56e0dd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a80656ea-06cc-48cb-9a8f-06700d56e0dd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Y_df",
              "summary": "{\n  \"name\": \"Y_df\",\n  \"rows\": 144,\n  \"fields\": [\n    {\n      \"column\": \"unique_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ds\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1949-01-31 00:00:00\",\n        \"max\": \"1960-12-31 00:00:00\",\n        \"num_unique_values\": 144,\n        \"samples\": [\n          \"1958-10-31 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 118,\n        \"samples\": [\n          293.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from neuralforecast.utils import AirPassengersDF\n",
        "\n",
        "Y_df = AirPassengersDF\n",
        "Y_df = Y_df.reset_index(drop=True)\n",
        "Y_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FriN8R2QzxI"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDJgj8g0QzxI"
      },
      "source": [
        "Next, we instantiate and train three models: `NBEATS`, `NHITS`, and `AutoMLP`. The models with their hyperparameters are defined in the `models` list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "pBUw-Dv9QzxI"
      },
      "outputs": [],
      "source": [
        "from ray import tune\n",
        "import torch\n",
        "import multiprocessing\n",
        "from neuralforecast.core import NeuralForecast\n",
        "from neuralforecast.auto import (\n",
        "    AutoRNN,\n",
        "    AutoLSTM,\n",
        "    AutoGRU,\n",
        "    AutoTCN,\n",
        "    AutoDeepAR,\n",
        "    AutoDilatedRNN,\n",
        "    AutoMLP,\n",
        "    AutoNBEATS,\n",
        "    AutoNBEATSx,\n",
        "    AutoNHITS,\n",
        "    AutoTFT,\n",
        "    AutoVanillaTransformer,\n",
        "    AutoInformer,\n",
        "    AutoAutoformer,\n",
        "    AutoFEDformer,\n",
        "    AutoPatchTST,\n",
        "    AutoTimesNet,\n",
        "    AutoStemGNN,\n",
        "    AutoHINT\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models1 =[\n",
        "    AutoRNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoLSTM(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoGRU(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoTCN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoDeepAR(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoDilatedRNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoMLP(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoNBEATS(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoNBEATSx(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoNHITS(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    ]\n",
        "\n",
        "models2 =[\n",
        "    AutoTFT(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoVanillaTransformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoInformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoAutoformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoFEDformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    #AutoPatchTST(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoTimesNet(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoStemGNN(config=None, n_series=1, h=horizon, cpus=cpus, gpus=gpus, verbose=True)\n",
        "    # AutoHINT(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "]"
      ],
      "metadata": {
        "id": "qNuhhOBquEB1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN0BRqkcQzxJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "nf = NeuralForecast(models=models2, freq='M')\n",
        "nf.fit(df=Y_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "from ray import tune\n",
        "import torch\n",
        "import multiprocessing\n",
        "from neuralforecast.core import NeuralForecast\n",
        "from neuralforecast.auto import (\n",
        "    AutoRNN,\n",
        "    AutoLSTM,\n",
        "    AutoGRU,\n",
        "    AutoTCN,\n",
        "    AutoDeepAR,\n",
        "    AutoDilatedRNN,\n",
        "    AutoMLP,\n",
        "    AutoNBEATS,\n",
        "    AutoNBEATSx,\n",
        "    AutoNHITS,\n",
        "    AutoTFT,\n",
        "    AutoVanillaTransformer,\n",
        "    AutoInformer,\n",
        "    AutoAutoformer,\n",
        "    AutoFEDformer,\n",
        "    AutoPatchTST,\n",
        "    AutoTimesNet,\n",
        "    AutoStemGNN,\n",
        "    AutoHINT\n",
        ")\n",
        "cpus = multiprocessing.cpu_count()\n",
        "gpus = torch.cuda.device_count()\n",
        "horizon=12\n",
        "models =[\n",
        "    AutoRNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoLSTM(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoGRU(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoTCN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoDeepAR(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoDilatedRNN(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoMLP(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoNBEATS(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoNBEATSx(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoNHITS(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoTFT(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoVanillaTransformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoInformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoAutoformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoFEDformer(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    #AutoPatchTST(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoTimesNet(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "    AutoStemGNN(config=None, n_series=1, h=horizon, cpus=cpus, gpus=gpus, verbose=True)\n",
        "    # AutoHINT(config=None, h=horizon, cpus=cpus, gpus=gpus, verbose=True),\n",
        "]\n",
        "date = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "\n",
        "try:\n",
        "    pbar = tqdm(total=len(models), desc=\"モデルの処理\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for model in models:\n",
        "        nf = NeuralForecast(models=[model], freq='M',local_scaler_type='standard')\n",
        "        nf.fit(df=Y_df)\n",
        "        path = f'./checkpoints_standard/{model.__class__.__name__}_{date}/'\n",
        "        nf.save(path=path, model_index=None, overwrite=True, save_dataset=True)\n",
        "\n",
        "        if Path(path).exists():\n",
        "\n",
        "            nf2 = NeuralForecast.load(path=path)\n",
        "            prediction = nf2.predict().reset_index()\n",
        "            prediction.head()\n",
        "            prediction = nf2.predict()\n",
        "            print(f'{path}のモデルによる予測: {prediction}')\n",
        "            shutil.rmtree('/content/drive/MyDrive/checkpoints_standard')  # 既存のディレクトリを削除\n",
        "            shutil.copytree('/content/checkpoints_standard', '/content/drive/MyDrive/checkpoints_standard')  # ディレクトリをコピー\n",
        "            print(\"ディレクトリのコピーが完了しました。\")\n",
        "        else:\n",
        "            print(f'{path}のモデルディレクトリは存在しません。')\n",
        "        pbar.update(1)\n",
        "except Exception as e:\n",
        "    print(f'モデルのロード中にエラーが発生しました: {str(e)}')"
      ],
      "metadata": {
        "id": "xrPvO9A9shcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f33790132a744f3be52b3979b67046b",
            "9422d12d02204a319643100060e931fe",
            "18afd98ba8b14a1196c745aabeb64ed3",
            "8ca02ff3bb1d45178012d3443d95f81e",
            "a821fd9a1b664afbbd5c4964394f4944",
            "8fa3965adda54cf79b27d7249e3a3e95",
            "44fa70a78b2041fe918b175cd0c1c902",
            "abe942f9dcbc45b7a8228caaf844b343",
            "10de412691f748f7a761b80a0221b900",
            "d5494336a83945c39c0692113ae7c473",
            "8572992d387d46c39bb4483cb8ee245b"
          ]
        },
        "outputId": "501d1742-7e1b-4c4e-967d-8c31cfbc2cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "モデルの処理:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f33790132a744f3be52b3979b67046b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-03 01:19:57,702\tINFO tune.py:622 -- [output] This will use the new output engine with verbosity 1. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2024-04-03_01-19-57   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 10                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2024-04-03_01-19-57\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-04-03_01-14-25_473825_1949/artifacts/2024-04-03_01-19-57/_train_tune_2024-04-03_01-19-57/driver_artifacts`\n",
            "\n",
            "Trial status: 10 PENDING\n",
            "Current time: 2024-04-03 01:19:57. Total running time: 0s\n",
            "Logical resource usage: 0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status       encoder_hidden_size     encoder_n_layers     context_size     decoder_hidden_size     learning_rate     max_steps     batch_size     random_seed     input_size     inference_input_size |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _train_tune_2e118_00000   PENDING                       50                    1               50                      64       0.0173876            1000             16              17            -12                      -12 |\n",
            "| _train_tune_2e118_00001   PENDING                      300                    2               10                     128       0.00417214           1000             32               1            -12                      -12 |\n",
            "| _train_tune_2e118_00002   PENDING                      100                    2                5                      64       0.000908835           500             16              17            -12                      -12 |\n",
            "| _train_tune_2e118_00003   PENDING                       50                    1                5                      64       0.0567662             500             16               3            768                      -12 |\n",
            "| _train_tune_2e118_00004   PENDING                      200                    2               10                     256       0.00019967            500             32               3            768                      -12 |\n",
            "| _train_tune_2e118_00005   PENDING                      300                    1               50                     128       0.0110875            1000             32               2            768                      -12 |\n",
            "| _train_tune_2e118_00006   PENDING                       50                    1                5                      64       0.00517433           1000             32               9            -12                      -12 |\n",
            "| _train_tune_2e118_00007   PENDING                       50                    1               50                      64       0.0489204            1000             16              19            -12                      -12 |\n",
            "| _train_tune_2e118_00008   PENDING                      100                    1               10                     256       0.000502431           500             32              13            768                      -12 |\n",
            "| _train_tune_2e118_00009   PENDING                       50                    1               10                     256       0.00018594            500             16              13            192                      -12 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial _train_tune_2e118_00000 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00000 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    16 |\n",
            "| context_size                                  50 |\n",
            "| decoder_hidden_size                           64 |\n",
            "| encoder_hidden_size                           50 |\n",
            "| encoder_n_layers                               1 |\n",
            "| h                                             12 |\n",
            "| inference_input_size                         -12 |\n",
            "| input_size                                   -12 |\n",
            "| learning_rate                            0.01739 |\n",
            "| loss                                       MAE() |\n",
            "| max_steps                                   1000 |\n",
            "| random_seed                                   17 |\n",
            "| valid_loss                                 MAE() |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=23590)\u001b[0m Seed set to 17\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m 2024-04-03 01:20:04.508403: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m 2024-04-03 01:20:04.508465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m 2024-04-03 01:20:04.510151: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m 2024-04-03 01:20:05.922953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=23590)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 130.27it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.477]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 120.28it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 131.43it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 114.48it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319]\n",
            "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 142.31it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.266]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255]         \n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 138.49it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.195]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 252.84it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m \n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.454]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.454]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.454]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 137.46it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.454]\n",
            "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 122.72it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.454]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.454]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.454]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=0.454]\n",
            "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 127.05it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=0.454]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=0.454]\n",
            "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 122.36it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.454]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.454]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 142.17it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.143, valid_loss=0.454]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 272.07it/s]\u001b[A\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.279]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.279]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.279]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.279]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.279]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=0.279]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0901, train_loss_epoch=0.0901, valid_loss=0.279]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0917, train_loss_epoch=0.0917, valid_loss=0.279]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.279]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 133.71it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.119, valid_loss=0.279]\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 250.09it/s]\u001b[A\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0967, train_loss_epoch=0.0967, valid_loss=0.216]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 110.32it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.216] \n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.216]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.216]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0991, train_loss_epoch=0.0991, valid_loss=0.216]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.216]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=0.216]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=0.216]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=0.216]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 138.36it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0643, valid_loss=0.216]\n",
            "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 126.01it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0731, valid_loss=0.216]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0731, valid_loss=0.216]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=0.216]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 148.60it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0928, valid_loss=0.216]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 282.27it/s]\u001b[A\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=0.272]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=0.272]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0561, train_loss_epoch=0.0561, valid_loss=0.272]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=0.272]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.272]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 124.73it/s, v_num=0, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=0.272]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=0.272]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=0.272]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=0.272]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 136.06it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=0.272]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 120.27it/s, v_num=0, train_loss_step=0.0521, train_loss_epoch=0.0521, valid_loss=0.272]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0521, train_loss_epoch=0.0521, valid_loss=0.272]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 139.02it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0579, valid_loss=0.272]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.20it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m \n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=0.289]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446, valid_loss=0.289]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0921, train_loss_epoch=0.0921, valid_loss=0.289]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=0.289]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 123.02it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0632, valid_loss=0.289]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 113.63it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=0.289]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=0.289]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0698, train_loss_epoch=0.0698, valid_loss=0.289]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0742, train_loss_epoch=0.0742, valid_loss=0.289]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=0.289]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0724, train_loss_epoch=0.0724, valid_loss=0.289]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 130.13it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0541, valid_loss=0.289]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 257.11it/s]\u001b[A\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0515, train_loss_epoch=0.0515, valid_loss=0.306]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=0.306]\n",
            "Epoch 614: 100%|██████████| 1/1 [00:00<00:00, 121.68it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0608, valid_loss=0.306]\n",
            "Epoch 614: 100%|██████████| 1/1 [00:00<00:00, 111.52it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=0.306]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=0.306]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.306]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0536, train_loss_epoch=0.0536, valid_loss=0.306]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=0.306]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=0.306]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0592, train_loss_epoch=0.0592, valid_loss=0.306]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=0.306]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.306]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 134.74it/s, v_num=0, train_loss_step=0.0745, train_loss_epoch=0.0784, valid_loss=0.306]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 251.29it/s]\u001b[A\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0531, train_loss_epoch=0.0531, valid_loss=0.238]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=0.238]\n",
            "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 121.81it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=0.238]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483, valid_loss=0.238]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=0.238]\n",
            "Epoch 740: 100%|██████████| 1/1 [00:00<00:00, 123.84it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.238]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.238]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=0.238]\n",
            "Epoch 763: 100%|██████████| 1/1 [00:00<00:00, 141.04it/s, v_num=0, train_loss_step=0.0705, train_loss_epoch=0.0645, valid_loss=0.238]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0705, train_loss_epoch=0.0705, valid_loss=0.238]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0904, train_loss_epoch=0.0904, valid_loss=0.238]\n",
            "Epoch 775: 100%|██████████| 1/1 [00:00<00:00, 129.18it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0904, valid_loss=0.238]\n",
            "Epoch 775: 100%|██████████| 1/1 [00:00<00:00, 119.20it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=0.238]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=0.238]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.238]\n",
            "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 138.28it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0661, valid_loss=0.238]\n",
            "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 127.45it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=0.238]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445, valid_loss=0.238]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=0.238]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 123.01it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.044, valid_loss=0.238]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 265.58it/s]\u001b[A\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.303]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=0.303]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=0.303]\n",
            "Epoch 832: 100%|██████████| 1/1 [00:00<00:00, 135.16it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0387, valid_loss=0.303]\n",
            "Epoch 832: 100%|██████████| 1/1 [00:00<00:00, 122.05it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=0.303]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=0.303]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0597, train_loss_epoch=0.0597, valid_loss=0.303]\n",
            "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 131.99it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0597, valid_loss=0.303]\n",
            "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 118.84it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.303]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.303]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=0.303]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=0.303]\n",
            "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 112.09it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.303]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.303]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0602, train_loss_epoch=0.0602, valid_loss=0.303]\n",
            "Epoch 888: 100%|██████████| 1/1 [00:00<00:00, 119.20it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0602, valid_loss=0.303]\n",
            "Epoch 888: 100%|██████████| 1/1 [00:00<00:00, 110.65it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=0.303]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=0.303]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 138.15it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0376, valid_loss=0.303]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 231.60it/s]\u001b[A\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=0.321]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=0.321]\n",
            "Epoch 921: 100%|██████████| 1/1 [00:00<00:00, 124.69it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.321]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.321]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=0.321]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0772, train_loss_epoch=0.0772, valid_loss=0.321]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484, valid_loss=0.321]\n",
            "Epoch 954: 100%|██████████| 1/1 [00:00<00:00, 108.33it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0484, valid_loss=0.321]\n",
            "Epoch 954: 100%|██████████| 1/1 [00:00<00:00, 100.65it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=0.321]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=0.321]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=0.321]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426, valid_loss=0.321]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429, valid_loss=0.321]\n",
            "Epoch 989: 100%|██████████| 1/1 [00:00<00:00, 129.19it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0429, valid_loss=0.321]\n",
            "Epoch 989: 100%|██████████| 1/1 [00:00<00:00, 120.45it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=0.321]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444, valid_loss=0.321]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 136.72it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0534, valid_loss=0.321]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 247.63it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=23590)\u001b[0m \n",
            "                                                                       \u001b[A\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 46.39it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0534, valid_loss=0.277] \n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 44.04it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=0.277]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 41.70it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=0.277]\n",
            "\n",
            "Trial _train_tune_2e118_00000 completed after 10 iterations at 2024-04-03 01:20:16. Total running time: 18s\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00000 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         0.92418 |\n",
            "| time_total_s                             13.2459 |\n",
            "| training_iteration                            10 |\n",
            "| loss                                     0.27687 |\n",
            "| train_loss                               0.04885 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial _train_tune_2e118_00001 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00001 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    32 |\n",
            "| context_size                                  10 |\n",
            "| decoder_hidden_size                          128 |\n",
            "| encoder_hidden_size                          300 |\n",
            "| encoder_n_layers                               2 |\n",
            "| h                                             12 |\n",
            "| inference_input_size                         -12 |\n",
            "| input_size                                   -12 |\n",
            "| learning_rate                            0.00417 |\n",
            "| loss                                       MAE() |\n",
            "| max_steps                                   1000 |\n",
            "| random_seed                                    1 |\n",
            "| valid_loss                                 MAE() |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=23718)\u001b[0m Seed set to 1\n",
            "\u001b[36m(_train_tune pid=23718)\u001b[0m 2024-04-03 01:20:24.073170: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23718)\u001b[0m 2024-04-03 01:20:24.073236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23718)\u001b[0m 2024-04-03 01:20:24.074744: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23718)\u001b[0m 2024-04-03 01:20:25.427150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 56.13it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]\n",
            "\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-04-03 01:20:27. Total running time: 30s\n",
            "Logical resource usage: 0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
            "Current best trial: 2e118_00000 with loss=0.2768729627132416 and params={'h': 12, 'encoder_hidden_size': 50, 'encoder_n_layers': 1, 'context_size': 50, 'decoder_hidden_size': 64, 'learning_rate': 0.01738756110759351, 'max_steps': 1000, 'batch_size': 16, 'loss': MAE(), 'random_seed': 17, 'input_size': -12, 'inference_input_size': -12, 'valid_loss': MAE()}\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         encoder_hidden_size     encoder_n_layers     context_size     decoder_hidden_size     learning_rate     max_steps     batch_size     random_seed     input_size     inference_input_size     iter     total time (s)       loss     train_loss |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _train_tune_2e118_00001   RUNNING                        300                    2               10                     128       0.00417214           1000             32               1            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00000   TERMINATED                      50                    1               50                      64       0.0173876            1000             16              17            -12                      -12       10            13.2459   0.276873      0.0488516 |\n",
            "| _train_tune_2e118_00002   PENDING                        100                    2                5                      64       0.000908835           500             16              17            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00003   PENDING                         50                    1                5                      64       0.0567662             500             16               3            768                      -12                                                       |\n",
            "| _train_tune_2e118_00004   PENDING                        200                    2               10                     256       0.00019967            500             32               3            768                      -12                                                       |\n",
            "| _train_tune_2e118_00005   PENDING                        300                    1               50                     128       0.0110875            1000             32               2            768                      -12                                                       |\n",
            "| _train_tune_2e118_00006   PENDING                         50                    1                5                      64       0.00517433           1000             32               9            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00007   PENDING                         50                    1               50                      64       0.0489204            1000             16              19            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00008   PENDING                        100                    1               10                     256       0.000502431           500             32              13            768                      -12                                                       |\n",
            "| _train_tune_2e118_00009   PENDING                         50                    1               10                     256       0.00018594            500             16              13            192                      -12                                                       |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 56.19it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428]\n",
            "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 58.15it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 58.08it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.451]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.49it/s]\u001b[A\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.792]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.792]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.792]\n",
            "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 56.95it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.792]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.792]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.792]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.792]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.792]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.792]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.792]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.792]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.792]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.792]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.792]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.792]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 50.59it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.792]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.792]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.792]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.792]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.792]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.792]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.792]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 60.57it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.375, valid_loss=0.792]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.87it/s]\u001b[A\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.745]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.745]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 61.50it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.745]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 58.10it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.745]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.745]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.745]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.745]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.745]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 60.43it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.277, valid_loss=0.745]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.745]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.745]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.745]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.745]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=0.745]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.745]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.745]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 59.77it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.745]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.745]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.745]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 58.54it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.202, valid_loss=0.745]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.745]        \n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.745]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.745]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 57.59it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.187, valid_loss=0.745]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.25it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.340]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.340]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.340]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.340]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.340]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 61.73it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.340]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 57.95it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.340]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.340]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.340]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.340]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 57.50it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.340]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.340]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.340]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.340]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 55.98it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.447, valid_loss=0.340]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.340]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.340]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.340]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.340]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.340]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 59.00it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.340]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 55.17it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.340]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.340]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.340]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 60.07it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.310, valid_loss=0.340]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.13it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.697]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.697]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.697]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 57.05it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.697]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.697]        \n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.697]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.697]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.697]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.697]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.697]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.697]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.697]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.697]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.697]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.697]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.697]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.697]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.697]\n",
            "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 54.46it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.697]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.697]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=0.697]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.697]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 61.56it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.697]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.04it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=23718)\u001b[0m \n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.823]\n",
            "Epoch 510: 100%|██████████| 1/1 [00:00<00:00, 58.13it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.823]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.823]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.823]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.823]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.823]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00, 59.46it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.823]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.823]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.823]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.823]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.823]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00, 58.08it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.823]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.823]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.823]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.823]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.823]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.823]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.823]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.823]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.823]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 60.83it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.332, valid_loss=0.823]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.27it/s]\u001b[A\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.744]\n",
            "Epoch 601: 100%|██████████| 1/1 [00:00<00:00, 59.37it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.744]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.744]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.744]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.744]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.744]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.744]        \n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.744]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.744]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 58.85it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.326, valid_loss=0.744]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 56.86it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.744]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.744]\n",
            "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 64.03it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.332, valid_loss=0.744]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.744]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.744]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.744]\n",
            "Epoch 653: 100%|██████████| 1/1 [00:00<00:00, 59.65it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.319, valid_loss=0.744]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.744]\n",
            "Epoch 659: 100%|██████████| 1/1 [00:00<00:00, 64.06it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.744]\n",
            "Epoch 659: 100%|██████████| 1/1 [00:00<00:00, 59.83it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.744]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.744]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.744]\n",
            "Epoch 665: 100%|██████████| 1/1 [00:00<00:00, 57.79it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.744]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.744]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.744]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.744]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.744]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.744]\n",
            "Epoch 694: 100%|██████████| 1/1 [00:00<00:00, 62.40it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.744]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.744]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 64.17it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.261, valid_loss=0.744]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.23it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.657]\n",
            "Epoch 705: 100%|██████████| 1/1 [00:00<00:00, 62.39it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.260, valid_loss=0.657]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.657]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.657]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.657]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.657]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.657]\n",
            "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 59.93it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.657]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.657]        \n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.657]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.657]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.657]\n",
            "Epoch 745: 100%|██████████| 1/1 [00:00<00:00, 58.04it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.657]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.657]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.657]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.657]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.657]\n",
            "Epoch 762: 100%|██████████| 1/1 [00:00<00:00, 61.50it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.657]\n",
            "Epoch 762: 100%|██████████| 1/1 [00:00<00:00, 57.69it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.657]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.657]\n",
            "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 61.85it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=0.657]\n",
            "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 57.83it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.657]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.657]\n",
            "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 60.10it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.657]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.657]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.657]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.657]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.657]\n",
            "Epoch 790: 100%|██████████| 1/1 [00:00<00:00, 56.63it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.657]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.657]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.657]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 58.86it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.199, valid_loss=0.657]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.14it/s]\u001b[A\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.730]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.730]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.730]        \n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.730]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.730]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.730]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.730]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.730]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.730]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.730]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.730]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.730]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.730]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.730]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.730]\n",
            "Epoch 872: 100%|██████████| 1/1 [00:00<00:00, 58.31it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.169, valid_loss=0.730]\n",
            "Epoch 872: 100%|██████████| 1/1 [00:00<00:00, 56.00it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.730]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.730]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.730]\n",
            "Epoch 883: 100%|██████████| 1/1 [00:00<00:00, 56.46it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.180, valid_loss=0.730]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.730]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.730]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.730]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 62.81it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.158, valid_loss=0.730]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.41it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=23718)\u001b[0m \n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.594]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.594]\n",
            "Epoch 910: 100%|██████████| 1/1 [00:00<00:00, 59.81it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.173, valid_loss=0.594]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.594]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.594]\n",
            "Epoch 916: 100%|██████████| 1/1 [00:00<00:00, 58.04it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.594]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.594]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.594]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.594]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=0.594]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.594]\n",
            "Epoch 939: 100%|██████████| 1/1 [00:00<00:00, 56.57it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.594]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.594]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.594]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.594]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=0.594]\n",
            "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 60.89it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=0.594]\n",
            "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 56.74it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.594]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.594]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.594]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=0.594]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.594]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.594]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.594]\n",
            "Epoch 991: 100%|██████████| 1/1 [00:00<00:00, 53.77it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.594]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.594]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0973, train_loss_epoch=0.0973, valid_loss=0.594]\n",
            "\n",
            "Trial _train_tune_2e118_00001 completed after 10 iterations at 2024-04-03 01:20:45. Total running time: 47s\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00001 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         1.81219 |\n",
            "| time_total_s                             22.6754 |\n",
            "| training_iteration                            10 |\n",
            "| loss                                     0.81258 |\n",
            "| train_loss                               0.10292 |\n",
            "+--------------------------------------------------+\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 58.99it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.0978, valid_loss=0.594] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.47it/s]\u001b[A\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 28.18it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.813]\n",
            "\n",
            "Trial _train_tune_2e118_00002 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00002 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    16 |\n",
            "| context_size                                   5 |\n",
            "| decoder_hidden_size                           64 |\n",
            "| encoder_hidden_size                          100 |\n",
            "| encoder_n_layers                               2 |\n",
            "| h                                             12 |\n",
            "| inference_input_size                         -12 |\n",
            "| input_size                                   -12 |\n",
            "| learning_rate                            0.00091 |\n",
            "| loss                                       MAE() |\n",
            "| max_steps                                    500 |\n",
            "| random_seed                                   17 |\n",
            "| valid_loss                                 MAE() |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=23887)\u001b[0m Seed set to 17\n",
            "\u001b[36m(_train_tune pid=23887)\u001b[0m 2024-04-03 01:20:53.216241: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23887)\u001b[0m 2024-04-03 01:20:53.216305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23887)\u001b[0m 2024-04-03 01:20:53.217717: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23887)\u001b[0m 2024-04-03 01:20:54.603845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=23887)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979]\n",
            "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 118.65it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.979]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951]         \n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657]\n",
            "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 111.15it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462]\n",
            "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 108.01it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431]\n",
            "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 125.86it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406]\n",
            "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 115.34it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.406]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405]\n",
            "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 140.31it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 134.98it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.394]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.35it/s]\u001b[A\n",
            "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 125.61it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.690]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.690]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.690]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.690]\n",
            "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 126.51it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.690]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.690]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.690]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.690]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 127.98it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.690]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.690]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.690]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.690]\n",
            "\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-04-03 01:20:58. Total running time: 1min 0s\n",
            "Logical resource usage: 0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
            "Current best trial: 2e118_00000 with loss=0.2768729627132416 and params={'h': 12, 'encoder_hidden_size': 50, 'encoder_n_layers': 1, 'context_size': 50, 'decoder_hidden_size': 64, 'learning_rate': 0.01738756110759351, 'max_steps': 1000, 'batch_size': 16, 'loss': MAE(), 'random_seed': 17, 'input_size': -12, 'inference_input_size': -12, 'valid_loss': MAE()}\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         encoder_hidden_size     encoder_n_layers     context_size     decoder_hidden_size     learning_rate     max_steps     batch_size     random_seed     input_size     inference_input_size     iter     total time (s)       loss     train_loss |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _train_tune_2e118_00002   RUNNING                        100                    2                5                      64       0.000908835           500             16              17            -12                      -12        1            5.26842   0.690054      0.395645  |\n",
            "| _train_tune_2e118_00000   TERMINATED                      50                    1               50                      64       0.0173876            1000             16              17            -12                      -12       10           13.2459    0.276873      0.0488516 |\n",
            "| _train_tune_2e118_00001   TERMINATED                     300                    2               10                     128       0.00417214           1000             32               1            -12                      -12       10           22.6754    0.812577      0.10292   |\n",
            "| _train_tune_2e118_00003   PENDING                         50                    1                5                      64       0.0567662             500             16               3            768                      -12                                                       |\n",
            "| _train_tune_2e118_00004   PENDING                        200                    2               10                     256       0.00019967            500             32               3            768                      -12                                                       |\n",
            "| _train_tune_2e118_00005   PENDING                        300                    1               50                     128       0.0110875            1000             32               2            768                      -12                                                       |\n",
            "| _train_tune_2e118_00006   PENDING                         50                    1                5                      64       0.00517433           1000             32               9            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00007   PENDING                         50                    1               50                      64       0.0489204            1000             16              19            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00008   PENDING                        100                    1               10                     256       0.000502431           500             32              13            768                      -12                                                       |\n",
            "| _train_tune_2e118_00009   PENDING                         50                    1               10                     256       0.00018594            500             16              13            192                      -12                                                       |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.690]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 125.01it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.205, valid_loss=0.690]\n",
            "\u001b[36m(_train_tune pid=23887)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=23887)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=23887)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.70it/s]\u001b[A\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.354]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.354]\n",
            "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 132.58it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.149, valid_loss=0.354]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.354]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.354]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.354]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 135.49it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.129, valid_loss=0.354]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 122.81it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.354]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.354]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 132.69it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.122, valid_loss=0.354]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.354]         \n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.354]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.354]\n",
            "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 107.09it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=0.354]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=0.354]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.354]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 122.57it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.354]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.354]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 134.12it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.119, valid_loss=0.354]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 273.92it/s]\u001b[A\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.258]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=0.258]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 116.76it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=0.258]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=0.258]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.258]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.258]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.258]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 129.19it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.113, valid_loss=0.258]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 109.01it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.258]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.258]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.258]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 114.12it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.258]\n",
            "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 100.47it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.258]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.258]         \n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.258]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.258]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0967, train_loss_epoch=0.0967, valid_loss=0.258]\n",
            "Epoch 396: 100%|██████████| 1/1 [00:00<00:00, 129.00it/s, v_num=0, train_loss_step=0.0933, train_loss_epoch=0.0933, valid_loss=0.258]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0933, train_loss_epoch=0.0933, valid_loss=0.258]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 139.56it/s, v_num=0, train_loss_step=0.0956, train_loss_epoch=0.107, valid_loss=0.258]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 252.24it/s]\u001b[A\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=0.277]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0997, train_loss_epoch=0.0997, valid_loss=0.277]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0953, train_loss_epoch=0.0953, valid_loss=0.277]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 125.10it/s, v_num=0, train_loss_step=0.0843, train_loss_epoch=0.0877, valid_loss=0.277]\n",
            "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 117.56it/s, v_num=0, train_loss_step=0.0843, train_loss_epoch=0.0843, valid_loss=0.277]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0843, train_loss_epoch=0.0843, valid_loss=0.277]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0898, train_loss_epoch=0.0898, valid_loss=0.277]\n",
            "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 106.75it/s, v_num=0, train_loss_step=0.0873, train_loss_epoch=0.0873, valid_loss=0.277]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0873, train_loss_epoch=0.0873, valid_loss=0.277]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.085, train_loss_epoch=0.085, valid_loss=0.277]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 137.47it/s, v_num=0, train_loss_step=0.089, train_loss_epoch=0.085, valid_loss=0.277]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.089, train_loss_epoch=0.089, valid_loss=0.277]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.277]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0802, train_loss_epoch=0.0802, valid_loss=0.277]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 143.60it/s, v_num=0, train_loss_step=0.0813, train_loss_epoch=0.0773, valid_loss=0.277]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.99it/s]\u001b[A\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 44.16it/s, v_num=0, train_loss_step=0.0813, train_loss_epoch=0.0813, valid_loss=0.268]\n",
            "\n",
            "Trial _train_tune_2e118_00002 completed after 5 iterations at 2024-04-03 01:21:00. Total running time: 1min 3s\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00002 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         0.88889 |\n",
            "| time_total_s                             8.84879 |\n",
            "| training_iteration                             5 |\n",
            "| loss                                     0.26812 |\n",
            "| train_loss                               0.08135 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial _train_tune_2e118_00003 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00003 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    16 |\n",
            "| context_size                                   5 |\n",
            "| decoder_hidden_size                           64 |\n",
            "| encoder_hidden_size                           50 |\n",
            "| encoder_n_layers                               1 |\n",
            "| h                                             12 |\n",
            "| inference_input_size                         -12 |\n",
            "| input_size                                   768 |\n",
            "| learning_rate                            0.05677 |\n",
            "| loss                                       MAE() |\n",
            "| max_steps                                    500 |\n",
            "| random_seed                                    3 |\n",
            "| valid_loss                                 MAE() |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=23997)\u001b[0m Seed set to 3\n",
            "\u001b[36m(_train_tune pid=23997)\u001b[0m 2024-04-03 01:21:08.318831: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23997)\u001b[0m 2024-04-03 01:21:08.318890: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23997)\u001b[0m 2024-04-03 01:21:08.320311: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=23997)\u001b[0m 2024-04-03 01:21:09.739084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 120.77it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.100]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 131.45it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.454]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 153.76it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431]\n",
            "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 134.48it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 144.23it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.419]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 279.71it/s]\u001b[A\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.818]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 127.46it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.818]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.818]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.818]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 114.02it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.818]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.818]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.818]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 122.65it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.518, valid_loss=0.818]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 111.63it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.818]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.818]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.818]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.818]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=0.818]\n",
            "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 114.43it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.761, valid_loss=0.818]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=0.818]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 142.87it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.586, valid_loss=0.818]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.818]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 116.35it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.818]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.818]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 134.43it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.453, valid_loss=0.818]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 266.02it/s]\u001b[A\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.729]\n",
            "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 124.99it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.729]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.729]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 146.58it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.729]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.729]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.729]\n",
            "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 113.96it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.729]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.729]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.729]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.729]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.729]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.729]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 135.27it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.429, valid_loss=0.729]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.71it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.950]\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 127.44it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.950]\n",
            "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 116.21it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.950]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.950]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.950]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 130.72it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.950]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 116.39it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.950]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.950]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.950]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.950]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.950]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.950]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.950]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 130.26it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.459, valid_loss=0.950]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.950]         \n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.950]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.950]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 129.33it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.950]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.950]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 126.59it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.460, valid_loss=0.950]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 263.23it/s]\u001b[A\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.842]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.842]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.842]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.842]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.842]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.842]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.842]\n",
            "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 143.59it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.842]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=0.842]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=0.842]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 130.52it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=0.842]\n",
            "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 113.22it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.842]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.842]\n",
            "\n",
            "Trial _train_tune_2e118_00003 completed after 5 iterations at 2024-04-03 01:21:15. Total running time: 1min 18s\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00003 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         0.92205 |\n",
            "| time_total_s                             8.83721 |\n",
            "| training_iteration                             5 |\n",
            "| loss                                     0.83291 |\n",
            "| train_loss                               0.62974 |\n",
            "+--------------------------------------------------+\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 133.98it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.592, valid_loss=0.842]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 276.89it/s]\u001b[A\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 46.40it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.833]\n",
            "\n",
            "Trial _train_tune_2e118_00004 started with configuration:\n",
            "+-------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00004 config            |\n",
            "+-------------------------------------------------+\n",
            "| batch_size                                   32 |\n",
            "| context_size                                 10 |\n",
            "| decoder_hidden_size                         256 |\n",
            "| encoder_hidden_size                         200 |\n",
            "| encoder_n_layers                              2 |\n",
            "| h                                            12 |\n",
            "| inference_input_size                        -12 |\n",
            "| input_size                                  768 |\n",
            "| learning_rate                            0.0002 |\n",
            "| loss                                      MAE() |\n",
            "| max_steps                                   500 |\n",
            "| random_seed                                   3 |\n",
            "| valid_loss                                MAE() |\n",
            "+-------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=24106)\u001b[0m Seed set to 3\n",
            "\u001b[36m(_train_tune pid=24106)\u001b[0m 2024-04-03 01:21:23.457469: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24106)\u001b[0m 2024-04-03 01:21:23.457530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24106)\u001b[0m 2024-04-03 01:21:23.458972: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24106)\u001b[0m 2024-04-03 01:21:24.822435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 129.69it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.100]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]         \n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 105.55it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 141.10it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 123.18it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 121.08it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 141.45it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.419]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 265.13it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24106)\u001b[0m \n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.825]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.825]\n",
            "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 116.95it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.825]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.825]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.825]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.825]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.825]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.825]\n",
            "\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-04-03 01:21:28. Total running time: 1min 30s\n",
            "Logical resource usage: 0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
            "Current best trial: 2e118_00002 with loss=0.2681165039539337 and params={'h': 12, 'encoder_hidden_size': 100, 'encoder_n_layers': 2, 'context_size': 5, 'decoder_hidden_size': 64, 'learning_rate': 0.0009088351060183551, 'max_steps': 500, 'batch_size': 16, 'loss': MAE(), 'random_seed': 17, 'input_size': -12, 'inference_input_size': -12, 'valid_loss': MAE()}\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         encoder_hidden_size     encoder_n_layers     context_size     decoder_hidden_size     learning_rate     max_steps     batch_size     random_seed     input_size     inference_input_size     iter     total time (s)       loss     train_loss |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _train_tune_2e118_00004   RUNNING                        200                    2               10                     256       0.00019967            500             32               3            768                      -12        1            5.10687   0.825278      0.416969  |\n",
            "| _train_tune_2e118_00000   TERMINATED                      50                    1               50                      64       0.0173876            1000             16              17            -12                      -12       10           13.2459    0.276873      0.0488516 |\n",
            "| _train_tune_2e118_00001   TERMINATED                     300                    2               10                     128       0.00417214           1000             32               1            -12                      -12       10           22.6754    0.812577      0.10292   |\n",
            "| _train_tune_2e118_00002   TERMINATED                     100                    2                5                      64       0.000908835           500             16              17            -12                      -12        5            8.84879   0.268117      0.0813497 |\n",
            "| _train_tune_2e118_00003   TERMINATED                      50                    1                5                      64       0.0567662             500             16               3            768                      -12        5            8.83721   0.832911      0.629744  |\n",
            "| _train_tune_2e118_00005   PENDING                        300                    1               50                     128       0.0110875            1000             32               2            768                      -12                                                       |\n",
            "| _train_tune_2e118_00006   PENDING                         50                    1                5                      64       0.00517433           1000             32               9            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00007   PENDING                         50                    1               50                      64       0.0489204            1000             16              19            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00008   PENDING                        100                    1               10                     256       0.000502431           500             32              13            768                      -12                                                       |\n",
            "| _train_tune_2e118_00009   PENDING                         50                    1               10                     256       0.00018594            500             16              13            192                      -12                                                       |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.825]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 112.98it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.825]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.825]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 131.51it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.182, valid_loss=0.825]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24106)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.21it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24106)\u001b[0m \n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.279]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.279]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.279]\n",
            "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 128.90it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.279]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.279]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 136.43it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.279]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 129.20it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.279]\n",
            "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 118.30it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.279]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.279]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=0.279]\n",
            "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 122.30it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=0.279]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=0.279]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.279]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 107.95it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.279]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.279]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.279]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.279]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 120.53it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.126, valid_loss=0.279]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.88it/s]\u001b[A\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 125.83it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.128, valid_loss=0.192]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=0.192]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.192]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.192]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.192]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.192]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=0.192]\n",
            "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 137.19it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.122, valid_loss=0.192]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=0.192]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.192]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=0.192]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 140.49it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.109, valid_loss=0.192]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.25it/s]\u001b[A\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.160]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 125.38it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.160]\n",
            "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 109.11it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.160]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.160]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.160]\n",
            "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 132.52it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.160]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.160]         \n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.160]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.160]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.160]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.160]\n",
            "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 123.45it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.160]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.160]\n",
            "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 128.74it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.160]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.160]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0986, train_loss_epoch=0.0986, valid_loss=0.160]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.097, train_loss_epoch=0.097, valid_loss=0.160]\n",
            "\n",
            "Trial _train_tune_2e118_00004 completed after 5 iterations at 2024-04-03 01:21:31. Total running time: 1min 33s\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00004 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                          0.9251 |\n",
            "| time_total_s                             8.78546 |\n",
            "| training_iteration                             5 |\n",
            "| loss                                     0.15889 |\n",
            "| train_loss                               0.09873 |\n",
            "+--------------------------------------------------+\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 131.00it/s, v_num=0, train_loss_step=0.0987, train_loss_epoch=0.097, valid_loss=0.160]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.31it/s]\u001b[A\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 44.14it/s, v_num=0, train_loss_step=0.0987, train_loss_epoch=0.0987, valid_loss=0.159]\n",
            "\n",
            "Trial _train_tune_2e118_00005 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00005 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    32 |\n",
            "| context_size                                  50 |\n",
            "| decoder_hidden_size                          128 |\n",
            "| encoder_hidden_size                          300 |\n",
            "| encoder_n_layers                               1 |\n",
            "| h                                             12 |\n",
            "| inference_input_size                         -12 |\n",
            "| input_size                                   768 |\n",
            "| learning_rate                            0.01109 |\n",
            "| loss                                       MAE() |\n",
            "| max_steps                                   1000 |\n",
            "| random_seed                                    2 |\n",
            "| valid_loss                                 MAE() |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=24216)\u001b[0m Seed set to 2\n",
            "\u001b[36m(_train_tune pid=24216)\u001b[0m 2024-04-03 01:21:38.386353: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24216)\u001b[0m 2024-04-03 01:21:38.386413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24216)\u001b[0m 2024-04-03 01:21:38.387862: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24216)\u001b[0m 2024-04-03 01:21:39.798503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=24216)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 89.90it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.459]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.03it/s]\u001b[A\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.837]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.837]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.837]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.837]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.837]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.837]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.837]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.837]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.837]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.837]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.837]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.837]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 91.23it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.372, valid_loss=0.837]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.26it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24216)\u001b[0m \n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.818]\n",
            "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 84.68it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.818]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.818]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.818]\n",
            "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 89.07it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.391, valid_loss=0.818]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.818]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 77.61it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.818]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 70.95it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.818]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.818]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.818]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.818]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.818]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.818]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.818]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 82.44it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.818]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.818]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.818]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 89.89it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.379, valid_loss=0.818]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.94it/s]\u001b[A\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.872]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 82.42it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.872]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.872]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.872]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.872]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.872]\n",
            "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 74.96it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.358, valid_loss=0.872]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.872]        \n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.872]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.872]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 90.43it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.872]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 79.90it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.872]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.872]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.872]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 91.39it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.336, valid_loss=0.872]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 85.78it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.872]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.872]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.872]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.872]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.872]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=0.872]\n",
            "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 82.67it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.304, valid_loss=0.872]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.872]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 82.63it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.341, valid_loss=0.872]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.38it/s]\u001b[A\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.966]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.966]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.966]\n",
            "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 77.76it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.966]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.966]        \n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.966]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.966]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.966]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.966]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.966]\n",
            "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 72.99it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.966]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.966]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 69.14it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.966]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.966]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.966]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.966]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.966]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.966]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 91.36it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.330, valid_loss=0.966]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.50it/s]\u001b[A\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.622]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.622]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.622]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 86.57it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.622]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 78.84it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.622]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.622]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00, 86.99it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.622]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.622]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=0.622]\n",
            "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 85.97it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.359, valid_loss=0.622]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.622]\n",
            "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 77.08it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.622]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.622]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 80.64it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.622]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.622]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00, 85.73it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.345, valid_loss=0.622]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.622]        \n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.622]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.622]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.622]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.622]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.622]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 86.44it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.357, valid_loss=0.622]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.60it/s]\u001b[A\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.911]\n",
            "Epoch 604: 100%|██████████| 1/1 [00:00<00:00, 91.77it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.911]\n",
            "Epoch 604: 100%|██████████| 1/1 [00:00<00:00, 84.76it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.911]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.911]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.911]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.911]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.911]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=0.911]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.911]\n",
            "Epoch 645: 100%|██████████| 1/1 [00:00<00:00, 86.48it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.911]\n",
            "Epoch 645: 100%|██████████| 1/1 [00:00<00:00, 79.35it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.911]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.911]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.911]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.911]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.911]\n",
            "Epoch 670: 100%|██████████| 1/1 [00:00<00:00, 89.27it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.443, valid_loss=0.911]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.911]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.911]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.911]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.911]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 89.19it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.346, valid_loss=0.911]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.40it/s]\u001b[A\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.908]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.908]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 89.18it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.908]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.908]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.908]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.908]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=0.908]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.908]\n",
            "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 87.59it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.295, valid_loss=0.908]\n",
            "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 82.29it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.908]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.908]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.908]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.908]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.908]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.908]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.908]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.908]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 82.88it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.321, valid_loss=0.908]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.55it/s]\u001b[A\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.813]\n",
            "Epoch 805: 100%|██████████| 1/1 [00:00<00:00, 82.67it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.813]\n",
            "Epoch 805: 100%|██████████| 1/1 [00:00<00:00, 75.15it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.813]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.813]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.813]\n",
            "Epoch 813: 100%|██████████| 1/1 [00:00<00:00, 81.48it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.813]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.813]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.813]\n",
            "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 77.37it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.463, valid_loss=0.813]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.813]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.813]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.813]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.813]\n",
            "Epoch 853: 100%|██████████| 1/1 [00:00<00:00, 84.98it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.374, valid_loss=0.813]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.813]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.813]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.813]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.813]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.813]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.813]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 85.45it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.813]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 201.93it/s]\u001b[A\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.853]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.853]\n",
            "Epoch 908: 100%|██████████| 1/1 [00:00<00:00, 79.84it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.853]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.853]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.853]\n",
            "Epoch 916: 100%|██████████| 1/1 [00:00<00:00, 75.68it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.369, valid_loss=0.853]\n",
            "Epoch 916: 100%|██████████| 1/1 [00:00<00:00, 71.46it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.853]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.853]\n",
            "Epoch 924: 100%|██████████| 1/1 [00:00<00:00, 83.93it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.413, valid_loss=0.853]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.853]\n",
            "Epoch 932: 100%|██████████| 1/1 [00:00<00:00, 76.40it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.376, valid_loss=0.853]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.853]\n",
            "Epoch 940: 100%|██████████| 1/1 [00:00<00:00, 88.59it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.853]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.853]        \n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.853]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.853]\n",
            "Epoch 948: 100%|██████████| 1/1 [00:00<00:00, 77.92it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.339, valid_loss=0.853]\n",
            "Epoch 948: 100%|██████████| 1/1 [00:00<00:00, 72.68it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.853]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.853]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.853]\n",
            "Epoch 956: 100%|██████████| 1/1 [00:00<00:00, 84.30it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.853]\n",
            "Epoch 956: 100%|██████████| 1/1 [00:00<00:00, 76.96it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.853]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.853]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.853]\n",
            "Epoch 964: 100%|██████████| 1/1 [00:00<00:00, 72.94it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.337, valid_loss=0.853]\n",
            "Epoch 964: 100%|██████████| 1/1 [00:00<00:00, 68.81it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.853]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.853]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.853]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.853]\n",
            "Epoch 980: 100%|██████████| 1/1 [00:00<00:00, 77.74it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.853]\n",
            "Epoch 980: 100%|██████████| 1/1 [00:00<00:00, 71.17it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.853]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.853]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.853]\n",
            "Epoch 988: 100%|██████████| 1/1 [00:00<00:00, 85.36it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.853]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.853]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.853]\n",
            "Epoch 996: 100%|██████████| 1/1 [00:00<00:00, 79.37it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.338, valid_loss=0.853]\n",
            "Epoch 996: 100%|██████████| 1/1 [00:00<00:00, 75.47it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.853]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.853]\n",
            "\n",
            "Trial _train_tune_2e118_00005 completed after 10 iterations at 2024-04-03 01:21:54. Total running time: 1min 56s\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00005 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         1.34004 |\n",
            "| time_total_s                             17.5258 |\n",
            "| training_iteration                            10 |\n",
            "| loss                                     0.89381 |\n",
            "| train_loss                               0.33392 |\n",
            "+--------------------------------------------------+\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 85.46it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.332, valid_loss=0.853]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.61it/s]\u001b[A\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 37.00it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.894]\n",
            "\n",
            "Trial status: 6 TERMINATED | 4 PENDING\n",
            "Current time: 2024-04-03 01:21:58. Total running time: 2min 0s\n",
            "Logical resource usage: 0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
            "Current best trial: 2e118_00004 with loss=0.15889066457748413 and params={'h': 12, 'encoder_hidden_size': 200, 'encoder_n_layers': 2, 'context_size': 10, 'decoder_hidden_size': 256, 'learning_rate': 0.00019967009922020209, 'max_steps': 500, 'batch_size': 32, 'loss': MAE(), 'random_seed': 3, 'input_size': 768, 'inference_input_size': -12, 'valid_loss': MAE()}\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         encoder_hidden_size     encoder_n_layers     context_size     decoder_hidden_size     learning_rate     max_steps     batch_size     random_seed     input_size     inference_input_size     iter     total time (s)       loss     train_loss |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _train_tune_2e118_00000   TERMINATED                      50                    1               50                      64       0.0173876            1000             16              17            -12                      -12       10           13.2459    0.276873      0.0488516 |\n",
            "| _train_tune_2e118_00001   TERMINATED                     300                    2               10                     128       0.00417214           1000             32               1            -12                      -12       10           22.6754    0.812577      0.10292   |\n",
            "| _train_tune_2e118_00002   TERMINATED                     100                    2                5                      64       0.000908835           500             16              17            -12                      -12        5            8.84879   0.268117      0.0813497 |\n",
            "| _train_tune_2e118_00003   TERMINATED                      50                    1                5                      64       0.0567662             500             16               3            768                      -12        5            8.83721   0.832911      0.629744  |\n",
            "| _train_tune_2e118_00004   TERMINATED                     200                    2               10                     256       0.00019967            500             32               3            768                      -12        5            8.78546   0.158891      0.0987338 |\n",
            "| _train_tune_2e118_00005   TERMINATED                     300                    1               50                     128       0.0110875            1000             32               2            768                      -12       10           17.5258    0.893813      0.333921  |\n",
            "| _train_tune_2e118_00006   PENDING                         50                    1                5                      64       0.00517433           1000             32               9            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00007   PENDING                         50                    1               50                      64       0.0489204            1000             16              19            -12                      -12                                                       |\n",
            "| _train_tune_2e118_00008   PENDING                        100                    1               10                     256       0.000502431           500             32              13            768                      -12                                                       |\n",
            "| _train_tune_2e118_00009   PENDING                         50                    1               10                     256       0.00018594            500             16              13            192                      -12                                                       |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial _train_tune_2e118_00006 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00006 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    32 |\n",
            "| context_size                                   5 |\n",
            "| decoder_hidden_size                           64 |\n",
            "| encoder_hidden_size                           50 |\n",
            "| encoder_n_layers                               1 |\n",
            "| h                                             12 |\n",
            "| inference_input_size                         -12 |\n",
            "| input_size                                   -12 |\n",
            "| learning_rate                            0.00517 |\n",
            "| loss                                       MAE() |\n",
            "| max_steps                                   1000 |\n",
            "| random_seed                                    9 |\n",
            "| valid_loss                                 MAE() |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=24360)\u001b[0m Seed set to 9\n",
            "\u001b[36m(_train_tune pid=24360)\u001b[0m 2024-04-03 01:22:02.326888: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24360)\u001b[0m 2024-04-03 01:22:02.326958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24360)\u001b[0m 2024-04-03 01:22:02.328424: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24360)\u001b[0m 2024-04-03 01:22:03.694375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 124.43it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 110.31it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 131.46it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 105.84it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 131.52it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 140.35it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.193]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.86it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24360)\u001b[0m \n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.372]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.372]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.372]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.372]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.372]\n",
            "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 139.30it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.145, valid_loss=0.372]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.372]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.372]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.372]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 143.18it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.125, valid_loss=0.372]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.85it/s]\u001b[A\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.215]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.215]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.215]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 136.72it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.124, valid_loss=0.215]\n",
            "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 126.87it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=0.215]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=0.215]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.215]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.215]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.215]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=0.215]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 124.03it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.111, valid_loss=0.215]\n",
            "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 113.33it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.215]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.215]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 139.48it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.108, valid_loss=0.215]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 265.60it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24360)\u001b[0m \n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.174]\n",
            "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 109.98it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=0.174]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=0.174]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.174]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0953, train_loss_epoch=0.0953, valid_loss=0.174]         \n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0953, train_loss_epoch=0.0953, valid_loss=0.174]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=0.174]\n",
            "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 109.41it/s, v_num=0, train_loss_step=0.0968, train_loss_epoch=0.0968, valid_loss=0.174]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0968, train_loss_epoch=0.0968, valid_loss=0.174]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0932, train_loss_epoch=0.0932, valid_loss=0.174]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0916, train_loss_epoch=0.0916, valid_loss=0.174]\n",
            "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 113.37it/s, v_num=0, train_loss_step=0.0995, train_loss_epoch=0.0995, valid_loss=0.174]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0995, train_loss_epoch=0.0995, valid_loss=0.174]\n",
            "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 131.61it/s, v_num=0, train_loss_step=0.0894, train_loss_epoch=0.0894, valid_loss=0.174]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0894, train_loss_epoch=0.0894, valid_loss=0.174]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 143.74it/s, v_num=0, train_loss_step=0.0961, train_loss_epoch=0.0951, valid_loss=0.174]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 270.22it/s]\u001b[A\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0899, train_loss_epoch=0.0899, valid_loss=0.177]\n",
            "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 117.49it/s, v_num=0, train_loss_step=0.0902, train_loss_epoch=0.0902, valid_loss=0.177]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0902, train_loss_epoch=0.0902, valid_loss=0.177]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0947, train_loss_epoch=0.0947, valid_loss=0.177]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0999, train_loss_epoch=0.0999, valid_loss=0.177]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0851, train_loss_epoch=0.0851, valid_loss=0.177]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=0.177]         \n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=0.177]\n",
            "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 125.97it/s, v_num=0, train_loss_step=0.0899, train_loss_epoch=0.0899, valid_loss=0.177]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0899, train_loss_epoch=0.0899, valid_loss=0.177]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=0.177]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 115.19it/s, v_num=0, train_loss_step=0.0842, train_loss_epoch=0.0842, valid_loss=0.177]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0842, train_loss_epoch=0.0842, valid_loss=0.177]\n",
            "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 140.93it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0869, valid_loss=0.177]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0789, valid_loss=0.177]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 137.15it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.077, valid_loss=0.177]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 274.66it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24360)\u001b[0m \n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.169]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0861, train_loss_epoch=0.0861, valid_loss=0.169]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0786, train_loss_epoch=0.0786, valid_loss=0.169]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0775, train_loss_epoch=0.0775, valid_loss=0.169]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 136.48it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=0.169]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 121.80it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=0.169]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=0.169]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0692, train_loss_epoch=0.0692, valid_loss=0.169]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=0.169]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0692, train_loss_epoch=0.0692, valid_loss=0.169]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 144.25it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0688, valid_loss=0.169]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.14it/s]\u001b[A\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=0.174]\n",
            "Epoch 603: 100%|██████████| 1/1 [00:00<00:00, 153.95it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=0.174]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0655, train_loss_epoch=0.0655, valid_loss=0.174]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0578, train_loss_epoch=0.0578, valid_loss=0.174]\n",
            "Epoch 615: 100%|██████████| 1/1 [00:00<00:00, 107.11it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.174]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.174]\n",
            "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 136.77it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0716, valid_loss=0.174]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.174]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=0.174]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=0.174]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.174]\n",
            "Epoch 673: 100%|██████████| 1/1 [00:00<00:00, 133.53it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0666, valid_loss=0.174]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=0.174]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=0.174]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=0.174]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 130.20it/s, v_num=0, train_loss_step=0.0798, train_loss_epoch=0.0581, valid_loss=0.174]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 250.93it/s]\u001b[A\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.183]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=0.183]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 143.25it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=0.183]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 124.40it/s, v_num=0, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=0.183]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=0.183]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=0.183]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0566, train_loss_epoch=0.0566, valid_loss=0.183]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=0.183]\n",
            "Epoch 753: 100%|██████████| 1/1 [00:00<00:00, 109.92it/s, v_num=0, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=0.183]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=0.183]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0554, train_loss_epoch=0.0554, valid_loss=0.183]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=0.183]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0561, train_loss_epoch=0.0561, valid_loss=0.183]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 128.46it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0419, valid_loss=0.183]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 230.32it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24360)\u001b[0m \n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0432, train_loss_epoch=0.0432, valid_loss=0.191]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.191]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=0.191]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=0.191]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=0.191]\n",
            "Epoch 864: 100%|██████████| 1/1 [00:00<00:00, 130.84it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=0.191]\n",
            "Epoch 864: 100%|██████████| 1/1 [00:00<00:00, 114.64it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=0.191]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=0.191]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=0.191]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.191]\n",
            "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 105.68it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.191]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.191]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=0.191]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 129.72it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0415, valid_loss=0.191]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.42it/s]\u001b[A\n",
            "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 108.87it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0395, valid_loss=0.209]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=0.209]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453, valid_loss=0.209]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0565, train_loss_epoch=0.0565, valid_loss=0.209]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=0.209]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=0.209]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=0.209]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.209]\n",
            "Epoch 975: 100%|██████████| 1/1 [00:00<00:00, 115.06it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.209] \n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.209]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.209]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.209]\n",
            "\n",
            "Trial _train_tune_2e118_00006 completed after 10 iterations at 2024-04-03 01:22:14. Total running time: 2min 16s\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00006 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         0.91237 |\n",
            "| time_total_s                             13.2583 |\n",
            "| training_iteration                            10 |\n",
            "| loss                                     0.22259 |\n",
            "| train_loss                               0.03386 |\n",
            "+--------------------------------------------------+\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 120.53it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.034, valid_loss=0.209]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 216.66it/s]\u001b[A\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 42.54it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.223]\n",
            "\n",
            "Trial _train_tune_2e118_00007 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial _train_tune_2e118_00007 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    16 |\n",
            "| context_size                                  50 |\n",
            "| decoder_hidden_size                           64 |\n",
            "| encoder_hidden_size                           50 |\n",
            "| encoder_n_layers                               1 |\n",
            "| h                                             12 |\n",
            "| inference_input_size                         -12 |\n",
            "| input_size                                   -12 |\n",
            "| learning_rate                            0.04892 |\n",
            "| loss                                       MAE() |\n",
            "| max_steps                                   1000 |\n",
            "| random_seed                                   19 |\n",
            "| valid_loss                                 MAE() |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=24486)\u001b[0m Seed set to 19\n",
            "\u001b[36m(_train_tune pid=24486)\u001b[0m 2024-04-03 01:22:21.189866: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24486)\u001b[0m 2024-04-03 01:22:21.189927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24486)\u001b[0m 2024-04-03 01:22:21.191295: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=24486)\u001b[0m 2024-04-03 01:22:22.541486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 140.51it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=2.320]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 117.81it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.537]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521]\n",
            "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 132.14it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 133.40it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.385]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 259.23it/s]\u001b[A\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 118.62it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.920]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 103.84it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.920]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.920]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.920]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.920]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.920]\n",
            "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 131.63it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.348, valid_loss=0.920]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.920]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.920]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.920]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.920]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.920]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 129.67it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.287, valid_loss=0.920]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.47it/s]\u001b[A\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.853]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.853]         \n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.853]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.853]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.853]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 136.26it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.260, valid_loss=0.853]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.853]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.853]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 114.13it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.853]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.853]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.853]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.853]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 148.14it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.238, valid_loss=0.853]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24486)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=24486)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.16it/s]\u001b[A\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.633]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.633]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.633]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.633]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 136.91it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.633]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.633]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.633]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.633]\n",
            "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 141.76it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.220, valid_loss=0.633]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.633]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.633]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 144.31it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.633]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.633]         \n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.633]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.633]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 146.98it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.160, valid_loss=0.633]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 282.18it/s]\u001b[A\n",
            "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 129.54it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.580]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.580]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.580]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 139.46it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=0.580]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=0.580]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.580]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.580]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 114.39it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.580]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.580]\n",
            "\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-04-03 01:22:28. Total running time: 2min 30s\n",
            "Logical resource usage: 0/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:V100)\n",
            "Current best trial: 2e118_00004 with loss=0.15889066457748413 and params={'h': 12, 'encoder_hidden_size': 200, 'encoder_n_layers': 2, 'context_size': 10, 'decoder_hidden_size': 256, 'learning_rate': 0.00019967009922020209, 'max_steps': 500, 'batch_size': 32, 'loss': MAE(), 'random_seed': 3, 'input_size': 768, 'inference_input_size': -12, 'valid_loss': MAE()}\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         encoder_hidden_size     encoder_n_layers     context_size     decoder_hidden_size     learning_rate     max_steps     batch_size     random_seed     input_size     inference_input_size     iter     total time (s)       loss     train_loss |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _train_tune_2e118_00007   RUNNING                         50                    1               50                      64       0.0489204            1000             16              19            -12                      -12        4            7.70651   0.580468      0.16949   |\n",
            "| _train_tune_2e118_00000   TERMINATED                      50                    1               50                      64       0.0173876            1000             16              17            -12                      -12       10           13.2459    0.276873      0.0488516 |\n",
            "| _train_tune_2e118_00001   TERMINATED                     300                    2               10                     128       0.00417214           1000             32               1            -12                      -12       10           22.6754    0.812577      0.10292   |\n",
            "| _train_tune_2e118_00002   TERMINATED                     100                    2                5                      64       0.000908835           500             16              17            -12                      -12        5            8.84879   0.268117      0.0813497 |\n",
            "| _train_tune_2e118_00003   TERMINATED                      50                    1                5                      64       0.0567662             500             16               3            768                      -12        5            8.83721   0.832911      0.629744  |\n",
            "| _train_tune_2e118_00004   TERMINATED                     200                    2               10                     256       0.00019967            500             32               3            768                      -12        5            8.78546   0.158891      0.0987338 |\n",
            "| _train_tune_2e118_00005   TERMINATED                     300                    1               50                     128       0.0110875            1000             32               2            768                      -12       10           17.5258    0.893813      0.333921  |\n",
            "| _train_tune_2e118_00006   TERMINATED                      50                    1                5                      64       0.00517433           1000             32               9            -12                      -12       10           13.2583    0.222588      0.0338576 |\n",
            "| _train_tune_2e118_00008   PENDING                        100                    1               10                     256       0.000502431           500             32              13            768                      -12                                                       |\n",
            "| _train_tune_2e118_00009   PENDING                         50                    1               10                     256       0.00018594            500             16              13            192                      -12                                                       |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=0.580]\n",
            "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 144.41it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.126, valid_loss=0.580]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.580]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.580]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.580]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nf2 = NeuralForecast.load(path=path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "MV94xU4-R2dP",
        "outputId": "a9dc8f39-16e5-4db8-ac01-75ef3ed5ba9f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'local_scaler_type'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-eb21a659d41b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralForecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neuralforecast/core.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"freq\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m             \u001b[0mlocal_scaler_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local_scaler_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m         )\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'local_scaler_type'"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install neuralforecast\n",
        "import neuralforecast as nf\n",
        "\n",
        "help(nf.NeuralForecast.load)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PIMlPgOceAu",
        "outputId": "71a45fe0-013f-45f6-e453-fd805ec40e13"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neuralforecast in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: coreforecast>=0.0.6 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (0.0.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (1.5.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.2.1+cu121)\n",
            "Requirement already satisfied: pytorch-lightning>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.2.1)\n",
            "Requirement already satisfied: ray[tune]>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (2.10.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (3.6.1)\n",
            "Requirement already satisfied: utilsforecast>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from neuralforecast) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->neuralforecast) (2023.4)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (1.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.10.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (0.11.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.13.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.31.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (14.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->neuralforecast) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->neuralforecast) (12.4.99)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->neuralforecast) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->neuralforecast) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->neuralforecast) (2.0.29)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->neuralforecast) (1.3.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->neuralforecast) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=2.0.0->neuralforecast) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->neuralforecast) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->neuralforecast) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->neuralforecast) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]>=2.2.0->neuralforecast) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]>=2.2.0->neuralforecast) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->neuralforecast) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->neuralforecast) (4.0.3)\n",
            "Help on function load in module neuralforecast.core:\n",
            "\n",
            "load(path, verbose=False, **kwargs)\n",
            "    Load NeuralForecast\n",
            "    \n",
            "    `core.NeuralForecast`'s method to load checkpoint from path.\n",
            "    \n",
            "    Parameters\n",
            "    -----------\n",
            "    path : str\n",
            "        Directory with stored artifacts.\n",
            "    kwargs\n",
            "        Additional keyword arguments to be passed to the function\n",
            "        `load_from_checkpoint`.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    result : NeuralForecast\n",
            "        Instantiated `NeuralForecast` class.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "local_scaler_type (str, optional): Type of local scaler to use. Can be one of `standard`, `minmax`, `quantile`, or `none`. Defaults to `standard`."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "kSRtrm8icfxc",
        "outputId": "4aef6169-ad81-40d4-dda9-7f366113f9ec"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "illegal target for annotation (<ipython-input-51-ed7b846e396d>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-ed7b846e396d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    local_scaler_type (str, optional): Type of local scaler to use. Can be one of `standard`, `minmax`, `quantile`, or `none`. Defaults to `standard`.\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m illegal target for annotation\n"
          ]
        }
      ]
    },
    {
      "source": [
        "nf2 = NeuralForecast.load(path=path, local_scaler_type=\"standard\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "1U8Z593qckIn",
        "outputId": "3fdec1cb-602c-4b8b-884a-f86078195a66"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'local_scaler_type'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-0b4f9d6ae862>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralForecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_scaler_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"standard\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neuralforecast/core.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"freq\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m             \u001b[0mlocal_scaler_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local_scaler_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m         )\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'local_scaler_type'"
          ]
        }
      ]
    },
    {
      "source": [
        "nf2 = NeuralForecast.load(path=path, local_scaler_type=\"standard\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "ZIIXQnpLcih4",
        "outputId": "5abb19a5-40d8-402a-f2d6-67ee7f40c0db"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'local_scaler_type'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0b4f9d6ae862>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralForecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_scaler_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"standard\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neuralforecast/core.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"freq\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m             \u001b[0mlocal_scaler_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local_scaler_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m         )\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'local_scaler_type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Initialize an empty dictionary to store the performance of each model\n",
        "model_performance = {}\n",
        "\n",
        "# Loop over each model\n",
        "for model in models:\n",
        "    try:\n",
        "        # Define the path where the model is saved\n",
        "        path = f'/content/drive/MyDrive/models/{model.__class__.__name__}/'\n",
        "\n",
        "        # Check if the model directory exists\n",
        "        if Path(path).exists():\n",
        "            # Load the model\n",
        "            nf = NeuralForecast.load(path=path)\n",
        "\n",
        "            # Check if the model has 'local_scaler_type' attribute\n",
        "            if hasattr(nf, 'local_scaler_type'):\n",
        "                # Generate predictions\n",
        "                predictions = nf.predict()\n",
        "\n",
        "                # Calculate the root mean squared error (RMSE)\n",
        "                rmse = np.sqrt(mean_squared_error(Y_df, predictions))\n",
        "\n",
        "                # Store the performance of the model\n",
        "                model_performance[model.__class__.__name__] = rmse\n",
        "\n",
        "                # Print the name of the model that was loaded successfully\n",
        "                print(f'モデル{model.__class__.__name__}が正常にロードされました。')\n",
        "            else:\n",
        "                print(f'モデル{model.__class__.__name__}はlocal_scaler_type属性を持っていません。')\n",
        "        else:\n",
        "            print(f'{path}のモデルディレクトリは存在しません。')\n",
        "    except Exception as e:\n",
        "        print(f'モデル{model.__class__.__name__}の処理中にエラーが発生しました: {str(e)}')\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create a bar chart\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a bar trace for each model\n",
        "for model, performance in model_performance.items():\n",
        "    fig.add_trace(go.Bar(x=[model], y=[performance], name=model))\n",
        "\n",
        "# Set the layout properties\n",
        "fig.update_layout(\n",
        "    title='Performance of each model',\n",
        "    xaxis_title='Model',\n",
        "    yaxis_title='RMSE',\n",
        "    barmode='group'\n",
        ")\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yYhL5OJBRoe2",
        "outputId": "f1d28986-aa3c-44ea-8afd-320fd4503714"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 18\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 6\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 13\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 9\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデルAutoRNNの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoLSTMの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoGRUの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoTCNの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoDeepARの処理中にエラーが発生しました: 'local_scaler_type'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 18\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 7\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデルAutoDilatedRNNの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoMLPの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoNBEATSの処理中にエラーが発生しました: 'local_scaler_type'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 6\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 2\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデルAutoNBEATSxの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoNHITSの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "/content/drive/MyDrive/models/AutoTFT/のモデルディレクトリは存在しません。\n",
            "モデルAutoVanillaTransformerの処理中にエラーが発生しました: 'local_scaler_type'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 14\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 3\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデルAutoInformerの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoAutoformerの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "モデルAutoFEDformerの処理中にエラーが発生しました: 'local_scaler_type'\n",
            "/content/drive/MyDrive/models/AutoTimesNet/のモデルディレクトリは存在しません。\n",
            "/content/drive/MyDrive/models/AutoStemGNN/のモデルディレクトリは存在しません。\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"ac5f3815-309f-49d2-8027-e6c0a01da9cc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ac5f3815-309f-49d2-8027-e6c0a01da9cc\")) {                    Plotly.newPlot(                        \"ac5f3815-309f-49d2-8027-e6c0a01da9cc\",                        [],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Performance of each model\"},\"xaxis\":{\"title\":{\"text\":\"Model\"}},\"yaxis\":{\"title\":{\"text\":\"RMSE\"}},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ac5f3815-309f-49d2-8027-e6c0a01da9cc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    shutil.rmtree('/content/drive/MyDrive/checkpoints')  # 既存のディレクトリを削除\n",
        "    shutil.copytree('/content/checkpoints', '/content/drive/MyDrive/checkpoints')  # ディレクトリをコピー\n",
        "    print(\"ディレクトリのコピーが完了しました。\")\n",
        "except Exception as e:\n",
        "    print(f'ディレクトリのコピー中にエラーが発生しました: {str(e)}')\n"
      ],
      "metadata": {
        "id": "RF5XD4Oir5su",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e280ce10-4990-41e9-8cc2-983bb18bd518"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ディレクトリのコピーが完了しました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxD8mxlpQzxJ"
      },
      "source": [
        "Produce the forecasts with the `predict` method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat_insample = nf.predict_insample(step_size=horizon)"
      ],
      "metadata": {
        "id": "EmswBIbqmrYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oznmdnmwQzxJ"
      },
      "outputs": [],
      "source": [
        "Y_hat_df = nf.predict().reset_index()\n",
        "Y_hat_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcbNLwchQzxJ"
      },
      "source": [
        "We plot the forecasts for each model. Note how the two `NBEATS` models are differentiated with a numerical suffix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leSfUotOQzxK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7viqH0ILQzxK"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\n",
        "\n",
        "plt.figure(figsize = (12, 3))\n",
        "plot_df[['y', 'NBEATS', 'NHITS', 'AutoMLP']].plot(linewidth=2)\n",
        "\n",
        "plt.title('AirPassengers Forecast', fontsize=10)\n",
        "plt.ylabel('Monthly Passengers', fontsize=10)\n",
        "plt.xlabel('Timestamp [t]', fontsize=10)\n",
        "plt.axvline(x=plot_df.index[-horizon], color='k', linestyle='--', linewidth=2)\n",
        "plt.legend(prop={'size': 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTTNjFRPQzxK"
      },
      "source": [
        "## 4. Save models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNAnHc_qQzxK"
      },
      "source": [
        "To save all the trained models use the `save` method. This method will save both the hyperparameters and the learnable weights (parameters).\n",
        "\n",
        "The `save` method has the following inputs:\n",
        "\n",
        "* `path`: directory where models will be saved.\n",
        "* `model_index`: optional list to specify which models to save. For example, to only save the `NHITS` model use `model_index=[2]`.\n",
        "* `overwrite`: boolean to overwrite existing files in `path`. When True, the method will only overwrite models with conflicting names.\n",
        "* `save_dataset`: boolean to save `Dataset` object with the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMnleGWTQzxL"
      },
      "outputs": [],
      "source": [
        "nf.save(path='./checkpoints/test_run2/',\n",
        "        model_index=None,\n",
        "        overwrite=True,\n",
        "        save_dataset=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpq_XjQiQzxL"
      },
      "source": [
        "For each model, two files are created and stored:\n",
        "\n",
        "* `[model_name]_[suffix].ckpt`: Pytorch Lightning checkpoint file with the model parameters and hyperparameters.\n",
        "* `[model_name]_[suffix].pkl`: Dictionary with configuration attributes.\n",
        "\n",
        "Where `model_name` corresponds to the name of the model in lowercase (eg. `nhits`). We use a numerical suffix to distinguish multiple models of each class. In this example the names will be `automlp_0`, `nbeats_0`, and `nhits_0`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS_fuMu0QzxL"
      },
      "source": [
        ":::{.callout-important}\n",
        "The `Auto` models will be stored as their base model. For example, the `AutoMLP` trained above is stored as an `MLP` model, with the best hyparparameters found during tuning.\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pfxCfCOQzxL"
      },
      "source": [
        "## 5. Load models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPrlGj7_QzxL"
      },
      "source": [
        "Load the saved models with the `load` method, specifying the `path`, and use the new `nf2` object to produce forecasts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh0cZj_mQzxL"
      },
      "outputs": [],
      "source": [
        "nf2 = NeuralForecast.load(path='./checkpoints/test_run2/')\n",
        "Y_hat_df = nf2.predict().reset_index()\n",
        "Y_hat_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxTzUPpSQzxM"
      },
      "source": [
        "Finally, plot the forecasts to confirm they are identical to the original forecasts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOxf8XOLQzxM"
      },
      "outputs": [],
      "source": [
        "plot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\n",
        "\n",
        "plt.figure(figsize = (12, 3))\n",
        "plot_df[['y', 'NBEATS', 'NHITS', 'MLP']].plot(linewidth=2)\n",
        "\n",
        "plt.title('AirPassengers Forecast', fontsize=10)\n",
        "plt.ylabel('Monthly Passengers', fontsize=10)\n",
        "plt.xlabel('Timestamp [t]', fontsize=10)\n",
        "plt.axvline(x=plot_df.index[-horizon], color='k', linestyle='--', linewidth=2)\n",
        "plt.legend(prop={'size': 10})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA2F17kpQzxM"
      },
      "source": [
        "## References\n",
        "\n",
        "https://pytorch-lightning.readthedocs.io/en/stable/common/checkpointing_basic.html\n",
        "\n",
        "[Oreshkin, B. N., Carpov, D., Chapados, N., & Bengio, Y. (2019). N-BEATS: Neural basis expansion analysis for interpretable time series forecasting. ICLR 2020](https://arxiv.org/abs/1905.10437)\n",
        "\n",
        "[Cristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023.](https://arxiv.org/abs/2201.12886)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import tune\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "from neuralforecast.losses.pytorch import MAE"
      ],
      "metadata": {
        "id": "ab4nVugSiO4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nhits_config = {\n",
        "       \"max_steps\": 100,                                                         # Number of SGD steps\n",
        "       \"input_size\": 24,                                                         # Size of input window\n",
        "       \"learning_rate\": tune.loguniform(1e-5, 1e-1),                             # Initial Learning rate\n",
        "       \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),               # MaxPool's Kernelsize\n",
        "       \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1]]), # Interpolation expressivity ratios\n",
        "       \"val_check_steps\": 50,                                                    # Compute validation every 50 steps\n",
        "       \"random_seed\": tune.randint(1, 10),                                       # Random seed\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ojoRNk9Si-yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoNHITS(h=12,\n",
        "                  loss=MAE(),\n",
        "                  config=None,\n",
        "                  search_alg=HyperOptSearch(),\n",
        "                  backend='ray',\n",
        "                  num_samples=10,\n",
        "                  cpus=cpus,\n",
        "                  gpus=gpus,\n",
        "                  verbose=True\n",
        "                  )\n"
      ],
      "metadata": {
        "id": "_3bBAdRziXcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING) # Use this to disable training prints from optuna\n"
      ],
      "metadata": {
        "id": "mg0Cf1x0idCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def config_nhits(trial):\n",
        "    return {\n",
        "        \"max_steps\": 100,                                                                                               # Number of SGD steps\n",
        "        \"input_size\": 24,                                                                                               # Size of input window\n",
        "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1),                                         # Initial Learning rate\n",
        "        \"n_pool_kernel_size\": trial.suggest_categorical(\"n_pool_kernel_size\", [[2, 2, 2], [16, 8, 1]]),                 # MaxPool's Kernelsize\n",
        "        \"n_freq_downsample\": trial.suggest_categorical(\"n_freq_downsample\", [[168, 24, 1], [24, 12, 1], [1, 1, 1]]),    # Interpolation expressivity ratios\n",
        "        \"val_check_steps\": 50,                                                                                          # Compute validation every 50 steps\n",
        "        \"random_seed\": trial.suggest_int(\"random_seed\", 1, 10),                                                         # Random seed\n",
        "    }\n"
      ],
      "metadata": {
        "id": "nObWbwy4ihZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoNHITS(h=12,\n",
        "                  loss=MAE(),\n",
        "                  config=None,\n",
        "                  search_alg=optuna.samplers.TPESampler(),\n",
        "                  backend='optuna',\n",
        "                  num_samples=10,\n",
        "                  cpus=cpus,\n",
        "                  gpus=gpus,\n",
        "                  verbose=True)\n"
      ],
      "metadata": {
        "id": "A8YrI_tuikV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nf = NeuralForecast(models=[model], freq='M')\n",
        "nf.fit(df=Y_df, val_size=24)\n",
        "nf.save(path='./checkpoints/optuna/',\n",
        "        model_index=None,\n",
        "        overwrite=True,\n",
        "        save_dataset=True)"
      ],
      "metadata": {
        "id": "Fbz1L_CxinVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = nf.models[0].results.trials_dataframe()\n",
        "results.drop(columns='user_attrs_ALL_PARAMS')\n"
      ],
      "metadata": {
        "id": "zagyfBuyitx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat_df_optuna = nf.predict()\n",
        "Y_hat_df_optuna = Y_hat_df_optuna.reset_index()\n",
        "Y_hat_df_optuna.head()\n"
      ],
      "metadata": {
        "id": "Sg09E1ZWiwY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "jvLe7mP_iz4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize = (20, 7))\n",
        "plot_df = pd.concat([Y_df, Y_hat_df]).reset_index()\n",
        "\n",
        "plt.plot(plot_df['ds'], plot_df['y'], label='y')\n",
        "plt.plot(plot_df['ds'], plot_df['AutoNHITS'], label='Ray')\n",
        "plt.plot(Y_hat_df_optuna['ds'], Y_hat_df_optuna['AutoNHITS'], label='Optuna')\n",
        "\n",
        "ax.set_title('AirPassengers Forecast', fontsize=22)\n",
        "ax.set_ylabel('Monthly Passengers', fontsize=20)\n",
        "ax.set_xlabel('Timestamp [t]', fontsize=20)\n",
        "ax.legend(prop={'size': 15})\n",
        "ax.grid()\n"
      ],
      "metadata": {
        "id": "TCz7JFiri2H3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f33790132a744f3be52b3979b67046b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9422d12d02204a319643100060e931fe",
              "IPY_MODEL_18afd98ba8b14a1196c745aabeb64ed3",
              "IPY_MODEL_8ca02ff3bb1d45178012d3443d95f81e"
            ],
            "layout": "IPY_MODEL_a821fd9a1b664afbbd5c4964394f4944"
          }
        },
        "9422d12d02204a319643100060e931fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fa3965adda54cf79b27d7249e3a3e95",
            "placeholder": "​",
            "style": "IPY_MODEL_44fa70a78b2041fe918b175cd0c1c902",
            "value": "モデルの処理:   0%"
          }
        },
        "18afd98ba8b14a1196c745aabeb64ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abe942f9dcbc45b7a8228caaf844b343",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10de412691f748f7a761b80a0221b900",
            "value": 0
          }
        },
        "8ca02ff3bb1d45178012d3443d95f81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5494336a83945c39c0692113ae7c473",
            "placeholder": "​",
            "style": "IPY_MODEL_8572992d387d46c39bb4483cb8ee245b",
            "value": " 0/17 [00:00&lt;?, ?it/s]"
          }
        },
        "a821fd9a1b664afbbd5c4964394f4944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fa3965adda54cf79b27d7249e3a3e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44fa70a78b2041fe918b175cd0c1c902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abe942f9dcbc45b7a8228caaf844b343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10de412691f748f7a761b80a0221b900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5494336a83945c39c0692113ae7c473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8572992d387d46c39bb4483cb8ee245b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}