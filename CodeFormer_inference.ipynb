{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arumajirou/-daily-test/blob/main/CodeFormer_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjdQE0kKcqjA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/14334509/179359809-bd45566a-486d-418f-83fa-67bbbba8c45c.png\" height=120>\n",
        "</p>\n",
        "\n",
        "# **CodeFormerの推論デモ**\n",
        "**符号表探索変成器による頑健な盲顔面復元に向けて（NeurIPS 2022)**\n",
        "Shangchen Zhou, Kelvin C.K. Chan, Chongyi Li, Chen Change Loy\n",
        "\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/sczhou/CodeFormer?style=social)](https://github.com/sczhou/CodeFormer) [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2206.11253) [![Hugging Face](https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue)](https://huggingface.co/spaces/sczhou/CodeFormer) ![visitors](https://visitor-badge.glitch.me/badge?page_id=sczhou/CodeFormer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnXeWdx9NzvN"
      },
      "source": [
        "# **1.はじめに**\n",
        "　今回ご紹介するのは、**Transfomer ベースの予測ネットワーク**を使うことによって、**低画質の顔画像を高画質化する CodeFormer という技術です。**\n",
        "\n",
        "---\n",
        "# **2.CodeFomerとは？**\n",
        "\n",
        "「人の顔写真を綺麗に復元したい」\n",
        "「Real-ESRGANのソフトウェアの準備に失敗してしまう・・・」\n",
        "\n",
        "このような場合には、**CodeFormerがオススメ**です。\n",
        "\n",
        "- CodeFormerは、**顔面修復のやり方**のことを言います\n",
        "- 顔面修復を簡単に言うと、**顔を綺麗にすること**です。\n",
        "- これと同じようなことは、**GFPGANでも可能**です。\n",
        "- あと、CodeFormerでは**Real-ESRGAN**を統合しています。\n",
        "\n",
        "- ただ、CodeFormerに統合された**Real-ESRGAN**では、**細かい計算式／計算方法指定まではできない**ようです。\n",
        "- CodeFormerの情報の発信元を見ると、**「RealESRGAN_x2plus.pth」が固定**で指定されています。\n",
        "\n",
        "- 現状では、**「RealESRGAN_x4plus.pth」を指定することは無理**そうです。\n",
        "\n",
        "- 「RealESRGAN_x4plus.pth」を利用したいなら、本家（Real-ESRGAN単独）を利用しましょう。\n",
        "\n",
        "\n",
        "下記は、**CodeFormerの概要図**で、**２段階で学習**を行います。\n",
        "\n",
        "---\n",
        "\n",
        "#### **1.まず（a）自己再構成学習を行います**\n",
        "- **高画質画像（Ih）**から**高画質記号化（HQ Encoder）**を通して**画像特徴量（Zh）を抽出**し\n",
        "- **最近傍適合（Nearest-Neighbor Matching）**で**離散符号表（Codebook C）に関連付け**し、\n",
        "\n",
        "- **解読器（HQ Decoder）で高画質画像に戻すことを学習**します。\n",
        "\n",
        "ここで学習した離散符号表以降は次で使用します。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### **2.次に(b）最終的なネットワークの学習を行います。**\n",
        "\n",
        "- **低画質画像（IL）**から**低画質記号化（LQ Encoder）**を通して**画像特徴量（ZL）を抽出**します。\n",
        "\n",
        "- ここで、**Transformer による予測ネットワーク（Code Prediction(符号予測)）**を使って、\n",
        "\n",
        "- 先程学習した**離散符号表以降に接続して学習する**のがミソです。\n",
        "\n",
        "- さらに、**CFT**で**低画質記号化**から**解読器**へ流す情報を**重み w で調整する**ことによって\n",
        "\n",
        "- **画像品質**と**忠実度**の**トレードオフを調整**することができます。\n",
        "<img src=\"https://github.com/sczhou/CodeFormer/raw/master/assets/network.jpg\" alt=\"CodeFormerの概要図\" title=\"CodeFormerの概要図\">\n",
        "\n",
        "---\n",
        "- http://cedro3.com/ai/codeformer/\n",
        "\n",
        "- https://self-development.info/%E3%80%90python%E3%80%91ai%E9%AB%98%E7%94%BB%E8%B3%AA%E5%8C%96%E3%83%84%E3%83%BC%E3%83%ABcodeformer%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELSPh7SNSpYd"
      },
      "source": [
        "# **概要**\n",
        "**盲顔面復元とは**、\n",
        "\n",
        "1) **劣化した入力**から**望ましい出力**への**対応付けを改善する**、あるいは、\n",
        "\n",
        "2)**入力で失われた高品質の詳細を補完**するための**補助的な案内**が必要となることが多い。\n",
        "\n",
        "- 本論文では、**小さな代理空間**において学習された**離散符号表(一連の符号の完全な記録)事前分布**が、\n",
        "\n",
        "- **顔復元を符号予測作業**と見なすことにより、\n",
        "\n",
        "- 復元対応付けの**不確実性と曖昧性を大幅に低減**し、\n",
        "\n",
        "- 一方で**高品質な顔生成**のための豊富な視覚的アトムを提供することを示す。 \n",
        "\n",
        "- この捉え方の下、我々は**CodeFormerと名付けたTransformerベースの予測ネットワーク**を提案し、\n",
        "\n",
        "- **符号予測**のための**低品質顔**の**大域的な構成**と**文脈**を**計算式／計算方法化**することで、\n",
        "\n",
        "- **入力が著しく劣化**した場合でも、**目標顔に近い自然顔**を発見することを可能にする。\n",
        "\n",
        "- また、**異なる劣化**への**適応性を高める**ため、**忠実度**と**品質**の柔軟な**トレードオフ(何かを得ると、別の何かを失う、相容れない関係のこと)**を可能にする**制御可能な特徴変換機能**を提案する。\n",
        "\n",
        "- **CodeFormer**は、**表現力豊か**な**符号表(一連の符号の完全な記録)事前定義**と\n",
        "\n",
        "- **大域的**な**模型（計算式／計算方法）を組み立てること**により、**品質**と**忠実度**の**両方**で**最先端技術**を凌駕し、\n",
        "\n",
        "- **劣化**に対する**優れた頑健性**を示す。\n",
        "\n",
        "合成および実世界のデータセット（プログラムで処理されるデータの集合体、ある目的で集められ、一定の形式に整えられたデータの集合体）を用いた広範な実験結果により、本手法の有効性を検証する。\n",
        "\n",
        "---\n",
        "<img src=\"https://shangchenzhou.com/projects/CodeFormer/assets/img/codeformer/network.jpg\" alt=\"CodeFormerの概要\" title=\"CodeFormerの概要\">\n",
        "\n",
        "---\n",
        "(a) まず、**自己再構成学習**により**顔画像**の**高品質な視覚部分**を**格納する**ための**離散符号表(一連の符号の完全な記録)**と**解読器（ 他の形式へ変換したデータを元に戻すこと）**を**学習**する。\n",
        "\n",
        "(b) **離散符号表(一連の符号の完全な記録)**と**解読器**を**固定**した上で、**符号列予測**のための**Transformer機能**を導入し、**低品質入力**の**大域的な顔合成**を**計算式／計算方法化**する。\n",
        "\n",
        "さらに、**制御可能**な**特徴変換機能**を用いて、**LQ符号化(データを他の形式へ変換する)**から **解読器（ 他の形式へ変換したデータを元に戻すこと）**への**情報の流れを制御**する。\n",
        "\n",
        "なお、この接続は**選択性**であり、**入力**が**著しく劣化**した場合の**悪影響を避ける**ために**無効にする**ことができ、\n",
        "\n",
        "**品質**と**忠実度**の間で**交換**するために**スカラー(大きさのみで表され、方向をもたない量の)重みwを調整**することも可能である。\n",
        "\n",
        "---\n",
        "https://shangchenzhou.com/projects/CodeFormer/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4pF-MkLXffn"
      },
      "source": [
        "# **GFPGANとは？**\n",
        "\n",
        "- **テンセントARC/GFPGAN**\n",
        "\n",
        "- **Generative Facial Prior GAN(事前顔生成敵対的生成神経網)**\n",
        "\n",
        "- この論文は、2021.11に提出されました。\n",
        "\n",
        "- **GFPGAN**は、**顔面修復の方法*のことを言います。\n",
        "- 顔面修復を簡単に言うと、**顔を綺麗にする**ことです。\n",
        "\n",
        "次の画像を見れば、**GFPGAN（一番右）**のできることがわかるでしょう。\n",
        "<img src=\"https://self-development.info/wp-content/uploads/2022/09/68747470733a2f2f78696e6e74616f2e6769746875622e696f2f70726f6a656374732f47465047414e5f7372632f67667067616e5f7465617365722e6a7067.jpg\" alt=\"GFPGANの概要\" title=\"GFPGANの概要\">\n",
        "\n",
        "上の比較画像から言えることは、GFPGAN最高ということですね。\n",
        "\n",
        "PULSEのようにやり過ぎず、**画質を上げることに成功**しています。\n",
        "\n",
        "- また、**GFPGAN**は**顔画像を高画質化**するだけではありません。\n",
        "**全体を高画質化**することも可能です。\n",
        "\n",
        "- そのためには、**Real-ESRGAN**のソフトウェアの準備が必要となります。\n",
        "\n",
        "- よって、**GFPGAN**と**Real-ESRGAN**はセットで導入を考えましょう。\n",
        "---\n",
        "- GFPGANは、実世界での**顔画像復元**の ための**実用的な方法**の開発を目指しています。\n",
        "- GFPGANは、**事前に学習した顔GAN（StyleGAN2など）**に格納されている豊富で多様な**事前分布を利用**して、**盲顔面復元**を行うものである。\n",
        "\n",
        "---\n",
        "- https://github.com/TencentARC/GFPGAN\n",
        "- https://self-development.info/%e4%ba%ba%e7%89%a9%e3%81%ae%e9%a1%94%e3%82%92%e7%b6%ba%e9%ba%97%ef%bc%88%e9%ab%98%e7%94%bb%e8%b3%aa%ef%bc%89%e3%81%ab%e3%81%99%e3%82%8bgfpgan%e3%81%ae%e3%82%a4%e3%83%b3%e3%82%b9%e3%83%88%e3%83%bc/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnk2rKqYaqC9"
      },
      "source": [
        "# **GFPGANとは？**\n",
        "\n",
        "**GFPGAN（Generative Facial Prior GAN)(事前顔生成敵対的生成神経網)**\n",
        "\n",
        "- 基本的には、従来からある**StyleGANを使ってボヤけた顔を復元する手法**ですが、いくつか改良ポイントがあります。\n",
        "\n",
        "- １つ目は、**GAN(敵対的生成ネットワーク)**の**前段**に **Degradation Removal（劣化除去機能）**を設けて、**latent codes W（潜在的符号関連付け）**と **Channel-Split SFT（分割空間機能変換）**で**接続**したことです。\n",
        "\n",
        "- このとき**GAN(敵対的生成ネットワーク)**へ**伝達する**のが、**従来の低解像度の情報**のみではなく、**低解像度〜高解像度の情報**であるため、学習後は**１回の転送路**で**結果を得る**ことが出来ます。\n",
        "\n",
        "- ２つ目は、**ロス(損失)**として **Facial Component Loss（ 顔を構成する部品毎の損失）**と **Identity Preserving Loss（顔の同一性を保持するための損失）**を**追加**したことです。\n",
        "\n",
        "路せて**Real-ESRGAN**を使った**一般的な画像復元**を行い**画像全体を鮮明に**しています。\n",
        "\n",
        "---\n",
        "# **生成的顔面事前分布を用いた実世界での盲顔面復元に向けて**\n",
        "\n",
        "\n",
        "- **盲顔復元**は通常、**顔形状事前分布**や**参照事前分布**などの\n",
        "\n",
        "- **顔事前分布に依存**して、**写実的**で**忠実な詳細**を**復元**する。 \n",
        "- しかし、**非常に低品質の入力**は**正確な形状事前分布**を**提供できず**、\n",
        "- **高品質の参照**は**接続できない**ため、**実世界での適用が制限**されている。\n",
        "- そこで本研究では、**事前に学習**された**顔GAN**に内包された**豊富で多様な事前分布**を利用して**盲顔復元を行うGFP-GAN**を提案する。\n",
        "- この**GFP-GAN**は、**領域分割**された**空間特徴変換層**を介して**顔復元処理**に組み込まれ、\n",
        "- **写実的さ**と**忠実度**の**良好な均衡**を実現する。 \n",
        "- **GAN反転手法**では**推論時**に**画像固有の最適化**が必要となるが、\n",
        "- **強力な生成顔事前分布**と**繊細な設計**により、\n",
        "- 本手法は**たった1回の転送路**で**顔の細部の復元**と**色の強調**を**同時に行う**ことが可能である。\n",
        "- 本手法は、**合成データ**および**実世界データ**の**両方**において、**先行技術より優れた性能を達成**することが、**広範な実験**により示されている。\n",
        "https://arxiv.org/abs/2101.04061\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<img src=\"https://api.axross-recipe.com/attachments/4526a9bf-d9ba-49fb-837e-749b27d097f6/url\" alt=\"GFPGANの概要\" title=\"GFPGANの概要\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKnwJcktfVYF"
      },
      "source": [
        "# **GFPGANを用いてより高解像度な画像を生成するレシピ**\n",
        "\n",
        "**GFPGANとは**\n",
        "\n",
        "**Generative Facial Prior GAN(以下、GFPGAN)**は、**2021年1月に論文発表**された**Blind Face Restoration(盲顔面修復)技術**です。\n",
        "\n",
        "- **Blind Face Restoration(盲顔面修復)**とは、**低解像度**や**雑音**や**ボケ**などによる**低品質な顔**から、**高品質な顔**を**復元する**ことを目的とする作業です。\n",
        "\n",
        "- 2021年に発表された本技術ですが、**Stable Diffusion**が生成した**人物画の顔部分**を**復元**する目的で活用され、**2022年に再び注目**が高まっています。\n",
        "\n",
        "---\n",
        "# **Degradation Removal Module(劣化除去機能)**\n",
        "**Degradation Removal Module(劣化除去機能)**は、**低解像度**や**雑音**などを持つ**低品質な画像**から**劣化を除去**し**後継機能**の**負担を軽減**することを**目的に設計**されています。\n",
        "\n",
        "<img src=\"https://api.axross-recipe.com/attachments/4526a9bf-d9ba-49fb-837e-749b27d097f6/url\" alt=\"GFPGANの概要\" title=\"GFPGANの概要\">\n",
        "\n",
        "**Degradation Removal Module(劣化除去機能)**は、**UNetベース**の**記号化・解読器で構築**されています。\n",
        "\n",
        "<img src=\"https://api.axross-recipe.com/attachments/fbf8e7cc-c856-408c-9fa5-6f2a8715c154/url\" alt=\"GFPGANの概要\" title=\"GFPGANの概要1\">\n",
        "\n",
        "\n",
        "はじめに、**画像xxが入力**されると、**画像**を**StyleGAN2**の**最も適した \n",
        "### $$潜在空間上に関連付けするための特徴量F_{latent}$$ \n",
        "$$F =feature(データを変形して得られ、その特徴を表現し、続く処理に利用される数値)$$ \n",
        "$$latent(隠れている, 見えない, (…に)潜んで, 潜伏性の)$$を抽出します。\n",
        "次に、**UNet解読器**で、**解像度ごと**に**複数**の\n",
        "### $$空間的特徴量F_{spatial}$$\n",
        "$$F =feature(データを変形して得られ、その特徴を表現し、続く処理に利用される数値)$$ \n",
        "$$spatial(空間の, 空間的な, 場所の)$$ を**抽出**します。\n",
        "この時、**各解像度**で**特徴量**と共に**画像**を**出力**し**正解画像**に**近づく**ように**訓練**されます。\n",
        "\n",
        "このような設計により、**劣化**を**取り除いたクリーンな特徴量**の**抽出**を目的としています。\n",
        "\n",
        "---\n",
        "Pretrained GAN as prior(事前学習済みGAN)\n",
        "Pretrained GAN as prior(事前学習済みGAN)では、前段で抽出した$$特徴量F_{latent}$$\n",
        "​と$$空間的特徴量F_{spatial}$$\n",
        "を入力に、**StyleGAN2**を用いて**高品質**で**忠実度の高い顔画像**を生成することを目的としています。\n",
        "<img src=\"https://api.axross-recipe.com/attachments/4526a9bf-d9ba-49fb-837e-749b27d097f6/url\" alt=\"GFPGANの概要\" title=\"GFPGANの概要\">\n",
        "\n",
        "ここでは、\n",
        "$$特徴量F_{latent}$$ \n",
        "\n",
        "\n",
        "を入力に**事前に訓練**された**GANの各畳み込み層を通過し**て、**異なる解像度スケール**の\n",
        "\n",
        "\n",
        "$$GAN特徴量F_{GAN}$$\n",
        "\n",
        "\n",
        "を生成します。\n",
        "次に、各解像度で$$空間特徴量F_{spatial}$$\n",
        "​を用いて$$GAN特徴量{F_{GAN}}$$\n",
        "​\n",
        "を**変調**します。**空間特徴量**は、**顔の空間位置**の**調整**や、**局所的な特性**などに**適応**し、**復元の忠実度を高める**ために用いられます。\n",
        "\n",
        "- **変調**には、$$Channel-Split SFT　領域分割空間特徴変換$$と呼ばれる**畳み込み**や**アフィン変換（類似・関連変換）（ある図形を回転させたり引き延ばしたりする変換）**から構成される**空間特徴変換(SFT)**を用いており、\n",
        "\n",
        "- **忠実度**と**写実性**の**均衡**を保ちながら$$GAN特徴量　F_{GAN}$$の変調を実現します。\n",
        "\n",
        "- これらの処理を繰り返し徐々に規模拡大し、最終的に$$復元画像\\hat{y}$$を生成しています。\n",
        "\n",
        "- また、さらに忠実度を高めるため以下の4種類の$$Loss 損失関数$$を適用しています。\n",
        "\n",
        "---\n",
        "\n",
        "$$Reconstruction Loss 復興損失 $$\n",
        "- Blind Face Restoration(盲顔面修\n",
        "復)作業で一般的に使用される\n",
        "\n",
        "---\n",
        "\n",
        "$$L1  知覚損失$$\n",
        "- **L1  知覚損失 生成画像**を**正解画像**に**近づける**ために使用\n",
        "\n",
        "---\n",
        "\n",
        "$$Adversarial Loss(ロジスティク損失)$$\n",
        "- **自然な質感の顔を復元**するために\n",
        "使用\n",
        "\n",
        "---\n",
        "\n",
        "$$Facial Component Loss(顔の成分の損失)$$\n",
        "- **関心領域(目、口)**を**不要な部分を除いて構図を調整**した修正プログラムが**正解データ**に**近いかどうか識別**させ**識別損失**などを算出。\n",
        "知覚的に重要な**目、口の復元のため**\n",
        "に使用\n",
        "\n",
        "---\n",
        "\n",
        "$$dentity Preserving Loss(歯列保存損失)$$\n",
        "- **事前学習済み顔認識計算式／計算方法ArcFace**を用いて、**生成画像**と**正解画像**の**顔認識特徴量の差分**を算出。**顔の同一性を維持**するために使用\n",
        "\n",
        "---\n",
        "\n",
        "これらの機能からなる$$GFPGAN(事前顔生成敵対的生成神経網)$$は、従来技術より**高品質な画像生成を実現**しています。\n",
        "\n",
        "それでは、実際にGFPGAN(事前顔生成敵対的生成神経網)を動かしていきます。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_avtsDo2uYMF"
      },
      "source": [
        "# **Real-ESRGAN**\n",
        "\n",
        "Real-ESRGANは、**高画質化ツール**です。\n",
        "次の画像を見れば、どういうモノであるかは一目瞭然と言えます\n",
        "\n",
        "<img src=\"https://self-development.info/wp-content/uploads/2022/08/teaser.jpg\" alt=\"Real-ESRGANの概要\" title=\"Real-ESRGANの概要1\">\n",
        "\n",
        "**Real-ESRGAN**は、技術的には**機械学習をベース**にしています。\n",
        "その際に利用している機械学習の枠組み（システム開発が楽になるように用意された、プログラムとかのひな形のこと）は、**PyTorch**になります。\n",
        "今回紹介するReal-ESRGANは**2018年に発表されたESRGAN**の進化版で、**2021年7月に発表**されています。\n",
        "\n",
        "普通の画像だけでなく、**アニメ画像及びアニメ動画にも対応**した計算式／計算方法が用意されているのが特徴です。\n",
        "<br>- Online inference<br>- Portable executable files (NCNN)<br>- Python script\n",
        "\n",
        "---\n",
        "\n",
        "# **Real-ESRGANを使用すると**\n",
        "- 小さな画像もキレイに拡大\n",
        "- 画質の粗い画像を高画質化\n",
        "※画像によっては平面的なものになったり、\n",
        "細かな部分で補正しきれていない形状が出たりします。\n",
        "\n",
        "\n",
        "---\n",
        "# **Real-ESRGAN：純粋な合成データで実世界の盲超解像を学習する**\n",
        "\n",
        "**未知で複雑な劣化を持つ低解像度画像の復元**を目的とした**盲超解像の試み**は数多くなされているが、\n",
        "\n",
        "一般的な**実世界の劣化画像への対応**にはまだ程遠いのが実情である。\n",
        "\n",
        "本研究では，**強力なESRGANを拡張**し，純粋な合成データを用いて学習させた**Real-ESRGAN**を**実用的な復元応用に適用**する．\n",
        "\n",
        "具体的には、**実世界の複雑な劣化**をよりよく模擬的再現するために、**高次の劣化模型（計算式／計算方法）を作成処理を導入**する。\n",
        "\n",
        "また、**合成処理**において、一般的な**波形の歪み**と**行き過ぎ**の構造を考慮する。\n",
        "\n",
        "さらに、**識別能力を高め**、**学習力学**を**安定化**させるために、**分光正規化**を伴う**U-Net識別器**を採用しています。\n",
        "\n",
        "様々な実データを用いた**広範な比較**により、先行研究よりも優れた**視覚的性能**を示すことができた。\n",
        "\n",
        "また、**学習組を急いで合成**するための効率的な実装を提供する。\n",
        "\n",
        "https://arxiv.org/abs/2107.10833\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **超解像の技術**\n",
        "- 超解像技術は、**単一枠超解像**と**複数枠超解像**に大別できます。\n",
        "\n",
        "- **単一枠超解像**は**周辺画素**などから**補完**を行い、**機械学習**や**データベース**を利用して**予測**することで、**1枚の低解像度画像**から**解像度を高める手法**です。\n",
        "\n",
        "- **複数枠超解像**は**互いに位置が異なる**複数枚の**低解像度画像**を**位置合わせ**して、**再構成する**ことで**解像度を高める技術**です。\n",
        "\n",
        "- 他には**時間の異なる**複数の画像を組み合わせたり、**異なる装置**から複数の画像を取得して、そこから**解像度を上げる技術**などもあります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U5Bu-qie_aH"
      },
      "source": [
        "# 1.**準備事項**\n",
        "開始する前に、選択されていることを確認してください。\n",
        "\n",
        "- Hardware Accelerator = GPU (プログラム実行時内容 -> プログラム実行時タイプの変更)\n",
        "\n",
        "そして、情報管理場所を複製し、環境を設定し、学習済みの計算式／計算方法をダウンロードします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SG9AcLQO_FQ",
        "outputId": "e56a7cb6-c84c-4935-e2eb-e7d45768ccf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'CodeFormer'...\n",
            "remote: Enumerating objects: 395, done.\u001b[K\n",
            "remote: Total 395 (delta 0), reused 0 (delta 0), pack-reused 395\u001b[K\n",
            "Receiving objects: 100% (395/395), 12.59 MiB | 14.58 MiB/s, done.\n",
            "Resolving deltas: 100% (160/160), done.\n",
            "/content/CodeFormer\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (0.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (0.18.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
            "Collecting tb-nightly\n",
            "  Downloading tb_nightly-2.12.0a20221220-py3-none-any.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (0.14.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (4.64.1)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (4.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.1->-r requirements.txt (line 12)) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2022.10.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2.8.8)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->-r requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (1.51.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tb-nightly->-r requirements.txt (line 11)) (2.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 11)) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tb-nightly->-r requirements.txt (line 11)) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly->-r requirements.txt (line 11)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly->-r requirements.txt (line 11)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->-r requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown->-r requirements.txt (line 17)) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown->-r requirements.txt (line 17)) (3.8.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests->-r requirements.txt (line 8)) (1.7.1)\n",
            "Installing collected packages: yapf, tb-nightly, lpips, addict\n",
            "Successfully installed addict-2.4.0 lpips-0.1.4 tb-nightly-2.12.0a20221220 yapf-0.32.0\n",
            "running develop\n",
            "running egg_info\n",
            "creating basicsr.egg-info\n",
            "writing basicsr.egg-info/PKG-INFO\n",
            "writing dependency_links to basicsr.egg-info/dependency_links.txt\n",
            "writing requirements to basicsr.egg-info/requires.txt\n",
            "writing top-level names to basicsr.egg-info/top_level.txt\n",
            "writing manifest file 'basicsr.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'basicsr.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.8/dist-packages/basicsr.egg-link (link to .)\n",
            "Adding basicsr 1.3.2 to easy-install.pth file\n",
            "\n",
            "Installed /content/CodeFormer\n",
            "Processing dependencies for basicsr==1.3.2\n",
            "Searching for gdown==4.4.0\n",
            "Best match: gdown 4.4.0\n",
            "Adding gdown 4.4.0 to easy-install.pth file\n",
            "Installing gdown script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for lpips==0.1.4\n",
            "Best match: lpips 0.1.4\n",
            "Adding lpips 0.1.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for yapf==0.32.0\n",
            "Best match: yapf 0.32.0\n",
            "Adding yapf 0.32.0 to easy-install.pth file\n",
            "Installing yapf script to /usr/local/bin\n",
            "Installing yapf-diff script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for torchvision==0.14.0+cu116\n",
            "Best match: torchvision 0.14.0+cu116\n",
            "Adding torchvision 0.14.0+cu116 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for torch==1.13.0+cu116\n",
            "Best match: torch 1.13.0+cu116\n",
            "Adding torch 1.13.0+cu116 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tb-nightly==2.12.0a20221220\n",
            "Best match: tb-nightly 2.12.0a20221220\n",
            "Adding tb-nightly 2.12.0a20221220 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scikit-image==0.18.3\n",
            "Best match: scikit-image 0.18.3\n",
            "Adding scikit-image 0.18.3 to easy-install.pth file\n",
            "Installing skivi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for opencv-python==4.6.0.66\n",
            "Best match: opencv-python 4.6.0.66\n",
            "Adding opencv-python 4.6.0.66 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for lmdb==0.99\n",
            "Best match: lmdb 0.99\n",
            "Adding lmdb 0.99 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for addict==2.4.0\n",
            "Best match: addict 2.4.0\n",
            "Adding addict 2.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for filelock==3.8.2\n",
            "Best match: filelock 3.8.2\n",
            "Adding filelock 3.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for beautifulsoup4==4.6.3\n",
            "Best match: beautifulsoup4 4.6.3\n",
            "Adding beautifulsoup4 4.6.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for typing-extensions==4.4.0\n",
            "Best match: typing-extensions 4.4.0\n",
            "Adding typing-extensions 4.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for grpcio==1.51.1\n",
            "Best match: grpcio 1.51.1\n",
            "Adding grpcio 1.51.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for google-auth==2.15.0\n",
            "Best match: google-auth 2.15.0\n",
            "Adding google-auth 2.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for wheel==0.38.4\n",
            "Best match: wheel 0.38.4\n",
            "Adding wheel 0.38.4 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for protobuf==3.19.6\n",
            "Best match: protobuf 3.19.6\n",
            "Adding protobuf 3.19.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for absl-py==1.3.0\n",
            "Best match: absl-py 1.3.0\n",
            "Adding absl-py 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Markdown==3.4.1\n",
            "Best match: Markdown 3.4.1\n",
            "Adding Markdown 3.4.1 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for imageio==2.9.0\n",
            "Best match: imageio 2.9.0\n",
            "Adding imageio 2.9.0 to easy-install.pth file\n",
            "Installing imageio_download_bin script to /usr/local/bin\n",
            "Installing imageio_remove_bin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for PyWavelets==1.4.1\n",
            "Best match: PyWavelets 1.4.1\n",
            "Adding PyWavelets 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for networkx==2.8.8\n",
            "Best match: networkx 2.8.8\n",
            "Adding networkx 2.8.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tifffile==2022.10.10\n",
            "Best match: tifffile 2022.10.10\n",
            "Adding tifffile 2022.10.10 to easy-install.pth file\n",
            "Installing lsm2bin script to /usr/local/bin\n",
            "Installing tiff2fsspec script to /usr/local/bin\n",
            "Installing tiffcomment script to /usr/local/bin\n",
            "Installing tifffile script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for certifi==2022.12.7\n",
            "Best match: certifi 2022.12.7\n",
            "Adding certifi 2022.12.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for PySocks==1.7.1\n",
            "Best match: PySocks 1.7.1\n",
            "Adding PySocks 1.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for cachetools==5.2.0\n",
            "Best match: cachetools 5.2.0\n",
            "Adding cachetools 5.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for rsa==4.9\n",
            "Best match: rsa 4.9\n",
            "Adding rsa 4.9 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for importlib-metadata==5.1.0\n",
            "Best match: importlib-metadata 5.1.0\n",
            "Adding importlib-metadata 5.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for kiwisolver==1.4.4\n",
            "Best match: kiwisolver 1.4.4\n",
            "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for zipp==3.11.0\n",
            "Best match: zipp 3.11.0\n",
            "Adding zipp 3.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for oauthlib==3.2.2\n",
            "Best match: oauthlib 3.2.2\n",
            "Adding oauthlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Finished processing dependencies for basicsr==1.3.2\n",
            "Downloading: \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/detection_Resnet50_Final.pth\" to /content/CodeFormer/weights/facelib/detection_Resnet50_Final.pth\n",
            "\n",
            "100% 104M/104M [00:00<00:00, 333MB/s] \n",
            "Downloading: \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/parsing_parsenet.pth\" to /content/CodeFormer/weights/facelib/parsing_parsenet.pth\n",
            "\n",
            "100% 81.4M/81.4M [00:06<00:00, 13.4MB/s]\n",
            "Downloading: \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth\" to /content/CodeFormer/weights/CodeFormer/codeformer.pth\n",
            "\n",
            "100% 359M/359M [00:01<00:00, 277MB/s]\n"
          ]
        }
      ],
      "source": [
        "#CodeFormerを複製し、CodeFormerフォルダに入る\n",
        "%cd /content\n",
        "!rm -rf CodeFormer\n",
        "!git clone https://github.com/sczhou/CodeFormer.git\n",
        "%cd CodeFormer\n",
        "\n",
        "# 環境設定\n",
        "# Pythonの依存関係をソフトウェアの準備する\n",
        "!pip install -r requirements.txt\n",
        "# basicsrのソフトウェアの準備\n",
        "!python basicsr/setup.py develop\n",
        "\n",
        "# 学習済み計算式／計算方法のダウンロード\n",
        "!python scripts/download_pretrained_models.py facelib\n",
        "!python scripts/download_pretrained_models.py CodeFormer\n",
        "\n",
        "#可視化機能\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1) \n",
        "  plt.title('Input', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('CodeFormer', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzLAguVdix6_"
      },
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "# **2.自分の画像でテストする 😀。**\n",
        "- 古い写真\n",
        "- DALLE2/Midjourney/安定した拡散によりAIが作成した顔画像\n",
        "もしCodeFormerがあなたの写真に役立つなら、私たちのレポにスターを付けてください。ありがとうございます。🤗\n",
        "\n",
        "If CodeFormer is helpful to your photos, please help star our [repo](https://github.com/sczhou/CodeFormer). Thanks! 🤗 \n",
        "\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/sczhou/CodeFormer?style=social)](https://github.com/sczhou/CodeFormer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 43
        },
        "id": "DK3esrSmiziX",
        "outputId": "3d61e44c-0928-49ed-cf0e-89012315aca1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a15f6217-af42-4288-b4ef-a80dd09300dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a15f6217-af42-4288-b4ef-a80dd09300dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 画像のアップロード\n",
        "import os #OSに依存しているさまざまな機能を利用するためのモジュール\n",
        "from google.colab import files #PCからGoogle Colabへのファイルのアップロード\n",
        "import shutil　#ディレクトリとファイルの操作\n",
        "\n",
        "upload_folder = 'inputs/user_upload' #ファイル場所の指定\n",
        "\n",
        "if os.path.isdir(upload_folder):#ファイルの存在確認  →　ファイルが存在していれば\n",
        "    shutil.rmtree(upload_folder)#フォルダを中のファイルやサブディレクトリごとすべて削除する\n",
        "os.mkdir(upload_folder)#フォルダを作成する →つまり初期化\n",
        "\n",
        "uploaded = files.upload()#ファイルをアップロードする\n",
        "for filename in uploaded.keys():#実行すると, ファイル選択が表示されるので, アップロードしたいファイルを選択すればよい.\n",
        "  dst_path = os.path.join(upload_folder, filename)#フォルダとファイルをパス結合する\n",
        "  print(f'{filename} を {dst_path}へ移動する')#ファイルをパス結合した場所に移動\n",
        "  shutil.move(filename, dst_path)#ファイル・フォルダを移動する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj2YQGg3J0TQ",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "# アップロードされた画像の推論\n",
        "#@markdown  品質（低い数値）と忠実度（高い数値）の均衡<br>\n",
        "# bg_upsampler realesrgan'を追加すると、背景を強調することができます。\n",
        "CODEFORMER_FIDELITY = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown `BACKGROUND_ENHANCE: Real-ESRGANで背景画像を強調する<br>\n",
        "BACKGROUND_ENHANCE = True #@param {type:\"boolean\"}\n",
        "#@markdown `FACE_UPSAMPLE  AIで作成した高解像度画像に対して復元した顔画像のサンプル数を水増しする<br>\n",
        "FACE_UPSAMPLE = False #@param {type:\"boolean\"}\n",
        "if BACKGROUND_ENHANCE:#背景_強化するなら\n",
        "  if FACE_UPSAMPLE:#顔画像のサンプル数を水増しするのなら\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan --face_upsample\n",
        "  else:#推論のための符号生成は、\"顔画像\"と \"Usersrgan(Real-ESRGAN)\"で行います。\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan\n",
        "else:\n",
        "  !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4hauJLwIQQV"
      },
      "outputs": [],
      "source": [
        "# 成果の可視化\n",
        "import os\n",
        "import glob#(かたまりの意)#特定のパターンにマッチするファイルを取得する\n",
        "#入力フォルダ\n",
        "input_folder = 'inputs/user_upload'\n",
        "#結果出力フォルダ\n",
        "result_folder = f'results/user_upload_{CODEFORMER_FIDELITY}/final_results'\n",
        "#入力フォルダのファイルを昇順に並べ替えinput_list変数に格納\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "print(f\"入力リスト{input_list}\")\n",
        "for input_path in input_list:#入力リストから入力ファイル場所を取り出す\n",
        "　print(\"*\"*30)\n",
        "　print(f\"入力ファイル場所={input_path}\")\n",
        "  img_input = imread(input_path)#入力場所の画像ファイルを読み込みimg_input変数に格納\n",
        "  #os.path.basename(input_path)  パスから入力ファイル名を取得する\n",
        "  print(\"*\"*30)\n",
        "  print(f\"入力ファイル名={os.path.basename(input_path)}\")\n",
        "　#入力ファイル名から拡張子を取得する\n",
        "  basename = os.path.splitext(os.path.basename(input_path))[0]\n",
        "  print(\"*\"*30)\n",
        "  print(f\"入力ファイル名の拡張子={os.path.splitext(os.path.basename(input_path))}\")\n",
        "  print(\"*\"*30)\n",
        "  print(f\"basename(パス名からディレクトリ部分を除いたファイル名)={basename}\")\n",
        "  #結果出力フォルダとパス名からディレクトリ部分を除いたファイル名を結合し[.png]形式に変換する\n",
        "  output_path = os.path.join(result_folder, basename+'.png')\n",
        "  print(\"*\"*30)\n",
        "  print(f\"結果出力フォルダ={result_folder}\")\n",
        "　print(\"*\"*30)\n",
        "  print(f\"出力場所={output_path}\") \n",
        "  img_output = imread(output_path)#出力場所の画像ファイルを読み込みimg_output変数に格納\n",
        "  display(img_input, img_output)#読み込んだ入力場所の画像ファイルと出力場所の画像ファイルをdisplay関数で埋め込み表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RRKl1iDMpVJ"
      },
      "outputs": [],
      "source": [
        "#ダウンロード結果\n",
        "!ls results　#結果のファイル一覧を表示する\n",
        "print('結果のダウンロード')\n",
        "#unixコマンドをpython上で記述する（ZIPファイルを全展開する）\n",
        "os.system(f'zip -r results.zip results/user_upload_{CODEFORMER_FIDELITY}/final_results')\n",
        "files.download(\"results.zip\")#出力結果ファイルをダウンロードする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72f3GJtIFZtf"
      },
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "## 3. 3.デモ画像（全体画像）に対する推論"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6CkQ2x-eSjH"
      },
      "outputs": [],
      "source": [
        "# 画像全体に対してwを0.7に設定しました\n",
        "# bg_upsampler realesrgan'を追加すると、背景を強調することができます。\n",
        "CODEFORMER_FIDELITY = 0.7 #CODEFORMER_忠実度=wを0.7　　低画質記号化から解読器へ流す情報を重みwで調整する\n",
        "print(f\"画像全体に対して重みw(CODEFORMER_忠実度)を{CODEFORMER_FIDELITY}に設定しました\")\n",
        "!python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/whole_imgs --bg_upsampler realesrgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG2mlYMjF8mQ"
      },
      "outputs": [],
      "source": [
        "# 成果の可視化\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/whole_imgs'#入力フォルダ\n",
        "print(\"*\"*30)\n",
        "print(f\"入力フォルダ={input_folder}\") \n",
        "result_folder = f'results/whole_imgs_{w}/final_results'#結果フォルダ\n",
        "print(\"*\"*30)\n",
        "print(f\"結果フォルダ={result_folder}\") \n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))#入力ファイルリスト\n",
        "print(\"*\"*30)\n",
        "print(f\"入力ファイルリスト={input_list}\")  \n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))#結果ファイルリスト\n",
        "print(\"*\"*30)\n",
        "print(f\"結果ファイルリスト={output_list}\")  \n",
        "#入力ファイルと結果ファイルからそれぞれの場所を取得する\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  print(\"*\"*30)\n",
        "  print(f\"入力ファイル場所(input_path)={input_path}\")  \n",
        "  print(\"*\"*30)\n",
        "  print(f\"結果ファイル場所(output_path)={output_path}\")  \n",
        "  img_input = imread(input_path)#入力ファイル場所から入力ファイルを読み込む\n",
        "  img_output = imread(output_path)#出力ファイル場所から出力ファイルを読み込む\n",
        "  display(img_input, img_output)#読み込んだ入力ファイルと出力ファイルを埋め込み表示する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrUil37TjFGR"
      },
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "# 4.デモ顔（切り抜き顔、整列顔）の推論"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJy16AUOjLkO",
        "outputId": "b4c24829-ded4-4ef4-dd36-42b737543747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file 'inference_codeformer.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -rf results\n",
        "\n",
        "#切り出した顔と並べた顔でwを0.5に設定しました CODEFORMER_忠実度=wを0.7　\n",
        "CODEFORMER_FIDELITY = 0.5#低画質記号化から解読器へ流す情報を重みwで調整する\n",
        "print(f\"切り出した顔と並べた顔で重みwを{CODEFORMER_FIDELITY}に設定しました\")\n",
        "!python inference_codeformer.py -w $CODEFORMER_FIDELITY --has_aligned --input_path inputs/cropped_faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1E9DHUt_k_I"
      },
      "outputs": [],
      "source": [
        "# 成果の可視化\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/cropped_faces'\n",
        "result_folder = f'results/cropped_faces_{w}/restored_faces'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAVowOigwBzZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}